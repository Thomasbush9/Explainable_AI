{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4_UELxj6ejp"
      },
      "source": [
        "# [0.5] - VAEs & GANs (exercises)\n",
        "\n",
        "> **ARENA [Streamlit Page](https://arena-chapter0-fundamentals.streamlit.app/05_[0.5]_VAEs_&_GANs)**\n",
        ">\n",
        "> **Colab: [exercises](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_exercises.ipynb?t=20250316) | [solutions](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_solutions.ipynb?t=20250316)**\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-2zick19fl-6GY1yoGaoUozyM3wObwmnQ), and ask any questions on the dedicated channels for this chapter of material.\n",
        "\n",
        "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n",
        "\n",
        "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etfnZtdU6ejq"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/headers/header-05.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqLChVQP6ejr"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqYP4egj6ejr"
      },
      "source": [
        "Today, we're studying two important classes of generative image models: **Generative Adversarial Networks (GANs)** and **Variational Autoencoders (VAEs)**. Although these generally aren't SOTA any more (thanks in part to the rise of diffusion models), there are some deep conceptual insights which can be gleaned from studying these models (VAEs in particular) which help lay the groundwork for more advanced models.\n",
        "\n",
        "These exercises will also hopefully bring much of this chapter full-circle:\n",
        "\n",
        "* We'll cover transposed convolutions, which will serve as a refresher on some of the ideas behind convolutions **(day 2: CNNs & ResNets)**\n",
        "* We'll be assembling NNet architectures from scratch, like in the ResNets exercises **(day 2: CNNs & ResNets)**\n",
        "* We'll work with different loss functions, and think intuitively about what it means to optimize them **(day 3: Optimization & Hyperparameters)**\n",
        "* We'll be working with `wandb`, and will learn how to log outputs produced by our models **(day 3: Optimization & Hyperparameters)**\n",
        "* We'll have to think carefully about how gradient propagation works between different parts of our model **(day 4: Backpropagation)**\n",
        "\n",
        "Note, many of today's exercises (especially those involving building models & writing forward pass functions) don't have as rigorous unit tests as previous days of content. Part of this is because the design spec for these models is less strict (we're not copying over weights from a pretrained model like last time, all that matters is that our model actually trains correctly, and so small changes to the solution architecture can sometimes be allowed). However, another part is that we're trying to move participants away from being too reliant on unit tests, and towards being able to independently reason through exercises or replications given just a description of the task or a paper implementation to follow. This is an invaluable skill to develop for any aspiring ML practitioner!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzIX6cVj6ejr"
      },
      "source": [
        "## Content & Learning Objectives\n",
        "\n",
        "### 1️⃣ Autoencoders & VAEs\n",
        "\n",
        "Autoencoders are a relatively simple architecture, at least compared to GANs: you learn a compressed representation of your data (mainly using linear layers and convolutions), then reconstruct it back into an image (with linear layers and transposed convolutions).\n",
        "\n",
        "Although autoencoders can learn some interesting low-dimensional representations, they are less good for generating images because their latent spaces aren't generally meaningful. This leads to VAEs, which solve this problem by having their encoders map to a distribution over latent vectors, rather than a single latent vector. This incentivises the latent space to be more meaningful, and we can more easily generate images from sample vectors in this space.\n",
        "\n",
        "We start with some reading material on autoencoders and transposed convolutions (which are often used in parallel with convolutions, to take a latent space and map it back into a full-size image). Then, we actually implement and train VAEs to generate MNIST images, as well as a do a bit of exploring our our autoencoders' latent spaces.\n",
        "\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about the transposed convolution operation\n",
        "> - Understand the basic architecture of autoencoders and VAEs\n",
        "> - Learn about the reparameterization trick for VAEs\n",
        "> - Implement your own autoencoder\n",
        "> - Implement your own VAE, and use it to generate realistic MNIST images\n",
        "> - (optional) Dive deeper into the mathematical underpinnings of VAEs, and learn about the ELBO loss function\n",
        "\n",
        "\n",
        "### 2️⃣ GANs\n",
        "\n",
        "Relative to autoencoders, GANs have a few more moving pieces in their architecture. They're best thought of as two separate networks (the generator and the discriminator) which are learning different goals simultaneously. The goal of the generator is to create images which fool the discriminator, and the goal of the discriminator is to distinguish between real and fake images. The ideal equilibrium point of training is when the generator produces perfect images and the discriminator can't tell the difference between real and fake - however, that's much simpler said than done! GANs are notoriously difficult to train, and we'll have to engage with some of these difficulties during our exercises.\n",
        "\n",
        "By the end of these exercises, you should have built and trained your own GANs, to generate celebrity pictures. By the time you're done, you'll hopefully have produced output like this (below), and you'll have everything you need to set up a competitor to Midjourney (plus or minus a few other foundational ML papers and an investment of a few hundred million dollars).\n",
        "                \n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan-last-output.png\" width=\"1100\">\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand the loss function used in GANs, and why it can be expected to result in the generator producing realistic outputs.\n",
        "> - Implement the DCGAN architecture from the paper, with relatively minimal guidance.\n",
        "> - Learn how to identify and fix bugs in your GAN architecture, to improve convergence properties.\n",
        "\n",
        "\n",
        "### 3️⃣ Bonus - Transposed Convolutions\n",
        "\n",
        "In this section, you'll implement the transposed convolution operation manually. This is similar to a regular convolution, but designed for upsampling rather than downsampling (i.e. producing an image from a latent vector rather producing output from an image). These are very important in many generative algorithms. Once you implement this, you'll be able to build your own GANs and VAEs from scratch, without using any pre-built layers.\n",
        "\n",
        "*Note - the bonus section from the CNNs day is a prerequisite for these bonus exercises. If you haven't completed that section, you'll need to do so before attempting these.*\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about & implement the transposed convolution operation.\n",
        "> - Implement GANs and/or VAEs entirely from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fd8_6de6ejr"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW8KFYcG6ejr",
        "outputId": "b36557c9-ec03-40e5-98d9-2fc0248d1d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.3.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping)\n",
            "  Downloading wadler_lindig-0.1.4-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading jaxtyping-0.3.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.4-py3-none-any.whl (20 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, wadler-lindig, torchinfo, fsspec, dill, multiprocess, jaxtyping, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 jaxtyping-0.3.0 multiprocess-0.70.16 torchinfo-1.8.0 wadler-lindig-0.1.4 xxhash-3.5.0\n",
            "--2025-03-30 15:51:50--  https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main [following]\n",
            "--2025-03-30 15:51:51--  https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.113.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.113.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/content/main.zip’\n",
            "\n",
            "main.zip                [         <=>        ]  21.08M  9.40MB/s    in 2.2s    \n",
            "\n",
            "2025-03-30 15:51:53 (9.40 MB/s) - ‘/content/main.zip’ saved [22107639]\n",
            "\n",
            "Archive:  /content/main.zip\n",
            "24d2f21d9e998f8f0112ea89ab8230eae0d28f62\n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/\n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/0.0_Prerequisites_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/0.0_Prerequisites_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/numbers.npy  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/pikachu.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/pikachu.stl  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/test_with_pytest.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/imagenet_labels.json  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/astronaut.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/chimpanzee.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/dragonfly.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/fireworks.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/frogs.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/golden_retriever.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/goofy.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/hourglass.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/iguana.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/platypus.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/volcano.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/0.3_Optimization_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/0.3_Optimization_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/0.4_Backprop_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/0.4_Backprop_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/utils.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/plotly_utils.py  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "repo = \"ARENA_3.0\"\n",
        "branch = \"main\"\n",
        "\n",
        "# Install dependencies\n",
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    %pip install torchinfo jaxtyping einops datasets\n",
        "\n",
        "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n",
        "root = (\n",
        "    \"/content\"\n",
        "    if IN_COLAB\n",
        "    else \"/root\"\n",
        "    if repo not in os.getcwd()\n",
        "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n",
        ")\n",
        "\n",
        "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n",
        "    if not IN_COLAB:\n",
        "        !sudo apt-get install unzip\n",
        "        %pip install jupyter ipython --upgrade\n",
        "\n",
        "    if not os.path.exists(f\"{root}/{chapter}\"):\n",
        "        !wget -P {root} https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/{branch}.zip\n",
        "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n",
        "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n",
        "        !rm {root}/{branch}.zip\n",
        "        !rmdir {root}/{repo}-{branch}\n",
        "\n",
        "\n",
        "if f\"{root}/{chapter}/exercises\" not in sys.path:\n",
        "    sys.path.append(f\"{root}/{chapter}/exercises\")\n",
        "\n",
        "os.chdir(f\"{root}/{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RS6F-Ml-6ejs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Literal\n",
        "\n",
        "import einops\n",
        "import torch as t\n",
        "import torchinfo\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from einops.layers.torch import Rearrange\n",
        "from jaxtyping import Float, Int\n",
        "from torch import Tensor, nn\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "section = \"part5_vaes_and_gans\"\n",
        "root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
        "exercises_dir = root_dir / chapter / \"exercises\"\n",
        "section_dir = exercises_dir / section\n",
        "if str(exercises_dir) not in sys.path:\n",
        "    sys.path.append(str(exercises_dir))\n",
        "\n",
        "\n",
        "import part5_vaes_and_gans.tests as tests\n",
        "import part5_vaes_and_gans.utils as utils\n",
        "from part2_cnns.utils import print_param_count\n",
        "from plotly_utils import imshow\n",
        "\n",
        "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_IzX4SU6ejs"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get a NumPy-related error</summary>\n",
        "\n",
        "This is an annoying colab-related issue which I haven't been able to find a satisfying fix for. If you restart runtime (but don't delete runtime), and run just the imports cell above again (but not the `%pip install` cell), the problem should go away.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paRsknWR6ejs"
      },
      "source": [
        "# 1️⃣ Autoencoders & VAEs\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about the transposed convolution operation\n",
        "> - Understand the basic architecture of autoencoders and VAEs\n",
        "> - Learn about the reparameterization trick for VAEs\n",
        "> - Implement your own autoencoder\n",
        "> - Implement your own VAE, and use it to generate realistic MNIST images\n",
        "> - (optional) Dive deeper into the mathematical underpinnings of VAEs, and learn about the ELBO loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c-5S6EF6ejs"
      },
      "source": [
        "## Reading\n",
        "\n",
        "**Note** - before you start the reading, you might want to run the first block of code in the \"Loading data\" section, because it can take a few minutes to run.\n",
        "\n",
        "* [Understanding VAEs (Medium)](https://medium.com/towards-data-science/understanding-variational-autoencoders-vaes-f70510919f73)\n",
        "    * A clear and accessible explanation of autoencoders and VAEs.\n",
        "    * You can stop at \"Mathematical details of VAEs\"; we'll (optionally) cover this in more detail later.\n",
        "* [Six (and a half) intuitions for KL divergence](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence)\n",
        "    * Optional reading.\n",
        "    * KL divergence is an important concept in VAEs (and will continue to be a useful concept for the rest of this course).\n",
        "* [From Autoencoder to Beta-VAE](https://lilianweng.github.io/posts/2018-08-12-vae/)\n",
        "    * Optional reading.\n",
        "    * This is a more in-depth look at VAEs, the maths behind them, and different architecture variants.\n",
        "* [Transposed Convolutions explained with… MS Excel!](https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8) (optional)\n",
        "    * Optional reading.\n",
        "    * The first part (up to the highlighted comment) is most valuable, since understanding transposed convolutions at a high level is more important than understanding the exact low-level operations that go into them (that's what the bonus is for!).\n",
        "    * [These visualisations](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md) may also help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq2dTJrD6ejs"
      },
      "source": [
        "## Loading data\n",
        "\n",
        "In these exercises, we'll be using either the Celeb-A dataset or the MNIST dataset. For convenience, we'll include a few functions here to load that data in.\n",
        "\n",
        "You should already be familiar with MNIST. You can read about the Celeb-A dataset [here](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) - essentially it's a large-scale face attributes dataset with more than 200k celebrity images, but we'll only be taking the images from this dataset rather the classifications. Run the code below to download the data from HuggingFace, and save it in your filesystem as images.\n",
        "\n",
        "The code should take 4-15 minutes to run in total, but feel free to move on if it's taking longer (you'll mostly be using MNIST in this section, and only using Celeb-A when you move on to GANs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "39FQLsYb6ejs",
        "outputId": "7f2ce5ec-4266-4ae0-828f-8e130c383117"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'section_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9b20a7ce260b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mceleb_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msection_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"data/celeba\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mceleb_image_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mceleb_data_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"img_align_celeba\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceleb_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'section_dir' is not defined"
          ]
        }
      ],
      "source": [
        "celeb_data_dir = section_dir / \"data/celeba\"\n",
        "celeb_image_dir = celeb_data_dir / \"img_align_celeba\"\n",
        "\n",
        "os.makedirs(celeb_image_dir, exist_ok=True)\n",
        "\n",
        "if len(list(celeb_image_dir.glob(\"*.jpg\"))) > 0:\n",
        "    print(\"Dataset already loaded.\")\n",
        "else:\n",
        "    dataset = load_dataset(\"nielsr/CelebA-faces\")\n",
        "    print(\"Dataset loaded.\")\n",
        "\n",
        "    for idx, item in tqdm(enumerate(dataset[\"train\"]), total=len(dataset[\"train\"]), desc=\"Saving imgs...\", ascii=True):\n",
        "        # The image is already a JpegImageFile, so we can directly save it\n",
        "        item[\"image\"].save(celeb_image_dir / f\"{idx:06}.jpg\")\n",
        "\n",
        "    print(\"All images have been saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSl6Nbmh6ejt"
      },
      "source": [
        "<details>\n",
        "<summary>Note on why we double-nest our saving paths, i.e. <code>celeba/img_align_celeba</code></summary>\n",
        "\n",
        "In the code above, each image is saved in the format `'data/celeba/img_align_celeba/000001.jpg'`, etc. The reason for this double nesting (rather than e.g. `data/celeba/000001.jpg`) is that the child folders represent the image classes. If we were training a classifier, we'd have multiple folders within `data/celeba`, with each one being a different class. In this dataset, we only have one class (real celeb images), so we only need one child folder.\n",
        "\n",
        "</details>\n",
        "\n",
        "Now, here's some code to load in either the Celeb-A or MNIST data. It also applies transformations to the data, to get it into the right input format for us.\n",
        "\n",
        "The function below allows you to load in either the Celeb-A or MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gAl8Hdap6ejt"
      },
      "outputs": [],
      "source": [
        "def get_dataset(dataset: Literal[\"MNIST\", \"CELEB\"], train: bool = True) -> Dataset:\n",
        "    assert dataset in [\"MNIST\", \"CELEB\"]\n",
        "\n",
        "    if dataset == \"CELEB\":\n",
        "        image_size = 64\n",
        "        assert train, \"CelebA dataset only has a training set\"\n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(image_size),\n",
        "                transforms.CenterCrop(image_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ]\n",
        "        )\n",
        "        trainset = datasets.ImageFolder(root=exercises_dir / \"part5_vaes_and_gans/data/celeba\", transform=transform)\n",
        "\n",
        "    elif dataset == \"MNIST\":\n",
        "        img_size = 28\n",
        "        transform = transforms.Compose(\n",
        "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "        )\n",
        "        trainset = datasets.MNIST(\n",
        "            root=exercises_dir / \"part5_vaes_and_gans/data\",\n",
        "            transform=transform,\n",
        "            download=True,\n",
        "        )\n",
        "\n",
        "    return trainset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJrHIUpp6ejt"
      },
      "source": [
        "We've also given you some code for visualising your data. You should run this code to make sure your data is correctly loaded in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CWvzRKC6ejt",
        "outputId": "ee3b1e26-d102-4b69-d5c8-5239d3fee8b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 41.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.15MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.4MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.44MB/s]\n"
          ]
        }
      ],
      "source": [
        "def display_data(x: Tensor, nrows: int, title: str):\n",
        "    \"\"\"Displays a batch of data, using plotly.\"\"\"\n",
        "    ncols = x.shape[0] // nrows\n",
        "    # Reshape into the right shape for plotting (make it 2D if image is monochrome)\n",
        "    y = einops.rearrange(x, \"(b1 b2) c h w -> (b1 h) (b2 w) c\", b1=nrows).squeeze()\n",
        "    # Normalize in the 0-1 range, then map to integer type\n",
        "    y = (y - y.min()) / (y.max() - y.min())\n",
        "    y = (y * 255).to(dtype=t.uint8)\n",
        "    # Display data\n",
        "    imshow(\n",
        "        y,\n",
        "        binary_string=(y.ndim == 2),\n",
        "        height=50 * (nrows + 4),\n",
        "        width=50 * (ncols + 5),\n",
        "        title=f\"{title}<br>single input shape = {x[0].shape}\",\n",
        "    )\n",
        "\n",
        "\n",
        "trainset_mnist = get_dataset(\"MNIST\")\n",
        "#trainset_celeb = get_dataset(\"CELEB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "E9-Mq-MM6ejt",
        "outputId": "e27ca3c7-b6f9-4568-d84e-3613fbb1996b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"87cd7dc1-70ea-409b-abd0-cf255046cc71\" class=\"plotly-graph-div\" style=\"height:450px; width:500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"87cd7dc1-70ea-409b-abd0-cf255046cc71\")) {                    Plotly.newPlot(                        \"87cd7dc1-70ea-409b-abd0-cf255046cc71\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAAIwAAACMCAAAAACLqx7iAAARE0lEQVR4Xu2ceXBVZZrGH4Y7F0MlVAhJkYJKKsqSIQOSDEIYJRlMgYooKTGhRVIaoS0iFovtgNCAwyoiOCAgq4ALiwEbZRHUJgE1tCBLCB2WsIQGErJQQBbCZXLe973zx13Pd74TFMu2uyq\\u002fv873PLn3vvc73\\u002fp+5wZopplfj17reX2SKv5qtIyIiJj+9ucdNrldb6oekHiDiK6rajBplfGq5GUqu1NVrQliO7+wegszM1\\u002f6jOu+76\\u002f66HOF6WYV9XUGpJRnAtcA8MYum2Cybxmcoor2JN1gL0bW0KHJljcN6XeRmH7MIJ4SEKd\\u002fErgG0GJVkeV1Ht40tMEkLytinjBsWbKiR5xjZuYDu121iuPhEyJiouw83hwQz5uD6Sgfm8p+BlwzTsS2UlUMqyTOKyLiT1Un\\u002fYMxzEdbI2G16gBArxvM+a9xWc90d9ArS83B7JFpprKPfmWG8YIqwtG3jvIfdYTuJn5d9RDWYjU\\u002fr4peEm8Q7QwdPDkK4Hp\\u002fh3qwwRzMAVHr28Ma5jxVA7KJ9oQBWUSXolQPwALOb6FqAICuG7nqeIbnmmmjT35DTMG0r5CY4LKPSDaq01QRc5iWhAE4TZSuegDQOp8fUzUAcO6gmsfbdfQUmL736evlDd8lAHwiZ8KDy17ijrIxXRUxnV1fhACthjTwTNXz0Kn20oevWiunL1FgkDAFE\\u002fjCYZk7XDLCXwwix+Cv2qhieCV9AaDzIaLc1qrp5Zka5knRqnqA8wMFNxf4LtdLJoCeSa8vXl5bX72zlnQdO73G+La9KiKKKDZqUkEtk\\u002fG06vnp8Q3zcu8N8fHUbRofKDEt810u5+uFhYUsjTUHFo3o6KhqDPyVnzhmXq+KQHgFMRFdvkIVqhVEeBbxn81SJl31V5ZzHn8T6ncmbd++ffv2kZ4+9LKc9xsBVhiGoauw5GoueSchej8tUh0Td\\u002fhOf5OQSaW+S+dsuvR4sBdErsxXJSDxgmF8pooBUtw8VtUCPDhrD3OhuQ1n0nveq8SN9CeTFUyu9FUloNowCgI1aeFxJt0YAwCIX1bOzI27zWomX\\u002fJcvHaDbcZ7wCYYNozhqhaMbTDRr11gZj40RNEz6c6SxJjMHZe4dLN+iAUA5LqtQ\\u002f56N3OsKgZhVzPt004yMx94xjLOZBJR+WkiKpilWsHkSrYqJZaxa6F1ggzwijaYiK3nmJm\\u002fTw9RHaDjD0RMVOVrOTbkyipV6m+wrocF6OFmSzDJn11mZr41Vz8YRs8gpne7qLJCrvvnB4OzZLnxbzNz8bw54ar+s8i21kz0t3cLJpvyElTtNyPsK9qivx2\\u002fBWFL6R+nappp5u\\u002fDe+4TTc0yv5C8oLVkgNDoUVOCNrB+4q4z2a1kuibkuJmZeZvmlY5U\\u002fzLVnkUuy4AJ3L\\u002fiOBEtUWUArT+3CyZhwcXLxEREROvCVBeRElgn2vG2qy5T1eJX3iK+eIK0uYTFdsHsIM\\u002fOl4iIHlFdRIokqprKfvKsdB1+pc07vwsDzj3W6nRkVIlf9RHeU1V8\\u002fPlJVK9r4cZ\\u002f\\u002fpfqeLGsSfykTBt+A8Dwf7\\u002fw34qTTURUEoMuRP0UC0CHC0xTtS3YERMTDQBhl4k+szaaSNGtAD2c4X4AUOz2plb+xe9kAn\\u002fbOvAK\\u002fs2vBHN1PTBTu8WhK1cqAeCJtkCZbreCXqrg47b7PgCJsXKf6nSY8XAUAIzS1gzARK+qWhDP5RGRtf0i\\u002fKbY7UZmG8VRQOvNVBBoLAprbYJxM9sHM6LYRURHNOtE7LALJqbSlQpgFV32KeaYxrVu4e6Bv\\u002fxgEr2IW1U8xGUNBPq5gbo3drtUswl6bItc+h3w+ouYq1oAQnrvZHYzl3VSHQC2t6lHqa9rb1ctDzu0+SxHNrv54BRn9KHGdaoHOPpcofqyLXVEFROtfQJNBMPM7GZmHqR6AIAdUqNKALKIuITooHaz7RxCNO0RRBwnIhqmi8bNvEXVACD2jw917969+yIifTATdMEMM1wVjybmETEZV9Q74ZhHtCscUYfZNfNPRF+lJVmyz0zU1AqxjV0wz0qDdXzKvzASQEIBMZF6F1u+TbWvtEXvg3TmUYQ98UktBTb7Pt4nosWqGCDTLph0ud1V1TA+BgBSblJmQoI6HuRQ3XMRg7bcoumerNzwXbss26SxumAcg729eWSdXTA4JctVyUObZXxW1QBUUMPRM0Q0taXqBHGW2a3c3pQ9FAMAEVk3ieofNZs+Ftfa7HAnU4U5L+UZZyqjWvXE7m+3\\u002f41NppmTD0AUaWl3TKoHMPA\\u002f3Ni\\u002fYp\\u002fi+nBrJwnEvuxeXa6KAEKzFk1ur+tCwQwiYqVmjpMXvrrK5usDi2WoKgEAztKHqvTTiT1hCSZpLRERlRQu6WE2grnq0q2PgCmkD\\u002fKecY6ups9GN72U+7TI2rWbaaaZe6NrqTd5+w\\u002fA0mr6QtXuSsLEc5sm6ldWv4D2BUzH26mqlqAd1ugFoQAwQLsH1xE67P96hY3YXw6gcvsR1fXSdeGTLSYf0U5bLTY\\u002f2U03OQFARKWIiNzQnsbpeEcCUNGU+1UfANCXiG0y9iFlMkrV\\u002fOTckosi8q6qm4iNn1ld7TlBOi8i1Xl5eXnL846KyGDlLwEAXUuZtWeQAJAvU1QpQKEUicgDqhzEgOU3hZlPAwA6DerUyTsthV4UaxoYAGbTTuUsLYhntRsHLxnHRES6qbKfDw6JSO3ykdbVwvMirt6qCODA7fOWJWOAGHE1McdGF4nIVlX10m61XDv8bLxmCnauvC1iWcEDSGeaZ18xiHHL6OCyaUc54sHuAOwyTdNHLZ16SxUBIC0rG43jT6kyEJ4C3CgHMD4GatIDAOCG3UASf6pRxK7NhMwsHZJuvT0A0McQEdcgzeY9dJ+bk4HXJpQyuzU1FCNidyr4jEtERESXRcNbvFkfCrDQ87Ifp1lWe08Rl3ZB4jaiulP8g\\u002fX+NhEMxt0WsWszblEP6Pw8\\u002fGW1JxxaaD48Ch1LZbPQdSNXbUhK5VOaYNz2wWDQ8OFZNfpgDvHlgarmJzZp0BoWEdlnSpkNIpqO9juoZpmz++ka\\u002f3F4gKZqBgBazJBzlq+Q7ETEDK617\\u002fMARhwUEZkYLE0iAgqIUtGXaGGw4yVGJFXVgnGKnFKaWvTR6iwgkvlhs67g2C8ipodv5vE2JJbzeHQt5aBnBgLEiJg+S+0Dc4C1yuRV2GbSBmAC9v7VrCvQ0VTAnCZ1uwFx97x838WUWpPRNO22e57jia6xdu3JDSJSIqW6UQ2Inp7puWi5V6QxJdjqS9Q3p4aIq2x24TEiajoEADbI6dTO6DX8mMgCSxd+fWNVVfWueO0+PLpI2gAA2s8XkSKT16vOk6zWtV0Atg24b4FI6a5aET75844MPxVJDAFC3qwVcdcpzXFwHhOtHW\\u002fbSJ3F2mCwMMczVlxTjbvwexE5mp9\\u002fVESkLk1178Zh2aFKAADnxIkbRW7qG4Y992\\u002fyfAmRxneSVfOurBHTstI+sf8TcQ5NK0nHGeSXFKrW3Ynb\\u002fNFKVWummWb+WXggt1Gf1vsNeLjuwqK2qvhLyNpworHxO8+caEfrw+VxqgZgsGuR7lDsnon8gq\\u002fv2lUvmu2Ilw49e8a+KKc1z+R1afjqXof5P0z+mPmkqh65Ni8CiK+j6aoDAD1Wf\\u002f11KfPcz917ramPVvsPqicVASJyrnDwQ+nBpI7ZYhARNSo1MND74PgssZy1AMA4Zr79URmzZKkWsMCl2TB56fsDExFZH0SN3n\\u002f5ci3xj0REpGS9BpV4EgkPSoXmW85o4HXzo5BYxVWWdRmcFXtUyU\\u002fkCapcOWgznVa3lQNKiYgovl38oxeJlDdo5W2A8SI5ZgcAFkhpNNB5i9x6RbWAaYFHzi0U0G4AXarr1acJviGihld7A1hOdD5Scb04inXJm+Ri\\u002fqh1hx18bYLqAPj+K1UJsJdGA+hSXa7cyMfqiEofAQDsINJ8oodCXTDONVyWXsrah2lTjG4A+uuPE\\u002fM4s1XCgvwT6rb4a6Lv0gCg7fM13isNztMyQ9UAvMvMwqtjVB3AyiInsq+La4xqAEAlHTxElKHKePZovidtM5moyDaBEy+SDESmTTUP7uOYWXZaDyIBNGbAWZoROuz2E6oD4GQDMdXpaw0AnnaRS9MMAQDOTiNFjq8tvCS1HwbrLbeKyM5gxU+CpCN5BYCl36oWACRncFMHYEz0sqoBIbFD5x8+XCwiYpSWvvmQOa+5lZlZv8pPk24IbQcggVULANCDSVuhAIC33MyW+TVk\\u002fikRkZqyRpHVlo7a4Y\\u002fChz\\u002fgg6oOAEgT7\\u002fwQpg9muJttg3HuYRpjmUi+FtfOJWn9OuKMnLfOPVksk0OzeJ2qAwAGuL0veLrGpPtI57w4VfMS8jLxJ+GqCrdnl+2Yf6vSUi\\u002fof5OfahV3jrWTlr9mHF8uVRwAQLedlda+5CH0U6JxlnoB5JgDQKud4uqvWsBc2QfHq9Wib\\u002fXR5TkA4PjgpG4YbXOJ\\u002fqBqProRmTMaXs7Iuu2zsk\\u002fSD9Z6AeZwviOTr5nyMkGMuZ0TlvRiSZF2slxFG1TJR\\u002fwa0qTdAGC2686dO1t1IwWwinP3Mz+tyn7G3GaumaXOhACAAQ31ton8jUT6um6S8cxybea9rOTirjfYnmsn7KTlll59d9pOrN83QRV\\u002fCiHLKFfV\\u002fMynC\\u002fcQy73zChdobx4AIE3\\u002fa7Bfiz5lM7WNuplm\\u002fqnYVNpkJrCrd82no\\u002f\\u002fP+6XzT6BAzpqT9KHRwSPoeJqm5vB9ZB81+Oh4O7cpJsvbqgQAiLkjYh6+59CEoFIKUeegYhDZeYbBhqGdwGIXN8omVfQTepVdI1URAHqIbDMvFOZQTdCAl6EPJrx\\u002f6S3DOHFSH8zI2iMvTbcuEr04JjJf0i28HRtEvEcPPuYQ3XjIVwg9QKTZiqd\\u002fabBhGC9k64JxTnbNDUcS242pKXZPoS4RSzAjiehLXzYniXTBZHmfbH0xW\\u002feLu9E8FsAbFaruJe4Y8ze6if33DdZgWk4jIt9TCR3Oam5T1jWj\\u002fnyVYdQP1dVMRHWuA4g9bxfMCeabujPFl1xyxBIM2pwhKvSmVpLIGkw6G8ZeZBvGWGiCcZwujgDwvSxQDB\\u002fCPFeRQh8ZueK6yNhO1mCwlogSATjHjv3OGkx2DdfvTUD2kbEOhBZYgnmOUwE8b9S1Vwwv\\u002f+vmb9RcSbczIjdXdXHEaYIZRUQ5ePj1GUREVKzkny4YPBlA5\\u002fYAkG8JZs8pBxBdZfn2Xt4vl8IoVYSze\\u002fdYAHFi\\u002ffUlNjCzt40ys3lISKwO3oHtszRgmQqEFfD7mjwSgD7lrEvqeGl3VbapGpKIiPw\\u002fOVkTbHW\\u002fYBiBkvU2pUkPPH5RzrYxyz5WipzsoIoBCmRcoGAe28+7v6z5H5MCLDF9eIZlXrt2JzcssrHF+3WqAQAYP8qNgVdVNRhrH0wiouojw71XpprJN4wJ\\u002fkJ8tXFObacvfLt5yOU8tYl6iCnmxvdVMZgCTlUlhK3bv8KTQEoiokvB+ez8oP8wEV\\u002fCFWoCDkCL9+70VjUAQOdTzPNV0UeXPn16dMi4kBEV+\\u002fEQ1fOSREQU\\u002fOX3MXsbcOg25nO6+ac\\u002fz1IlD4OZ2ZOcU3F2e\\u002feWiOuaiFTdlHc8omU9UFMZDbw1mvzC7Nxw7HNvL5nU4l+Tb8\\u002f9XLcD3nTV+24qbYH92qx6+8W\\u002fA1DhPlkEAPjY7AZILiei4MPt1GsGG4ZhsLHXf79MPNRo13cvMmeoGgBggojs7G+pCSu9K4P\\u002fKQWAjjPZMAyj\\u002fFN97211rNTmYD6hmqdr0hoA4or2vKRqep4\\u002fNlt59xeLjRMv6G8+kMNq7tTHSBdPUrVfmVOFttV9qVqXRvk1qbyH5EUzP4\\u002f\\u002fB0a7nGAMXcCjAAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"MNIST data\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":450,\"width\":500},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('87cd7dc1-70ea-409b-abd0-cf255046cc71');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Display MNIST\n",
        "x = next(iter(DataLoader(trainset_mnist, batch_size=25)))[0]\n",
        "display_data(x, nrows=5, title=\"MNIST data\")\n",
        "\n",
        "# Display CelebA\n",
        "# x = next(iter(DataLoader(trainset_celeb, batch_size=25)))[0]\n",
        "# display_data(x, nrows=5, title=\"CelebA data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R17t8jDX6ejt"
      },
      "source": [
        "### Holdout data\n",
        "\n",
        "Lastly, we'll also get some **holdout data** that we can use during training. The tensor below has shape `(10, 1, 28, 28)`, and contains a single image from each of the 10 MNIST classes. We do this because we want to monitor our autoencoder's reconstructions for each different image type while it trains. We might find that some images are reconstructed better than others!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "C2wapBtK6ejt",
        "outputId": "77aaf0aa-7beb-45be-94c2-1cb4d3e3c56a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b736baa4-9157-4793-b8dc-00a1917f37e3\" class=\"plotly-graph-div\" style=\"height:250px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b736baa4-9157-4793-b8dc-00a1917f37e3\")) {                    Plotly.newPlot(                        \"b736baa4-9157-4793-b8dc-00a1917f37e3\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAAcCAAAAACfA\\u002f\\u002fyAAAHg0lEQVR4Xu2Ye0xUVwLGPyPBaMAglkA0EDdVzBKpENdCtmqUNHWND2JbTFtJl7Qx9RFfa1RspVGLoqvGrhpbtcq2rmvBRwVcUbegVkirrgEb62PVMSA+wFR5qBjn++7sHzMwc89cqGu2yW7X319zft\\u002fMZOa7Z845d4BnPOP\\u002fgnhXjameAWBDA\\u002feb7mdlSL7yk035X0d0hVjd27Q\\u002fJ0l3Sf5oWj8fyDPCdACAsJh3F4WaEkB8wlSPJGmfU+oj7fZAU6FrZGRkzsqv+vzV0\\u002fqhmcUXU\\u002fNHmfaJ6XH6Rj\\u002fT\\u002fQQvXhfv1TO1oy+Rdd+t4aYE8KtPqkmuNzUSVl+rpUiS3B7erodPDHgOgIUH7MXE9X97S6EkqWaPmk+MtIUAUkm9acono8\\u002fgwXG\\u002fty6Emb5Tug+7RvHU69QiM\\u002fLxodupmIGf3qeufc\\u002fg615Msq0YvtSuc3YEPAfosvms7ZXJd+XDnfnqqylB7xrvktJNGcAfsr+QfjAtkLjl8GGXtPwrz9fBP8OUjWelOZM2ppgBgB3eb5FVpl1m5OXlO+7v47oZsuen90hejBtADjMizCRv5i7PzS2zF3PFXkxf6wvbOPKyJKnyYGuTzbfxEUv6mq6dEdML3ST5+LyZYJakh5\\u002fXSVamGWHSbarsLKkvzQQYclcqn6u6wekehxTAsDq3+21TIoskL8XCqZiQ2NgYAAivJff4f58uezGl1mLbGOmfTZfO9EDCFrv3UvnwygDTeYk5VlvbRJ0iSQbt5kseaPuqKCTVq968uCGpzSwfFRJ2kJpnRN51tyRsbHYUoBbHjWmrVGY64G\\u002fklV1xwHiHYtrIaCE\\u002fbh+98MBeTKVlzt\\u002fwLlv0luHaSBfznCfMyy6S5MDeA0ddI0vNeLXligH6F1r3p5lRFlkaDmSSNVFmFr9T9dWvex+LO+0hAOA5uRvSTAn0WfLbKAB4t+Ni3igj6V97F1q2YqJvWbGBYwDAapV3MR0AIGKNOB8AZq9ZY0RHSD6YMRTAJvLKc0aKlHP6vEefYt2ZYya54vpwABfIoLUrtJiNo3v7roR4wp4CQL8zcueYMoBtHRUz+VwryX90bxf51sKAGDusixGBYwBAj3K9YjoAQNhRj1KAuXNcksc2c15pJl3ehayYXBsYAQBCt6ou3SXNNIMcte7vDnSb8EBLzQyppP+A4ljMVLcO9TSlj1nZi7JP8Zuupu+3+Pjx4yJ5d0rAd8i3\\u002fBMvPKO41Zrsz9p5vqnmzzMcJs04yjUASfvI5vP6Ni4gOUx+kwYAvd5q9D2ys1aSpS3m9Iy4zf0A+p8kC3oYGVCpcv\\u002fAowr\\u002fwEd6o\\u002ft4tCkBAN2Hlkgeqe55M0l0kd7tuihQ51sZAAYnz\\u002ft4U1NLQ0kTgzZkAJjYKC2IMW3YTNYtQ\\u002fxO1f8leYTOBxbz2ply79OzybNBL4R3V7JK4k0dRcZFLahoEt3jzQzjHnK2fyRu9A+89JOUb0oACHnxOlvqCpvJW\\u002fPNc2GiS5I8kjQmQG\\u002fSj1VVVbIeN1aum9w3pP5xQBZA4hFpk7nMjiFzEF3Mxo2hgy40Bn1MABjfytag5RVA192WZZWYFoi4RZGsvc5bZgRk8GZ7x6F5OhJ0MvzE7XY7XdjQCeTilxBZTZKTzGbi3v\\u002fNoEGDBq0jA4vBgqKioqKid7x70RTrSmAWQEQm9XfDLSCBCnIEUklz9fUicorpAGC3JBWbFkBKgy79MSHmGNeZCZBBV9vD0I9YMzowA4Ckq273HlMCCMkjD0Qg6rRal+4lD6UlO230PY1ibBRYq0zVziM9Gmk3edqHpBuajXiXAuZ4ACs8ksMl7PO+pdOf6TvTtzPcE7wsAxn8k+9R0k7utUUAgAa3uyJoFgFdV7JpWi8M\\u002fY4XRyH8dzua6C84gIzOi0k1lZcXlpVKVcb6m8e9SLrO7bUNJ\\u002fs6fCAgtFSc7rBoZ8rKDsvUdtO3M1oMOsMAGfIdFOfelf187kVut9Nd21Q2vxE5pvA+c7xL\\u002fZsHDvgPpSFjfTv0O81PUczAjTckPT5o6FQydWojqXrnd+w+hdoRYVpg5D2N69bvsjo5cDgXw0frk2Izimvk2mUeQwHke6TADaCNW3xw5iLJD4I2amB4KWMBIDLzHtnS8Z8EBZ7g2wzEzL0qSScnmMGQZu9NqfO6i7AvyVkO8wXLraMImdFgOa3KXjqYMSRvXCBZscyMACTVqXWNeX8BAFUkWTyvf4gZAKgmN6xYsWLFaZFfv2amfgqsLFNFp\\u002f0gSZUTHb7i2DKR22Y7\\u002fyuEX5OXTAcAyFV5SIbuON58eZnmWEzfb0mR9W0rjZ2RbjnvHGGZ67Kjza3IRzV96OZmp1LbKLA220Xk7suSdCLdf1Z+UgZupe1o42ezCo5JwecUP4keORSDmCUU13Zw19phMZ2RvI0kealqfaIZ2Sjw2IpJ2VMrSfeXBx9Cf5qdZAe\\u002fldmSdWdpp1X\\u002fkw6LSOfEHH+KYhD6XgP3vOd0BLWRZZ8xKyWdy8uNCHRPSkIJNzns1ADQa37L0TmmtJPFsgTT\\u002fUJYxasd9PIkhB9i4dNM0\\u002f8B0oL\\u002fNfh3CN\\u002fAX+qU+Q\\u002fyL63HCVafPD22AAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"MNIST holdout data\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":250,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b736baa4-9157-4793-b8dc-00a1917f37e3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "testset = get_dataset(\"MNIST\", train=False)\n",
        "HOLDOUT_DATA = dict()\n",
        "for data, target in DataLoader(testset, batch_size=1):\n",
        "    if target.item() not in HOLDOUT_DATA:\n",
        "        HOLDOUT_DATA[target.item()] = data.squeeze()\n",
        "        if len(HOLDOUT_DATA) == 10:\n",
        "            break\n",
        "HOLDOUT_DATA = t.stack([HOLDOUT_DATA[i] for i in range(10)]).to(dtype=t.float, device=device).unsqueeze(1)\n",
        "\n",
        "display_data(HOLDOUT_DATA, nrows=1, title=\"MNIST holdout data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uSRF54F6ejt"
      },
      "source": [
        "You might be wondering why we do this, rather than just e.g. generating some random noise and seeing what the decoder's reconstruction is. The answer is that **our autoencoder's latent space might not be meaningful**. In other words, it's unclear exactly how to sample from it to get output which will look like an MNIST image. We'll return to this idea when we study VAEs later in these exercises.\n",
        "\n",
        "*For the rest of this section (not including the bonus), we'll assume we're working with the MNIST dataset rather than Celeb-A.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO-lEUuo6ejt"
      },
      "source": [
        "## Transposed Convolutions\n",
        "\n",
        "**What are transposed convolutions, and why should we care about them?** One high-level intuition goes something like this: most of the generator's architecture is basically the discriminator architecture in reverse. We need something that performs the reverse of a convolution - not literally the inverse operation, but something reverse in spirit, which uses a kernel of weights to project up to some array of larger size.\n",
        "\n",
        "**Importantly, a transposed convolution isn't literally the inverse of a convolution**. A lot of confusion can come from misunderstanding this!\n",
        "\n",
        "You can describe the difference between convolutions and transposed convolutions as follows:\n",
        "\n",
        "* In convolutions, you slide the kernel around inside the input. At each position of the kernel, you take a sumproduct between the kernel and that section of the input to calculate a single element in the output.\n",
        "* In transposed convolutions, you slide the kernel around what will eventually be your output, and at each position you add some multiple of the kernel to your output.\n",
        "\n",
        "Below is an illustration of both for comparison, in the 1D case (where $*$ stands for the 1D convolution operator, and $*^T$ stands for the transposed convolution operator). Note the difference in size between the output in both cases. With standard convolutions, our output is smaller than our input, because we're having to fit the kernel inside the input in order to produce the output. But in our transposed convolutions, the output is actually larger than the input, because we're fitting the kernel inside the output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-1.png\" width=\"700\">\n",
        "\n",
        "We won't actually have you implement the transposed convolution operation in these exercises; instead we've pushed it to the bonus section. For now, you can just use the `ConvTranspose2d` module which has already been imported for you from today's solutions file, in place of your own implementation. You can use it exactly the same way you use normal convolutional layers: for instance `ConvTranspose2d(32, 16, 4, stride=2, padding=1)` will define a convolution layer that maps a tensor from `(batch_size, in_channels=32, height, width)` up to shape `(batch_size, out_channels=16, height * 2, width * 2)`.\n",
        "\n",
        "[These visualisations](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md) (linked in the reading material) may also help build intuition for the transposed convolution module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUP1vgul6ejt"
      },
      "source": [
        "## Autoencoders\n",
        "\n",
        "We'll start by looking at **Autoencoders**, which are much conceptually simpler than VAEs. These are simply systems which learn a compressed representation of the input, and then reconstruct it. There are two parts to this:\n",
        "\n",
        "* The **encoder** learns to compress the output into a latent space which is lower-dimensional than the original image.\n",
        "* The **decoder** learns to uncompress the encoder's output back into a faithful representation of the original image.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/ae-diagram-l.png\" width=\"700\">\n",
        "                \n",
        "Our loss function is simply some metric of the distance between the input and the reconstructed input, e.g. the $l_2$ loss.\n",
        "\n",
        "You'll start by writing your own autoencoder. We've given some guidance on architecture below, although in general because we're working with a fairly simple dataset (MNIST) and a fairly robust architecture (at least compared to GANs in the next section!), you model is still likely to work well even if it deviates slightly from the specification we'll give below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XqOy_wz6ejt"
      },
      "source": [
        "### Exercise - implement autoencoder\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 15-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "*Note - for the rest of this section (not including the bonus), we'll assume we're working with the MNIST dataset rather than Celeb-A.*\n",
        "\n",
        "Your encoder should consist of two convolutional blocks (i.e. convolution plus ReLU), followed by two fully connected linear layers with a ReLU in between them. Both convolutions will have kernel size 4, stride 2, padding 1 (recall this halves the size of the image). We'll have 16 and 32 output channels respectively.\n",
        "\n",
        "The decoder will be the exact mirror image of the encoder (with convolutions replaced by transposed convolutions).\n",
        "\n",
        "The only free parameters in your implementation will be `latent_dim_size` and `hidden_dim_size`. The former determines the size of the latent space (otherwise called the bottleneck dimension) between the encoder and decoder, and the latter determines the size of the final linear layer we insert just before the end / just after the start of the encoder / decoder's architecture respectively.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/ae-help-10.png\" width=\"1100\">\n",
        "\n",
        "A few extra notes:\n",
        "\n",
        "* You'll need to reshape between the convolutional blocks and linear layers. For this, you might find the `einops` library helpful - they have a function `einops.layers.torch.Rearrange` (imported for you as `Rearrange`) which works like the standard einops function, except that it takes a string and returns a module which performs the corresponding rearrangement. Just like any other module, it can be used inside things like `Sequential` (this way, the logic inside the `forward` method can be very simple!).\n",
        "\n",
        "```python\n",
        ">>> x = t.randn(100, 3, 4, 5)\n",
        ">>> x.shape\n",
        "torch.Size([100, 3, 4, 5])\n",
        "\n",
        ">>> module = Rearrange(\"b c h w -> b (c h w)\")\n",
        ">>> module(x).shape\n",
        "torch.Size([100, 60])\n",
        "```\n",
        "\n",
        "* Note that we don't include a ReLU in the very last layer of the decoder or generator, we only include them ***between successive convolutions or linear layers*** - can you see why it wouldn't make sense to put ReLUs at the end?\n",
        "* The convolutions don't have biases, although we have included biases in the linear layers (this will be important if you want your parameter count to match the solution, but not really that important for good performance).\n",
        "\n",
        "Now, implement your autoencoder below. We recommend you define `encoder` and `decoder` to help make your code run with the functions we've written for you later.\n",
        "\n",
        "<!-- You can test your answer by comparing the architecture to the solution directly. As this course goes on, we won't always include test functions as the exercises get a bit more open-ended and solutions to them are likely to vary more; it's also good practice to find ways to test your answers when you don't have access to black-box tests that you can trust!\n",
        "\n",
        "from part5_vaes_and_gans.solutions import Autoencoder as SolutionAutoencoder\n",
        "\n",
        "soln_Autoencoder = SolutionAutoencoder(latent_dim_size=5, hidden_dim_size=128)\n",
        "my_Autoencoder = Autoencoder(latent_dim_size=5, hidden_dim_size=128)\n",
        "\n",
        "print_param_count(my_Autoencoder, soln_Autoencoder)\n",
        "# print_param_count(my_Autoencoder, soln_Autoencoder, filename=str(section_dir / \"0503.html\"))\n",
        "\n",
        "<iframe src=\"https://info-arena.github.io/ARENA_img/misc/media-05/0503.html\" width=\"920\" height=\"470\"></iframe> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM5-QkRe6eju",
        "outputId": "dacabcdb-2858-4478-de03-d6ba2dadb225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([1, 5])\n",
            "All tests in `test_autoencoder` passed!\n"
          ]
        }
      ],
      "source": [
        "# Importing all modules you'll need, from previous solutions (you're encouraged to substitute your own implementations instead, if you want to!)\n",
        "from part2_cnns.solutions import BatchNorm2d, Conv2d, Linear, ReLU, Sequential\n",
        "\n",
        "from part5_vaes_and_gans.solutions import ConvTranspose2d\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim_size: int, hidden_dim_size: int):\n",
        "        \"\"\"Creates the encoder & decoder modules.\"\"\"\n",
        "        super().__init__()\n",
        "        self.latent = latent_dim_size\n",
        "        self.hidden = 5\n",
        "        c2l = Rearrange('b c h w -> b (c h w)')\n",
        "        l2c = Rearrange('b (c h w)-> b c h w', c = 32, h=7, w=7)\n",
        "        self.encoder = Sequential(\n",
        "            #convolutional block\n",
        "            Conv2d(in_channels=1, out_channels=16,kernel_size=4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            BatchNorm2d(num_features=16),\n",
        "            Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            BatchNorm2d(num_features=32),\n",
        "            c2l,\n",
        "            Linear(in_features=32*7*7, out_features=self.latent),\n",
        "            ReLU(),\n",
        "            Linear(in_features=self.latent, out_features=self.hidden)\n",
        "\n",
        "        )\n",
        "        self.decoder = Sequential(\n",
        "            Linear(self.hidden, self.latent),\n",
        "            ReLU(),\n",
        "            Linear(self.latent, 32*7*7),\n",
        "            ReLU(),\n",
        "            l2c,\n",
        "            ConvTranspose2d(32, 16, 4, 2, 1),\n",
        "            BatchNorm2d(16),\n",
        "            ReLU(),\n",
        "            ConvTranspose2d(16, 1, 4, 2, 1)\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Returns the reconstruction of the input, after mapping through encoder & decoder.\"\"\"\n",
        "        print(self.hidden)\n",
        "        z = self.encoder(x)\n",
        "        print(z.shape)\n",
        "        x_prime = self.decoder(z)\n",
        "        return x_prime\n",
        "\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_autoencoder(Autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uaj-eZQP6eju"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim_size: int, hidden_dim_size: int):\n",
        "        \"\"\"Creates the encoder & decoder modules.\"\"\"\n",
        "        super().__init__()\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.hidden_dim_size = hidden_dim_size\n",
        "        self.encoder = Sequential(\n",
        "            Conv2d(1, 16, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            Conv2d(16, 32, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            Rearrange(\"b c h w -> b (c h w)\"),\n",
        "            Linear(7 * 7 * 32, hidden_dim_size),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim_size, latent_dim_size),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            Linear(latent_dim_size, hidden_dim_size),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim_size, 7 * 7 * 32),\n",
        "            ReLU(),\n",
        "            Rearrange(\"b (c h w) -> b c h w\", c=32, h=7, w=7),\n",
        "            ConvTranspose2d(32, 16, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            ConvTranspose2d(16, 1, 4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Returns the reconstruction of the input, after mapping through encoder & decoder.\"\"\"\n",
        "        z = self.encoder(x)\n",
        "        x_prime = self.decoder(z)\n",
        "        return x_prime\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRRoq3fq6eju"
      },
      "source": [
        "## Training your Autoencoder\n",
        "\n",
        "Once you've got the architecture right, you should write a training loop which works with [MSE loss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html) between the original and reconstructed data. The standard Adam optimiser with default parameters should suffice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HKTm8Ac6eju"
      },
      "source": [
        "### Logging images to `wandb`\n",
        "\n",
        "Weights and biases provides a nice feature allowing you to log images! This requires you to use the function `wandb.Image`. The first argument is `data_or_path`, which can be any of the following:\n",
        "\n",
        "* A numpy array in shape `(height, width)` or `(height, width, 1)` -> interpreted as monochrome image\n",
        "* A numpy array in shape `(height, width, 3)` -> interpreted as RGB image\n",
        "* A PIL image (can be RGB or monochrome)\n",
        "\n",
        "When it comes to logging, you can log a list of images rather than a single image. Example code, and the output it produces from my GAN (you'll create output like this in the next section!):\n",
        "\n",
        "```python\n",
        "# arr is a numpy array of shape (8, 28, 28, 3), i.e. it's an array of 8 RGB images\n",
        "images = [wandb.Image(a) for a in arr]\n",
        "wandb.log({\"images\": images}, step=self.step)\n",
        "```\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/gan_output_2.png\" width=\"750\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jrt_AOC6eju"
      },
      "source": [
        "### Exercise - write autoencoder training loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 20-35 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should now implement your training loop below. We've filled in some methods for you (and have given you a dataclass to hold arguments), your job is to complete `training_step` and `train`. The former should perform a single training step by optimizing against the reconstruction loss between the image and target (you might find `nn.MSELoss` suitable for this). The latter should be structured like training code you might have seen before, in other words:\n",
        "\n",
        "- Iterate over `self.args.epochs` epochs\n",
        "- For each epoch, you should:\n",
        "    - Iterate over the training data and perform a training step for each batch. We also recommend using & updating a progress bar, and logging to wandb if this is enabled in your training arguments.\n",
        "    - Evaluate the model on the holdout data via `self.log_samples()`, every `args.log_every_n_steps` total steps.\n",
        "\n",
        "Some last tips before we get started:\n",
        "\n",
        "- Don't use wandb until you've ironed out the bugs in your code, and loss seems to be going down based on the in-notebook logging. This is why we've given you the `use_wandb` argument in your dataclass.\n",
        "- Remember to increment `self.step` as you train (this is necessary if you're passing this argument to `wandb.log`). Note we're using `step` here rather than `examples_seen` like in earlier exercises, because it'll prove more useful for our purposes.\n",
        "- Your wandb logging should take place in `training_step` not `train` (this is better practice in general because often there will be variables only defined in the scope of `training_step` that you might want to log - even though that's not the case here, it will be later).\n",
        "- Iterating through `self.trainloader` will give you tuples of `(img, label)`, but you don't need to use the labels - all you need is the image.\n",
        "\n",
        "If you find yourself disconnecting from runtime when you run the training code, then visit https://wandb.ai/authorize and get a `<LOGIN-KEY>` to use in this code: `wandb.login(key=<LOGIN-KEY>)`. If this fails (i.e. you're still getting disconnected), then we recommend either using VSCode instead or some other IDE, or just setting `wandb=False` and displaying / saving your logged output inline. You can take `imshow` and turn it into saved output via code like `imshow(..., return_fig=True).write_html(\"filename.html\")`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RlFjNOrA6eju",
        "outputId": "2be0f87f-e99c-4514-be64-0e4a35e8425a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mt-w-bush\u001b[0m (\u001b[33mt-w-bush-tilburg-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/chapter0_fundamentals/exercises/wandb/run-20250330_160036-y887zknf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder/runs/y887zknf' target=\"_blank\">eager-spaceship-1</a></strong> to <a href='https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder' target=\"_blank\">https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder/runs/y887zknf' target=\"_blank\">https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder/runs/y887zknf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=1.4832, step=01024:   2%|1         | 2/118 [00:00<00:14,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=1.3023, step=02048:   3%|3         | 4/118 [00:00<00:13,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=1.1829, step=03072:   5%|5         | 6/118 [00:00<00:13,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=1.0790, step=04096:   7%|6         | 8/118 [00:01<00:14,  7.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=1.0006, step=05120:   8%|8         | 10/118 [00:01<00:13,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.9308, step=06144:  10%|#         | 12/118 [00:01<00:13,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.8967, step=07168:  12%|#1        | 14/118 [00:01<00:13,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.8701, step=08192:  14%|#3        | 16/118 [00:02<00:12,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.8420, step=09216:  15%|#5        | 18/118 [00:02<00:12,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.8197, step=10240:  17%|#6        | 20/118 [00:02<00:11,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7857, step=11264:  19%|#8        | 22/118 [00:02<00:11,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7647, step=12288:  20%|##        | 24/118 [00:02<00:11,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7806, step=13312:  22%|##2       | 26/118 [00:03<00:10,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7468, step=14336:  24%|##3       | 28/118 [00:03<00:10,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7350, step=15360:  25%|##5       | 30/118 [00:03<00:10,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7314, step=16384:  27%|##7       | 32/118 [00:03<00:10,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7252, step=17408:  29%|##8       | 34/118 [00:04<00:09,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7225, step=18432:  31%|###       | 36/118 [00:04<00:09,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7245, step=19456:  32%|###2      | 38/118 [00:04<00:09,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7092, step=20480:  34%|###3      | 40/118 [00:04<00:09,  8.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7094, step=21504:  36%|###5      | 42/118 [00:05<00:09,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7253, step=22528:  37%|###7      | 44/118 [00:05<00:08,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7143, step=23552:  39%|###8      | 46/118 [00:05<00:08,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.7066, step=24576:  41%|####      | 48/118 [00:05<00:08,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6948, step=25600:  42%|####2     | 50/118 [00:06<00:08,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6928, step=26624:  44%|####4     | 52/118 [00:06<00:08,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6910, step=27648:  46%|####5     | 54/118 [00:06<00:07,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6861, step=28672:  47%|####7     | 56/118 [00:06<00:07,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6846, step=29696:  49%|####9     | 58/118 [00:07<00:07,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6877, step=30720:  51%|#####     | 60/118 [00:07<00:07,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6811, step=31744:  53%|#####2    | 62/118 [00:07<00:06,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6928, step=32768:  54%|#####4    | 64/118 [00:07<00:06,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6672, step=33792:  56%|#####5    | 66/118 [00:08<00:06,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6597, step=34816:  58%|#####7    | 68/118 [00:08<00:06,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6794, step=35840:  59%|#####9    | 70/118 [00:08<00:05,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6557, step=36864:  61%|######1   | 72/118 [00:08<00:05,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6509, step=37888:  63%|######2   | 74/118 [00:09<00:05,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6604, step=38912:  64%|######4   | 76/118 [00:09<00:05,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6520, step=39936:  66%|######6   | 78/118 [00:09<00:04,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6505, step=40960:  68%|######7   | 80/118 [00:09<00:04,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6866, step=41984:  69%|######9   | 82/118 [00:10<00:04,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6529, step=43008:  71%|#######1  | 84/118 [00:10<00:04,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6507, step=44032:  73%|#######2  | 86/118 [00:10<00:03,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6589, step=45056:  75%|#######4  | 88/118 [00:10<00:03,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6548, step=46080:  76%|#######6  | 90/118 [00:11<00:03,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6493, step=47104:  78%|#######7  | 92/118 [00:11<00:03,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6627, step=48128:  80%|#######9  | 94/118 [00:11<00:02,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6571, step=49152:  81%|########1 | 96/118 [00:11<00:02,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6420, step=50176:  83%|########3 | 98/118 [00:12<00:02,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6470, step=51200:  85%|########4 | 100/118 [00:12<00:02,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6290, step=52224:  86%|########6 | 102/118 [00:12<00:01,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6533, step=53248:  88%|########8 | 104/118 [00:12<00:01,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6387, step=54272:  90%|########9 | 106/118 [00:12<00:01,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6279, step=55296:  92%|#########1| 108/118 [00:13<00:01,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6302, step=56320:  93%|#########3| 110/118 [00:13<00:01,  7.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6265, step=57344:  95%|#########4| 112/118 [00:13<00:00,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6335, step=58368:  97%|#########6| 114/118 [00:13<00:00,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6202, step=59392:  98%|#########8| 116/118 [00:14<00:00,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.6124, step=60000: 100%|##########| 118/118 [00:14<00:00,  8.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6206, step=61024:   2%|1         | 2/118 [00:00<00:14,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6146, step=62048:   3%|3         | 4/118 [00:00<00:14,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6332, step=63072:   5%|5         | 6/118 [00:00<00:14,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6299, step=64096:   7%|6         | 8/118 [00:01<00:13,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6205, step=65120:   8%|8         | 10/118 [00:01<00:13,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6177, step=66144:  10%|#         | 12/118 [00:01<00:12,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6208, step=67168:  12%|#1        | 14/118 [00:01<00:12,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6216, step=68192:  14%|#3        | 16/118 [00:01<00:12,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6138, step=69216:  15%|#5        | 18/118 [00:02<00:12,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6129, step=70240:  17%|#6        | 20/118 [00:02<00:13,  7.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6181, step=71264:  19%|#8        | 22/118 [00:02<00:13,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6117, step=72288:  20%|##        | 24/118 [00:03<00:12,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6155, step=73312:  22%|##2       | 26/118 [00:03<00:11,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6218, step=74336:  24%|##3       | 28/118 [00:03<00:11,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6022, step=75360:  25%|##5       | 30/118 [00:03<00:10,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6098, step=76384:  27%|##7       | 32/118 [00:04<00:10,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5928, step=77408:  29%|##8       | 34/118 [00:04<00:10,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6284, step=78432:  31%|###       | 36/118 [00:04<00:10,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5938, step=79456:  32%|###2      | 38/118 [00:04<00:10,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6134, step=80480:  34%|###3      | 40/118 [00:05<00:09,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6173, step=81504:  36%|###5      | 42/118 [00:05<00:09,  7.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6121, step=82528:  37%|###7      | 44/118 [00:05<00:09,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5912, step=83552:  39%|###8      | 46/118 [00:05<00:08,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5971, step=84576:  41%|####      | 48/118 [00:06<00:08,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6008, step=85600:  42%|####2     | 50/118 [00:06<00:08,  7.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6017, step=86624:  44%|####4     | 52/118 [00:06<00:08,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6072, step=87648:  46%|####5     | 54/118 [00:06<00:07,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6006, step=88672:  47%|####7     | 56/118 [00:07<00:07,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5904, step=89696:  49%|####9     | 58/118 [00:07<00:07,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.6141, step=90720:  51%|#####     | 60/118 [00:07<00:07,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5910, step=91744:  53%|#####2    | 62/118 [00:07<00:06,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5979, step=92768:  54%|#####4    | 64/118 [00:07<00:06,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5898, step=93792:  56%|#####5    | 66/118 [00:08<00:06,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5906, step=94816:  58%|#####7    | 68/118 [00:08<00:06,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5885, step=95840:  59%|#####9    | 70/118 [00:08<00:06,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5931, step=96864:  61%|######1   | 72/118 [00:09<00:05,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5797, step=97888:  63%|######2   | 74/118 [00:09<00:05,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5925, step=98912:  64%|######4   | 76/118 [00:09<00:05,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5909, step=99936:  66%|######6   | 78/118 [00:09<00:04,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5979, step=100960:  68%|######7   | 80/118 [00:10<00:04,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5831, step=101984:  69%|######9   | 82/118 [00:10<00:04,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5806, step=103008:  71%|#######1  | 84/118 [00:10<00:04,  7.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5777, step=104032:  73%|#######2  | 86/118 [00:10<00:04,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5744, step=105056:  75%|#######4  | 88/118 [00:11<00:03,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5735, step=106080:  76%|#######6  | 90/118 [00:11<00:03,  7.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5780, step=107104:  78%|#######7  | 92/118 [00:11<00:03,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5686, step=108128:  80%|#######9  | 94/118 [00:11<00:03,  7.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5711, step=109152:  81%|########1 | 96/118 [00:12<00:02,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5741, step=110176:  83%|########3 | 98/118 [00:12<00:02,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5762, step=111200:  85%|########4 | 100/118 [00:12<00:02,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5693, step=112224:  86%|########6 | 102/118 [00:12<00:01,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5560, step=113248:  88%|########8 | 104/118 [00:13<00:01,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5511, step=114272:  90%|########9 | 106/118 [00:13<00:01,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5531, step=115296:  92%|#########1| 108/118 [00:13<00:01,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5659, step=116320:  93%|#########3| 110/118 [00:13<00:00,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5440, step=117344:  95%|#########4| 112/118 [00:14<00:00,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5566, step=118368:  97%|#########6| 114/118 [00:14<00:00,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5673, step=119392:  98%|#########8| 116/118 [00:14<00:00,  7.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=01, loss=0.5645, step=120000: 100%|##########| 118/118 [00:14<00:00,  7.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5751, step=120512:   1%|          | 1/118 [00:00<00:14,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5707, step=121024:   2%|1         | 2/118 [00:00<00:14,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5650, step=121536:   3%|2         | 3/118 [00:00<00:15,  7.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5558, step=122048:   3%|3         | 4/118 [00:00<00:14,  7.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5492, step=122560:   4%|4         | 5/118 [00:00<00:14,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5480, step=123072:   5%|5         | 6/118 [00:00<00:14,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5457, step=123584:   6%|5         | 7/118 [00:00<00:13,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5538, step=124096:   7%|6         | 8/118 [00:01<00:13,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5303, step=124608:   8%|7         | 9/118 [00:01<00:13,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5525, step=125120:   8%|8         | 10/118 [00:01<00:13,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5408, step=125632:   9%|9         | 11/118 [00:01<00:13,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5392, step=126144:  10%|#         | 12/118 [00:01<00:13,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5403, step=126656:  11%|#1        | 13/118 [00:01<00:13,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5445, step=127168:  12%|#1        | 14/118 [00:01<00:13,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5457, step=127680:  13%|#2        | 15/118 [00:01<00:12,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5427, step=128192:  14%|#3        | 16/118 [00:02<00:12,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5444, step=128704:  14%|#4        | 17/118 [00:02<00:12,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5429, step=129216:  15%|#5        | 18/118 [00:02<00:12,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5454, step=129728:  16%|#6        | 19/118 [00:02<00:12,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5460, step=130240:  17%|#6        | 20/118 [00:02<00:11,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5456, step=130752:  18%|#7        | 21/118 [00:02<00:11,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5444, step=131264:  19%|#8        | 22/118 [00:02<00:11,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5513, step=131776:  19%|#9        | 23/118 [00:02<00:11,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5417, step=132288:  20%|##        | 24/118 [00:02<00:11,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5435, step=132800:  21%|##1       | 25/118 [00:03<00:11,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5332, step=133312:  22%|##2       | 26/118 [00:03<00:11,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5384, step=133824:  23%|##2       | 27/118 [00:03<00:11,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5439, step=134336:  24%|##3       | 28/118 [00:03<00:11,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5430, step=134848:  25%|##4       | 29/118 [00:03<00:11,  7.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5344, step=135360:  25%|##5       | 30/118 [00:03<00:11,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5354, step=135872:  26%|##6       | 31/118 [00:03<00:10,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5373, step=136384:  27%|##7       | 32/118 [00:03<00:10,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5382, step=136896:  28%|##7       | 33/118 [00:04<00:10,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5240, step=137408:  29%|##8       | 34/118 [00:04<00:10,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5377, step=137920:  30%|##9       | 35/118 [00:04<00:10,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5372, step=138432:  31%|###       | 36/118 [00:04<00:10,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5275, step=138944:  31%|###1      | 37/118 [00:04<00:10,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5344, step=139456:  32%|###2      | 38/118 [00:04<00:10,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5381, step=139968:  33%|###3      | 39/118 [00:04<00:09,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5441, step=140480:  34%|###3      | 40/118 [00:05<00:09,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5195, step=140992:  35%|###4      | 41/118 [00:05<00:09,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5274, step=141504:  36%|###5      | 42/118 [00:05<00:09,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5313, step=142016:  36%|###6      | 43/118 [00:05<00:09,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5339, step=142528:  37%|###7      | 44/118 [00:05<00:09,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5262, step=143040:  38%|###8      | 45/118 [00:05<00:09,  7.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5420, step=143552:  39%|###8      | 46/118 [00:05<00:09,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5362, step=144064:  40%|###9      | 47/118 [00:05<00:09,  7.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5320, step=144576:  41%|####      | 48/118 [00:06<00:09,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5242, step=145088:  42%|####1     | 49/118 [00:06<00:08,  7.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5207, step=145600:  42%|####2     | 50/118 [00:06<00:08,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5230, step=146112:  43%|####3     | 51/118 [00:06<00:08,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5200, step=146624:  44%|####4     | 52/118 [00:06<00:08,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5175, step=147136:  45%|####4     | 53/118 [00:06<00:08,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5219, step=147648:  46%|####5     | 54/118 [00:06<00:07,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5160, step=148160:  47%|####6     | 55/118 [00:06<00:07,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5156, step=148672:  47%|####7     | 56/118 [00:07<00:07,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5335, step=149184:  48%|####8     | 57/118 [00:07<00:07,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5235, step=149696:  49%|####9     | 58/118 [00:07<00:07,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5189, step=150208:  50%|#####     | 59/118 [00:07<00:07,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5159, step=150720:  51%|#####     | 60/118 [00:07<00:07,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5172, step=151232:  52%|#####1    | 61/118 [00:07<00:07,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5296, step=151744:  53%|#####2    | 62/118 [00:07<00:07,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5366, step=152256:  53%|#####3    | 63/118 [00:07<00:06,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5263, step=152768:  54%|#####4    | 64/118 [00:08<00:06,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5246, step=153280:  55%|#####5    | 65/118 [00:08<00:06,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5177, step=153792:  56%|#####5    | 66/118 [00:08<00:06,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5273, step=154304:  57%|#####6    | 67/118 [00:08<00:06,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5321, step=154816:  58%|#####7    | 68/118 [00:08<00:06,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5392, step=155328:  58%|#####8    | 69/118 [00:08<00:05,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5254, step=155840:  59%|#####9    | 70/118 [00:08<00:05,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5215, step=156352:  60%|######    | 71/118 [00:08<00:05,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5325, step=156864:  61%|######1   | 72/118 [00:09<00:05,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5104, step=157376:  62%|######1   | 73/118 [00:09<00:05,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5273, step=157888:  63%|######2   | 74/118 [00:09<00:05,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5141, step=158400:  64%|######3   | 75/118 [00:09<00:05,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5048, step=158912:  64%|######4   | 76/118 [00:09<00:05,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5028, step=159424:  65%|######5   | 77/118 [00:09<00:05,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5088, step=159936:  66%|######6   | 78/118 [00:09<00:04,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5196, step=160448:  67%|######6   | 79/118 [00:09<00:04,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5090, step=160960:  68%|######7   | 80/118 [00:09<00:04,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5190, step=161472:  69%|######8   | 81/118 [00:10<00:04,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5099, step=161984:  69%|######9   | 82/118 [00:10<00:04,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5219, step=162496:  70%|#######   | 83/118 [00:10<00:04,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5206, step=163008:  71%|#######1  | 84/118 [00:10<00:04,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5239, step=163520:  72%|#######2  | 85/118 [00:10<00:04,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5159, step=164032:  73%|#######2  | 86/118 [00:10<00:03,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5156, step=164544:  74%|#######3  | 87/118 [00:10<00:03,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5158, step=165056:  75%|#######4  | 88/118 [00:10<00:03,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5132, step=165568:  75%|#######5  | 89/118 [00:11<00:03,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5034, step=166080:  76%|#######6  | 90/118 [00:11<00:03,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5165, step=166592:  77%|#######7  | 91/118 [00:11<00:03,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5144, step=167104:  78%|#######7  | 92/118 [00:11<00:03,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5240, step=167616:  79%|#######8  | 93/118 [00:11<00:03,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5123, step=168128:  80%|#######9  | 94/118 [00:11<00:02,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5080, step=168640:  81%|########  | 95/118 [00:11<00:02,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5121, step=169152:  81%|########1 | 96/118 [00:11<00:02,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5168, step=169664:  82%|########2 | 97/118 [00:12<00:02,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5151, step=170176:  83%|########3 | 98/118 [00:12<00:02,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5081, step=170688:  84%|########3 | 99/118 [00:12<00:02,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5126, step=171200:  85%|########4 | 100/118 [00:12<00:02,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5111, step=171712:  86%|########5 | 101/118 [00:12<00:02,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5065, step=172224:  86%|########6 | 102/118 [00:12<00:01,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5074, step=172736:  87%|########7 | 103/118 [00:12<00:01,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5148, step=173248:  88%|########8 | 104/118 [00:12<00:01,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.4834, step=173760:  89%|########8 | 105/118 [00:13<00:01,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5234, step=174272:  90%|########9 | 106/118 [00:13<00:01,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5244, step=174784:  91%|######### | 107/118 [00:13<00:01,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5165, step=175296:  92%|#########1| 108/118 [00:13<00:01,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5080, step=175808:  92%|#########2| 109/118 [00:13<00:01,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5088, step=176320:  93%|#########3| 110/118 [00:13<00:01,  7.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5091, step=176832:  94%|#########4| 111/118 [00:13<00:00,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5020, step=177344:  95%|#########4| 112/118 [00:13<00:00,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5034, step=177856:  96%|#########5| 113/118 [00:14<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5063, step=178368:  97%|#########6| 114/118 [00:14<00:00,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5019, step=178880:  97%|#########7| 115/118 [00:14<00:00,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5178, step=179392:  98%|#########8| 116/118 [00:14<00:00,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=02, loss=0.5150, step=180000: 100%|##########| 118/118 [00:14<00:00,  8.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/118 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5013, step=181024:   2%|1         | 2/118 [00:00<00:14,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5114, step=181536:   3%|2         | 3/118 [00:00<00:14,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4897, step=182048:   3%|3         | 4/118 [00:00<00:14,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4977, step=182560:   4%|4         | 5/118 [00:00<00:14,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5013, step=183072:   5%|5         | 6/118 [00:00<00:14,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5043, step=183584:   6%|5         | 7/118 [00:00<00:13,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5082, step=184096:   7%|6         | 8/118 [00:00<00:13,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5027, step=184608:   8%|7         | 9/118 [00:01<00:13,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5048, step=185120:   8%|8         | 10/118 [00:01<00:13,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5163, step=185632:   9%|9         | 11/118 [00:01<00:13,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4911, step=186144:  10%|#         | 12/118 [00:01<00:13,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5162, step=186656:  11%|#1        | 13/118 [00:01<00:12,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5128, step=187168:  12%|#1        | 14/118 [00:01<00:13,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5007, step=187680:  13%|#2        | 15/118 [00:01<00:12,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4983, step=188192:  14%|#3        | 16/118 [00:01<00:12,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4941, step=188704:  14%|#4        | 17/118 [00:02<00:12,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5003, step=189216:  15%|#5        | 18/118 [00:02<00:12,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4972, step=189728:  16%|#6        | 19/118 [00:02<00:12,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5036, step=190240:  17%|#6        | 20/118 [00:02<00:11,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5143, step=190752:  18%|#7        | 21/118 [00:02<00:11,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4999, step=191264:  19%|#8        | 22/118 [00:02<00:11,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4957, step=191776:  19%|#9        | 23/118 [00:02<00:11,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4893, step=192288:  20%|##        | 24/118 [00:02<00:11,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5109, step=192800:  21%|##1       | 25/118 [00:03<00:11,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4952, step=193312:  22%|##2       | 26/118 [00:03<00:11,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5024, step=193824:  23%|##2       | 27/118 [00:03<00:11,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4947, step=194336:  24%|##3       | 28/118 [00:03<00:11,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4955, step=194848:  25%|##4       | 29/118 [00:03<00:10,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4928, step=195360:  25%|##5       | 30/118 [00:03<00:10,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4897, step=195872:  26%|##6       | 31/118 [00:03<00:10,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4907, step=196384:  27%|##7       | 32/118 [00:03<00:10,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4936, step=196896:  28%|##7       | 33/118 [00:04<00:10,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4919, step=197408:  29%|##8       | 34/118 [00:04<00:10,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4968, step=197920:  30%|##9       | 35/118 [00:04<00:10,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4962, step=198432:  31%|###       | 36/118 [00:04<00:10,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5038, step=198944:  31%|###1      | 37/118 [00:04<00:10,  7.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4791, step=199456:  32%|###2      | 38/118 [00:04<00:10,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4852, step=199968:  33%|###3      | 39/118 [00:04<00:10,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4856, step=200480:  34%|###3      | 40/118 [00:05<00:10,  7.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4940, step=200992:  35%|###4      | 41/118 [00:05<00:10,  7.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4925, step=201504:  36%|###5      | 42/118 [00:05<00:09,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4907, step=202016:  36%|###6      | 43/118 [00:05<00:09,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4707, step=202528:  37%|###7      | 44/118 [00:05<00:09,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4807, step=203040:  38%|###8      | 45/118 [00:05<00:09,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4985, step=203552:  39%|###8      | 46/118 [00:05<00:08,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4770, step=204064:  40%|###9      | 47/118 [00:05<00:08,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4883, step=204576:  41%|####      | 48/118 [00:05<00:08,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4914, step=205088:  42%|####1     | 49/118 [00:06<00:08,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4925, step=205600:  42%|####2     | 50/118 [00:06<00:08,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4947, step=206112:  43%|####3     | 51/118 [00:06<00:08,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4961, step=206624:  44%|####4     | 52/118 [00:06<00:08,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4760, step=207136:  45%|####4     | 53/118 [00:06<00:07,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4969, step=207648:  46%|####5     | 54/118 [00:06<00:07,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4888, step=208160:  47%|####6     | 55/118 [00:06<00:07,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4872, step=208672:  47%|####7     | 56/118 [00:06<00:07,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4970, step=209184:  48%|####8     | 57/118 [00:07<00:07,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5014, step=209696:  49%|####9     | 58/118 [00:07<00:07,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4940, step=210208:  50%|#####     | 59/118 [00:07<00:07,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4866, step=210720:  51%|#####     | 60/118 [00:07<00:07,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4916, step=211232:  52%|#####1    | 61/118 [00:07<00:06,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4980, step=211744:  53%|#####2    | 62/118 [00:07<00:06,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4996, step=212256:  53%|#####3    | 63/118 [00:07<00:06,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5007, step=212768:  54%|#####4    | 64/118 [00:07<00:06,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4878, step=213280:  55%|#####5    | 65/118 [00:08<00:06,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4755, step=213792:  56%|#####5    | 66/118 [00:08<00:06,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4800, step=214304:  57%|#####6    | 67/118 [00:08<00:06,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4866, step=214816:  58%|#####7    | 68/118 [00:08<00:06,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4871, step=215328:  58%|#####8    | 69/118 [00:08<00:05,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4734, step=215840:  59%|#####9    | 70/118 [00:08<00:05,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4884, step=216352:  60%|######    | 71/118 [00:08<00:05,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4916, step=216864:  61%|######1   | 72/118 [00:08<00:05,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4865, step=217376:  62%|######1   | 73/118 [00:09<00:05,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4804, step=217888:  63%|######2   | 74/118 [00:09<00:05,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5074, step=218400:  64%|######3   | 75/118 [00:09<00:05,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4912, step=218912:  64%|######4   | 76/118 [00:09<00:05,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4912, step=219424:  65%|######5   | 77/118 [00:09<00:05,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4909, step=219936:  66%|######6   | 78/118 [00:09<00:04,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4978, step=220448:  67%|######6   | 79/118 [00:09<00:04,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4706, step=220960:  68%|######7   | 80/118 [00:09<00:04,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4872, step=221472:  69%|######8   | 81/118 [00:10<00:04,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4876, step=221984:  69%|######9   | 82/118 [00:10<00:04,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4780, step=222496:  70%|#######   | 83/118 [00:10<00:04,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4759, step=223008:  71%|#######1  | 84/118 [00:10<00:04,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4778, step=223520:  72%|#######2  | 85/118 [00:10<00:04,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4738, step=224032:  73%|#######2  | 86/118 [00:10<00:03,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4721, step=224544:  74%|#######3  | 87/118 [00:10<00:03,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.5028, step=225056:  75%|#######4  | 88/118 [00:10<00:03,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4800, step=225568:  75%|#######5  | 89/118 [00:11<00:03,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4838, step=226080:  76%|#######6  | 90/118 [00:11<00:03,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4735, step=226592:  77%|#######7  | 91/118 [00:11<00:03,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4945, step=227104:  78%|#######7  | 92/118 [00:11<00:03,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4814, step=227616:  79%|#######8  | 93/118 [00:11<00:03,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4831, step=228128:  80%|#######9  | 94/118 [00:11<00:02,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4824, step=228640:  81%|########  | 95/118 [00:11<00:02,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4879, step=229152:  81%|########1 | 96/118 [00:11<00:02,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4730, step=229664:  82%|########2 | 97/118 [00:12<00:02,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4932, step=230176:  83%|########3 | 98/118 [00:12<00:02,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4898, step=230688:  84%|########3 | 99/118 [00:12<00:02,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4864, step=231200:  85%|########4 | 100/118 [00:12<00:02,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4776, step=231712:  86%|########5 | 101/118 [00:12<00:02,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4777, step=232224:  86%|########6 | 102/118 [00:12<00:01,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4826, step=232736:  87%|########7 | 103/118 [00:12<00:01,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4864, step=233248:  88%|########8 | 104/118 [00:12<00:01,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4761, step=233760:  89%|########8 | 105/118 [00:13<00:01,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4778, step=234272:  90%|########9 | 106/118 [00:13<00:01,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4860, step=234784:  91%|######### | 107/118 [00:13<00:01,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4869, step=235296:  92%|#########1| 108/118 [00:13<00:01,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4853, step=235808:  92%|#########2| 109/118 [00:13<00:01,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4781, step=236320:  93%|#########3| 110/118 [00:13<00:00,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4823, step=236832:  94%|#########4| 111/118 [00:13<00:00,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4785, step=237344:  95%|#########4| 112/118 [00:13<00:00,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4717, step=237856:  96%|#########5| 113/118 [00:13<00:00,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4880, step=238368:  97%|#########6| 114/118 [00:14<00:00,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4940, step=238880:  97%|#########7| 115/118 [00:14<00:00,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4917, step=239392:  98%|#########8| 116/118 [00:14<00:00,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=03, loss=0.4836, step=240000: 100%|##########| 118/118 [00:14<00:00,  8.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4822, step=241024:   2%|1         | 2/118 [00:00<00:15,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4872, step=242048:   3%|3         | 4/118 [00:00<00:14,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4877, step=243072:   5%|5         | 6/118 [00:00<00:13,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4731, step=244096:   7%|6         | 8/118 [00:01<00:13,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4751, step=245120:   8%|8         | 10/118 [00:01<00:13,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4824, step=246144:  10%|#         | 12/118 [00:01<00:13,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4698, step=247168:  12%|#1        | 14/118 [00:01<00:12,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4643, step=248192:  14%|#3        | 16/118 [00:01<00:12,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4768, step=249216:  15%|#5        | 18/118 [00:02<00:13,  7.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4723, step=250240:  17%|#6        | 20/118 [00:02<00:12,  7.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4896, step=251264:  19%|#8        | 22/118 [00:02<00:11,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4953, step=252288:  20%|##        | 24/118 [00:03<00:11,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4830, step=253312:  22%|##2       | 26/118 [00:03<00:11,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4669, step=254336:  24%|##3       | 28/118 [00:03<00:10,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4761, step=255360:  25%|##5       | 30/118 [00:03<00:11,  7.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4637, step=256384:  27%|##7       | 32/118 [00:04<00:11,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4932, step=257408:  29%|##8       | 34/118 [00:04<00:10,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4761, step=258432:  31%|###       | 36/118 [00:04<00:10,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4754, step=259456:  32%|###2      | 38/118 [00:04<00:09,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4822, step=260480:  34%|###3      | 40/118 [00:05<00:09,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4695, step=261504:  36%|###5      | 42/118 [00:05<00:10,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4739, step=262528:  37%|###7      | 44/118 [00:05<00:10,  7.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4635, step=263552:  39%|###8      | 46/118 [00:05<00:10,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4667, step=264576:  41%|####      | 48/118 [00:06<00:09,  7.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4632, step=265600:  42%|####2     | 50/118 [00:06<00:08,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4743, step=266624:  44%|####4     | 52/118 [00:06<00:08,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4687, step=267648:  46%|####5     | 54/118 [00:06<00:08,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4593, step=268672:  47%|####7     | 56/118 [00:07<00:07,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4617, step=269696:  49%|####9     | 58/118 [00:07<00:07,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4774, step=270720:  51%|#####     | 60/118 [00:07<00:07,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4615, step=271744:  53%|#####2    | 62/118 [00:07<00:06,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4780, step=272768:  54%|#####4    | 64/118 [00:08<00:06,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4713, step=273792:  56%|#####5    | 66/118 [00:08<00:07,  7.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4745, step=274816:  58%|#####7    | 68/118 [00:08<00:06,  7.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4692, step=275840:  59%|#####9    | 70/118 [00:08<00:06,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4637, step=276864:  61%|######1   | 72/118 [00:09<00:05,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4471, step=277888:  63%|######2   | 74/118 [00:09<00:05,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4640, step=278912:  64%|######4   | 76/118 [00:09<00:05,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4655, step=279936:  66%|######6   | 78/118 [00:09<00:05,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4665, step=280960:  68%|######7   | 80/118 [00:10<00:04,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4486, step=281984:  69%|######9   | 82/118 [00:10<00:04,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4672, step=283008:  71%|#######1  | 84/118 [00:10<00:04,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4583, step=284032:  73%|#######2  | 86/118 [00:10<00:03,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4709, step=285056:  75%|#######4  | 88/118 [00:11<00:03,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4721, step=286080:  76%|#######6  | 90/118 [00:11<00:03,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4793, step=287104:  78%|#######7  | 92/118 [00:11<00:03,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4674, step=288128:  80%|#######9  | 94/118 [00:11<00:03,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4550, step=289152:  81%|########1 | 96/118 [00:12<00:02,  7.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4705, step=290176:  83%|########3 | 98/118 [00:12<00:02,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4576, step=291200:  85%|########4 | 100/118 [00:12<00:02,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4648, step=292224:  86%|########6 | 102/118 [00:12<00:02,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4589, step=293248:  88%|########8 | 104/118 [00:13<00:01,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4797, step=294272:  90%|########9 | 106/118 [00:13<00:01,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4686, step=295296:  92%|#########1| 108/118 [00:13<00:01,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4730, step=296320:  93%|#########3| 110/118 [00:14<00:01,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4686, step=297344:  95%|#########4| 112/118 [00:14<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4495, step=298368:  97%|#########6| 114/118 [00:14<00:00,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4659, step=299392:  98%|#########8| 116/118 [00:14<00:00,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=04, loss=0.4880, step=300000: 100%|##########| 118/118 [00:14<00:00,  7.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/118 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4723, step=301024:   2%|1         | 2/118 [00:00<00:14,  7.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4588, step=301536:   3%|2         | 3/118 [00:00<00:14,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4632, step=302048:   3%|3         | 4/118 [00:00<00:14,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4521, step=302560:   4%|4         | 5/118 [00:00<00:14,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4582, step=303072:   5%|5         | 6/118 [00:00<00:14,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4623, step=303584:   6%|5         | 7/118 [00:00<00:13,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4714, step=304096:   7%|6         | 8/118 [00:01<00:13,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4600, step=304608:   8%|7         | 9/118 [00:01<00:13,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4586, step=305120:   8%|8         | 10/118 [00:01<00:13,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4506, step=305632:   9%|9         | 11/118 [00:01<00:13,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4531, step=306144:  10%|#         | 12/118 [00:01<00:13,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4655, step=306656:  11%|#1        | 13/118 [00:01<00:12,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4587, step=307168:  12%|#1        | 14/118 [00:01<00:12,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4834, step=307680:  13%|#2        | 15/118 [00:01<00:12,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4722, step=308192:  14%|#3        | 16/118 [00:01<00:12,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4694, step=308704:  14%|#4        | 17/118 [00:02<00:12,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4499, step=309216:  15%|#5        | 18/118 [00:02<00:12,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4535, step=309728:  16%|#6        | 19/118 [00:02<00:12,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4601, step=310240:  17%|#6        | 20/118 [00:02<00:12,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4788, step=310752:  18%|#7        | 21/118 [00:02<00:11,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4469, step=311264:  19%|#8        | 22/118 [00:02<00:11,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4536, step=311776:  19%|#9        | 23/118 [00:02<00:11,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4461, step=312288:  20%|##        | 24/118 [00:02<00:11,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4529, step=312800:  21%|##1       | 25/118 [00:03<00:11,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4613, step=313312:  22%|##2       | 26/118 [00:03<00:11,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4624, step=313824:  23%|##2       | 27/118 [00:03<00:11,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4708, step=314336:  24%|##3       | 28/118 [00:03<00:10,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4550, step=314848:  25%|##4       | 29/118 [00:03<00:10,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4697, step=315360:  25%|##5       | 30/118 [00:03<00:11,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4483, step=315872:  26%|##6       | 31/118 [00:03<00:10,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4531, step=316384:  27%|##7       | 32/118 [00:03<00:10,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4545, step=316896:  28%|##7       | 33/118 [00:04<00:10,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4467, step=317408:  29%|##8       | 34/118 [00:04<00:10,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4496, step=317920:  30%|##9       | 35/118 [00:04<00:10,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4592, step=318432:  31%|###       | 36/118 [00:04<00:10,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4546, step=318944:  31%|###1      | 37/118 [00:04<00:10,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4567, step=319456:  32%|###2      | 38/118 [00:04<00:09,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4551, step=319968:  33%|###3      | 39/118 [00:04<00:09,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4622, step=320480:  34%|###3      | 40/118 [00:04<00:09,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4482, step=320992:  35%|###4      | 41/118 [00:05<00:09,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4456, step=321504:  36%|###5      | 42/118 [00:05<00:10,  7.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4634, step=322016:  36%|###6      | 43/118 [00:05<00:09,  7.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4693, step=322528:  37%|###7      | 44/118 [00:05<00:09,  7.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4659, step=323040:  38%|###8      | 45/118 [00:05<00:09,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4471, step=323552:  39%|###8      | 46/118 [00:05<00:09,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4602, step=324064:  40%|###9      | 47/118 [00:05<00:08,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4681, step=324576:  41%|####      | 48/118 [00:06<00:08,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4598, step=325088:  42%|####1     | 49/118 [00:06<00:08,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4649, step=325600:  42%|####2     | 50/118 [00:06<00:08,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4550, step=326112:  43%|####3     | 51/118 [00:06<00:08,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4575, step=326624:  44%|####4     | 52/118 [00:06<00:08,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4520, step=327136:  45%|####4     | 53/118 [00:06<00:08,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4567, step=327648:  46%|####5     | 54/118 [00:06<00:07,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4549, step=328160:  47%|####6     | 55/118 [00:06<00:07,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4726, step=328672:  47%|####7     | 56/118 [00:06<00:07,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4527, step=329184:  48%|####8     | 57/118 [00:07<00:07,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4633, step=329696:  49%|####9     | 58/118 [00:07<00:07,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4599, step=330208:  50%|#####     | 59/118 [00:07<00:07,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4605, step=330720:  51%|#####     | 60/118 [00:07<00:07,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4529, step=331232:  52%|#####1    | 61/118 [00:07<00:07,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4531, step=331744:  53%|#####2    | 62/118 [00:07<00:06,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4570, step=332256:  53%|#####3    | 63/118 [00:07<00:06,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4509, step=332768:  54%|#####4    | 64/118 [00:07<00:06,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4719, step=333280:  55%|#####5    | 65/118 [00:08<00:06,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4545, step=333792:  56%|#####5    | 66/118 [00:08<00:06,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4625, step=334304:  57%|#####6    | 67/118 [00:08<00:06,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4578, step=334816:  58%|#####7    | 68/118 [00:08<00:06,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4773, step=335328:  58%|#####8    | 69/118 [00:08<00:06,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4542, step=335840:  59%|#####9    | 70/118 [00:08<00:05,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4407, step=336352:  60%|######    | 71/118 [00:08<00:05,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4515, step=336864:  61%|######1   | 72/118 [00:08<00:05,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4644, step=337376:  62%|######1   | 73/118 [00:09<00:05,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4613, step=337888:  63%|######2   | 74/118 [00:09<00:05,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4463, step=338400:  64%|######3   | 75/118 [00:09<00:05,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4536, step=338912:  64%|######4   | 76/118 [00:09<00:05,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4596, step=339424:  65%|######5   | 77/118 [00:09<00:05,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4730, step=339936:  66%|######6   | 78/118 [00:09<00:04,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4644, step=340448:  67%|######6   | 79/118 [00:09<00:04,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4658, step=340960:  68%|######7   | 80/118 [00:09<00:04,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4551, step=341472:  69%|######8   | 81/118 [00:10<00:04,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4404, step=341984:  69%|######9   | 82/118 [00:10<00:04,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4583, step=342496:  70%|#######   | 83/118 [00:10<00:04,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4382, step=343008:  71%|#######1  | 84/118 [00:10<00:04,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4446, step=343520:  72%|#######2  | 85/118 [00:10<00:04,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4496, step=344032:  73%|#######2  | 86/118 [00:10<00:03,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4612, step=344544:  74%|#######3  | 87/118 [00:10<00:03,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4458, step=345056:  75%|#######4  | 88/118 [00:10<00:03,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4501, step=345568:  75%|#######5  | 89/118 [00:11<00:03,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4627, step=346080:  76%|#######6  | 90/118 [00:11<00:03,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4395, step=346592:  77%|#######7  | 91/118 [00:11<00:03,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4548, step=347104:  78%|#######7  | 92/118 [00:11<00:03,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4362, step=347616:  79%|#######8  | 93/118 [00:11<00:03,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4553, step=348128:  80%|#######9  | 94/118 [00:11<00:02,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4522, step=348640:  81%|########  | 95/118 [00:11<00:02,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4449, step=349152:  81%|########1 | 96/118 [00:11<00:02,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4471, step=349664:  82%|########2 | 97/118 [00:12<00:02,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4486, step=350176:  83%|########3 | 98/118 [00:12<00:02,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4525, step=350688:  84%|########3 | 99/118 [00:12<00:02,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4503, step=351200:  85%|########4 | 100/118 [00:12<00:02,  7.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4565, step=351712:  86%|########5 | 101/118 [00:12<00:02,  7.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4429, step=352224:  86%|########6 | 102/118 [00:12<00:02,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4375, step=352736:  87%|########7 | 103/118 [00:12<00:01,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4407, step=353248:  88%|########8 | 104/118 [00:13<00:01,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4445, step=353760:  89%|########8 | 105/118 [00:13<00:01,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4631, step=354272:  90%|########9 | 106/118 [00:13<00:01,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4617, step=354784:  91%|######### | 107/118 [00:13<00:01,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4621, step=355296:  92%|#########1| 108/118 [00:13<00:01,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4494, step=355808:  92%|#########2| 109/118 [00:13<00:01,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4489, step=356320:  93%|#########3| 110/118 [00:13<00:00,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4443, step=356832:  94%|#########4| 111/118 [00:13<00:00,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4612, step=357344:  95%|#########4| 112/118 [00:13<00:00,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4485, step=357856:  96%|#########5| 113/118 [00:14<00:00,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4564, step=358368:  97%|#########6| 114/118 [00:14<00:00,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4553, step=358880:  97%|#########7| 115/118 [00:14<00:00,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4440, step=359392:  98%|#########8| 116/118 [00:14<00:00,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=05, loss=0.4765, step=360000: 100%|##########| 118/118 [00:14<00:00,  8.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/118 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4543, step=361024:   2%|1         | 2/118 [00:00<00:14,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4369, step=361536:   3%|2         | 3/118 [00:00<00:14,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4394, step=362048:   3%|3         | 4/118 [00:00<00:14,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4571, step=362560:   4%|4         | 5/118 [00:00<00:14,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4439, step=363072:   5%|5         | 6/118 [00:00<00:13,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4522, step=363584:   6%|5         | 7/118 [00:00<00:13,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4635, step=364096:   7%|6         | 8/118 [00:00<00:13,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4522, step=364608:   8%|7         | 9/118 [00:01<00:13,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4456, step=365120:   8%|8         | 10/118 [00:01<00:13,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4451, step=365632:   9%|9         | 11/118 [00:01<00:13,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4530, step=366144:  10%|#         | 12/118 [00:01<00:13,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4524, step=366656:  11%|#1        | 13/118 [00:01<00:12,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4583, step=367168:  12%|#1        | 14/118 [00:01<00:12,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4510, step=367680:  13%|#2        | 15/118 [00:01<00:12,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4510, step=368192:  14%|#3        | 16/118 [00:01<00:12,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4469, step=368704:  14%|#4        | 17/118 [00:02<00:12,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4467, step=369216:  15%|#5        | 18/118 [00:02<00:12,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4418, step=369728:  16%|#6        | 19/118 [00:02<00:12,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4599, step=370240:  17%|#6        | 20/118 [00:02<00:12,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4424, step=370752:  18%|#7        | 21/118 [00:02<00:12,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4443, step=371264:  19%|#8        | 22/118 [00:02<00:11,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4484, step=371776:  19%|#9        | 23/118 [00:02<00:11,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4608, step=372288:  20%|##        | 24/118 [00:02<00:11,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4494, step=372800:  21%|##1       | 25/118 [00:03<00:11,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4515, step=373312:  22%|##2       | 26/118 [00:03<00:11,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4527, step=373824:  23%|##2       | 27/118 [00:03<00:11,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4602, step=374336:  24%|##3       | 28/118 [00:03<00:11,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4650, step=374848:  25%|##4       | 29/118 [00:03<00:11,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4494, step=375360:  25%|##5       | 30/118 [00:03<00:11,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4388, step=375872:  26%|##6       | 31/118 [00:03<00:10,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4565, step=376384:  27%|##7       | 32/118 [00:03<00:10,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4526, step=376896:  28%|##7       | 33/118 [00:04<00:10,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4416, step=377408:  29%|##8       | 34/118 [00:04<00:10,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4461, step=377920:  30%|##9       | 35/118 [00:04<00:10,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4464, step=378432:  31%|###       | 36/118 [00:04<00:10,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4458, step=378944:  31%|###1      | 37/118 [00:04<00:10,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4511, step=379456:  32%|###2      | 38/118 [00:04<00:09,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4321, step=379968:  33%|###3      | 39/118 [00:04<00:09,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4530, step=380480:  34%|###3      | 40/118 [00:04<00:09,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4387, step=380992:  35%|###4      | 41/118 [00:05<00:09,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4479, step=381504:  36%|###5      | 42/118 [00:05<00:09,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4545, step=382016:  36%|###6      | 43/118 [00:05<00:09,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4290, step=382528:  37%|###7      | 44/118 [00:05<00:09,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4531, step=383040:  38%|###8      | 45/118 [00:05<00:09,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4448, step=383552:  39%|###8      | 46/118 [00:05<00:09,  7.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4451, step=384064:  40%|###9      | 47/118 [00:05<00:09,  7.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4491, step=384576:  41%|####      | 48/118 [00:05<00:08,  7.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4527, step=385088:  42%|####1     | 49/118 [00:06<00:08,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4335, step=385600:  42%|####2     | 50/118 [00:06<00:08,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4468, step=386112:  43%|####3     | 51/118 [00:06<00:08,  7.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4561, step=386624:  44%|####4     | 52/118 [00:06<00:08,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4389, step=387136:  45%|####4     | 53/118 [00:06<00:08,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4444, step=387648:  46%|####5     | 54/118 [00:06<00:08,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4470, step=388160:  47%|####6     | 55/118 [00:06<00:07,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4336, step=388672:  47%|####7     | 56/118 [00:06<00:07,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4406, step=389184:  48%|####8     | 57/118 [00:07<00:07,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4528, step=389696:  49%|####9     | 58/118 [00:07<00:07,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4452, step=390208:  50%|#####     | 59/118 [00:07<00:07,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4521, step=390720:  51%|#####     | 60/118 [00:07<00:07,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4347, step=391232:  52%|#####1    | 61/118 [00:07<00:07,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4510, step=391744:  53%|#####2    | 62/118 [00:07<00:07,  7.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4501, step=392256:  53%|#####3    | 63/118 [00:07<00:06,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4405, step=392768:  54%|#####4    | 64/118 [00:08<00:06,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4493, step=393280:  55%|#####5    | 65/118 [00:08<00:06,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4578, step=393792:  56%|#####5    | 66/118 [00:08<00:06,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4354, step=394304:  57%|#####6    | 67/118 [00:08<00:06,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4611, step=394816:  58%|#####7    | 68/118 [00:08<00:06,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4453, step=395328:  58%|#####8    | 69/118 [00:08<00:06,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4453, step=395840:  59%|#####9    | 70/118 [00:08<00:05,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4438, step=396352:  60%|######    | 71/118 [00:08<00:05,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4586, step=396864:  61%|######1   | 72/118 [00:09<00:05,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4332, step=397376:  62%|######1   | 73/118 [00:09<00:05,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4465, step=397888:  63%|######2   | 74/118 [00:09<00:05,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4320, step=398400:  64%|######3   | 75/118 [00:09<00:05,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4403, step=398912:  64%|######4   | 76/118 [00:09<00:05,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4513, step=399424:  65%|######5   | 77/118 [00:09<00:05,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4424, step=399936:  66%|######6   | 78/118 [00:09<00:04,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4599, step=400448:  67%|######6   | 79/118 [00:09<00:04,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4418, step=400960:  68%|######7   | 80/118 [00:10<00:04,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4453, step=401472:  69%|######8   | 81/118 [00:10<00:04,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4418, step=401984:  69%|######9   | 82/118 [00:10<00:04,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4511, step=402496:  70%|#######   | 83/118 [00:10<00:04,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4348, step=403008:  71%|#######1  | 84/118 [00:10<00:04,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4435, step=403520:  72%|#######2  | 85/118 [00:10<00:04,  7.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4485, step=404032:  73%|#######2  | 86/118 [00:10<00:04,  7.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4384, step=404544:  74%|#######3  | 87/118 [00:10<00:03,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4394, step=405056:  75%|#######4  | 88/118 [00:11<00:03,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4385, step=405568:  75%|#######5  | 89/118 [00:11<00:03,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4555, step=406080:  76%|#######6  | 90/118 [00:11<00:03,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4470, step=406592:  77%|#######7  | 91/118 [00:11<00:03,  7.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4543, step=407104:  78%|#######7  | 92/118 [00:11<00:03,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4491, step=407616:  79%|#######8  | 93/118 [00:11<00:03,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4542, step=408128:  80%|#######9  | 94/118 [00:11<00:03,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4460, step=408640:  81%|########  | 95/118 [00:11<00:02,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4648, step=409152:  81%|########1 | 96/118 [00:12<00:02,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4370, step=409664:  82%|########2 | 97/118 [00:12<00:02,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4449, step=410176:  83%|########3 | 98/118 [00:12<00:02,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4463, step=410688:  84%|########3 | 99/118 [00:12<00:02,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4264, step=411200:  85%|########4 | 100/118 [00:12<00:02,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4385, step=411712:  86%|########5 | 101/118 [00:12<00:02,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4362, step=412224:  86%|########6 | 102/118 [00:12<00:02,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4451, step=412736:  87%|########7 | 103/118 [00:12<00:01,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4526, step=413248:  88%|########8 | 104/118 [00:13<00:01,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4392, step=413760:  89%|########8 | 105/118 [00:13<00:01,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4372, step=414272:  90%|########9 | 106/118 [00:13<00:01,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4452, step=414784:  91%|######### | 107/118 [00:13<00:01,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4308, step=415296:  92%|#########1| 108/118 [00:13<00:01,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4721, step=415808:  92%|#########2| 109/118 [00:13<00:01,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4578, step=416320:  93%|#########3| 110/118 [00:13<00:01,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4503, step=416832:  94%|#########4| 111/118 [00:13<00:00,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4439, step=417344:  95%|#########4| 112/118 [00:14<00:00,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4416, step=417856:  96%|#########5| 113/118 [00:14<00:00,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4435, step=418368:  97%|#########6| 114/118 [00:14<00:00,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4467, step=418880:  97%|#########7| 115/118 [00:14<00:00,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4472, step=419392:  98%|#########8| 116/118 [00:14<00:00,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4396, step=420000:  99%|#########9| 117/118 [00:14<00:00,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=06, loss=0.4396, step=420000: 100%|##########| 118/118 [00:14<00:00,  7.99it/s]\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4327, step=421024:   2%|1         | 2/118 [00:00<00:14,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4425, step=421536:   3%|2         | 3/118 [00:00<00:14,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4463, step=422048:   3%|3         | 4/118 [00:00<00:14,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4444, step=422560:   4%|4         | 5/118 [00:00<00:14,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4366, step=423072:   5%|5         | 6/118 [00:00<00:14,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4435, step=423584:   6%|5         | 7/118 [00:00<00:14,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4508, step=424096:   7%|6         | 8/118 [00:01<00:13,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4341, step=424608:   8%|7         | 9/118 [00:01<00:13,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4456, step=425120:   8%|8         | 10/118 [00:01<00:13,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4568, step=425632:   9%|9         | 11/118 [00:01<00:13,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4594, step=426144:  10%|#         | 12/118 [00:01<00:13,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4426, step=426656:  11%|#1        | 13/118 [00:01<00:13,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4410, step=427168:  12%|#1        | 14/118 [00:01<00:13,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4355, step=427680:  13%|#2        | 15/118 [00:01<00:12,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4324, step=428192:  14%|#3        | 16/118 [00:02<00:12,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4377, step=428704:  14%|#4        | 17/118 [00:02<00:12,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4303, step=429216:  15%|#5        | 18/118 [00:02<00:12,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4440, step=429728:  16%|#6        | 19/118 [00:02<00:12,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4408, step=430240:  17%|#6        | 20/118 [00:02<00:12,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4419, step=430752:  18%|#7        | 21/118 [00:02<00:11,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4281, step=431264:  19%|#8        | 22/118 [00:02<00:11,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4341, step=431776:  19%|#9        | 23/118 [00:02<00:11,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4386, step=432288:  20%|##        | 24/118 [00:02<00:11,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4452, step=432800:  21%|##1       | 25/118 [00:03<00:11,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4508, step=433312:  22%|##2       | 26/118 [00:03<00:11,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4300, step=433824:  23%|##2       | 27/118 [00:03<00:11,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4397, step=434336:  24%|##3       | 28/118 [00:03<00:11,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4369, step=434848:  25%|##4       | 29/118 [00:03<00:11,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4241, step=435360:  25%|##5       | 30/118 [00:03<00:11,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4452, step=435872:  26%|##6       | 31/118 [00:03<00:10,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4289, step=436384:  27%|##7       | 32/118 [00:04<00:10,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4451, step=436896:  28%|##7       | 33/118 [00:04<00:10,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4451, step=437408:  29%|##8       | 34/118 [00:04<00:10,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4376, step=437920:  30%|##9       | 35/118 [00:04<00:10,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4432, step=438432:  31%|###       | 36/118 [00:04<00:10,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4410, step=438944:  31%|###1      | 37/118 [00:04<00:10,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4630, step=439456:  32%|###2      | 38/118 [00:04<00:10,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4222, step=439968:  33%|###3      | 39/118 [00:04<00:09,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4383, step=440480:  34%|###3      | 40/118 [00:05<00:09,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4563, step=440992:  35%|###4      | 41/118 [00:05<00:09,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4417, step=441504:  36%|###5      | 42/118 [00:05<00:09,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4436, step=442016:  36%|###6      | 43/118 [00:05<00:09,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4555, step=442528:  37%|###7      | 44/118 [00:05<00:09,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4336, step=443040:  38%|###8      | 45/118 [00:05<00:09,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4404, step=443552:  39%|###8      | 46/118 [00:05<00:08,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4252, step=444064:  40%|###9      | 47/118 [00:05<00:08,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4258, step=444576:  41%|####      | 48/118 [00:06<00:08,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4471, step=445088:  42%|####1     | 49/118 [00:06<00:08,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4591, step=445600:  42%|####2     | 50/118 [00:06<00:08,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4461, step=446112:  43%|####3     | 51/118 [00:06<00:08,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4465, step=446624:  44%|####4     | 52/118 [00:06<00:08,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4440, step=447136:  45%|####4     | 53/118 [00:06<00:08,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4351, step=447648:  46%|####5     | 54/118 [00:06<00:08,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4366, step=448160:  47%|####6     | 55/118 [00:06<00:07,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4334, step=448672:  47%|####7     | 56/118 [00:07<00:07,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4372, step=449184:  48%|####8     | 57/118 [00:07<00:07,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4309, step=449696:  49%|####9     | 58/118 [00:07<00:07,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4378, step=450208:  50%|#####     | 59/118 [00:07<00:07,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4404, step=450720:  51%|#####     | 60/118 [00:07<00:07,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4357, step=451232:  52%|#####1    | 61/118 [00:07<00:07,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4462, step=451744:  53%|#####2    | 62/118 [00:07<00:07,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4270, step=452256:  53%|#####3    | 63/118 [00:07<00:06,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4346, step=452768:  54%|#####4    | 64/118 [00:08<00:06,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4466, step=453280:  55%|#####5    | 65/118 [00:08<00:06,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4366, step=453792:  56%|#####5    | 66/118 [00:08<00:06,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4333, step=454304:  57%|#####6    | 67/118 [00:08<00:06,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4227, step=454816:  58%|#####7    | 68/118 [00:08<00:06,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4294, step=455328:  58%|#####8    | 69/118 [00:08<00:06,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4362, step=455840:  59%|#####9    | 70/118 [00:08<00:06,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4371, step=456352:  60%|######    | 71/118 [00:08<00:05,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4402, step=456864:  61%|######1   | 72/118 [00:09<00:05,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4382, step=457376:  62%|######1   | 73/118 [00:09<00:05,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4287, step=457888:  63%|######2   | 74/118 [00:09<00:05,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4488, step=458400:  64%|######3   | 75/118 [00:09<00:05,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4414, step=458912:  64%|######4   | 76/118 [00:09<00:05,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4471, step=459424:  65%|######5   | 77/118 [00:09<00:05,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4449, step=459936:  66%|######6   | 78/118 [00:09<00:05,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4376, step=460448:  67%|######6   | 79/118 [00:09<00:04,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4445, step=460960:  68%|######7   | 80/118 [00:10<00:04,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4279, step=461472:  69%|######8   | 81/118 [00:10<00:04,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4466, step=461984:  69%|######9   | 82/118 [00:10<00:04,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4340, step=462496:  70%|#######   | 83/118 [00:10<00:04,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4230, step=463008:  71%|#######1  | 84/118 [00:10<00:04,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4391, step=463520:  72%|#######2  | 85/118 [00:10<00:04,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4439, step=464032:  73%|#######2  | 86/118 [00:10<00:04,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4432, step=464544:  74%|#######3  | 87/118 [00:10<00:03,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4574, step=465056:  75%|#######4  | 88/118 [00:11<00:03,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4426, step=465568:  75%|#######5  | 89/118 [00:11<00:03,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4431, step=466080:  76%|#######6  | 90/118 [00:11<00:03,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4348, step=466592:  77%|#######7  | 91/118 [00:11<00:03,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4224, step=467104:  78%|#######7  | 92/118 [00:11<00:03,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4289, step=467616:  79%|#######8  | 93/118 [00:11<00:03,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4320, step=468128:  80%|#######9  | 94/118 [00:11<00:03,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4428, step=468640:  81%|########  | 95/118 [00:11<00:02,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4467, step=469152:  81%|########1 | 96/118 [00:12<00:02,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4460, step=469664:  82%|########2 | 97/118 [00:12<00:02,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4483, step=470176:  83%|########3 | 98/118 [00:12<00:02,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4340, step=470688:  84%|########3 | 99/118 [00:12<00:02,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4347, step=471200:  85%|########4 | 100/118 [00:12<00:02,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4364, step=471712:  86%|########5 | 101/118 [00:12<00:02,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4394, step=472224:  86%|########6 | 102/118 [00:12<00:02,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4342, step=472736:  87%|########7 | 103/118 [00:12<00:01,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4351, step=473248:  88%|########8 | 104/118 [00:13<00:01,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4447, step=473760:  89%|########8 | 105/118 [00:13<00:01,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4361, step=474272:  90%|########9 | 106/118 [00:13<00:01,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4510, step=474784:  91%|######### | 107/118 [00:13<00:01,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4394, step=475296:  92%|#########1| 108/118 [00:13<00:01,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4387, step=475808:  92%|#########2| 109/118 [00:13<00:01,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4371, step=476320:  93%|#########3| 110/118 [00:13<00:00,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4328, step=476832:  94%|#########4| 111/118 [00:13<00:00,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4291, step=477344:  95%|#########4| 112/118 [00:14<00:00,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4314, step=477856:  96%|#########5| 113/118 [00:14<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4431, step=478368:  97%|#########6| 114/118 [00:14<00:00,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4385, step=478880:  97%|#########7| 115/118 [00:14<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4358, step=479392:  98%|#########8| 116/118 [00:14<00:00,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4770, step=480000:  99%|#########9| 117/118 [00:14<00:00,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=07, loss=0.4770, step=480000: 100%|##########| 118/118 [00:14<00:00,  8.02it/s]\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4426, step=481024:   2%|1         | 2/118 [00:00<00:14,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4460, step=481536:   3%|2         | 3/118 [00:00<00:14,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4331, step=482048:   3%|3         | 4/118 [00:00<00:14,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4248, step=482560:   4%|4         | 5/118 [00:00<00:14,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4322, step=483072:   5%|5         | 6/118 [00:00<00:13,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4402, step=483584:   6%|5         | 7/118 [00:00<00:13,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4316, step=484096:   7%|6         | 8/118 [00:00<00:13,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4299, step=484608:   8%|7         | 9/118 [00:01<00:13,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4277, step=485120:   8%|8         | 10/118 [00:01<00:13,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4335, step=485632:   9%|9         | 11/118 [00:01<00:13,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4274, step=486144:  10%|#         | 12/118 [00:01<00:13,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4405, step=486656:  11%|#1        | 13/118 [00:01<00:13,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4271, step=487168:  12%|#1        | 14/118 [00:01<00:12,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4269, step=487680:  13%|#2        | 15/118 [00:01<00:12,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4273, step=488192:  14%|#3        | 16/118 [00:01<00:12,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4241, step=488704:  14%|#4        | 17/118 [00:02<00:12,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4404, step=489216:  15%|#5        | 18/118 [00:02<00:12,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4301, step=489728:  16%|#6        | 19/118 [00:02<00:12,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4372, step=490240:  17%|#6        | 20/118 [00:02<00:11,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4284, step=490752:  18%|#7        | 21/118 [00:02<00:11,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4504, step=491264:  19%|#8        | 22/118 [00:02<00:11,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4341, step=491776:  19%|#9        | 23/118 [00:02<00:11,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4569, step=492288:  20%|##        | 24/118 [00:02<00:11,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4235, step=492800:  21%|##1       | 25/118 [00:03<00:11,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4333, step=493312:  22%|##2       | 26/118 [00:03<00:11,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4334, step=493824:  23%|##2       | 27/118 [00:03<00:11,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4238, step=494336:  24%|##3       | 28/118 [00:03<00:11,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4298, step=494848:  25%|##4       | 29/118 [00:03<00:10,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4424, step=495360:  25%|##5       | 30/118 [00:03<00:10,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4308, step=495872:  26%|##6       | 31/118 [00:03<00:10,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4378, step=496384:  27%|##7       | 32/118 [00:03<00:10,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4238, step=496896:  28%|##7       | 33/118 [00:04<00:10,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4387, step=497408:  29%|##8       | 34/118 [00:04<00:10,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4452, step=497920:  30%|##9       | 35/118 [00:04<00:10,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4335, step=498432:  31%|###       | 36/118 [00:04<00:10,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4350, step=498944:  31%|###1      | 37/118 [00:04<00:09,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4266, step=499456:  32%|###2      | 38/118 [00:04<00:09,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4487, step=499968:  33%|###3      | 39/118 [00:04<00:09,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4290, step=500480:  34%|###3      | 40/118 [00:04<00:09,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4309, step=500992:  35%|###4      | 41/118 [00:05<00:09,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4343, step=501504:  36%|###5      | 42/118 [00:05<00:09,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4280, step=502016:  36%|###6      | 43/118 [00:05<00:09,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4418, step=502528:  37%|###7      | 44/118 [00:05<00:09,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4300, step=503040:  38%|###8      | 45/118 [00:05<00:08,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4460, step=503552:  39%|###8      | 46/118 [00:05<00:08,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4345, step=504064:  40%|###9      | 47/118 [00:05<00:08,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4415, step=504576:  41%|####      | 48/118 [00:05<00:08,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4273, step=505088:  42%|####1     | 49/118 [00:06<00:08,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4259, step=505600:  42%|####2     | 50/118 [00:06<00:08,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4400, step=506112:  43%|####3     | 51/118 [00:06<00:08,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4305, step=506624:  44%|####4     | 52/118 [00:06<00:08,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4264, step=507136:  45%|####4     | 53/118 [00:06<00:08,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4332, step=507648:  46%|####5     | 54/118 [00:06<00:07,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4425, step=508160:  47%|####6     | 55/118 [00:06<00:07,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4275, step=509696:  49%|####9     | 58/118 [00:07<00:08,  7.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4230, step=510720:  51%|#####     | 60/118 [00:07<00:07,  7.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4376, step=511744:  53%|#####2    | 62/118 [00:07<00:07,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4234, step=512768:  54%|#####4    | 64/118 [00:08<00:06,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4374, step=513792:  56%|#####5    | 66/118 [00:08<00:06,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4319, step=514816:  58%|#####7    | 68/118 [00:08<00:06,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4484, step=515840:  59%|#####9    | 70/118 [00:08<00:05,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4367, step=516864:  61%|######1   | 72/118 [00:08<00:05,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4385, step=517888:  63%|######2   | 74/118 [00:09<00:05,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4457, step=518912:  64%|######4   | 76/118 [00:09<00:05,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4341, step=519936:  66%|######6   | 78/118 [00:09<00:04,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4297, step=520960:  68%|######7   | 80/118 [00:09<00:04,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4260, step=521984:  69%|######9   | 82/118 [00:10<00:04,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4301, step=523008:  71%|#######1  | 84/118 [00:10<00:04,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4362, step=524032:  73%|#######2  | 86/118 [00:10<00:03,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4387, step=525056:  75%|#######4  | 88/118 [00:10<00:03,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4406, step=526080:  76%|#######6  | 90/118 [00:11<00:03,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4353, step=527104:  78%|#######7  | 92/118 [00:11<00:03,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4216, step=528128:  80%|#######9  | 94/118 [00:11<00:03,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4319, step=529152:  81%|########1 | 96/118 [00:11<00:02,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4280, step=530176:  83%|########3 | 98/118 [00:12<00:02,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4349, step=531200:  85%|########4 | 100/118 [00:12<00:02,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4235, step=532224:  86%|########6 | 102/118 [00:12<00:02,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4289, step=533248:  88%|########8 | 104/118 [00:13<00:01,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4320, step=534272:  90%|########9 | 106/118 [00:13<00:01,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4267, step=535296:  92%|#########1| 108/118 [00:13<00:01,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4351, step=536320:  93%|#########3| 110/118 [00:13<00:00,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4327, step=537344:  95%|#########4| 112/118 [00:14<00:00,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4322, step=538368:  97%|#########6| 114/118 [00:14<00:00,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4222, step=539392:  98%|#########8| 116/118 [00:14<00:00,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=08, loss=0.4180, step=540000: 100%|##########| 118/118 [00:14<00:00,  8.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/118 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4462, step=541024:   2%|1         | 2/118 [00:00<00:14,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4360, step=541536:   3%|2         | 3/118 [00:00<00:14,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4471, step=542048:   3%|3         | 4/118 [00:00<00:14,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4381, step=542560:   4%|4         | 5/118 [00:00<00:14,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4281, step=543072:   5%|5         | 6/118 [00:00<00:14,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4258, step=543584:   6%|5         | 7/118 [00:00<00:14,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4369, step=544096:   7%|6         | 8/118 [00:01<00:13,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4223, step=544608:   8%|7         | 9/118 [00:01<00:13,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4257, step=545120:   8%|8         | 10/118 [00:01<00:13,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4336, step=545632:   9%|9         | 11/118 [00:01<00:13,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4300, step=546144:  10%|#         | 12/118 [00:01<00:13,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4253, step=546656:  11%|#1        | 13/118 [00:01<00:13,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4401, step=547168:  12%|#1        | 14/118 [00:01<00:13,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4371, step=547680:  13%|#2        | 15/118 [00:01<00:12,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4270, step=548192:  14%|#3        | 16/118 [00:02<00:12,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4099, step=548704:  14%|#4        | 17/118 [00:02<00:12,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4343, step=549216:  15%|#5        | 18/118 [00:02<00:12,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4292, step=549728:  16%|#6        | 19/118 [00:02<00:12,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4311, step=550240:  17%|#6        | 20/118 [00:02<00:12,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4206, step=550752:  18%|#7        | 21/118 [00:02<00:12,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4147, step=551264:  19%|#8        | 22/118 [00:02<00:11,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4423, step=551776:  19%|#9        | 23/118 [00:02<00:11,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4345, step=552288:  20%|##        | 24/118 [00:03<00:11,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4230, step=552800:  21%|##1       | 25/118 [00:03<00:11,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4207, step=553312:  22%|##2       | 26/118 [00:03<00:11,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4235, step=553824:  23%|##2       | 27/118 [00:03<00:11,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4232, step=554336:  24%|##3       | 28/118 [00:03<00:11,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4413, step=554848:  25%|##4       | 29/118 [00:03<00:10,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4236, step=555360:  25%|##5       | 30/118 [00:03<00:10,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4168, step=555872:  26%|##6       | 31/118 [00:03<00:10,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4231, step=556384:  27%|##7       | 32/118 [00:03<00:10,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4099, step=556896:  28%|##7       | 33/118 [00:04<00:10,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4122, step=557408:  29%|##8       | 34/118 [00:04<00:10,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4514, step=557920:  30%|##9       | 35/118 [00:04<00:10,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4325, step=558432:  31%|###       | 36/118 [00:04<00:10,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4412, step=558944:  31%|###1      | 37/118 [00:04<00:10,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4362, step=559456:  32%|###2      | 38/118 [00:04<00:09,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4389, step=559968:  33%|###3      | 39/118 [00:04<00:09,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4274, step=560480:  34%|###3      | 40/118 [00:04<00:09,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4436, step=560992:  35%|###4      | 41/118 [00:05<00:09,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4365, step=561504:  36%|###5      | 42/118 [00:05<00:09,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4284, step=562016:  36%|###6      | 43/118 [00:05<00:09,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4284, step=562528:  37%|###7      | 44/118 [00:05<00:09,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4332, step=563040:  38%|###8      | 45/118 [00:05<00:09,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4394, step=563552:  39%|###8      | 46/118 [00:05<00:08,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4325, step=564064:  40%|###9      | 47/118 [00:05<00:08,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4340, step=564576:  41%|####      | 48/118 [00:05<00:08,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4362, step=565088:  42%|####1     | 49/118 [00:06<00:08,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4248, step=565600:  42%|####2     | 50/118 [00:06<00:08,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4163, step=566112:  43%|####3     | 51/118 [00:06<00:08,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4419, step=566624:  44%|####4     | 52/118 [00:06<00:08,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4238, step=567136:  45%|####4     | 53/118 [00:06<00:08,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4212, step=567648:  46%|####5     | 54/118 [00:06<00:08,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4506, step=568160:  47%|####6     | 55/118 [00:06<00:07,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4356, step=568672:  47%|####7     | 56/118 [00:06<00:07,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4190, step=569184:  48%|####8     | 57/118 [00:07<00:07,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4256, step=569696:  49%|####9     | 58/118 [00:07<00:07,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4380, step=570208:  50%|#####     | 59/118 [00:07<00:07,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4293, step=570720:  51%|#####     | 60/118 [00:07<00:07,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4304, step=571232:  52%|#####1    | 61/118 [00:07<00:07,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4389, step=571744:  53%|#####2    | 62/118 [00:07<00:06,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4283, step=572256:  53%|#####3    | 63/118 [00:07<00:06,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4312, step=572768:  54%|#####4    | 64/118 [00:07<00:06,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4268, step=573280:  55%|#####5    | 65/118 [00:08<00:06,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4280, step=573792:  56%|#####5    | 66/118 [00:08<00:06,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4302, step=574304:  57%|#####6    | 67/118 [00:08<00:06,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4433, step=574816:  58%|#####7    | 68/118 [00:08<00:06,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4170, step=575328:  58%|#####8    | 69/118 [00:08<00:06,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4331, step=575840:  59%|#####9    | 70/118 [00:08<00:06,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4212, step=576352:  60%|######    | 71/118 [00:08<00:05,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4261, step=576864:  61%|######1   | 72/118 [00:08<00:05,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4205, step=577376:  62%|######1   | 73/118 [00:09<00:05,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4241, step=577888:  63%|######2   | 74/118 [00:09<00:05,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4297, step=578400:  64%|######3   | 75/118 [00:09<00:05,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4267, step=578912:  64%|######4   | 76/118 [00:09<00:05,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4218, step=579424:  65%|######5   | 77/118 [00:09<00:05,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4254, step=579936:  66%|######6   | 78/118 [00:09<00:05,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4295, step=580448:  67%|######6   | 79/118 [00:09<00:04,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4202, step=580960:  68%|######7   | 80/118 [00:10<00:04,  7.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4306, step=581472:  69%|######8   | 81/118 [00:10<00:04,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4166, step=581984:  69%|######9   | 82/118 [00:10<00:04,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4317, step=582496:  70%|#######   | 83/118 [00:10<00:04,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4292, step=583008:  71%|#######1  | 84/118 [00:10<00:04,  7.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4314, step=583520:  72%|#######2  | 85/118 [00:10<00:04,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4117, step=584032:  73%|#######2  | 86/118 [00:10<00:04,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4224, step=584544:  74%|#######3  | 87/118 [00:10<00:03,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4301, step=585056:  75%|#######4  | 88/118 [00:11<00:03,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4267, step=585568:  75%|#######5  | 89/118 [00:11<00:03,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4266, step=586080:  76%|#######6  | 90/118 [00:11<00:03,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4253, step=586592:  77%|#######7  | 91/118 [00:11<00:03,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4258, step=587104:  78%|#######7  | 92/118 [00:11<00:03,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4344, step=587616:  79%|#######8  | 93/118 [00:11<00:03,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4449, step=588128:  80%|#######9  | 94/118 [00:11<00:03,  7.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4203, step=588640:  81%|########  | 95/118 [00:11<00:02,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4260, step=589152:  81%|########1 | 96/118 [00:12<00:02,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4284, step=589664:  82%|########2 | 97/118 [00:12<00:02,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4403, step=590176:  83%|########3 | 98/118 [00:12<00:02,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4233, step=590688:  84%|########3 | 99/118 [00:12<00:02,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4357, step=591200:  85%|########4 | 100/118 [00:12<00:02,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4228, step=591712:  86%|########5 | 101/118 [00:12<00:02,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4297, step=592224:  86%|########6 | 102/118 [00:12<00:02,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4370, step=592736:  87%|########7 | 103/118 [00:12<00:01,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4336, step=593248:  88%|########8 | 104/118 [00:13<00:01,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4185, step=593760:  89%|########8 | 105/118 [00:13<00:01,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4147, step=594272:  90%|########9 | 106/118 [00:13<00:01,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4303, step=594784:  91%|######### | 107/118 [00:13<00:01,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4342, step=595296:  92%|#########1| 108/118 [00:13<00:01,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4239, step=595808:  92%|#########2| 109/118 [00:13<00:01,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4350, step=596320:  93%|#########3| 110/118 [00:13<00:00,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4170, step=596832:  94%|#########4| 111/118 [00:13<00:00,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4355, step=597344:  95%|#########4| 112/118 [00:14<00:00,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4267, step=597856:  96%|#########5| 113/118 [00:14<00:00,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4229, step=598368:  97%|#########6| 114/118 [00:14<00:00,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4288, step=598880:  97%|#########7| 115/118 [00:14<00:00,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4131, step=599392:  98%|#########8| 116/118 [00:14<00:00,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=09, loss=0.4289, step=600000: 100%|##########| 118/118 [00:14<00:00,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▇▆▅▅▅▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.4289</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">eager-spaceship-1</strong> at: <a href='https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder/runs/y887zknf' target=\"_blank\">https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder/runs/y887zknf</a><br> View project at: <a href='https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder' target=\"_blank\">https://wandb.ai/t-w-bush-tilburg-university/day5-autoencoder</a><br>Synced 5 W&B file(s), 100 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250330_160036-y887zknf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "@dataclass\n",
        "class AutoencoderArgs:\n",
        "    # architecture\n",
        "    latent_dim_size: int = 5\n",
        "    hidden_dim_size: int = 128\n",
        "\n",
        "    # data / training\n",
        "    dataset: Literal[\"MNIST\", \"CELEB\"] = \"MNIST\"\n",
        "    batch_size: int = 512\n",
        "    epochs: int = 10\n",
        "    lr: float = 1e-3\n",
        "    betas: tuple[float, float] = (0.5, 0.999)\n",
        "\n",
        "    # logging\n",
        "    use_wandb: bool = False\n",
        "    wandb_project: str | None = \"day5-autoencoder\"\n",
        "    wandb_name: str | None = None\n",
        "    log_every_n_steps: int = 250\n",
        "\n",
        "\n",
        "class AutoencoderTrainer:\n",
        "    def __init__(self, args: AutoencoderArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True)\n",
        "        self.model = Autoencoder(\n",
        "            latent_dim_size=args.latent_dim_size,\n",
        "            hidden_dim_size=args.hidden_dim_size,\n",
        "        ).to(device)\n",
        "        self.optimizer = t.optim.Adam(self.model.parameters(), lr=args.lr, betas=args.betas)\n",
        "        self.step = 0\n",
        "        self.loss = nn.MSELoss()\n",
        "\n",
        "    def training_step(self, img: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Performs a training step on the batch of images in `img`. Returns the loss. Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        # pass imgs to model\n",
        "\n",
        "        pred = self.model.forward(img)\n",
        "        loss = self.loss(pred, img)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        self.step += img.shape[0]\n",
        "\n",
        "        if args.use_wandb:\n",
        "          wandb.log(dict(loss=loss), step=self.step)\n",
        "\n",
        "        return loss\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluates model on holdout data, either logging to weights & biases or displaying output.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        output = self.model(HOLDOUT_DATA)\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output.cpu().numpy()]}, step=self.step)\n",
        "        else:\n",
        "            display_data(t.concat([HOLDOUT_DATA, output]), nrows=2, title=\"AE reconstructions\")\n",
        "\n",
        "    def train(self) -> Autoencoder:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        # YOUR CODE HERE - iterate over epochs, and train your model\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "\n",
        "            progress_bar = tqdm(self.trainloader, total=int(len(self.trainloader)), ascii=True)\n",
        "\n",
        "            for imgs, _ in progress_bar:\n",
        "                imgs = imgs.to(device)\n",
        "                loss = self.training_step(imgs)\n",
        "                progress_bar.set_description(f\"{epoch=:02d}, {loss=:.4f}, step={self.step:05d}\")\n",
        "                #pbar.set_postfix(loss=f\"{loss:.3f}\", ex_seen=f\"{self.step=:06}\")\n",
        "                # log every 250 steps\n",
        "                if self.step % self.args.log_every_n_steps == 0:\n",
        "\n",
        "                  self.log_samples()\n",
        "\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model\n",
        "\n",
        "\n",
        "args = AutoencoderArgs(use_wandb=True)\n",
        "trainer = AutoencoderTrainer(args)\n",
        "autoencoder = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICTgcCII6eju"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class AutoencoderTrainer:\n",
        "    def __init__(self, args: AutoencoderArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True)\n",
        "        self.model = Autoencoder(\n",
        "            latent_dim_size=args.latent_dim_size,\n",
        "            hidden_dim_size=args.hidden_dim_size,\n",
        "        ).to(device)\n",
        "        self.optimizer = t.optim.Adam(self.model.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step(self, img: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Performs a training step on the batch of images in `img`. Returns the loss. Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        # Compute loss, backprop on it, and perform an optimizer step\n",
        "        img_reconstructed = self.model(img)\n",
        "        loss = nn.MSELoss()(img, img_reconstructed)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Increment step counter and log to wandb if enabled\n",
        "        self.step += img.shape[0]\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log(dict(loss=loss), step=self.step)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluates model on holdout data, either logging to weights & biases or displaying output.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        output = self.model(HOLDOUT_DATA)\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output.cpu().numpy()]}, step=self.step)\n",
        "        else:\n",
        "            display_data(t.concat([HOLDOUT_DATA, output]), nrows=2, title=\"AE reconstructions\")\n",
        "\n",
        "    def train(self) -> Autoencoder:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            # Iterate over training data, performing a training step for each batch\n",
        "            progress_bar = tqdm(self.trainloader, total=int(len(self.trainloader)), ascii=True)\n",
        "            for img, label in progress_bar:  # remember that label is not used\n",
        "                img = img.to(device)\n",
        "                loss = self.training_step(img)\n",
        "                progress_bar.set_description(f\"{epoch=:02d}, {loss=:.4f}, step={self.step:05d}\")\n",
        "                if self.step % self.args.log_every_n_steps == 0:\n",
        "                    self.log_samples()\n",
        "\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPGRJRHP6eju"
      },
      "source": [
        "After the first epoch, you should be able to get output of the following quality:\n",
        "\n",
        "<br>\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ae-epoch-1.png\" width=\"750\">\n",
        "\n",
        "And by the 10th epoch, you should be getting something like this:\n",
        "\n",
        "<br>\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ae-epoch-10.png\" width=\"750\">\n",
        "\n",
        "Note how the reconstructions it's mixing up features for some of the numbers - for instance, the 5 seems to have been partly reconstructed as a 3. But overall, it seems pretty accurate!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-scT4rm6eju"
      },
      "source": [
        "## Latent space of an autoencoder\n",
        "\n",
        "We'll now return to the issue we mentioned briefly earlier - how to generate output? We might want to generate output by just producing random noise and passing it through our decoder, but this raises a question - how should we interpret the latent space between our encoder and decoder?\n",
        "\n",
        "We can try and plot the outputs produced by the decoder over a range. The code below does this (you might have to adjust it slightly depending on how you've implemented your autoencoder):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "9SDbZRgf6ejv",
        "outputId": "9c126959-078a-413d-e0d5-29713a4bb4d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b04fa1e3-88ab-47bb-b5b0-f5ad5189e3c1\" class=\"plotly-graph-div\" style=\"height:600px; width:640px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b04fa1e3-88ab-47bb-b5b0-f5ad5189e3c1\")) {                    Plotly.newPlot(                        \"b04fa1e3-88ab-47bb-b5b0-f5ad5189e3c1\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.007419333,0.0,0.0,0.0,0.022930093,0.022079222,0.014853939,0.0,0.0,0.0,0.00071939826,0.003948882,0.0,0.0072453544,0.017559208,0.015543424,0.0,0.015983365,0.016407795,0.0,0.0,0.0,0.0,0.0,0.010180987,0.021797478,0.0,0.0,0.010225095,0.0,0.0,0.0,0.010683395,0.019920148,0.011729799,0.00006750226,0.0,0.0,0.0,0.0,0.0,0.014203683,0.02048684,0.01499977,0.0,0.017002918,0.023668274,0.0,0.0,0.0,0.0,0.0,0.0,0.009077169,0.0,0.0,0.012467191,0.0,0.0,0.0,0.0043530017,0.021329083,0.01860848,0.01611074,0.0,0.0,0.0,0.0,0.0,0.020133123,0.017274864,0.0064065233,0.0,0.013436638,0.01571764,0.0,0.0,0.0,0.0,0.0,0.0,0.0026562065,0.0,0.0,0.010734245,0.0,0.0,0.0,0.0034451932,0.0046197027,0.0,0.0,0.0,0.0,0.0,0.0,0.0069880486,0.020743087,0.014629178,0.0,0.0,0.0017640442,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007753305,0.0,0.0,0.0,0.00086793303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01334282,0.022950709,0.012068249,0.0,0.0,0.002717793,0.0039539635,0.0,0.0,0.0,0.0,0.0045760274,0.00048410892,0.0,0.0,0.0,0.0016099662,0.0,0.0,0.005795613,0.0067866817,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.027706735,0.031753078,0.010084003,0.0,0.0,0.009304263,0.008168064,0.0,0.01158455,0.0025752336,0.0,0.013553977,0.01287663,0.0,0.0,0.0,0.0,0.0,0.0,0.021683097,0.029878847,0.009665616,0.014952041,0.002969578,0.0,0.0,0.0,0.0,0.035211302,0.029142067,0.006741777,0.0,0.0,0.009193055,0.0065577477,0.0,0.016836002,0.007464446,0.0,0.017328933,0.028428517,0.010914579,0.0078009143,0.0,0.0,0.0,0.0,0.031175122,0.04037293,0.021131039,0.037460037,0.02226971,0.0,0.0,0.0,0.0,0.0442828,0.032880433,0.008186966,0.0,0.0,0.0052649677,0.0029889792,0.0,0.017579094,0.0059097856,0.0,0.019511022,0.036344543,0.01956731,0.014556445,0.0,0.0,0.0,0.0,0.04467643,0.044650763,0.030807875,0.06198547,0.058707595,0.0,0.0,0.0,0.0,0.056748196,0.041383825,0.010107294,0.0,0.0,0.012526654,0.006168984,0.0,0.013126016,0.0013245046,0.0,0.018158115,0.037146874,0.015467398,0.018110298,0.0,0.0,0.0,0.0,0.048430584,0.041067354,0.03521224,0.08765784,0.103663065,0.0050159544,0.0,0.0,0.0,0.07400265,0.052435502,0.013973974,0.0,0.0,0.027934715,0.013490453,0.0,0.010292985,0.0037251413,0.0,0.010420419,0.018756159,0.0,0.0084349215,0.0,0.0,0.0019045919,0.0,0.049540825,0.028909475,0.03221561,0.105721064,0.13615234,0.017895006,0.0,0.0,0.0,0.09073971,0.0616396,0.012102507,0.0,0.0,0.05105044,0.023638174,0.0,0.007503316,0.014401868,0.0,0.0020302683,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.029860273,0.055547558,0.064456776,0.008202411,0.0,0.0,0.044088356,0.0,0.0,0.0,0.036578655,0.05343101,0.0,0.028778717,0.0,0.0,0.0,0.0,0.0,0.00087173283,0.052548073,0.042088814,0.020739026,0.0,0.0,0.0,0.0,0.0,0.018974513,0.049447887,0.06898187,0.026197396,0.0,0.0,0.012958936,0.0,0.0,0.0,0.016240105,0.010734469,0.0,0.02288346,0.0,0.0,0.0,0.0,0.0,0.0,0.03294634,0.023653269,0.027226962,0.0,0.0,0.0,0.0,0.0,0.024135955,0.048650302,0.068982325,0.03448934,0.002529323,0.0,0.0,0.0,0.005783066,0.0,0.0063605383,0.0,0.0,0.010348082,0.0023057312,0.0,0.0,0.0,0.0,0.0,0.023095846,0.012804799,0.024755642,0.0,0.0,0.0,0.0,0.0,0.024677992,0.017762743,0.018711284,0.000003144145,0.012950674,0.0,0.0,0.0,0.004995212,0.0,0.016250826,0.0,0.0,0.0,0.0020978153,0.0,0.0022043884,0.0,0.0,0.0,0.021320961,0.0025678426,0.015822276,0.0,0.0,0.0,0.0,0.0,0.018315352,0.019274808,0.015653893,0.0,0.0037645996,0.0,0.0,0.0,0.0010001063,0.009626143,0.027825154,0.0,0.0003233403,0.0,0.0053721815,0.0,0.02057767,0.0,0.009301767,0.0,0.036779,0.015424252,0.022016376,0.0002014935,0.0,0.0,0.0,0.011374973,0.027513467,0.035156526,0.03158792,0.0,0.0,0.0,0.0,0.0,0.014878675,0.024518177,0.032564953,0.0,0.018372424,0.0,0.018525846,0.0,0.04186824,0.014392346,0.029275991,0.010539748,0.07539855,0.061901405,0.049148366,0.01892376,0.0,0.0,0.0,0.031920068,0.062825926,0.07028129,0.07353537,0.023398861,0.017156921,0.0,0.0,0.0,0.035956725,0.033591814,0.031596296,0.0,0.024410151,0.0,0.032256864,0.0,0.053829826,0.033942178,0.04017444,0.022530757,0.11475667,0.097130105,0.06614519,0.0303296,0.0,0.0,0.0,0.046586253,0.082753934,0.0925962,0.10883572,0.054644212,0.046370342,0.0,0.0,0.0,0.04617378,0.031045474,0.02477745,0.0,0.023012772,0.0010297298,0.040096216,0.0,0.06395751,0.042252347,0.04356817,0.028833538,0.13936362,0.12106976,0.07714836,0.03574109,0.0,0.0058524907,0.0027060807,0.07150079,0.103862554,0.11680234,0.16109511,0.11041156,0.107297644,0.0,0.0,0.0,0.060245022,0.03972967,0.031510994,0.0,0.024778903,0.0,0.031924777,0.0,0.058526874,0.033284873,0.030630544,0.022729762,0.13655944,0.1277477,0.07828914,0.03517597,0.0,0.021433666,0.030258,0.08409946,0.10978771,0.118217684,0.2226033,0.1753859,0.17947775,0.0,0.0,0.0028148144,0.08575281,0.066035084,0.050960638,0.0,0.018996663,0.0,0.00096710026,0.0,0.04410304,0.003369704,0.008056805,0.0017388463,0.088676766,0.084677115,0.05801028,0.029751621,0.0,0.026517883,0.03800659,0.07208661,0.09074824,0.103889674,0.26682463,0.23382494,0.2415489,0.0,0.0013869256,0.027877294,0.12103542,0.090212286,0.06531105,0.0,0.010189965,0.0,0.0,0.0,0.03890606,0.0,0.0,0.0,0.05247254,0.03850519,0.028560765,0.020522185],[0.0,0.0,0.005188942,0.011988364,0.059458084,0.037516862,0.09420307,0.02936165,0.0,0.12152318,0.034917496,0.0,0.09476465,0.07626486,0.06272952,0.10883505,0.052496456,0.008259587,0.0,0.0,0.0,0.0,0.04238037,0.060100794,0.09211667,0.026482545,0.010885954,0.0027356148,0.0,0.0,0.0074158013,0.00506489,0.04434044,0.027022801,0.08522037,0.047991753,0.0014026612,0.09492703,0.026881926,0.0,0.08173153,0.059064664,0.023582786,0.043796472,0.005502641,0.005510792,0.0,0.012482114,0.0013333708,0.005197197,0.03694103,0.01895608,0.050602436,0.027235262,0.020129137,0.008894816,0.0,0.0,0.014887415,0.017014734,0.037468188,0.021832645,0.07944012,0.050085247,0.0062565356,0.030995116,0.0,0.0,0.058826625,0.039445557,0.016534537,0.020872615,0.0039141774,0.019520178,0.0,0.014161497,0.036825903,0.019528165,0.027111381,0.0,0.022595577,0.018609047,0.022702463,0.024155252,0.0,0.0,0.015184164,0.02219145,0.031494305,0.0069803745,0.036435686,0.03537839,0.026955985,0.011713944,0.006172821,0.0,0.048082255,0.02841378,0.0069806874,0.0,0.0,0.03289687,0.004053667,0.007913545,0.027282082,0.0038312078,0.0016076863,0.0,0.012557074,0.008151926,0.01392705,0.02899868,0.0,0.001535505,0.011448704,0.020638213,0.019579336,0.026937611,0.02375754,0.018510945,0.035142377,0.0014752895,0.017274857,0.0,0.063286416,0.034832463,0.009372905,0.0,0.0,0.033479586,0.017312221,0.0,0.025234856,0.007722579,0.0,0.009820379,0.030985191,0.025417171,0.02779539,0.042759694,0.0,0.003404826,0.0114388615,0.03204789,0.019922495,0.07298398,0.03326136,0.019499958,0.06275877,0.0,0.034247853,0.01530721,0.1056461,0.04465262,0.005885899,0.0,0.010132834,0.058034696,0.042414956,0.0,0.024921924,0.018778116,0.0,0.03510929,0.07626082,0.07334913,0.061614648,0.061348118,0.0,0.0059993714,0.009655811,0.063099846,0.04205057,0.1420323,0.07321823,0.054830372,0.10092826,0.0,0.05315288,0.03796283,0.14358705,0.050060675,0.0,0.0,0.039195694,0.0885579,0.05667787,0.0,0.035202004,0.034010738,0.0,0.05646865,0.111591466,0.10178728,0.08992446,0.069898576,0.0,0.011688411,0.013454981,0.08273504,0.052930012,0.18221298,0.10456434,0.09291262,0.1379653,0.0,0.05672829,0.047324948,0.16083111,0.052074105,0.0,0.0,0.057068206,0.10925159,0.06941131,0.0,0.040976904,0.04441811,0.0,0.07224418,0.1330225,0.11779758,0.10278821,0.07412391,0.0,0.021074288,0.025162175,0.09706929,0.06569859,0.22070086,0.16470957,0.17036656,0.20232055,0.0064380243,0.07805209,0.0654977,0.17843004,0.06695078,0.0,0.0,0.05713597,0.097822145,0.0613574,0.0,0.02367828,0.017438881,0.0,0.06676641,0.13888459,0.12487782,0.10514323,0.069919586,0.0005238056,0.030977301,0.03379728,0.100767605,0.06664545,0.24759656,0.23703794,0.2625332,0.2679388,0.029126875,0.08520054,0.08118263,0.21456516,0.091968626,0.0,0.0,0.025305256,0.0406799,0.03086584,0.0,0.0,0.0,0.0,0.03037037,0.099974796,0.09996115,0.099902734,0.06264958,0.0008748472,0.03317865,0.023726672,0.08401443,0.03922148,0.24386099,0.27865964,0.33502164,0.33070403,0.07365602,0.119592644,0.121833205,0.2664947,0.10812299,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013205588,0.069041625,0.07299753,0.082312465,0.05204048],[0.014393933,0.0015953332,0.0,0.0,0.09202254,0.07551266,0.06826359,0.051038884,0.107147165,0.18733124,0.22256497,0.1579556,0.17921653,0.22080004,0.1505803,0.110141866,0.0,0.0,0.0,0.05876988,0.08659129,0.059931986,0.08369032,0.09395267,0.035065882,0.0,0.0067830533,0.0041174144,0.017523952,0.02708736,0.0,0.0,0.062256955,0.06589448,0.07398577,0.057574414,0.09423378,0.13905036,0.12691155,0.07866684,0.121695146,0.1183151,0.04139635,0.0,0.0,0.0,0.0,0.07800405,0.148795,0.08364707,0.078970775,0.052406594,0.017173119,0.0,0.0019025058,0.0,0.015597746,0.042451955,0.01820705,0.0093443915,0.055526957,0.06030958,0.06748819,0.045802556,0.06610858,0.06979844,0.0074567795,0.0,0.014544614,0.0105394125,0.0,0.0,0.0,0.0,0.003973186,0.083658196,0.14786904,0.076569185,0.06305951,0.020064354,0.0,0.0,0.0066115335,0.007700056,0.01001592,0.030479118,0.024169646,0.0,0.023746558,0.006105788,0.019352369,0.015583269,0.06649199,0.054871425,0.0,0.0,0.010417812,0.0,0.0,0.0,0.0,0.010772377,0.025175333,0.056756243,0.101147875,0.032834023,0.031862043,0.0,0.0,0.0,0.007208459,0.0045434684,0.00384444,0.011744328,0.01829832,0.0,0.008169688,0.00022017956,0.011706412,0.0,0.036410548,0.03860558,0.0,0.0,0.019689485,0.021676034,0.0,0.0,0.0028377771,0.02582129,0.04379137,0.0374718,0.078801244,0.022327937,0.019143358,0.0,0.0,0.012443095,0.026773848,0.009591453,0.0,0.0,0.0054569393,0.0,0.007322751,0.021519579,0.04121323,0.0,0.006968364,0.018240608,0.017280549,0.0,0.041139834,0.04674513,0.033411607,0.0,0.063170254,0.054716893,0.052803792,0.024403356,0.065266706,0.028178051,0.0057258084,0.0,0.0069483966,0.061130382,0.05826056,0.020994931,0.0,0.0,0.0,0.0,0.027430527,0.06685937,0.100669906,0.022542536,0.0120177865,0.021862432,0.042529598,0.0,0.042059973,0.046749376,0.051160745,0.023455277,0.10170138,0.082867555,0.0447352,0.008210339,0.059697017,0.03269043,0.0,0.0,0.028543495,0.083795816,0.07143931,0.025057197,0.0,0.0,0.00040470064,0.0,0.03879796,0.09655841,0.14440638,0.059798002,0.0365924,0.0343752,0.050698422,0.0,0.036029793,0.039971665,0.05231291,0.031099975,0.1257796,0.1107823,0.053114444,0.0,0.060042553,0.031637065,0.0,0.006573841,0.03930755,0.08303967,0.06579771,0.020836525,0.0,0.0,0.02256225,0.0,0.059048146,0.15544216,0.20754486,0.1260729,0.09507199,0.076450884,0.07845321,0.0,0.043057054,0.048796654,0.07045309,0.027663827,0.13103484,0.12100918,0.05414044,0.0,0.018487148,0.0064903796,0.0,0.0139127225,0.04768227,0.09500474,0.06938362,0.009655982,0.0,0.0,0.054807983,0.025120258,0.08418469,0.23240972,0.2905909,0.21242934,0.16450772,0.13661438,0.10892989,0.0,0.061888874,0.08339142,0.10640943,0.01887831,0.09996085,0.08951354,0.03688734,0.0,0.0,0.0,0.0,0.0,0.02764827,0.0943196,0.07316966,0.0,0.0026980042,0.0076089576,0.06913269,0.031638294,0.07410196,0.2653172,0.34767595,0.2946688,0.24147296,0.23793635,0.17218944,0.0,0.08275359,0.11857864,0.14005853,0.016020894,0.060781717,0.046157435,0.010853246,0.0,0.0,0.0,0.0,0.0,0.007997952,0.072600126,0.0553632,0.0],[0.0,0.0,0.0,0.0,0.11847075,0.19045095,0.11197986,0.116108336,0.22541961,0.2295742,0.3739209,0.4065482,0.43861252,0.48451406,0.41059512,0.14262432,0.0,0.0,0.0,0.0049841106,0.0,0.023998223,0.0056912005,0.06587896,0.0,0.015668862,0.0,0.0,0.0,0.0,0.0,0.0,0.09741494,0.1614112,0.10254875,0.08626593,0.16024186,0.13766065,0.2138103,0.2291635,0.27470195,0.31658763,0.22649989,0.031561285,0.0,0.0,0.0,0.03930808,0.025415964,0.05010155,0.009119362,0.044927314,0.0,0.01616709,0.0,0.0,0.0,0.014816128,0.0,0.012358539,0.07912287,0.1219596,0.07686747,0.04883454,0.08403225,0.04260309,0.031969108,0.0021910518,0.04653003,0.113121115,0.08719471,0.0,0.0,0.0,0.0,0.044797346,0.033556707,0.058731735,0.0047887266,0.023468874,0.0,0.016989544,0.0,0.0,0.0,0.02214177,0.0,0.00497514,0.052855216,0.05059418,0.021442555,0.011874549,0.05241835,0.020945333,0.0,0.0,0.0016141683,0.031079516,0.028566271,0.0,0.0,0.023534507,0.0199669,0.028431758,0.014937468,0.037060566,0.0,0.0,0.0,0.011662461,0.0,0.0,0.0,0.022436716,0.0,0.003306374,0.04064452,0.020344935,0.0,0.0,0.021662995,0.018885687,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06885511,0.0553416,0.012107104,0.020154834,0.056367107,0.0025366843,0.0,0.0,0.02201794,0.011000633,0.0,0.0,0.022648029,0.0,0.0031837523,0.04100059,0.014509074,0.0,0.0,0.0,0.03871973,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08090029,0.076503485,0.0,0.018804587,0.07274694,0.016215585,0.0,0.0,0.043750472,0.035406552,0.0016905367,0.0,0.012958996,0.0,0.0100822,0.05909606,0.027650908,0.0,0.0,0.0,0.06351773,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08666794,0.078756645,0.0,0.0032805204,0.071049325,0.01670874,0.0,0.0,0.05469016,0.04181184,0.0033794492,0.0,0.021829762,0.0,0.013622567,0.07062948,0.04529205,0.010854624,0.0,0.006293699,0.07332866,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10459094,0.09097546,0.0,0.0,0.060931765,0.012653947,0.0,0.0,0.048640907,0.030057065,0.0,0.0,0.04057294,0.0,0.01720076,0.08642728,0.08687423,0.06514974,0.04734437,0.06183841,0.122983865,0.011794612,0.0,0.0,0.0,0.0,0.0,0.0,0.101336956,0.10685938,0.0,0.0,0.03464102,0.009408832,0.0,0.0054326206,0.054183938,0.019478485,0.0,0.0,0.062210716,0.0,0.033910304,0.10640085,0.1535687,0.14909756,0.13925952,0.13358645,0.195146,0.052479558,0.0,0.0,0.0,0.0,0.0,0.0,0.08007371,0.091356106,0.0,0.0,0.0,0.0,0.0,0.011119612,0.064986244,0.019607574,0.0,0.0,0.07191882,0.0,0.034343414,0.096910365,0.19957966,0.22304818,0.21971713,0.20618567,0.29209852,0.12768508,0.0,0.0,0.0,0.0,0.0,0.0,0.058765747,0.06197784,0.0,0.0,0.0,0.0,0.0,0.003865838,0.05200421,0.010473244,0.0],[0.0,0.0,0.0,0.055523507,0.09324019,0.029201724,0.16612346,0.2716266,0.31725436,0.5380371,0.56823796,0.76791775,0.79764926,0.878073,0.6441217,0.33681536,0.042379327,0.0,0.0,0.015953198,0.0,0.0031517595,0.0,0.024353184,0.00063602626,0.06511016,0.05123827,0.003424868,0.0,0.0,0.0,0.030906625,0.05902292,0.01670134,0.102310404,0.17850213,0.20666906,0.35327289,0.36083907,0.52066576,0.5874165,0.640637,0.4533344,0.18809663,0.0,0.0,0.0,0.012397565,0.0,0.03648328,0.0,0.02572646,0.0022943616,0.040837355,0.032143123,0.00066514313,0.0,0.004073411,0.0,0.03195245,0.04148768,0.017472744,0.056746207,0.094468646,0.10505548,0.15175933,0.10809508,0.17150527,0.27857065,0.36849272,0.2754501,0.06788046,0.0,0.0,0.0,0.012798801,0.0103518665,0.04211905,0.0,0.016936712,0.0021338165,0.025059193,0.01765953,0.00087176263,0.0,0.0,0.0,0.013574913,0.011889592,0.0,0.0,0.005984552,0.03502395,0.06770129,0.03853947,0.038927972,0.08880223,0.14785564,0.12223924,0.05249332,0.035455845,0.037353642,0.0,0.034542203,0.017379567,0.04125586,0.0,0.00849808,0.0,0.0029996037,0.0,0.0,0.0,0.0,0.0,0.0027071685,0.010763481,0.0,0.0,0.0,0.0,0.0094578415,0.0,0.0,0.0,0.013146006,0.0,0.0,0.05823806,0.16315657,0.13792908,0.112504855,0.094026506,0.05356589,0.02303753,0.000037804246,0.0,0.0,0.0,0.0062002465,0.0,0.0058299378,0.0,0.0013958365,0.03510224,0.016876973,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049801238,0.2581616,0.29565495,0.27522492,0.24079052,0.1445155,0.0676462,0.0,0.0,0.0,0.0,0.025636055,0.0,0.009374715,0.0025108457,0.0124207735,0.063865095,0.050671004,0.018252201,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017592683,0.26665172,0.35952428,0.37540022,0.33092853,0.20970193,0.09010269,0.0,0.0,0.0,0.0,0.041681632,0.0,0.028342932,0.017797492,0.024021879,0.08547136,0.08102985,0.033657752,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02076517,0.28382933,0.38643748,0.41538018,0.36635852,0.2415593,0.09635538,0.0,0.0,0.0,0.0,0.043198794,0.0,0.05066949,0.036149055,0.02993001,0.07695162,0.09855154,0.06753271,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0013066083,0.2879961,0.42030108,0.47518945,0.37347382,0.22790894,0.09236109,0.0,0.0,0.0,0.0,0.0376222,0.0,0.06226924,0.051717527,0.03832268,0.051273644,0.11816836,0.118699856,0.015937999,0.04797207,0.009422801,0.02051194,0.0,0.0,0.0,0.0,0.0,0.0,0.28225344,0.4302963,0.48521847,0.3018881,0.14504977,0.06444571,0.008224562,0.0,0.0036742985,0.002268955,0.03054548,0.0,0.07425498,0.06476642,0.044350296,0.039807484,0.14123745,0.19317979,0.09060812,0.14295928,0.07827392,0.06472518,0.0,0.0,0.0,0.0,0.0,0.0,0.29048473,0.41990566,0.4435339,0.21687013,0.08771862,0.04106479,0.022096373,0.0029588789,0.014752679,0.009073973,0.028784558],[0.0,0.0,0.053755186,0.11249875,0.1501159,0.15280409,0.25413844,0.39972627,0.4626112,0.5499176,0.65020853,0.7809777,0.9273549,0.9046093,0.75353664,0.49378657,0.1474941,0.035307847,0.0,0.0,0.0,0.0,0.0,0.0,0.02642528,0.024770476,0.016457781,0.011613868,0.0,0.0,0.02628339,0.07408483,0.09165774,0.0967818,0.18564963,0.2866328,0.3239476,0.34553826,0.4873922,0.6141845,0.77591276,0.79287237,0.66255015,0.38976556,0.11239098,0.00794296,0.0,0.0,0.0,0.0,0.0,0.0,0.034191623,0.009843469,0.013609804,0.016449854,0.0008045435,0.004408464,0.016369224,0.061437987,0.056036517,0.06688177,0.12073011,0.19549641,0.18995073,0.14101015,0.27512762,0.33941555,0.5015172,0.62324935,0.5439701,0.2964918,0.105774574,0.03859535,0.0,0.0,0.0,0.0,0.0,0.0,0.03302619,0.0015042871,0.0016304255,0.018311001,0.0,0.0,0.0,0.033243395,0.01912883,0.03648828,0.05536764,0.10608596,0.111402504,0.061840825,0.12631792,0.1645079,0.24805075,0.35327196,0.3641572,0.28411877,0.16402458,0.12444679,0.03556359,0.015302353,0.0,0.0,0.0,0.0,0.020236954,0.0,0.0,0.016899325,0.0,0.0,0.0,0.02053342,0.009035833,0.024106607,0.045489796,0.07624455,0.06663483,0.038121782,0.06866582,0.065778814,0.09495379,0.097526565,0.101135865,0.18276449,0.19071284,0.27976418,0.19223423,0.14241415,0.07475197,0.0,0.0,0.0,0.016636387,0.0,0.0020662993,0.023171335,0.0,0.0025452077,0.0,0.034085408,0.02687613,0.028882474,0.045338295,0.06186585,0.025772892,0.014674656,0.044323266,0.01128038,0.029972516,0.0,0.0012622923,0.14742252,0.27167368,0.41066736,0.40570986,0.34365615,0.24133423,0.09430757,0.03498003,0.00925108,0.011134796,0.011766091,0.014608428,0.035778463,0.0,0.015295595,0.0,0.058480427,0.055315323,0.053763285,0.05228828,0.06674574,0.0038750619,0.0,0.022700727,0.0,0.0023474693,0.0,0.0,0.14242502,0.28739452,0.49533248,0.55538905,0.48976552,0.36958593,0.17078549,0.07211366,0.014517985,0.00430876,0.02336859,0.027792484,0.047225744,0.0,0.035438895,0.0,0.07734892,0.07860304,0.07828787,0.0628318,0.08045706,0.0,0.0,0.022386812,0.0,0.0,0.0,0.0,0.14707972,0.29357678,0.5245829,0.6151595,0.5523786,0.4339047,0.21184546,0.09537954,0.01771336,0.0056737214,0.029562637,0.032074355,0.055310972,0.0,0.05209405,0.0008356422,0.081616655,0.065422714,0.08822082,0.073901504,0.11667371,0.048841402,0.021714196,0.05061592,0.0,0.0,0.0,0.0,0.13664612,0.27126306,0.5081362,0.6537084,0.6264555,0.45196652,0.18783665,0.09676951,0.01337295,0.010030739,0.031216577,0.028298326,0.060145967,0.0,0.05752776,0.0014269501,0.07755113,0.026990935,0.08523346,0.106070116,0.16950934,0.13556619,0.10012878,0.1020767,0.0,0.0,0.0,0.0,0.11467813,0.23708764,0.4584847,0.6399278,0.6331024,0.37201613,0.09673026,0.07190239,0.002793491,0.03285362,0.0348856,0.02236627,0.06238918,0.0,0.06522021,0.0,0.08041267,0.019059815,0.109890856,0.19247518,0.2517503,0.28363383,0.21901777,0.17615235,0.0,0.0,0.0,0.0,0.11952147,0.25076413,0.45690268,0.62682676,0.56897014,0.29107738,0.04885046,0.07370986,0.014706761,0.06943377,0.041153572,0.02572032,0.06724364],[0.0,0.0102614835,0.07968223,0.085955426,0.13670056,0.15936717,0.26948637,0.31390166,0.22284034,0.2475209,0.30844963,0.30525514,0.46034163,0.6260736,0.6882018,0.5106271,0.23320794,0.0,0.0,0.0,0.0,0.0,0.0,0.0561966,0.03964735,0.0,0.0,0.0,0.0,0.0,0.040789917,0.05412498,0.09881644,0.104427084,0.20282002,0.22621492,0.14143199,0.22545463,0.3284039,0.38815022,0.5594231,0.72051203,0.73741454,0.53661877,0.21044502,0.0,0.0,0.0,0.0,0.0,0.0,0.03275173,0.018871576,0.0,0.0,0.0,0.0,0.0,0.02435314,0.0368129,0.07475591,0.08446127,0.15492907,0.1559287,0.09298654,0.1580123,0.2891512,0.40493274,0.5730307,0.7098316,0.70520335,0.5228448,0.24220607,0.0,0.0,0.0,0.0,0.0,0.00170964,0.025191583,0.008921623,0.0058722347,0.0,0.0,0.0,0.0,0.0,0.025431357,0.06084626,0.06601573,0.095630564,0.08172794,0.101733446,0.15577257,0.25965428,0.31845564,0.4271747,0.5303802,0.5651586,0.50193644,0.38434047,0.1801039,0.0,0.0,0.0,0.0,0.02348417,0.015829705,0.0068976507,0.009900808,0.0,0.0123005435,0.0,0.0,0.0,0.041058205,0.06776012,0.082346916,0.093459666,0.059408076,0.11361226,0.16213727,0.23421836,0.24125206,0.25255632,0.25710082,0.21852553,0.30159968,0.41923982,0.4202013,0.24923402,0.058585025,0.0,0.0,0.04639993,0.0,0.0,0.0026371777,0.011412248,0.034887046,0.0,0.009970374,0.0,0.071168974,0.10894706,0.08109978,0.074243546,0.044632487,0.09170115,0.15570582,0.17865504,0.18070073,0.084679544,0.031736948,0.0,0.15156074,0.4321255,0.63309574,0.59405625,0.37483567,0.16892564,0.016519353,0.06542975,0.0,0.0,0.0125392005,0.037075035,0.05791059,0.0,0.028472513,0.009814218,0.09969315,0.1535168,0.085487746,0.06843593,0.03994818,0.077476576,0.16130558,0.1500794,0.15471642,0.0,0.0,0.0,0.11931101,0.4600498,0.7804793,0.8525941,0.632375,0.32721585,0.061351262,0.062409475,0.0,0.0,0.02630362,0.05635369,0.070300475,0.0,0.046919495,0.025193825,0.12316997,0.18607205,0.094253,0.08480414,0.05844649,0.088985294,0.16618837,0.14206883,0.14740586,0.0,0.0,0.0,0.109726086,0.4677388,0.8356008,0.9504785,0.74171966,0.40670747,0.08967176,0.063098036,0.0,0.0,0.0345809,0.066062875,0.0787821,0.0,0.06449672,0.030369602,0.10800092,0.18882968,0.09685883,0.12598349,0.107389696,0.13776484,0.17410922,0.1488353,0.12374264,0.0,0.0,0.0,0.09246528,0.41786224,0.8229625,1.0,0.80382115,0.4070111,0.079949096,0.053906932,0.0,0.0,0.034605883,0.0671899,0.084584355,0.0,0.08774179,0.049287915,0.08684614,0.18111232,0.11124998,0.21352798,0.20714498,0.25401694,0.24396443,0.20231855,0.12347389,0.0,0.0,0.0,0.07996987,0.3577835,0.7757239,1.0,0.74269325,0.2960835,0.010394253,0.025631882,0.0,0.0,0.03715232,0.06674414,0.08638604,0.0,0.11137998,0.095488414,0.10468971,0.19406211,0.14336252,0.3117653,0.34949487,0.4009323,0.36253655,0.28767288,0.1552479,0.0,0.0,0.0,0.10928756,0.3925323,0.75927216,0.94587004,0.60466045,0.18767644,0.0,0.01746349,0.0,0.014436632,0.047995254,0.07759955,0.089022025],[0.028981365,0.0,0.026219882,0.08065502,0.04332611,0.15059625,0.31854707,0.15519315,0.0012121946,0.04529602,0.09006798,0.0,0.08698492,0.38420457,0.49142772,0.43503344,0.26742378,0.018578373,0.0,0.0,0.0,0.011181101,0.0029940158,0.015448682,0.04850442,0.0008506626,0.0,0.014369421,0.016122408,0.0,0.0,0.053183928,0.008997634,0.108206406,0.23942758,0.12194125,0.024052389,0.11316938,0.14955121,0.072045356,0.33931342,0.55582637,0.6083118,0.48764497,0.24769257,0.008467481,0.0,0.0,0.0,0.027094379,0.010820061,0.0029318929,0.036809757,0.015339896,0.0,0.01071199,0.018027924,0.0,0.0,0.022957802,0.0,0.087957025,0.1765104,0.10525961,0.05352314,0.1435684,0.2285713,0.26164848,0.4978838,0.6379291,0.63320273,0.54194385,0.2928079,0.07956055,0.03473176,0.0,0.0,0.025311127,0.021154746,0.0,0.014220037,0.015267253,0.0,0.004022062,0.017375104,0.0,0.0,0.0015776455,0.005541235,0.07349025,0.11388463,0.10519407,0.17230971,0.26435316,0.31688786,0.3513533,0.46537095,0.5748427,0.574842,0.5751753,0.42840964,0.2845803,0.18848065,0.0,0.0,0.007089667,0.020016626,0.0,0.0,0.004114479,0.0,0.0,0.017075874,0.0,0.0005711764,0.0,0.026528925,0.09271693,0.0768746,0.1300459,0.31478888,0.38807893,0.39568532,0.39204842,0.35855746,0.356663,0.3305629,0.4100861,0.45809007,0.48064536,0.36770672,0.025847644,0.0,0.0,0.008276492,0.0,0.0,0.0,0.0,0.0015491694,0.024959214,0.0,0.003632024,0.0008980781,0.04853367,0.07612249,0.047466442,0.13768256,0.33050972,0.43791282,0.37436742,0.36251736,0.23639515,0.15301917,0.14593439,0.24358243,0.43902904,0.6555625,0.66177666,0.38541108,0.17800796,0.0,0.0,0.0,0.0,0.0,0.012391195,0.0,0.035700172,0.0,0.00599353,0.0149526,0.071770355,0.059992492,0.025131658,0.14216381,0.3288992,0.46783078,0.36147898,0.3465125,0.15237404,0.051304236,0.10314678,0.20165592,0.45555705,0.78204095,0.8807398,0.6680189,0.34272295,0.0,0.0,0.0,0.0,0.0,0.034900457,0.0,0.040803082,0.0,0.010057412,0.026228733,0.093145154,0.06098274,0.0309586,0.17487319,0.35482758,0.49061823,0.35815978,0.32415837,0.10713427,0.0038957149,0.07839067,0.18027404,0.4597714,0.8379294,0.9816479,0.78585315,0.41402125,0.0,0.0,0.0,0.0,0.0,0.04492113,0.0,0.048224412,0.004037142,0.0121876,0.01660636,0.089191124,0.08755205,0.08360426,0.24457118,0.39070648,0.5082197,0.36087674,0.2885723,0.06478334,0.0,0.019668072,0.12664928,0.37939173,0.83096874,1.0,0.82487893,0.3843494,0.0,0.0,0.0,0.0,0.0,0.0514727,0.0013994277,0.056455784,0.023619764,0.025377408,0.011195049,0.07601422,0.16038221,0.18886302,0.35545808,0.4539135,0.55861866,0.37215266,0.27976608,0.06257866,0.0,0.0,0.058260165,0.29142225,0.7863943,0.9463353,0.7380297,0.26103133,0.0,0.0,0.0,0.0,0.0,0.063815355,0.019125007,0.06253452,0.056607246,0.07314369,0.039732568,0.08088294,0.21690276,0.30301154,0.47191238,0.51241064,0.62064666,0.40673918,0.3201642,0.080429606,0.0,0.0,0.058091737,0.30711907,0.7532382,0.83957916,0.6056757,0.18026909,0.0,0.0,0.0,0.0,0.0,0.07336577,0.037207127],[0.0019688755,0.0,0.0,0.052597545,0.066923834,0.0025153607,0.040542245,0.051017493,0.0,0.0,0.0,0.0,0.12041535,0.50952303,0.8099148,0.81709987,0.47798622,0.23015057,0.0,0.0,0.0,0.033342525,0.0,0.04322154,0.0,0.0,0.0,0.0,0.0,0.0,0.00035779178,0.026624992,0.017617136,0.0,0.04173278,0.067044236,0.0095316395,0.0,0.0,0.06798582,0.26949465,0.5521564,0.7839278,0.72133845,0.41124886,0.160245,0.0,0.0,0.0,0.00062450767,0.0,0.0352291,0.0,0.0,0.0,0.0,0.0,0.0,0.0021417737,0.0005736649,0.0,0.0014070123,0.04024648,0.08926073,0.047023624,0.09455107,0.13467313,0.22357686,0.3683585,0.4936368,0.65826404,0.57750344,0.4089381,0.15376556,0.0,0.0,0.0,0.0,0.0,0.025192462,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01529713,0.034031868,0.14775269,0.19947475,0.29276755,0.33580512,0.30784357,0.37096846,0.3510295,0.44155633,0.4506244,0.50618154,0.30558926,0.06324248,0.0,0.0,0.0,0.0,0.012207426,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.042379543,0.051754266,0.22628146,0.37265337,0.49801445,0.5586941,0.3837853,0.31399184,0.14821656,0.17343396,0.2967422,0.5088111,0.50284535,0.30167454,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.064249985,0.07874684,0.29149663,0.46149153,0.5975251,0.644434,0.4006304,0.2817026,0.026569486,0.029997803,0.20685971,0.49295872,0.6959696,0.7218268,0.37011245,0.09038365,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.082752384,0.10616471,0.33889246,0.50547105,0.6458783,0.6912695,0.4106577,0.27483183,0.016098,0.024703987,0.20010312,0.49787855,0.8629095,1.0,0.66357064,0.23991168,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01013232,0.0,0.0,0.0,0.109474346,0.14758307,0.39014953,0.5558978,0.6781472,0.70267916,0.3877241,0.25216216,0.0,0.010625675,0.1924327,0.5077681,0.9288884,1.0,0.77561533,0.2911675,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0006156117,0.0,0.0,0.0,0.14390625,0.21203232,0.4246571,0.574531,0.664821,0.671943,0.36209038,0.2455284,0.0,0.0,0.1376937,0.46030253,0.939304,1.0,0.8027116,0.2434201,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0057047606,0.040002346,0.0680771,0.23195389,0.33654374,0.5211885,0.607351,0.63415223,0.6054799,0.33099842,0.24722368,0.014542453,0.0,0.07732164,0.42224753,0.9184221,1.0,0.69876975,0.13343132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021093883,0.0784401,0.107113,0.1225808,0.2952188,0.42954683,0.6129778,0.6534972,0.6480178,0.5732305,0.34871936,0.2761705,0.031829983,0.0,0.06905897,0.45519125,0.9101865,1.0,0.543432,0.037887968,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0028030872,0.043605022,0.06365782,0.0,0.03462079,0.0,0.0,0.041816607,0.0,0.0,0.0,0.053922497,0.39343894,0.80010563,1.0,0.96323615,0.5096905,0.07877092,0.0,0.0,0.0,0.0,0.000104919076,0.0,0.0,0.0,0.0,0.047405146,0.0035317987,0.03651733,0.060046926,0.0,0.008863166,0.0,0.0,0.0496061,0.012366988,0.0,0.0053890496,0.12030896,0.37309673,0.7019667,0.9859117,0.84128535,0.4424938,0.070287466,0.0,0.0,0.0,0.0,0.007128954,0.003156647,0.0,0.0,0.0,0.027883366,0.0043251663,0.025847845,0.041092746,0.0,0.0,0.0,0.0028054267,0.068452075,0.06821418,0.10266916,0.14488882,0.18577094,0.33734384,0.5118589,0.726964,0.6586946,0.4326625,0.1793795,0.0,0.0,0.0,0.0,0.036182947,0.017427087,0.0,0.0,0.0,0.013470359,0.0014359951,0.01224675,0.011349104,0.0,0.0,0.0,0.015130512,0.14228809,0.23483637,0.35217637,0.35017604,0.25852185,0.2811214,0.2982179,0.42361224,0.48973995,0.5708673,0.4145165,0.046124563,0.0,0.0,0.0,0.056074336,0.020440511,0.0,0.0,0.0,0.0036785007,0.002502337,0.0033067465,0.0,0.0,0.0,0.0,0.107747555,0.24877326,0.42096698,0.61700267,0.6032083,0.36199823,0.2177865,0.07488124,0.17981862,0.2985261,0.624639,0.6685477,0.30630293,0.014509596,0.0,0.0,0.046041973,0.005443722,0.0,0.0,0.0,0.00020228326,0.0,0.0,0.0,0.0,0.018302575,0.036090054,0.2351807,0.36624914,0.58337784,0.7924355,0.76447004,0.42707062,0.2001063,0.0,0.0957411,0.19768421,0.63675654,0.88684624,0.74093455,0.3311593,0.039229795,0.0,0.033579372,0.0,0.0,0.0,0.001417309,0.0,0.0,0.0,0.0,0.0,0.040315665,0.072470844,0.32860512,0.44432724,0.67277366,0.8848589,0.83626693,0.44685382,0.17966858,0.0,0.09743859,0.12198617,0.6550962,1.0,1.0,0.57332754,0.10419595,0.0,0.03329218,0.0,0.0016951263,0.0,0.002623424,0.0,0.0,0.0,0.0,0.0,0.053177975,0.114526674,0.40819138,0.52207196,0.7535605,0.941841,0.8527632,0.42770463,0.15873736,0.0,0.09315631,0.09030067,0.67997366,1.0,1.0,0.66023517,0.11765666,0.0,0.038369223,0.0,0.008009002,0.0,0.007101789,0.00075778365,0.0,0.0,0.0,0.0,0.083571516,0.1561154,0.46615088,0.5693752,0.7535747,0.8867595,0.78911334,0.39253038,0.15880911,0.0,0.10799502,0.041617617,0.6561713,1.0,1.0,0.68763965,0.089369655,0.0,0.021268897,0.0010904223,0.026222214,0.0,0.01051075,0.0041766465,0.0,0.0,0.0,0.0,0.121556774,0.23979354,0.5344594,0.6353107,0.71356946,0.74039733,0.61751455,0.31351712,0.1490109,0.049139865,0.12188843,0.008172952,0.66343886,1.0,1.0,0.66761965,0.08601087,0.0,0.021939777,0.016527392,0.050211154,0.0,0.013775393,0.003236562,0.0,0.0,0.0,0.0,0.15378109,0.32006007,0.6058094,0.69324213,0.7184768,0.6316154,0.51155,0.28591517,0.13635436,0.03515105,0.10692949,0.009548128,0.7115763,1.0,1.0,0.58636975,0.06448661,0.0,0.026514903,0.02817905,0.04444381,0.0,0.0,0.0],[0.10140626,0.12060095,0.07892834,0.009419188,0.0,0.0,0.0,0.00405927,0.0,0.0,0.0,0.22445357,0.5455992,1.0,1.0,1.0,0.41197473,0.0,0.0,0.0,0.0,0.0,0.019214638,0.07714494,0.022868969,0.0,0.0,0.0,0.057129353,0.09187637,0.075472444,0.040833943,0.0,0.0,0.0,0.0,0.0,0.015839979,0.049404323,0.22305492,0.45958138,0.8393487,1.0,0.89596134,0.36082458,0.0,0.0,0.0,0.0,0.0,0.0024787933,0.06989223,0.017037809,0.0,0.0,0.0,0.017799743,0.04617632,0.043449506,0.036223374,0.0,0.0,0.0,0.0,0.04046998,0.11605744,0.14899862,0.19780819,0.33300903,0.54200107,0.76770735,0.6806448,0.3742698,0.043659292,0.0,0.0,0.0,0.0,0.0015012771,0.05491411,0.017494611,0.0,0.0,0.0,0.0,0.0,0.0,0.0030115396,0.0,0.0,0.0,0.05477783,0.22276229,0.3449629,0.32158434,0.21530853,0.22501358,0.24345222,0.3591435,0.48730797,0.5343142,0.36916882,0.13423349,0.0,0.0,0.0,0.0,0.037459604,0.019047178,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013311237,0.03948333,0.18056439,0.47265732,0.6440674,0.52513784,0.27853423,0.12994911,0.019817851,0.050091133,0.31370682,0.6548673,0.7492081,0.4346075,0.0,0.0,0.0,0.0,0.015739903,0.019034281,0.0,0.0005674958,0.006144412,0.0,0.0,0.0,0.0,0.0,0.11256998,0.18238372,0.370502,0.69191235,0.9009306,0.7035067,0.3650586,0.14717473,0.0,0.0,0.21456203,0.6750984,0.9988649,0.8354295,0.27065438,0.0,0.0,0.0,0.0,0.017011493,0.0,0.0045219213,0.017956994,0.0,0.0,0.0,0.0,0.0,0.18140936,0.28197643,0.48844516,0.8034981,1.0,0.7913079,0.38559335,0.14725426,0.0,0.0,0.14529277,0.6908804,1.0,1.0,0.49669933,0.059255503,0.0,0.022879235,0.026989587,0.046536595,0.0021753758,0.0049536973,0.02567581,0.0,0.0,0.0,0.0,0.013148427,0.24437463,0.364484,0.5708968,0.88196903,1.0,0.8048478,0.36562198,0.14406516,0.0,0.0,0.13272789,0.6818864,1.0,1.0,0.59321314,0.085266754,0.0,0.03505464,0.04795696,0.062475793,0.0064844936,0.01143229,0.030870646,0.0,0.0,0.0,0.0,0.026478767,0.27736259,0.43177146,0.6055053,0.8500121,1.0,0.73386836,0.33705473,0.18479082,0.016447172,0.0,0.114383824,0.66188854,1.0,1.0,0.63607574,0.090086,0.0,0.049714535,0.06346541,0.07780519,0.016631618,0.017372452,0.030174427,0.0,0.0,0.0,0.0,0.0401166,0.31682563,0.50666845,0.6144958,0.767333,0.8415499,0.60962224,0.28459597,0.22245461,0.04536411,0.0,0.13319261,0.7233293,1.0,1.0,0.63682824,0.10179235,0.0,0.06963734,0.09177001,0.098923445,0.026886195,0.024931833,0.025213383,0.0,0.0,0.0,0.0,0.08169678,0.3931163,0.5794288,0.6342904,0.7514578,0.7754623,0.5599798,0.27916977,0.23521492,0.043302782,0.0,0.16891673,0.8096458,1.0,1.0,0.58699894,0.08740537,0.0,0.07674639,0.11292903,0.09657964,0.008743137,0.006093532,0.0121901035],[0.071062654,0.06769742,0.03755343,0.0,0.0,0.0,0.0006981939,0.0,0.0,0.078707576,0.07603569,0.30778283,0.56637555,1.0,1.0,0.92301154,0.029596329,0.0,0.0,0.0,0.0,0.0,0.06075137,0.0,0.0,0.011654988,0.011048533,0.0,0.02584327,0.036954008,0.04073841,0.0,0.0,0.0,0.0,0.0,0.019212514,0.08295521,0.075446844,0.23328191,0.4297704,0.892454,1.0,0.8066635,0.09764951,0.0,0.0,0.0,0.0,0.0,0.020331629,0.0,0.0,0.008163288,0.020387508,0.0012257695,0.0,0.0007185489,0.015051797,0.0,0.0,0.0,0.0,0.008792184,0.10778087,0.1856062,0.14930259,0.16529772,0.29162753,0.5753568,0.7582772,0.63228536,0.2584746,0.054344036,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0118571,0.020512462,0.007050194,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06406383,0.28245252,0.40620035,0.32042342,0.15497172,0.17549631,0.26081023,0.40830255,0.48460537,0.53899056,0.43323982,0.13136862,0.0,0.0,0.0,0.0,0.0021575987,0.0030017346,0.030017585,0.01783488,0.0074629113,0.0,0.0,0.0,0.0,0.0,0.0,0.051069804,0.22443151,0.5329707,0.66318345,0.49101353,0.15855041,0.053497545,0.05450557,0.111499004,0.304156,0.70584816,0.81416065,0.35359693,0.0,0.0,0.0,0.0,0.020725787,0.043266244,0.039210252,0.022632658,0.013246797,0.0,0.0,0.0,0.0,0.0,0.064253904,0.2184003,0.47172517,0.76830876,0.8725805,0.62652934,0.18557897,0.003980845,0.010306835,0.0,0.18353768,0.6992617,0.9974964,0.6602141,0.14305389,0.0,0.0,0.0018434227,0.024658158,0.06961731,0.033563294,0.042960733,0.02214814,0.0,0.0,0.0,0.0,0.0,0.12516874,0.33778793,0.6329025,0.92465115,1.0,0.7008482,0.17170861,0.0,0.0,0.0,0.097718306,0.6921447,1.0,0.8600979,0.3248775,0.0,0.0007196516,0.02742327,0.043330297,0.0761497,0.021840274,0.046241418,0.025994316,0.0,0.0,0.0,0.0,0.0,0.18952356,0.42416275,0.72568023,1.0,1.0,0.7219258,0.16552693,0.0,0.0,0.0,0.07102758,0.6711467,1.0,0.9523285,0.4139747,0.004232943,0.0014134049,0.043712273,0.05798371,0.081428416,0.022871219,0.046018377,0.032993168,0.0,0.0,0.0,0.0,0.0,0.2384723,0.49779344,0.75312835,0.97797245,0.97289956,0.63986874,0.17797238,0.0,0.026410617,0.0,0.062361114,0.67093074,1.0,1.0,0.47660196,0.028688177,0.02461911,0.06251492,0.074321866,0.08303708,0.016895235,0.04435151,0.029640876,0.0,0.0,0.0,0.0,0.0,0.29377618,0.5526566,0.71544397,0.82805717,0.79604024,0.500407,0.20266655,0.0,0.035310373,0.0,0.0917076,0.7571384,1.0,1.0,0.5130507,0.072182715,0.06621088,0.08804713,0.11143723,0.10148174,0.01395192,0.044822358,0.020186022,0.0,0.0,0.0,0.0,0.039506838,0.36494565,0.5866676,0.6934958,0.74899274,0.7385775,0.4504338,0.23958912,0.0,0.025441766,0.0,0.13108547,0.85847664,1.0,1.0,0.5243563,0.11129488,0.09289572,0.11029856,0.1409596,0.11142763,0.0056785047,0.035920978,0.0075079873],[0.06764711,0.08239159,0.042786516,0.0,0.0,0.0,0.0,0.042818815,0.019750684,0.058550693,0.16702019,0.33515096,0.69746655,1.0,1.0,0.7030227,0.12932485,0.0,0.0,0.0,0.0,0.020411454,0.035395533,0.0,0.0,0.0,0.019267738,0.025611244,0.026875064,0.06371271,0.04934644,0.0,0.0,0.0,0.0,0.026660286,0.02331601,0.06008239,0.1535449,0.22399218,0.5007308,0.91123414,1.0,0.6755165,0.15717429,0.0,0.0,0.0,0.0,0.017162636,0.024800785,0.0,0.0,0.0,0.015520483,0.02103009,0.0,0.027596168,0.026073627,0.0,0.0,0.0,0.0,0.03707371,0.10193277,0.17505,0.23687783,0.17862225,0.33305854,0.6024176,0.77312815,0.5820003,0.27735168,0.099780895,0.020480692,0.0,0.0,0.0015868098,0.019500807,0.0,0.0,0.0,0.0073459595,0.015390843,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.088684596,0.28129953,0.42005157,0.3901825,0.18497537,0.20200264,0.29413056,0.46004307,0.49715698,0.54738915,0.4247958,0.17949131,0.0,0.0,0.0015523285,0.029790603,0.0,0.0,0.0,0.0036855787,0.012503728,0.0,0.0,0.0,0.0,0.0,0.0,0.012748286,0.24557544,0.5407142,0.6487499,0.48293746,0.19629163,0.11805843,0.08625747,0.18322833,0.4814899,0.7776898,0.7348415,0.30181736,0.0,0.0,0.015428774,0.054290257,0.001511991,0.010229386,0.024492264,0.01511322,0.020974815,0.0,0.0,0.0,0.0016095489,0.0,0.08424453,0.18757586,0.5183806,0.8003533,0.8324012,0.5528225,0.20344898,0.07967192,0.0,0.0,0.39359355,0.80851704,0.9230296,0.51702315,0.08923892,0.0,0.008517973,0.063335374,0.03559999,0.05798036,0.05624453,0.032367237,0.027534612,0.0,0.0078078285,0.0,0.0025598705,0.0,0.16676423,0.32642314,0.7330234,1.0,0.97600174,0.59462386,0.184474,0.046393894,0.0,0.0,0.316171,0.81718326,1.0,0.67212385,0.19791079,0.0,0.0,0.053134777,0.050098255,0.09459573,0.069537364,0.03968302,0.026498303,0.0,0.024169274,0.0,0.019122876,0.028223999,0.23817733,0.40608156,0.8518957,1.0,1.0,0.6203023,0.19353727,0.058335833,0.0,0.0,0.28167075,0.7839513,1.0,0.7526447,0.28288996,0.04584664,0.0,0.066632785,0.06515279,0.09315072,0.06506015,0.039256677,0.025126368,0.0,0.034018315,0.0,0.028366901,0.053265132,0.30894333,0.4800586,0.90313554,1.0,1.0,0.6118856,0.23177579,0.09630665,0.0,0.0,0.21863528,0.75536895,1.0,0.83143836,0.36584112,0.10576559,0.0060580447,0.07512543,0.064183764,0.086912274,0.063286304,0.038075134,0.02534493,0.0,0.030153595,0.0,0.03216915,0.06336545,0.36711746,0.52209234,0.90447855,1.0,0.92958575,0.59706193,0.28530586,0.14583258,0.0,0.0,0.18685858,0.7923656,1.0,0.9164592,0.42137897,0.15824173,0.043466993,0.101803064,0.07098248,0.07599765,0.059643485,0.03971351,0.02958943,0.0,0.011090629,0.0,0.046082065,0.09590949,0.41400826,0.5360239,0.8921604,1.0,0.9358009,0.63973576,0.3605979,0.17910716,0.0,0.0,0.1600307,0.8245672,1.0,0.9693254,0.4488263,0.20198989,0.08451729,0.14589621,0.104339,0.06689486,0.046886742,0.03284908,0.031323403],[0.068301894,0.030965604,0.035529345,0.0,0.0,0.0,0.0,0.0,0.034963667,0.04361341,0.11637145,0.22952676,0.4768899,0.9229269,1.0,0.5399714,0.076608986,0.0,0.030253425,0.0,0.015008651,0.04568085,0.013932347,0.0,0.0,0.035194933,0.09913668,0.0,0.021573193,0.011804856,0.029711671,0.0,0.0,0.0,0.0,0.0049110353,0.045466796,0.074156016,0.11633887,0.2121791,0.41451544,0.8691107,0.9986013,0.581984,0.13902539,0.008921251,0.011494942,0.0,0.008751504,0.06640319,0.019705981,0.0,0.0,0.033735365,0.09270567,0.0,0.0,0.0,0.011426173,0.0,0.0,0.0,0.0,0.043205313,0.12144886,0.20963562,0.23018812,0.27927402,0.33623248,0.7060164,0.8237659,0.59097314,0.2742784,0.1803562,0.062171407,0.0,0.03684199,0.068252146,0.034087352,0.0,0.0,0.026803076,0.07141636,0.0,0.0,0.0,0.009880476,0.0,0.0,0.0,0.0,0.10954103,0.28990763,0.47307068,0.41215646,0.3648134,0.32457346,0.513459,0.59410715,0.63999677,0.5383183,0.42698985,0.16963594,0.023452662,0.046383753,0.08312605,0.059930325,0.011832148,0.0040165484,0.022337772,0.056052767,0.0,0.0,0.0,0.018634431,0.0,0.0,0.0,0.0184092,0.25959182,0.5076009,0.7349697,0.53962594,0.41292208,0.33768445,0.35317838,0.43282282,0.6904349,0.8308018,0.72800463,0.28932586,0.045164496,0.03280039,0.10740689,0.09629226,0.030811302,0.04397726,0.035574578,0.061098084,0.014251843,0.0,0.0,0.03360629,0.0,0.005102545,0.096431166,0.18485147,0.48190087,0.73459566,0.9640254,0.62885106,0.46603578,0.37546688,0.22844283,0.3224783,0.6182098,0.97658336,0.9903499,0.52622455,0.1692279,0.027779236,0.07513903,0.124331035,0.047760017,0.08352099,0.059858,0.06793404,0.036950484,0.0,0.0,0.04798586,0.0,0.027683645,0.17687462,0.3310459,0.6802156,0.92646146,1.0,0.6878763,0.4817449,0.40361965,0.13010228,0.23364574,0.5403929,1.0,1.0,0.7060577,0.28099704,0.04121487,0.037240528,0.1376571,0.06346243,0.11534553,0.071147665,0.055433027,0.04334955,0.0,0.0,0.05588662,0.0,0.0681051,0.23163489,0.4139772,0.78349596,1.0,1.0,0.73771375,0.51927286,0.44355553,0.117474996,0.2051585,0.47616512,1.0,1.0,0.81079686,0.37649268,0.084382206,0.05174073,0.14411244,0.07003254,0.122211635,0.06973998,0.054743327,0.046220787,0.0,0.0,0.05625081,0.0,0.089328766,0.28202596,0.5027684,0.87208635,1.0,1.0,0.747665,0.57316375,0.48748863,0.10325124,0.14657845,0.4160866,1.0,1.0,0.89766175,0.48101342,0.14127293,0.07446426,0.13799709,0.07242413,0.114760235,0.07557446,0.072505854,0.06667871,0.0,0.0,0.04575222,0.0,0.08437138,0.30475736,0.568669,0.9284939,0.9780594,1.0,0.7523801,0.6288197,0.5022065,0.09043415,0.083388455,0.40419805,1.0,1.0,0.9579359,0.5560875,0.20145541,0.14668277,0.17200944,0.08028662,0.10493008,0.084493645,0.10635264,0.093918376,0.0,0.0,0.023063138,0.0,0.10167346,0.32106107,0.59579045,0.97579455,0.9791353,1.0,0.7948959,0.6895185,0.4952371,0.09598492,0.033620983,0.38994694,1.0,1.0,0.98348415,0.59512633,0.24643543,0.22223297,0.22481754,0.11497857,0.10512407,0.08115249,0.12764235,0.11075924],[0.0,0.013933636,0.0008992255,0.0,0.0,0.02292908,0.0,0.0,0.05272396,0.020726241,0.0,0.07732069,0.28721327,0.70947,0.7490101,0.44673282,0.13985007,0.109138995,0.11618708,0.0,0.04093326,0.10748525,0.0,0.0,0.0,0.049881376,0.03471513,0.0,0.0,0.01068607,0.0072705224,0.0,0.0,0.0,0.0,0.0,0.07259126,0.06362656,0.014489397,0.108332075,0.29225725,0.76878554,0.8532786,0.5936299,0.22536731,0.14591,0.11276357,0.0,0.023488902,0.103405125,0.009617075,0.01894395,0.0,0.033309743,0.021990784,0.0,0.0,0.0,0.0041113496,0.0,0.0,0.0,0.0066089407,0.0,0.118822,0.17077929,0.17862976,0.19761164,0.29725915,0.627069,0.74086475,0.59736955,0.40055442,0.31850088,0.196866,0.0,0.04809656,0.10953462,0.04311067,0.023931764,0.0,0.0033158362,0.0037907958,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01654882,0.03551931,0.2487151,0.3662901,0.36615402,0.32929343,0.35688537,0.51537895,0.60658777,0.57179314,0.6129328,0.51488936,0.29971188,0.0,0.06745929,0.11375851,0.06950242,0.030112147,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06471697,0.17516586,0.48397428,0.6530453,0.5833781,0.49205267,0.4407959,0.4488315,0.4958412,0.5903071,0.82095736,0.70933723,0.38623595,0.025494158,0.09388432,0.1237877,0.10561028,0.062672354,0.034026742,0.04475691,0.01882124,0.0,0.0,0.0,0.0015390813,0.0,0.0,0.015603803,0.18373607,0.38867003,0.7533969,0.96008515,0.8125656,0.67349577,0.5374991,0.34768623,0.33977485,0.5218928,0.94568074,0.91570073,0.54387736,0.13746181,0.11818054,0.10694997,0.13672635,0.10821114,0.12783726,0.13086317,0.06258907,0.014595777,0.0,0.0,0.0,0.0,0.0,0.07394816,0.32947624,0.62973624,1.0,1.0,0.9584736,0.7741699,0.58036655,0.27009124,0.2101202,0.44236404,1.0,1.0,0.68281054,0.2339859,0.14131732,0.10220192,0.16754499,0.1463025,0.20818526,0.20635025,0.09546652,0.028145328,0.0,0.0,0.0,0.0,0.0,0.109564885,0.3941393,0.74503624,1.0,1.0,1.0,0.84689814,0.6154801,0.2667136,0.16900937,0.39962673,1.0,1.0,0.809556,0.3443104,0.19367254,0.11563335,0.17526072,0.15577191,0.21886759,0.22743225,0.10632408,0.03275983,0.0,0.0,0.0,0.0,0.0,0.15240759,0.47920412,0.84051853,1.0,1.0,1.0,0.9247799,0.67101747,0.3041247,0.16784772,0.36793363,1.0,1.0,0.92064506,0.47157097,0.25914693,0.11696865,0.17410381,0.15752421,0.23175201,0.25517303,0.12830757,0.043711223,0.0,0.0,0.0,0.0,0.0,0.17979775,0.5550711,0.943931,1.0,1.0,1.0,0.97375846,0.713159,0.37199384,0.1986826,0.38143307,1.0,1.0,0.9886028,0.5737971,0.36732545,0.17105916,0.2084913,0.17195201,0.25054568,0.28682816,0.15494354,0.06073577,0.0,0.0,0.0,0.0,0.0,0.19198123,0.58515155,1.0,1.0,1.0,1.0,1.0,0.7545653,0.44781786,0.23985985,0.3632848,1.0,1.0,1.0,0.61471933,0.47523433,0.25337052,0.25902754,0.19639435,0.26339215,0.3167621,0.1795241,0.07686199],[0.008836344,0.0,0.01926747,0.0,0.0038211495,0.024553813,0.04886341,0.0,0.0,0.0,0.0,0.0,0.11736454,0.5716446,0.47859013,0.33236945,0.21582314,0.28583556,0.22480021,0.009421974,0.04390651,0.0,0.0,0.0,0.0,0.018716022,0.0,0.0,0.0,0.0,0.023776338,0.0,0.0,0.0,0.028915234,0.0,0.0,0.0,0.019101538,0.01953531,0.16112046,0.64265,0.61341536,0.4798414,0.27167672,0.3074116,0.1832084,0.0,0.0,0.0,0.0,0.008614287,0.0,0.007952459,0.004191324,0.0,0.0,0.0,0.022637501,0.0,0.0,0.0,0.02094885,0.0,0.0,0.054319903,0.15773395,0.11802192,0.18965481,0.52151316,0.53835,0.51866466,0.39741206,0.42706186,0.20194408,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014107473,0.0,0.0,0.0,0.007876389,0.031194583,0.11360724,0.21223514,0.31856608,0.2641223,0.26728576,0.43312383,0.46229935,0.53560036,0.58157164,0.56062496,0.22712956,0.005236298,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011629589,0.0,0.0,0.0,0.03276717,0.14881304,0.34848064,0.47689652,0.51145184,0.42332917,0.3458872,0.364596,0.40800118,0.5779098,0.753938,0.6709372,0.2724415,0.048885666,0.0,0.0019504577,0.0,0.0,0.05157499,0.044937707,0.027320012,0.0,0.0,0.0,0.01818356,0.0,0.0,0.04113789,0.107923135,0.31709647,0.6118666,0.75855666,0.7259149,0.6062739,0.42598075,0.29191872,0.2885886,0.54243463,0.8571225,0.8131938,0.4032464,0.10885694,0.0,0.0063791797,0.0,0.030815065,0.13270925,0.13393125,0.083694205,0.0016321391,0.0,0.0024872124,0.019389272,0.0,0.0,0.08655764,0.24156117,0.55798334,0.868362,0.97414523,0.8725125,0.7148955,0.46012402,0.22599109,0.17924175,0.48306388,0.89368075,0.9297331,0.53444064,0.16609818,0.018733881,0.023451284,0.0,0.068784565,0.21488069,0.21015075,0.12745033,0.01536002,0.0,0.0,0.02035068,0.0,0.0,0.10060379,0.2990641,0.6677206,1.0,1.0,0.9828338,0.7887346,0.48650187,0.21123001,0.13139255,0.43631452,0.90146106,1.0,0.6983038,0.28010964,0.093048245,0.032410182,0.0,0.071287274,0.22767639,0.23867123,0.14438125,0.016924463,0.0,0.0,0.02093397,0.0,0.0,0.112225614,0.35894504,0.7603027,1.0,1.0,1.0,0.92068726,0.57271105,0.24752156,0.13511166,0.38938612,0.87686473,1.0,0.87090564,0.42280895,0.18488662,0.0455798,0.0,0.07156212,0.24783698,0.25913975,0.1443992,0.021864146,0.0,0.0,0.022530265,0.0,0.0,0.10619481,0.41107666,0.8375688,1.0,1.0,1.0,1.0,0.69608754,0.34639078,0.21094096,0.4039384,0.8916696,1.0,1.0,0.5711242,0.34812164,0.15342759,0.04708235,0.10489157,0.28114724,0.2762925,0.13908887,0.03327614,0.0,0.0,0.028726704,0.0,0.0,0.091724515,0.42150664,0.885466,1.0,1.0,1.0,1.0,0.82347745,0.4492044,0.25831395,0.37569785,0.8736351,1.0,1.0,0.69837224,0.5126536,0.301723,0.16949424,0.16291595,0.33041677,0.3070971,0.15066284,0.051072255],[0.0,0.0,0.039070807,0.0577603,0.06665198,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05833132,0.25315082,0.26971447,0.24393737,0.2659918,0.2288929,0.22163919,0.09251503,0.08153133,0.075377375,0.0,0.07514067,0.016339108,0.049863093,0.011310928,0.026367411,0.0,0.0,0.022487849,0.04710623,0.050535984,0.0,0.0,0.0,0.01395569,0.0,0.027897522,0.024761923,0.07718487,0.3319425,0.38304693,0.39668328,0.3787573,0.27476168,0.20449227,0.010460436,0.0034424067,0.039859153,0.0,0.067257926,0.014687747,0.052365743,0.011623129,0.01705563,0.0,0.0,0.0076118335,0.036252573,0.03366358,0.0,0.0,0.0,0.015148528,0.0,0.06683183,0.04323774,0.06466665,0.22801772,0.34799504,0.42492527,0.53019303,0.39610457,0.23442179,0.0,0.0,0.012018591,0.0,0.055437163,0.016738161,0.04331118,0.0062870607,0.003584087,0.0,0.0,0.0,0.012988836,0.01107996,0.0,0.0,0.0,0.051280186,0.06451501,0.11371656,0.09075612,0.08840088,0.15221538,0.2962289,0.43850917,0.6659285,0.5273482,0.26260966,0.0,0.0,0.0,0.001455754,0.046273425,0.01407481,0.024286464,0.0,0.0,0.0,0.0,0.0,0.0024545044,0.0,0.0,0.0,0.051342495,0.19317451,0.23430121,0.20213838,0.16245055,0.12810786,0.117176555,0.28571585,0.5036773,0.78212255,0.6164249,0.2582553,0.009890467,0.0,0.002710089,0.031053558,0.08336898,0.047612585,0.035837457,0.0,0.0,0.008834586,0.0,0.0,0.0,0.0,0.007559657,0.05114892,0.15952715,0.34301868,0.40454435,0.28353453,0.25242245,0.1779989,0.09168166,0.24187908,0.52116936,0.8112338,0.65931875,0.248547,0.03154877,0.0,0.0,0.06150218,0.15528055,0.12213031,0.09393222,0.006050043,0.018544331,0.018313035,0.0,0.0,0.0,0.0,0.035598442,0.15329085,0.32531843,0.5037699,0.5361554,0.34418023,0.30295408,0.19980893,0.046917327,0.1715206,0.49487364,0.8106895,0.7065451,0.28501034,0.064705744,0.0,0.0,0.08866292,0.20986299,0.1895278,0.1378872,0.02302204,0.02993533,0.024283677,0.0,0.0,0.0,0.0,0.035323292,0.19040482,0.40860665,0.60400885,0.6244332,0.41206282,0.3477684,0.22869092,0.042030826,0.12491626,0.45617718,0.8262468,0.8453451,0.45747805,0.17359225,0.016078264,0.0,0.103843376,0.2334541,0.21639168,0.14986469,0.025424771,0.024913661,0.03272911,0.0,0.0,0.0,0.0,0.040615857,0.22372669,0.45815963,0.65291315,0.70925397,0.52908814,0.49564862,0.32255432,0.09635526,0.098232165,0.41881365,0.8610569,1.0,0.6935382,0.31686407,0.068292186,0.027377322,0.13868311,0.2469602,0.23006532,0.15356073,0.026360057,0.030056909,0.04172457,0.0,0.0,0.0,0.0,0.05155097,0.24189878,0.4795876,0.70216537,0.8086324,0.69250077,0.71242094,0.46660668,0.18514241,0.12742378,0.4562351,0.9842633,1.0,0.9422909,0.49408758,0.21786603,0.17422256,0.23801474,0.27144295,0.23471206,0.14903443,0.026743814,0.04599902,0.04918447,0.0,0.0,0.0,0.0,0.02904328,0.23498712,0.4826693,0.7754796,0.91405755,0.8768576,0.93487304,0.6131926,0.2599845,0.13709563,0.47235268,1.0,1.0,1.0,0.6985423,0.41653913,0.36525273,0.33282685,0.32944885,0.2657488,0.16280499,0.042436577,0.065160796],[0.0,0.0,0.0515481,0.046056725,0.078029305,0.0,0.0,0.041404627,0.029029384,0.00914596,0.055988774,0.0,0.19312648,0.18462396,0.19381262,0.22798608,0.19150576,0.3181102,0.26864633,0.258884,0.17199127,0.039771043,0.0,0.0,0.06958188,0.057581313,0.0,0.03432838,0.0,0.0,0.031461775,0.02435571,0.052101776,0.0,0.0,0.06309315,0.02214016,0.06108757,0.065556616,0.0,0.15633436,0.20470941,0.25720504,0.35611588,0.31664097,0.35909957,0.2610136,0.14371058,0.09177981,0.024118543,0.009866148,0.0,0.06191597,0.055763744,0.0,0.032138832,0.0,0.0,0.009264998,0.013877459,0.038566753,0.0,0.0,0.0545919,0.009412289,0.04863391,0.046085566,0.0,0.06902953,0.11516682,0.2289527,0.41648722,0.49908465,0.4539581,0.26141346,0.08088212,0.058630466,0.0,0.0057073757,0.0,0.060660407,0.050181776,0.0,0.027510308,0.0,0.0,0.0,0.0,0.022111498,0.0,0.0,0.03275588,0.007986955,0.0317569,0.04347069,0.0,0.005677402,0.02324003,0.17932135,0.45625347,0.6555033,0.5349361,0.25647002,0.039895773,0.013077259,0.0,0.0027670264,0.0,0.05028379,0.026434876,0.0,0.02931773,0.0,0.0,0.0,0.0,0.014064588,0.0,0.0,0.030225247,0.05647198,0.06318246,0.051943764,0.0,0.0,0.0,0.16430788,0.5303457,0.7662964,0.56024325,0.24264777,0.0300631,0.0,0.0,0.00564,0.010170475,0.06125789,0.0,0.0042442232,0.041831203,0.004182294,0.0,0.0,0.0,0.009162948,0.014293149,0.0,0.05272294,0.1063322,0.08634809,0.03985227,0.01533214,0.0,0.0,0.13811205,0.5375026,0.765475,0.4984005,0.1962443,0.009783514,0.0,0.0,0.011721559,0.061461948,0.12216781,0.013690084,0.027723797,0.06052511,0.009834968,0.0,0.0,0.0,0.010424279,0.03229946,0.04590156,0.11986174,0.17327698,0.11182307,0.039288305,0.027641349,0.0,0.0,0.071054965,0.50983787,0.7701992,0.50090593,0.2130232,0.025073335,0.0,0.0,0.030351326,0.107840955,0.17321905,0.026035562,0.032209933,0.06930168,0.014635466,0.0,0.0,0.0,0.011598334,0.029126994,0.06158389,0.1653193,0.21390945,0.14444804,0.06268517,0.05307295,0.0,0.0,0.0,0.43751705,0.80919147,0.6597165,0.3820613,0.12451399,0.0,0.0,0.04996776,0.13298956,0.19821545,0.03534548,0.025753096,0.063734576,0.022427723,0.0010457635,0.0,0.0,0.013158388,0.016520455,0.05811809,0.19760549,0.23468219,0.19813515,0.16427618,0.156699,0.018646307,0.0,0.0,0.38388532,0.89609474,0.90895444,0.6234929,0.2650106,0.0,0.035984628,0.07932283,0.16347994,0.2118374,0.035167962,0.024745792,0.07304756,0.03338919,0.019865982,0.0,0.0,0.021867141,0.0,0.04228683,0.2415899,0.26398993,0.28350353,0.34520566,0.32933623,0.15344183,0.0,0.0,0.44876152,1.0,1.0,0.92640674,0.44906783,0.10291508,0.18819724,0.15956973,0.21037698,0.22305563,0.030107416,0.030154862,0.09590523,0.042400837,0.030632451,0.0,0.0,0.027385987,0.0,0.018673755,0.28901958,0.31458932,0.3825078,0.55672073,0.5077566,0.27572858,0.0,0.0,0.50065523,1.0,1.0,1.0,0.6989812,0.3175,0.3521846,0.23999438,0.28278768,0.26433158,0.05055953,0.04749065,0.113975406],[0.0,0.0,0.0,0.033777438,0.0,0.0,0.042719476,0.04650183,0.06920619,0.04783213,0.049747862,0.086096674,0.10758511,0.16415514,0.2194736,0.22073373,0.44120836,0.5791611,0.41711038,0.32482892,0.18460485,0.06040121,0.046049535,0.041234784,0.06505808,0.04002355,0.057827257,0.03046865,0.0,0.0,0.0,0.027804762,0.0,0.0,0.05716715,0.05611547,0.06670767,0.07027733,0.04576637,0.060285695,0.03800834,0.1122445,0.20832224,0.28972793,0.5361817,0.60312855,0.36413065,0.1983456,0.09738068,0.037811205,0.057956852,0.03957796,0.06566133,0.0417846,0.056960993,0.022725374,0.0,0.0,0.0000072568655,0.031769976,0.002987042,0.021050155,0.06790809,0.055942483,0.047043197,0.049701236,0.010014243,0.026516005,0.0,0.06208671,0.19578373,0.38899332,0.6756289,0.6516744,0.33031082,0.064377256,0.006321177,0.0,0.04063838,0.028586313,0.05863425,0.04147634,0.052260213,0.015510768,0.0,0.0,0.013428979,0.020299934,0.0,0.027363248,0.061771072,0.031300552,0.021530725,0.009194382,0.0,0.0,0.0,0.0047335476,0.17025141,0.45572394,0.7648946,0.6373526,0.30003196,0.0031213015,0.0,0.0,0.026447289,0.016679332,0.0443141,0.029869765,0.038487934,0.013688944,0.0,0.0,0.026821986,0.0033485144,0.0,0.022827625,0.054743327,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18046908,0.51696736,0.7751609,0.55756754,0.25692832,0.0,0.0,0.0,0.023965843,0.0,0.012807876,0.008519232,0.020097017,0.019072287,0.0025366396,0.007344544,0.03947349,0.0,0.0,0.021080546,0.042045973,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17570311,0.46608096,0.5945288,0.33206624,0.15202925,0.0,0.0,0.0,0.046780877,0.0,0.0011674613,0.012558192,0.029618159,0.0398978,0.009856164,0.017283611,0.04436464,0.0,0.0,0.02029901,0.03882478,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13222548,0.40245074,0.4999413,0.24680448,0.13687947,0.0,0.0,0.0,0.06941253,0.0,0.0,0.008269057,0.03817448,0.06302733,0.017627575,0.018905558,0.0385048,0.0,0.0,0.01705511,0.037097745,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.029705837,0.31863916,0.52443725,0.37278932,0.27720195,0.020266213,0.000259161,0.0009084046,0.07604456,0.0,0.0,0.0031453222,0.03630563,0.07018596,0.030744605,0.030509055,0.044091135,0.0,0.0,0.015086137,0.040205605,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29065102,0.6432503,0.59747785,0.49638736,0.12848878,0.030204013,0.030404255,0.105266534,0.031210706,0.0,0.016515993,0.038780488,0.07312441,0.049233004,0.04829383,0.052404933,0.0,0.0,0.016453259,0.04384443,0.0,0.0,0.0,0.08792935,0.06312649,0.0,0.0,0.0,0.44192016,0.95761925,0.9805378,0.79203504,0.27318758,0.10907857,0.09909155,0.15629216,0.087725,0.021068737,0.054664396,0.058456488,0.07884912,0.06400303,0.06142164,0.058015004,0.0,0.0,0.033990584,0.060870312,0.0,0.051719375,0.11104087,0.23179175,0.15936859,0.0,0.0,0.0,0.5231209,1.0,1.0,1.0,0.5338045,0.26430583,0.18139903,0.1813055,0.13364013,0.057277553,0.10727476,0.08703813,0.07858737],[0.0,0.0,0.0,0.0,0.0045218766,0.020601578,0.0,0.0,0.0,0.034470193,0.032086916,0.0,0.11919515,0.19534637,0.14902043,0.20462224,0.34861493,0.50650615,0.41394228,0.3714705,0.2903642,0.24155653,0.15302415,0.04013382,0.036830924,0.0,0.048083924,0.0,0.0,0.0,0.0,0.0,0.0,0.020856075,0.0,0.0019029975,0.0,0.012349479,0.016238965,0.0,0.06491926,0.08702594,0.11410863,0.24928138,0.43433535,0.53383803,0.3444152,0.26235625,0.23282777,0.23197514,0.13220099,0.025566496,0.034644455,0.0021752715,0.033925228,0.0,0.0019515306,0.0,0.0,0.0,0.0,0.02514749,0.0,0.01519753,0.0,0.0,0.000116571784,0.0,0.021892577,0.029290304,0.1704342,0.3777207,0.6026716,0.578061,0.27521712,0.11675106,0.10726379,0.142458,0.07673642,0.0,0.036961727,0.013237871,0.027469605,0.0,0.003699407,0.0,0.0,0.0,0.0,0.032557257,0.0,0.012176067,0.0008029938,0.0,0.0,0.0,0.0,0.0,0.19214642,0.47489482,0.7041394,0.552734,0.2407158,0.031811662,0.04044751,0.06564684,0.019286476,0.0,0.027577378,0.014608651,0.02573485,0.0,0.007357508,0.0,0.0,0.0,0.0,0.04026963,0.0,0.0,0.027320407,0.0,0.0,0.0,0.0,0.0,0.23656611,0.5474586,0.72687054,0.4903428,0.20790145,0.0,0.0120566115,0.01847209,0.0,0.0,0.0,0.0048036277,0.018487915,0.0045199245,0.0070154592,0.011659898,0.0075516477,0.0,0.0,0.03900443,0.0,0.0,0.057273693,0.0,0.0,0.0,0.0,0.0,0.23561913,0.49500185,0.54234475,0.312314,0.13356738,0.0,0.015041031,0.023414463,0.0,0.0,0.0,0.029358573,0.04669609,0.03577637,0.009070687,0.025200658,0.023436688,0.0,0.0,0.037730806,0.0,0.0,0.07616183,0.0,0.0,0.0,0.0,0.0,0.17917222,0.427122,0.43682873,0.2382002,0.10206235,0.0,0.033032633,0.041385174,0.018572211,0.0,0.0,0.04545106,0.07817764,0.06867407,0.014197588,0.02986671,0.01980494,0.0,0.0,0.03805145,0.0,0.0,0.079321966,0.0,0.0,0.0,0.0,0.0,0.07462776,0.35638875,0.4862845,0.3526885,0.1899836,0.0,0.028481074,0.05100953,0.02428379,0.005614385,0.0,0.04870172,0.092986375,0.0861247,0.021993585,0.04212156,0.019020021,0.0,0.0,0.028969467,0.0,0.0,0.08695687,0.0,0.0,0.0,0.0,0.0,0.0,0.32615614,0.593785,0.5545322,0.34458834,0.03051924,0.053671367,0.08109258,0.048781395,0.023173079,0.0,0.05269418,0.08587672,0.077575445,0.02513133,0.051887862,0.010629043,0.0,0.0,0.017152578,0.0,0.0,0.11387102,0.03292162,0.045782425,0.0,0.0,0.0,0.044696532,0.43424737,0.8478541,0.86451906,0.549475,0.17031753,0.13030072,0.14571354,0.094994515,0.051637158,0.0,0.06692496,0.07123655,0.05225081,0.02499485,0.054163367,0.0023366958,0.0,0.0,0.016286328,0.0,0.0039871633,0.14095567,0.107708395,0.11567177,0.0,0.0,0.0,0.046762437,0.47163147,1.0,1.0,0.86042523,0.43698263,0.26544756,0.20289792,0.11286043,0.080008544,0.014024138,0.0930724,0.061586186,0.022821307],[0.0,0.01302883,0.019465148,0.0,0.0,0.0,0.0,0.016764678,0.095011,0.0,0.04735917,0.042236015,0.050799474,0.0317899,0.058911227,0.26816165,0.5548646,0.64818424,0.5092912,0.33984628,0.2670917,0.1741141,0.14527787,0.058168292,0.0494608,0.017813109,0.051399007,0.045041747,0.0,0.015250333,0.01380685,0.0,0.0,0.0,0.0,0.041546226,0.07588237,0.0,0.025987722,0.0,0.0,0.0,0.0,0.26348114,0.56624067,0.60764486,0.45936394,0.29626703,0.21226089,0.1521075,0.10794416,0.022817478,0.02432423,0.0111120865,0.03257045,0.034253404,0.0,0.013136588,0.0,0.0,0.0,0.0,0.011551827,0.035736844,0.058448285,0.0,0.0055040717,0.0,0.0,0.0,0.009955816,0.33119065,0.6263558,0.59692675,0.38648272,0.15401305,0.08028845,0.06653724,0.03575281,0.0,0.000050604343,0.012664743,0.012446567,0.014726073,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012642607,0.039863393,0.0,0.0,0.0,0.0,0.0,0.044526502,0.3846879,0.6363964,0.5466528,0.29172373,0.03689792,0.0,0.010040522,0.0,0.0,0.0011792332,0.008274898,0.0,0.00084757805,0.0022991747,0.0,0.0,0.004633859,0.0,0.0,0.0,0.0,0.030366838,0.013783969,0.0,0.0,0.0,0.011785284,0.11332324,0.42942262,0.5951267,0.4561689,0.20788062,0.0,0.0,0.0068262294,0.0,0.0,0.0,0.0,0.0,0.0061670914,0.0041812807,0.0,0.0,0.010769732,0.0,0.0,0.0,0.0,0.025377914,0.045424588,0.0,0.0,0.0,0.0644983,0.18053028,0.36585057,0.37632865,0.26488024,0.11423749,0.0,0.0007023066,0.04072342,0.023753807,0.0,0.0,0.0,0.009695716,0.029177971,0.0076890737,0.0,0.0,0.010683835,0.0,0.0,0.0,0.0,0.017099328,0.046996526,0.0,0.0,0.0,0.0459416,0.12846875,0.2571901,0.21825603,0.1518946,0.07411035,0.0,0.020335905,0.07304716,0.053388126,0.0,0.0095920265,0.0075403154,0.02921848,0.051814184,0.009238169,0.0,0.0,0.0050468445,0.0014418662,0.0,0.0,0.0,0.0190235,0.04877495,0.0,0.0,0.0,0.0,0.056369968,0.23119284,0.2680139,0.23071122,0.12832107,0.0,0.0179158,0.07486114,0.056585662,0.003431946,0.017525598,0.015547611,0.042058103,0.06679951,0.008729555,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.045986414,0.099521086,0.0,0.0,0.0,0.0,0.002875641,0.24583343,0.37120616,0.35953772,0.23387563,0.029603578,0.021756679,0.07324501,0.055021755,0.0072393566,0.020341508,0.015281469,0.03219933,0.06257154,0.0073095635,0.0,0.0,0.0,0.0,0.0,0.0,0.015227966,0.08867164,0.15536804,0.030095339,0.0,0.0,0.0,0.022875935,0.39588702,0.5952993,0.57107013,0.4127856,0.1681145,0.07032777,0.089153506,0.05784054,0.016103372,0.023876801,0.010579973,0.0031513274,0.04359562,0.00850258,0.0,0.0,0.0,0.0,0.0,0.0,0.047865264,0.10733896,0.18028948,0.06079045,0.0,0.0,0.0,0.031547174,0.51078403,0.79689354,0.8225795,0.66588277,0.39016438,0.16113706,0.1165297,0.0451139,0.03738951,0.041393608,0.012523964,0.0,0.027065098],[0.0,0.03996303,0.061775826,0.0,0.0,0.0,0.019850552,0.023562618,0.09873587,0.06308017,0.026223093,0.0,0.0894199,0.09531401,0.20695141,0.5537018,0.73102856,0.6985943,0.3762073,0.3004701,0.20691606,0.17733552,0.10499946,0.048243694,0.06630198,0.022287048,0.037279606,0.06951548,0.0,0.038872667,0.043612547,0.0,0.0,0.0,0.025222443,0.026324965,0.08096704,0.012144424,0.0,0.0,0.0064862072,0.0,0.15682408,0.5101719,0.69840354,0.6262785,0.33951163,0.28572214,0.16585597,0.13367745,0.09831679,0.016748078,0.041670695,0.004118532,0.014391474,0.054558486,0.0,0.02842968,0.01773829,0.0,0.0,0.002804622,0.027844243,0.029921778,0.062005244,0.0,0.0,0.0,0.0,0.0,0.20318384,0.5232324,0.7325089,0.6159838,0.29692334,0.18686193,0.07823903,0.06597949,0.056296304,0.0,0.042217538,0.004335046,0.0,0.03219527,0.0052785575,0.00048805773,0.0,0.0017836988,0.0,0.009528294,0.024625912,0.042808644,0.06265355,0.0,0.0,0.0,0.0,0.0,0.24258326,0.51950234,0.70957184,0.56924355,0.24033374,0.10193401,0.036560744,0.0074229985,0.020063676,0.0,0.05033271,0.0012089759,0.0,0.016033217,0.014244452,0.0,0.0,0.024054378,0.0,0.003994152,0.028658152,0.0435953,0.08542122,0.016150288,0.0,0.0,0.0,0.019531272,0.33374447,0.53663915,0.6552381,0.46419233,0.19096527,0.07021618,0.029094473,0.012810528,0.010362864,0.0,0.022709757,0.0,0.0,0.01677274,0.016559541,0.0,0.0,0.045123413,0.0,0.0,0.023796357,0.049149774,0.10610014,0.05830106,0.04724086,0.0,0.04171682,0.07117413,0.41548294,0.4726578,0.50516343,0.31572267,0.15314272,0.03968449,0.04147152,0.040957414,0.0271018,0.007832825,0.025791846,0.0,0.0,0.026809804,0.020805188,0.0,0.0,0.06648497,0.0,0.0,0.028573751,0.052132018,0.12633209,0.07288786,0.09856431,0.0,0.038958877,0.05365797,0.35902005,0.37551665,0.39143485,0.24294424,0.15650928,0.039634727,0.084617,0.075222045,0.05285459,0.019323483,0.032478325,0.0,0.0073798224,0.03627552,0.026115745,0.0,0.0,0.07298381,0.0,0.0,0.028697796,0.05932992,0.14301312,0.08209291,0.12349988,0.009106755,0.022164248,0.007572241,0.32360315,0.36326075,0.4363603,0.32198954,0.21071672,0.05711224,0.10875234,0.0864351,0.06945914,0.02803079,0.03337547,0.0,0.013276428,0.043355502,0.028427467,0.0,0.0,0.06747637,0.0,0.0,0.035750568,0.076202475,0.17339326,0.13644703,0.13562918,0.0,0.011554375,0.0,0.21992564,0.30215573,0.47693175,0.39695573,0.28222662,0.10379029,0.11740883,0.10444667,0.09368549,0.02758842,0.00955914,0.0,0.009124145,0.042762764,0.026323788,0.0,0.0,0.06513107,0.0,0.0,0.058531433,0.09768222,0.20153111,0.19694403,0.13519761,0.0,0.018451832,0.0,0.15511069,0.3133697,0.54183704,0.43724614,0.330453,0.21726108,0.14031011,0.13283312,0.12593488,0.018922083,0.0,0.0,0.0,0.029886656,0.027700692,0.0,0.0,0.079192616,0.0,0.0,0.094723746,0.119764075,0.23002486,0.21821111,0.12614763,0.0,0.011801869,0.0,0.09588355,0.32331008,0.5982039,0.51461935,0.433724,0.38476753,0.16459471,0.1458091,0.1331379,0.029332034,0.0,0.0,0.0,0.017133616],[0.021398619,0.053600088,0.023391724,0.0,0.0,0.0,0.0054134578,0.0,0.0007366687,0.066589005,0.028897703,0.0,0.0,0.09063864,0.28136176,0.43051505,0.6460694,0.60844314,0.45377016,0.109960616,0.15457451,0.20879643,0.10290614,0.016786493,0.012936614,0.03126754,0.051772334,0.040265553,0.021555237,0.036733516,0.02744089,0.0,0.0,0.0,0.0,0.0,0.0,0.049091987,0.0,0.0,0.0,0.021060616,0.18902524,0.35910955,0.5996138,0.5954169,0.45040697,0.1282113,0.11339188,0.14636192,0.04510466,0.002541855,0.0,0.021273151,0.029174402,0.023960851,0.016924903,0.016601697,0.022046953,0.005760558,0.021252222,0.012354478,0.0003017336,0.0,0.0,0.020685121,0.0,0.0,0.0,0.0,0.17085238,0.37315452,0.62890506,0.6060627,0.41365254,0.10389359,0.034668468,0.0562848,0.0,0.0,0.0003787279,0.022873156,0.005890563,0.0035838485,0.005892016,0.012089923,0.024900474,0.015193917,0.028947875,0.032972343,0.015051618,0.0,0.0,0.0079879165,0.0,0.0,0.0,0.0,0.17762794,0.38225877,0.5986057,0.5199617,0.30701408,0.040614545,0.0,0.0,0.0,0.0,0.013690904,0.02598422,0.0,0.0,0.0,0.015976682,0.030589223,0.015447855,0.026667275,0.035553493,0.016163506,0.016192377,0.012640782,0.0076577663,0.0,0.0,0.0,0.027135007,0.25146526,0.4256093,0.5803821,0.4066195,0.20017904,0.0058252886,0.0,0.0,0.0,0.0,0.0,0.012145698,0.0,0.0,0.0,0.014143646,0.022339918,0.0065322444,0.017717697,0.020864196,0.022775523,0.037337728,0.046061233,0.0,0.017540984,0.029970221,0.06921083,0.1574935,0.3833006,0.44315284,0.5033773,0.30358508,0.12698948,0.0,0.001280114,0.013832338,0.0,0.011051878,0.0026049316,0.0,0.0,0.0,0.0,0.017891787,0.020952806,0.005555317,0.02089256,0.0293748,0.04718259,0.06487735,0.06517718,0.0,0.03626728,0.07076291,0.11372203,0.15124258,0.35710558,0.3726158,0.40302265,0.24435613,0.09719713,0.0,0.02355235,0.022677734,0.0,0.025077008,0.012780607,0.0,0.0,0.0,0.0,0.021900207,0.026380487,0.0017175674,0.018486194,0.022884399,0.04330936,0.07346459,0.071927965,0.0,0.041966386,0.083794616,0.105204284,0.12518167,0.3127907,0.35568577,0.4250694,0.3018015,0.1408861,0.02641154,0.044467874,0.02851659,0.0,0.03261534,0.013467528,0.0,0.0,0.0,0.0011446774,0.029803924,0.034348086,0.00030688941,0.020075187,0.014953978,0.0309266,0.08844222,0.09627289,0.0,0.03620754,0.07123588,0.041916266,0.0,0.11651035,0.1995281,0.35488856,0.31260777,0.19081369,0.080186754,0.07450998,0.020522892,0.0,0.02147673,0.0,0.0,0.0,0.0,0.014814287,0.033616267,0.03850382,0.0,0.027416795,0.01743064,0.018301487,0.10258408,0.12755421,0.0,0.012779281,0.038797177,0.0,0.0,0.0,0.06283689,0.23716581,0.28416497,0.26378176,0.17655087,0.124482274,0.023643307,0.0,0.0,0.0,0.0,0.0,0.0,0.024081506,0.03833203,0.04881557,0.0,0.0320528,0.028525993,0.026196435,0.11964467,0.14758737,0.0,0.0017455816,0.016668268,0.0,0.0,0.0,0.012932107,0.18535823,0.31807336,0.36240947,0.2871303,0.19265527,0.053772435,0.0,0.0,0.0,0.0,0.0,0.0],[0.008371271,0.024531282,0.034706526,0.0,0.0,0.010296628,0.046240434,0.0,0.041737534,0.0,0.0,0.0,0.0,0.0474014,0.105478495,0.05410772,0.24862014,0.27314642,0.16840506,0.0,0.013829216,0.12941162,0.03966575,0.009176068,0.006915383,0.023379266,0.005537316,0.026510462,0.004151672,0.0074924156,0.019620806,0.0,0.0,0.0,0.031630345,0.0,0.011825815,0.00016181171,0.0,0.0,0.0,0.009745985,0.080687925,0.06682306,0.3010645,0.3445729,0.25798288,0.03191477,0.03417494,0.09135801,0.006042488,0.0,0.0,0.020419493,0.0,0.01755029,0.0,0.0,0.0015325248,0.0,0.0,0.0,0.03555397,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08151318,0.17284524,0.40084064,0.42185032,0.3037266,0.053669848,0.0145097,0.027439415,0.0,0.0,0.008409299,0.023717396,0.0,0.0013563484,0.0,0.0,0.0,0.0,0.0,0.011065699,0.058027588,0.02460435,0.0,0.0076279268,0.0,0.0,0.0,0.0,0.12602018,0.27493447,0.45369953,0.4241963,0.2608912,0.044128463,0.0029259324,0.0,0.0,0.009071603,0.02760832,0.022946134,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012414083,0.057348542,0.047576368,0.0,0.015741266,0.0013752431,0.0,0.0,0.06830587,0.23448166,0.40191424,0.5088118,0.38513815,0.22610833,0.051189274,0.016291268,0.004092261,0.012314163,0.0047216415,0.026540838,0.011355564,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020689234,0.059842847,0.06600469,0.0198071,0.014776938,0.011699431,0.031563655,0.04949764,0.2508074,0.39372575,0.51049286,0.53689885,0.35634568,0.21377215,0.045730866,0.022786997,0.024659865,0.034296036,0.0144370645,0.02037447,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.054380156,0.09352748,0.09220916,0.029100232,0.021116368,0.03375741,0.07437754,0.102012105,0.3036519,0.4069227,0.5231828,0.53165424,0.3410109,0.21556234,0.062045164,0.026539586,0.03265912,0.047955118,0.025485009,0.029001378,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.058034927,0.104214594,0.10222456,0.03586039,0.026806183,0.043621004,0.07863381,0.097331986,0.27895656,0.36930162,0.5126898,0.5574881,0.38833094,0.24588671,0.083291516,0.03396704,0.04612471,0.062786646,0.031375624,0.030846909,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05221904,0.10615647,0.116275825,0.057557985,0.013481751,0.040078722,0.06223289,0.026770793,0.12866862,0.17795873,0.33792382,0.46211493,0.37004384,0.26125002,0.116610385,0.049945243,0.048791736,0.049816787,0.012893766,0.029618852,0.0,0.0,0.0,0.0,0.0,0.0,0.0038967729,0.0,0.04687401,0.10377083,0.13409895,0.08130957,0.0,0.01944393,0.041088954,0.0,0.01537507,0.042423733,0.17630702,0.29728657,0.32956094,0.31608325,0.1999096,0.10949215,0.068150915,0.027161628,0.0,0.018884555,0.0,0.0,0.0,0.0,0.0,0.0,0.015630297,0.0,0.04581672,0.10017972,0.14774328,0.086239755,0.0,0.0,0.03202428,0.0,0.0,0.0,0.10489714,0.18292215,0.32585183,0.38950616,0.28895062,0.17675135,0.11370121,0.0386464,0.0,0.028026208,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.018924944,0.06641457,0.029202834,0.07606729,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03275849,0.09911961,0.06664789,0.045791835,0.04610827,0.048023723,0.0316524,0.0064278916,0.0,0.053311095,0.027333759,0.01631663,0.0,0.0,0.0,0.0,0.0,0.0,0.034161314,0.0043550283,0.045529425,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10737468,0.17537446,0.13122523,0.045508556,0.027971387,0.0,0.0,0.0,0.0,0.04997555,0.026567988,0.012006201,0.0,0.0,0.0,0.0,0.0,0.0,0.02367878,0.0030949414,0.020710997,0.0,0.0,0.0,0.0,0.0,0.0,0.020694003,0.21587873,0.24053162,0.16190334,0.030444823,0.003903553,0.0,0.0,0.0,0.0,0.042890035,0.011543445,0.0005219728,0.0,0.0,0.0,0.010361619,0.0,0.010935463,0.035929695,0.013969764,0.0081525,0.0,0.0,0.0,0.0,0.0,0.013064697,0.12489567,0.29430318,0.25805047,0.14757243,0.025630571,0.00045850873,0.0,0.0,0.0,0.008072279,0.04305522,0.0056741238,0.0,0.0,0.0,0.007827513,0.021754406,0.0,0.025508694,0.033642873,0.004561931,0.0,0.0,0.0,0.0,0.0,0.040344484,0.13221158,0.26040077,0.36714128,0.27506247,0.15417174,0.039631583,0.011171073,0.0016296804,0.007254228,0.0008856207,0.014446601,0.025477327,0.0,0.0,0.0,0.0,0.019363284,0.014213279,0.0,0.033996,0.033995524,0.004214585,0.0,0.0,0.0,0.0377673,0.08821176,0.21245462,0.32862848,0.4028837,0.3857926,0.29128802,0.16055498,0.054667234,0.03139791,0.040074736,0.021294042,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.027476594,0.003997326,0.0,0.044681534,0.050455004,0.0026406348,0.0,0.0,0.0,0.08187488,0.16837633,0.2758516,0.42582858,0.45535058,0.37398785,0.29715943,0.16550183,0.0554711,0.024650998,0.04687421,0.025908977,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030336477,0.0,0.0,0.035363443,0.05102531,0.0011172742,0.0,0.0,0.0,0.0883903,0.15278424,0.24622291,0.39982986,0.4440096,0.39808446,0.31971568,0.1873844,0.06835313,0.04019753,0.057438806,0.039552882,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05386404,0.0030535161,0.0,0.017783724,0.04563541,0.016585462,0.0,0.0,0.007969111,0.08594281,0.10140868,0.10876329,0.2373449,0.29154855,0.35237533,0.30406767,0.21714988,0.088538274,0.054257415,0.053548925,0.0458764,0.0,0.008831248,0.0,0.0,0.0,0.0,0.014344022,0.07799974,0.00954923,0.0,0.0084002465,0.051574834,0.057855308,0.0,0.0,0.0042327642,0.07123907,0.072201,0.034599833,0.10626207,0.1299675,0.2566316,0.26451606,0.27667665,0.16604033,0.107083164,0.054781206,0.050301425,0.0,0.00552471,0.0,0.0,0.0,0.0,0.040776573,0.098099925,0.0064793155,0.0,0.013939597,0.050615095,0.07790415,0.0,0.0,0.0,0.07475444,0.09375025,0.052045546,0.051631674,0.058459155,0.19309993,0.22735998,0.30488968,0.2532322,0.18201345,0.08945525,0.07266629,0.0,0.014941648,0.0,0.0,0.0],[0.0,0.013248369,0.024722032,0.07386392,0.007949524,0.007024385,0.03861686,0.057943866,0.0,0.022687413,0.0,0.0,0.0,0.0,0.0,0.0,0.059708796,0.047168948,0.027372912,0.05742786,0.14196715,0.06997843,0.04370153,0.0,0.002193004,0.061786078,0.02192755,0.024169669,0.0,0.026648238,0.037284546,0.080791056,0.01685255,0.0,0.02840399,0.03425519,0.0,0.02320084,0.0,0.0,0.020329773,0.009942584,0.0,0.0,0.10686708,0.09322067,0.03253513,0.058391333,0.084009245,0.017277636,0.030539237,0.0,0.020824827,0.06440198,0.031332657,0.018582605,0.0,0.020171434,0.023997247,0.049581893,0.007786453,0.0,0.028912812,0.015614465,0.0,0.036016278,0.0,0.0,0.022749625,0.020124085,0.0,0.0,0.14275864,0.118391655,0.024792619,0.05713389,0.03372387,0.0,0.025348924,0.0,0.047012426,0.053530604,0.024677493,0.011887997,0.0,0.019082092,0.024854094,0.041828103,0.008090019,0.02176749,0.044209704,0.014627039,0.0,0.031597562,0.0,0.0,0.0,0.021043532,0.020759597,0.014624186,0.17556983,0.104215376,0.0068676397,0.032609448,0.015235104,0.002779469,0.029845424,0.0041657835,0.06375855,0.05422332,0.021396056,0.0072414503,0.0,0.029381476,0.025757894,0.024937585,0.01109755,0.034974746,0.051378854,0.0051095188,0.0,0.023968443,0.0,0.006394908,0.0075897276,0.05410616,0.08789603,0.09597966,0.23395137,0.11507374,0.015643694,0.010406904,0.0,0.016891927,0.027969241,0.017960094,0.058896646,0.04573267,0.011148706,0.0037377626,0.0,0.04358974,0.023620866,0.0060351714,0.015103847,0.042298943,0.06596384,0.0074231625,0.0006221384,0.033173718,0.018011428,0.06763179,0.12576124,0.20565687,0.19788885,0.15007675,0.23003797,0.11110564,0.008413471,0.0,0.0,0.018729784,0.0031288564,0.02530513,0.038724624,0.02500505,0.0,0.0010184497,0.0,0.05695997,0.021055073,0.0,0.013825223,0.049975626,0.073763505,0.0,0.0,0.039822258,0.05786325,0.12492228,0.18436252,0.28923613,0.26075655,0.17000568,0.21994989,0.113401964,0.0041601956,0.0,0.0,0.0067505315,0.0,0.036863126,0.03577821,0.024770088,0.0,0.0016134977,0.0,0.065723255,0.019636825,0.0,0.013566881,0.047110237,0.074473135,0.0,0.0,0.04258079,0.07880166,0.14834736,0.17834017,0.2746951,0.237183,0.1751343,0.23578376,0.13279213,0.010094292,0.0,0.0,0.018879086,0.0,0.042637415,0.03940048,0.031956792,0.0,0.0044235885,0.0,0.08050607,0.03488884,0.0,0.0035763085,0.034422934,0.0730045,0.0026281923,0.0030810088,0.047989868,0.110021815,0.16922195,0.10384384,0.16396801,0.120130576,0.106751524,0.2169148,0.1267019,0.02058331,0.0,0.0,0.029937483,0.0,0.03663958,0.03766197,0.03139645,0.0,0.0,0.0,0.10214597,0.054446258,0.023232736,0.00387986,0.023306653,0.084535286,0.044408277,0.038389854,0.056744263,0.12190561,0.17210992,0.04595928,0.06822619,0.005510345,0.0051183254,0.1430804,0.09450354,0.049010627,0.03163416,0.032209165,0.038516216,0.0,0.016831093,0.029268026,0.01697506,0.0,0.0,0.011049539,0.13570897,0.07167311,0.038208842,0.0007099658,0.016628511,0.08391921,0.06583753,0.051676378,0.043524407,0.109664924,0.18458083,0.055531114,0.04546906,0.0,0.0,0.06533776,0.03497114,0.041746676,0.074181505,0.09577018,0.06739726,0.0028768033,0.009686179,0.034219675,0.020917788,0.0,0.0],[0.014591768,0.035332747,0.025560334,0.043630302,0.0,0.09498151,0.08080801,0.0,0.0,0.0,0.03088034,0.07084782,0.01207307,0.0,0.0,0.0,0.030487083,0.041056663,0.051674895,0.0107317045,0.06309866,0.05053865,0.032049306,0.0,0.0,0.0,0.0,0.0098912865,0.00932356,0.05350034,0.040711656,0.034177646,0.0,0.077718854,0.0683394,0.0,0.0,0.0,0.014249869,0.05261489,0.0034865737,0.0,0.0,0.0,0.02352336,0.020656548,0.039911553,0.012321748,0.037157975,0.016565502,0.022344664,0.0,0.0035363138,0.0,0.0034368932,0.00909467,0.0,0.036989473,0.021935858,0.011574753,0.0,0.05174473,0.042738155,0.0,0.0,0.0,0.007243179,0.045673124,0.0,0.0,0.0,0.0,0.008446105,0.0,0.02518887,0.008454591,0.016968735,0.0,0.01747822,0.0,0.012307212,0.0,0.008157998,0.007034309,0.0,0.021780394,0.021218188,0.016729198,0.0,0.032932587,0.039582774,0.011710055,0.0074475035,0.0,0.0,0.039250836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0061209276,0.0026323497,0.02291359,0.0,0.02936396,0.0028047413,0.01400689,0.0035395771,0.0,0.014215656,0.01638455,0.020955607,0.0,0.007491678,0.031943098,0.031934805,0.03625665,0.0,0.0,0.027077273,0.0011987239,0.028278142,0.024806589,0.0,0.010502055,0.0,0.0,0.0,0.0,0.0027680248,0.0191032,0.00342156,0.041838296,0.008135088,0.01564575,0.0,0.0,0.021332934,0.018522985,0.029969037,0.0,0.0,0.028576307,0.05004728,0.062882625,0.0,0.0,0.02642154,0.052518874,0.11710088,0.094399236,0.027165294,0.008897625,0.0,0.0,0.0,0.0,0.0,0.005640194,0.00828395,0.046676032,0.012023024,0.01550144,0.0,0.0002643317,0.028837241,0.023088723,0.042410627,0.0035035908,0.0,0.029008828,0.063053,0.08234982,0.0,0.0,0.04685063,0.106393956,0.18269643,0.15342522,0.046374686,0.013186455,0.0,0.0,0.0,0.0,0.0,0.0,0.019486658,0.052843936,0.013687663,0.014308229,0.0,0.0,0.036323167,0.03025072,0.049814664,0.00592272,0.0,0.026981786,0.071167976,0.09185277,0.0,0.0,0.047588103,0.10320483,0.1813438,0.15057862,0.051421687,0.026084341,0.0,0.0,0.0,0.0,0.0,0.0066357628,0.03159949,0.06681359,0.015045807,0.010125384,0.0,0.0,0.050408147,0.04916796,0.06306104,0.011870384,0.0,0.026815712,0.07732081,0.08641879,0.0,0.002132088,0.049116686,0.06295709,0.111912936,0.10643063,0.060961507,0.044645317,0.001526624,0.0,0.0,0.0,0.0,0.0035117418,0.034320347,0.07123914,0.0020012707,0.0,0.0,0.0,0.05669502,0.0735624,0.07395056,0.024374634,0.0,0.039578043,0.097649015,0.07352165,0.0,0.012528889,0.047846638,0.0050685853,0.01923883,0.04039132,0.052206792,0.048467286,0.0,0.0,0.008232139,0.0026541501,0.0,0.0003014356,0.033836536,0.06949593,0.0,0.0,0.0,0.0033139735,0.06636138,0.091993004,0.08057831,0.0307085,0.0,0.028556451,0.10957021,0.06551916,0.0,0.019864716,0.050428957,0.0,0.0,0.009153582,0.03991826,0.04429456,0.0,0.0,0.019984193,0.024487406,0.0,0.0066059753,0.039726913,0.08247563,0.0,0.0,0.0],[0.009752966,0.0,0.0074692667,0.0,0.04513713,0.033235706,0.02562274,0.0,0.0,0.0,0.0,0.0046785325,0.0,0.002510503,0.0014931709,0.017544486,0.0,0.021167055,0.008843653,0.0,0.0,0.0,0.0,0.0,0.0060479045,0.02191326,0.0,0.0,0.015014067,0.0,0.0,0.0,0.027641721,0.032158583,0.03544555,0.01843404,0.0,0.0,0.0,0.008664839,0.0,0.01764284,0.0050225705,0.008341581,0.0,0.007756382,0.01133012,0.0,0.0,0.0,0.0,0.0,0.0,0.0096066,0.0,0.0,0.01698634,0.0,0.0,0.0,0.011461765,0.023682535,0.025406048,0.015834227,0.0,0.0,0.0,0.0,0.0,0.019010857,0.0023433715,0.00254488,0.0,0.008706912,0.015916295,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013514288,0.0,0.0,0.0,0.0,0.00914526,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015258215,0.0006522238,0.0,0.0,0.0063854754,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010989718,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0016839355,0.015704699,0.0,0.0,0.0012592226,0.008825831,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004292175,0.0,0.0,0.0026462078,0.0027008355,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0062501878,0.010311812,0.0,0.0,0.0,0.014303148,0.0023741275,0.0,0.0056296736,0.0068861768,0.012227364,0.003518641,0.0008763224,0.0,0.0,0.0,0.0010356605,0.0,0.0,0.006462358,0.0107566565,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014141157,0.014903054,0.0008509606,0.0,0.0,0.013310105,0.0072247386,0.0,0.0102527365,0.011430867,0.011924036,0.010619834,0.009383798,0.0,0.0,0.0,0.0007714629,0.0,0.0,0.014586471,0.018194646,0.0019655526,0.0046941787,0.004890591,0.0,0.0,0.0,0.0,0.028813943,0.022374801,0.0046776384,0.0,0.0,0.022210598,0.01797504,0.0,0.013658464,0.009003274,0.00088596344,0.016248338,0.020007886,0.0024899691,0.0016595125,0.0,0.0018358529,0.0,0.0,0.035787947,0.028286323,0.018995412,0.045861565,0.06563394,0.008247405,0.0,0.0,0.0,0.04686054,0.026915625,0.00714805,0.0,0.0,0.039961606,0.02898316,0.0,0.0031320304,0.006832339,0.0,0.019924112,0.03407494,0.009828031,0.0065628737,0.0,0.0027463138,0.0,0.0,0.04250098,0.022157826,0.026495285,0.07319656,0.10713936,0.014219567,0.0,0.0,0.0,0.063971914,0.037369914,0.010706417,0.0,0.0,0.05249065,0.032407343,0.0,0.0,0.00913991,0.0,0.016072735,0.027553476,0.0,0.0,0.0,0.00028288364,0.0046945363,0.0,0.03878931,0.0099641085,0.019572996,0.086358815,0.1198093,0.0141299665,0.0,0.0,0.0,0.08170651,0.043708436,0.014155969,0.0,0.0,0.06448578,0.03562457,0.0,0.0,0.020691752,0.0,0.0041159242,0.0050551593,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.06376338,0.06868442,0.056282915,0.0,0.0,0.0,0.020128429,0.0,0.015732959,0.0,0.0494942,0.075141564,0.011238813,0.00627926,0.0,0.005765088,0.0,0.0,0.0,0.0,0.040065408,0.0534684,0.041735165,0.0,0.0,0.0,0.0,0.0,0.038607746,0.06821293,0.08117567,0.036049783,0.0,0.0,0.008688554,0.0,0.0,0.0,0.045336775,0.041197397,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025721133,0.02055414,0.021844298,0.0,0.0,0.0,0.0,0.0,0.027052,0.045401327,0.0529643,0.030550614,0.0,0.0,0.0,0.0,0.0,0.0,0.01516778,0.003598854,0.0,0.003919214,0.0,0.0,0.0,0.0,0.0,0.0,0.013657488,0.0060561076,0.018147983,0.0,0.0,0.0,0.0,0.0,0.016817026,0.01599776,0.009722561,0.00477162,0.005421683,0.0,0.0,0.0,0.0037872493,0.0036977232,0.0014105439,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009066939,0.0,0.015028708,0.0,0.0,0.0,0.0,0.0,0.008186065,0.009734005,0.0,0.0,0.0,0.0,0.0,0.0,0.0025482029,0.017005056,0.012221776,0.0,0.0,0.0,0.0,0.0,0.0075395033,0.0,0.0071047917,0.0,0.010400884,0.0,0.007990114,0.0,0.0,0.0,0.0,0.0022830516,0.014192909,0.020629607,0.009170905,0.0,0.0,0.0,0.0,0.0,0.0012737215,0.013978429,0.012553439,0.0,0.003839478,0.0,0.0,0.0,0.030143254,0.00991039,0.026302077,0.0,0.03913971,0.026672572,0.029514723,0.0014131814,0.0,0.0,0.0,0.0072292835,0.028785288,0.032151423,0.024937235,0.0,0.0,0.0,0.0,0.0,0.006841995,0.01946082,0.018627465,0.0,0.009417966,0.0,0.005198255,0.0,0.039801218,0.022102855,0.03412845,0.0043952167,0.059876844,0.043123774,0.039255805,0.012254983,0.0,0.0,0.0,0.020829625,0.04528489,0.05094607,0.06585225,0.025210485,0.025847971,0.0,0.0,0.0,0.022569142,0.03535507,0.0342149,0.0,0.028302066,0.0,0.021340512,0.0,0.041135527,0.02130273,0.032305703,0.017045908,0.08509552,0.07201086,0.0554611,0.023649998,0.0,0.013574652,0.0015040189,0.05376652,0.07170965,0.07792245,0.13818958,0.102969065,0.10438433,0.0,0.0,0.0,0.03918098,0.045836814,0.04368233,0.0,0.03933522,0.0,0.009512916,0.0,0.031967357,0.010038175,0.015959166,0.023631454,0.099864274,0.091404006,0.059562154,0.023393758,0.0,0.023648314,0.022877127,0.05515849,0.06997408,0.087344915,0.19328877,0.15746062,0.16005,0.0,0.00024165213,0.00951723,0.071943,0.06469011,0.057153925,0.0,0.020578302,0.0,0.0,0.0,0.017786458,0.00031602383,0.0,0.019235574,0.0851693,0.06829272,0.03833457,0.016921185,0.0,0.026908688,0.02395697,0.02978491,0.048129395,0.07653792,0.23512712,0.20695294,0.21264291,0.011404425,0.035070762,0.05648259,0.12167891,0.079978436,0.07181623,0.0,0.01056274,0.0,0.0,0.0,0.01523339,0.001606971,0.0,0.0056123585,0.05290333,0.026580684,0.010101505,0.0063971654],[0.0,0.0,0.032598473,0.018325076,0.07354316,0.07441193,0.070724174,0.0,0.0,0.044235006,0.0322766,0.018335827,0.13669357,0.10739648,0.12506557,0.17553648,0.10759252,0.0,0.0,0.0,0.0,0.0,0.017602816,0.034894645,0.06675579,0.033227943,0.013646588,0.0,0.0,0.0,0.024078697,0.012512736,0.053521045,0.056591384,0.0848553,0.04204931,0.0,0.060157917,0.023478605,0.0,0.08950536,0.059923038,0.08520705,0.115022376,0.031893738,0.0,0.0,0.0,0.0,0.0,0.01869139,0.026268035,0.051457018,0.018124267,0.0121608,0.011018999,0.0,0.0,0.026868671,0.011532865,0.036542088,0.022738405,0.05972784,0.040130377,0.0017497987,0.03960658,0.010195501,0.0,0.06499175,0.03032501,0.040920503,0.057173558,0.0013596416,0.009997845,0.00809031,0.026624262,0.031491384,0.016335636,0.036390312,0.0060815737,0.026508637,0.017836161,0.008142047,0.013691686,0.0,0.005810648,0.023784861,0.013836734,0.022128858,0.0052608103,0.032235973,0.031342454,0.016739666,0.024492465,0.0047148764,0.0,0.045013815,0.008815534,0.016467564,0.016897425,0.0,0.02742298,0.005760677,0.02036839,0.03548576,0.0059786513,0.018365346,0.0,0.012543201,0.014621504,0.00404346,0.0165689,0.0,0.0084867105,0.016021341,0.0062770173,0.008468986,0.01711239,0.012536727,0.010869145,0.019586787,0.01186204,0.016865462,0.0,0.059146903,0.013402939,0.014621571,0.0,0.0,0.032865666,0.012076013,0.009425841,0.026567966,0.0,0.0019421577,0.0,0.007473342,0.010398284,0.0040275156,0.026168004,0.0,0.004434943,0.0075240135,0.010150552,0.011103511,0.049813032,0.018125705,0.006480418,0.037028216,0.0,0.031009123,0.0,0.07692692,0.008381747,0.0,0.0,0.0,0.022825323,0.016511254,0.0,0.028886631,0.010887913,0.0,0.01564581,0.041286655,0.04526723,0.036380008,0.04463733,0.0,0.0,0.003825456,0.02329532,0.021065332,0.07680908,0.033422403,0.017501548,0.056160904,0.0,0.03855052,0.01067929,0.10001777,0.022319026,0.0006765425,0.0,0.0,0.033157602,0.018669806,0.0,0.03130786,0.020412266,0.0,0.02870401,0.06275234,0.060692012,0.055351928,0.05537626,0.0,0.004481852,0.010196112,0.0414885,0.033645093,0.11382571,0.07557801,0.065555535,0.095561765,0.0,0.042626582,0.020792633,0.122688815,0.048314326,0.004318163,0.0,0.025880925,0.066264525,0.042556405,0.0,0.020265006,0.009162106,0.0,0.03708119,0.08682934,0.0873463,0.078318805,0.06620657,0.0035060048,0.028953172,0.030514404,0.067971855,0.05117476,0.16414925,0.14772137,0.16690075,0.16640867,0.0075432435,0.04332491,0.026270136,0.14805901,0.06636854,0.0013961047,0.0,0.028583318,0.051030643,0.046843395,0.0,0.0,0.0,0.0,0.033630624,0.10088067,0.103000715,0.09248912,0.06695772,0.0044124126,0.035417892,0.02875898,0.06290583,0.0433437,0.19607401,0.20336959,0.24410272,0.21968803,0.035691373,0.07616362,0.07139355,0.19091126,0.08316315,0.0,0.0,0.0,0.0,0.013859116,0.0,0.0,0.0,0.0,0.026622683,0.08883269,0.085000455,0.08160835,0.058783904,0.0017900318,0.029771246,0.006257355,0.036365822,0.017123073,0.20578486,0.24738313,0.3136714,0.28997827,0.084990494,0.122286774,0.13850245,0.23958158,0.094625965,0.002613172,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014419541,0.061921187,0.06454125,0.066263966,0.047505856],[0.009801306,0.011315674,0.0,0.0,0.11615112,0.086068794,0.034841634,0.01003056,0.063559905,0.15523997,0.23063555,0.18802904,0.22786513,0.33729917,0.29554373,0.21712202,0.05354677,0.030470781,0.0,0.0,0.007729128,0.009481743,0.03228364,0.065535694,0.025650539,0.0,0.0,0.0027511716,0.011659771,0.02498933,0.0,0.0,0.08085404,0.085020475,0.062590584,0.03521371,0.06303153,0.10105497,0.11266037,0.06665228,0.15015902,0.24378219,0.2095622,0.14526904,0.0,0.0,0.0,0.024341255,0.07458244,0.053654462,0.06698428,0.06781197,0.02696269,0.0,0.0,0.006792374,0.016118653,0.05291847,0.020146206,0.0,0.037479833,0.03545902,0.039597765,0.037946634,0.06633871,0.06867494,0.032614693,0.0,0.06944248,0.104564585,0.07902458,0.038372993,0.0,0.0,0.0,0.055665895,0.12757511,0.08094078,0.07330783,0.037998356,0.01963403,0.0,0.0,0.0003581345,0.010519676,0.03981609,0.027806044,0.0,0.017487973,0.0033332705,0.016247854,0.024047367,0.06997673,0.05186498,0.011147715,0.0,0.031197444,0.017485656,0.0,0.0,0.0,0.0,0.00066132843,0.055764064,0.093054816,0.039497174,0.037504174,0.004503399,0.0030376017,0.0,0.0,0.0,0.0029633194,0.018032901,0.0148846805,0.0,0.004980117,0.00428389,0.0031128377,0.0,0.029732525,0.03497307,0.007985748,0.0,0.024897747,0.021638349,0.0,0.0,0.0,0.015459426,0.020665042,0.029775575,0.05585125,0.008441336,0.01294145,0.0,0.0,0.00070258975,0.011152506,0.004385665,0.0,0.0,0.0,0.0,0.0029029995,0.017833792,0.019627102,0.0,0.0037957728,0.011763088,0.0099734515,0.0,0.027224787,0.036312915,0.0049060434,0.0,0.016401969,0.01932796,0.024352044,0.023605347,0.052114725,0.021409199,0.006411113,0.0,0.002983436,0.042990386,0.04729096,0.016668685,0.0,0.0,0.0,0.0,0.009931162,0.029544577,0.043321945,0.0,0.0027556717,0.012691207,0.021852292,0.0,0.040499598,0.047210373,0.027444087,0.0,0.037782937,0.024631836,0.030591227,0.027875647,0.059007198,0.031885587,0.0070541278,0.0,0.007217817,0.05995412,0.06368567,0.022309765,0.0,0.0,0.0,0.0,0.029285327,0.06900118,0.09220248,0.022726893,0.013288781,0.013879202,0.027772397,0.0,0.044203162,0.05869305,0.051337488,0.020836659,0.08699942,0.07061018,0.051553078,0.019855186,0.044511735,0.021039575,0.0,0.0,0.019829415,0.08663574,0.08274864,0.02768585,0.0014925897,0.0,0.02827333,0.0,0.06423208,0.14973368,0.17200322,0.096425556,0.061971664,0.04521954,0.042150363,0.0,0.04704316,0.07931931,0.08472675,0.042929783,0.10920878,0.09272362,0.059797592,0.0,0.0,0.0,0.0,0.0,0.030813612,0.10235487,0.08826548,0.014429279,0.005280331,0.0058630705,0.049175225,0.012297176,0.07646333,0.20849353,0.23153076,0.16372554,0.12735616,0.14168209,0.11235239,0.0,0.060296014,0.11110391,0.12536345,0.04336434,0.06620623,0.030160196,0.026013933,0.0,0.0,0.0,0.0,0.0,0.023459598,0.09092841,0.069180295,0.0,0.0077599064,0.0011285692,0.04091639,0.0085700005,0.06079895,0.24780363,0.29850015,0.25252497,0.21822177,0.27094728,0.20326439,0.0017219931,0.08586432,0.14062962,0.16088963,0.047665134,0.032142267,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012155578,0.07198414,0.047118597,0.0],[0.0,0.0,0.0,0.0,0.12407553,0.16929318,0.075812906,0.06897086,0.1879746,0.23707086,0.36780745,0.4558319,0.54562694,0.6331918,0.6412628,0.34835678,0.11706296,0.0,0.0,0.0,0.0,0.0,0.0,0.048136525,0.0,0.01646591,0.0,0.0,0.0,0.0,0.0,0.0,0.10043433,0.15183961,0.086830944,0.039958008,0.1028863,0.11035898,0.20165065,0.2721594,0.38391936,0.49739856,0.4845879,0.23913094,0.052867398,0.0,0.0,0.0,0.0,0.03480406,0.013852969,0.058461443,0.0,0.00028558075,0.0,0.0,0.0,0.014393255,0.0,0.0,0.051888227,0.08383761,0.064002454,0.027188636,0.063484676,0.028793968,0.054723352,0.080291346,0.17352945,0.28992957,0.2574877,0.11608195,0.0056417286,0.0,0.0,0.0144917,0.019023538,0.053260036,0.015733868,0.037133873,0.0,0.0075601935,0.0,0.0,0.0,0.024503037,0.0,0.00047552586,0.036593348,0.03328134,0.025351532,0.0011217445,0.036771603,0.0045735687,0.0,0.0,0.026784979,0.08693932,0.081955895,0.041486338,0.0,0.0,0.0,0.016290054,0.003326118,0.022393338,0.0,0.0051289946,0.0,0.011187024,0.0,0.0,0.0,0.019075148,0.0,0.0022861362,0.030254789,0.010749705,0.0,0.0,0.0014599562,0.0067027733,0.0,0.0,0.0049463958,0.006872952,0.0,0.0,0.0,0.04076764,0.029040568,0.0,0.0,0.018814817,0.0,0.0,0.0,0.011085443,0.0076731816,0.0,0.0,0.004620433,0.0,0.0072927848,0.037380032,0.008790866,0.0,0.0,0.0,0.021950178,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04495962,0.030102,0.0,0.009923339,0.058158807,0.013860397,0.0,0.0,0.035078645,0.037314318,0.00406532,0.0,0.0015641004,0.0,0.009471819,0.04766711,0.013530612,0.0,0.0,0.0,0.036411695,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.050619192,0.046291575,0.0012543797,0.02330026,0.07717425,0.019802794,0.0,0.0,0.04713451,0.047033265,0.006432697,0.0,0.008100033,0.0,0.01795467,0.06382435,0.03647475,0.020910263,0.0,0.0003386289,0.04895857,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08351394,0.077335015,0.0,0.0050559193,0.067479976,0.022131339,0.0,0.0,0.065376036,0.057159297,0.0067346916,0.0,0.03602416,0.0,0.03336502,0.09127119,0.09141081,0.07606059,0.028763235,0.03783617,0.0835416,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09590982,0.092203304,0.0,0.0,0.029244572,0.02189961,0.0,0.006344788,0.07952961,0.058290333,0.0,0.0,0.05943329,0.0,0.04403215,0.11549843,0.14503689,0.1263323,0.09820856,0.108400635,0.18491878,0.06230168,0.0,0.0,0.0,0.0,0.0,0.0,0.04227388,0.05625134,0.0,0.0,0.00838764,0.016473107,0.0,0.013774961,0.07073341,0.042420596,0.0,0.0,0.0592746,0.0,0.040434055,0.12355148,0.19996664,0.19355643,0.17766379,0.19661063,0.31310713,0.14941877,0.0,0.0,0.0,0.0,0.0,0.0,0.0055087954,0.022229582,0.0,0.0,0.0,0.008904614,0.0,0.01212433,0.059042916,0.027667478,0.0],[0.0,0.0,0.0,0.051373094,0.10343364,0.05150015,0.12937051,0.2441267,0.2890027,0.50583535,0.54968137,0.77411574,0.85740346,1.0,0.88904715,0.6648617,0.31771618,0.007274419,0.0,0.0,0.0,0.0,0.0,0.011023581,0.0028321892,0.05021479,0.02885773,0.0,0.0,0.0,0.0,0.03482963,0.059500612,0.0,0.041948363,0.12137836,0.16009456,0.31066197,0.35220432,0.59543276,0.71438533,0.8512227,0.6963122,0.4567544,0.15622078,0.0,0.0,0.0,0.0,0.020585947,0.0,0.014719188,0.0,0.0380921,0.025605716,0.002217874,0.0,0.000988543,0.0,0.020926416,0.026045337,0.0,0.002350077,0.048281267,0.07293157,0.12615609,0.11814176,0.26768667,0.4240939,0.5838498,0.4783579,0.2664723,0.04794295,0.0,0.0,0.0,0.0,0.028758697,0.0,0.01023522,0.0,0.026299551,0.017793275,0.0010762215,0.0,0.0,0.0,0.00401628,0.004068464,0.0,0.0,0.008129992,0.02806317,0.04756184,0.03506486,0.06928812,0.14841858,0.26566613,0.22991043,0.110660285,0.036653295,0.0,0.0,0.0050385892,0.0,0.017441526,0.0,0.0050585717,0.0,0.00904505,0.0043786764,0.0018204898,0.0,0.0,0.0,0.0,0.009014189,0.0,0.0,0.0,0.0,0.01089783,0.0022327155,0.0,0.009355664,0.038038857,0.0045187026,0.0,0.036734,0.083470635,0.05016748,0.03649643,0.025280371,0.010819711,0.0,0.0,0.0,0.0,0.0,0.008677252,0.0,0.0,0.0,0.0,0.026479483,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032000683,0.18391249,0.2285963,0.19561104,0.15787071,0.07033138,0.038108423,0.0,0.0,0.0,0.0,0.021520674,0.0,0.0,0.0,0.0,0.03952878,0.011143766,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019941233,0.22767733,0.29703647,0.28033906,0.24030608,0.1278463,0.06568747,0.0,0.0,0.0,0.0,0.02991955,0.0,0.0,0.0,0.0,0.036040924,0.025488935,0.020437248,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026406497,0.26834935,0.35072613,0.34862176,0.2788722,0.15191118,0.07029474,0.0,0.0,0.0,0.00412485,0.03764633,0.0,0.017278545,0.015654974,0.010718472,0.029842094,0.051115558,0.05730144,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28564736,0.4027812,0.42960453,0.27944404,0.12386464,0.057331398,0.012148656,0.0,0.00920783,0.016082965,0.037799425,0.0,0.040614814,0.042301,0.03687261,0.046754867,0.07978828,0.09212833,0.0,0.05308626,0.01856824,0.021959595,0.0,0.0,0.0020098984,0.0,0.0,0.0,0.23155136,0.368845,0.41503763,0.22870862,0.08705438,0.046628073,0.028877318,0.010270819,0.013976023,0.018160082,0.030092068,0.0020468682,0.05509346,0.056892566,0.05343304,0.058641113,0.12215632,0.16521066,0.08132608,0.17017597,0.11543547,0.074666664,0.0,0.0,0.027874254,0.0,0.0,0.0,0.21696869,0.34380105,0.38952565,0.18359034,0.05780679,0.024283275,0.043613926,0.02585578,0.020991057,0.019178621,0.020601928],[0.0040560514,0.013366014,0.04610116,0.10254436,0.1438136,0.14027028,0.1853572,0.34746134,0.3891629,0.5138554,0.55625993,0.7332285,0.8901449,0.96112275,0.897283,0.7426775,0.44809115,0.18989778,0.027459525,0.0,0.0,0.0,0.0,0.0,0.037303187,0.0,0.0,0.0026672632,0.000014826655,0.014043391,0.04777307,0.08203511,0.09281313,0.06175705,0.084643036,0.19807386,0.23041937,0.29744735,0.4219197,0.6177176,0.8221939,0.88217044,0.7890217,0.5681127,0.26450524,0.07891049,0.0,0.0,0.0,0.0,0.0,0.0,0.020354755,0.0,0.012066938,0.010688998,0.0,0.01187703,0.02425129,0.061205953,0.042487435,0.02975811,0.04186333,0.10063376,0.11155848,0.11670231,0.22912279,0.36524016,0.59025246,0.7216381,0.6581865,0.44547868,0.18994348,0.047926947,0.0,0.0,0.0,0.0,0.0,0.0,0.025405012,0.0,0.0018960088,0.009087719,0.0,0.006578274,0.0017966181,0.027928978,0.00582359,0.019265309,0.038379483,0.053693004,0.056845307,0.0404836,0.11292052,0.17212813,0.2878215,0.4365068,0.44439542,0.3303582,0.15733148,0.09203832,0.0,0.0,0.0,0.0,0.0,0.0,0.023489632,0.0,0.00213328,0.014423087,0.0,0.0,0.0,0.013974957,0.0016963184,0.0,0.024601936,0.03982015,0.050189637,0.02730611,0.04020752,0.074523136,0.09941821,0.13178313,0.16672942,0.19713846,0.16584817,0.19136038,0.06873393,0.046811797,0.01787705,0.0,0.0,0.0,0.012555584,0.0,0.0059814006,0.018363975,0.0,0.0,0.0,0.017358921,0.014672063,0.0032663196,0.031553946,0.029199548,0.010833286,0.0132994875,0.01892928,0.017343052,0.022040509,0.0,0.04010357,0.14407727,0.2398924,0.34302557,0.29902732,0.25676775,0.14752822,0.022274576,0.0,0.0,0.0,0.0,0.008635059,0.02248957,0.0,0.0,0.0,0.028562494,0.029495552,0.021797478,0.04040782,0.042611934,0.005664587,0.0042916983,0.018066838,0.0,0.009531096,0.0,0.005766578,0.13869847,0.2663108,0.40900952,0.41336942,0.35476518,0.23006138,0.078925535,0.015935495,0.0,0.0,0.0053152144,0.014635168,0.02890443,0.0,0.0,0.0,0.031522736,0.024110816,0.026891097,0.045864,0.05125478,0.010665618,0.005886771,0.02798567,0.0,0.0014288127,0.0,0.0,0.13869265,0.2931363,0.45390034,0.4879343,0.4380985,0.27818072,0.09746344,0.038991444,0.009008639,0.014280111,0.019799523,0.020964734,0.039444968,0.0,0.023032635,0.0,0.03635995,0.010844268,0.03084419,0.062665924,0.06710423,0.041874133,0.032385744,0.049644843,0.0,0.0,0.0,0.0,0.11791311,0.2642609,0.43530154,0.5369503,0.5312153,0.27917376,0.05215756,0.04216814,0.009286709,0.038589142,0.032511212,0.014464244,0.050749056,0.0,0.040839545,0.008275107,0.061921053,0.018532857,0.04680989,0.096758604,0.11640511,0.16105323,0.114585206,0.09186855,0.0,0.01599177,0.0,0.0,0.08061021,0.18981634,0.3580948,0.50323355,0.5070371,0.2415598,0.0041650683,0.03924974,0.013710059,0.061746597,0.036961608,0.012214258,0.052810848,0.0,0.05446297,0.012178086,0.08707526,0.036384933,0.08622463,0.18637298,0.21467614,0.3260337,0.23971201,0.17787303,0.0,0.024987794,0.0,0.0,0.08019112,0.17086563,0.35065556,0.49487978,0.46282953,0.20601514,0.0,0.04338196,0.02663476,0.09972022,0.041064113,0.00809215,0.052098565],[0.0,0.01883173,0.05250033,0.026571535,0.07055941,0.113530956,0.19507045,0.23645976,0.1466174,0.15570869,0.18200225,0.16116156,0.34608203,0.56619114,0.6852246,0.5789975,0.3617012,0.10064187,0.0,0.0,0.0,0.0,0.0,0.06937249,0.044281945,0.0,0.0,0.0,0.0,0.0,0.043304995,0.034853972,0.05313623,0.025836691,0.09725268,0.13827975,0.08406194,0.14553316,0.2078177,0.2408821,0.46219808,0.6934974,0.77877533,0.59484273,0.28450966,0.009674892,0.0,0.0,0.0,0.0,0.0,0.042358816,0.024943411,0.0,0.0,0.0,0.0,0.0,0.024702743,0.023510233,0.05340284,0.017655045,0.06346425,0.07102902,0.05169873,0.1042314,0.19671306,0.28916627,0.4871202,0.6981078,0.7621745,0.5956622,0.27408612,0.0,0.0,0.0,0.0,0.0029290766,0.0024495572,0.015501946,0.0,0.0,0.0,0.0,0.0,0.0,0.0004903674,0.018484391,0.044869706,0.042465597,0.054114074,0.026906624,0.05372972,0.1096279,0.20759219,0.2653743,0.39718014,0.55256855,0.64033556,0.56753516,0.35445967,0.100429796,0.0,0.0,0.0,0.0,0.0029467493,0.0038882643,0.0,0.0,0.0,0.016362362,0.0,0.0,0.0,0.028174907,0.044985957,0.06206251,0.056304723,0.027029276,0.08907597,0.14336523,0.20172226,0.21282095,0.25932327,0.2982396,0.30884534,0.35555214,0.3839944,0.30918056,0.1307799,0.0,0.0,0.0,0.01898285,0.0,0.0,0.005409315,0.010350801,0.03288661,0.0,0.0030377954,0.0,0.05037585,0.06512774,0.061757937,0.044749662,0.012486987,0.07217723,0.13626571,0.1401109,0.15177855,0.10580905,0.082832456,0.037037484,0.19925646,0.4233266,0.56488454,0.483145,0.24920416,0.06349333,0.0,0.034407847,0.0,0.0,0.00023768842,0.020754889,0.050305046,0.0,0.009805448,0.0,0.06937063,0.10064692,0.074735224,0.051088735,0.019826494,0.07242887,0.13902947,0.13245957,0.14048283,0.048436865,0.0019205958,0.0,0.15353252,0.4459024,0.6610579,0.6325082,0.40090573,0.16568658,0.0063043013,0.04714588,0.0,0.0,0.0077996477,0.03245391,0.056721345,0.0,0.025478624,0.0032142252,0.059989408,0.10187171,0.06412523,0.057462692,0.031401955,0.08926028,0.16755639,0.1576552,0.15174246,0.015958428,0.0,0.0,0.1554811,0.46857208,0.7411847,0.7553381,0.5029312,0.1988201,0.0060786754,0.043137968,0.0,0.0,0.013340399,0.04278086,0.060996868,0.0,0.056995884,0.021952339,0.0456424,0.10882197,0.05718024,0.089428015,0.06023866,0.13474366,0.19899927,0.19470425,0.15617679,0.009488031,0.0,0.0,0.15321782,0.43416476,0.74992424,0.8388063,0.5614066,0.16393688,0.0,0.019864038,0.0,0.0,0.01498507,0.044628203,0.06462472,0.0,0.087735094,0.050924994,0.06283118,0.1452783,0.08540882,0.15761341,0.15107231,0.24105752,0.27104476,0.24118233,0.16227263,0.035065435,0.0,0.0,0.13338992,0.35719335,0.65552473,0.7789291,0.49225742,0.10227449,0.0,0.014715552,0.0013612062,0.0,0.020469554,0.046587415,0.06616489,0.0,0.11482485,0.095644824,0.10167612,0.18554357,0.13078162,0.25363693,0.29852986,0.40467292,0.41613597,0.35757467,0.22325704,0.10337717,0.0,0.0,0.14650655,0.39402044,0.64755195,0.73834264,0.4130001,0.050350912,0.0,0.0087255165,0.021223523,0.017728455,0.029663406,0.048479334,0.06540333],[0.04461591,0.00786069,0.017352,0.059963554,0.02167651,0.09905179,0.25225267,0.09482274,0.0,0.0,0.0,0.0,0.0,0.3079306,0.48223752,0.49289626,0.33198482,0.082034364,0.0,0.0,0.0,0.023464046,0.031120569,0.02352684,0.027787633,0.0,0.0,0.031239495,0.014631897,0.0,0.0,0.061839677,0.0,0.03299626,0.16417655,0.059975863,0.0,0.016361877,0.037441514,0.0,0.2066465,0.50783944,0.6314283,0.5134988,0.26224938,0.031082936,0.0,0.0,0.0,0.030862004,0.017962724,0.008255832,0.029800013,0.00017566979,0.0,0.029034734,0.008422844,0.0,0.0,0.028928027,0.0,0.028843053,0.11206937,0.04971707,0.00042003393,0.044291683,0.12250788,0.089844234,0.37169218,0.61084473,0.7007032,0.5709539,0.27866104,0.045699276,0.0,0.0,0.0,0.025021017,0.017408065,0.0,0.011520006,0.009782217,0.0,0.01821597,0.006213166,0.0,0.0,0.0117243305,0.0,0.049279504,0.0880501,0.04323867,0.08400711,0.14459592,0.22985172,0.24613789,0.4176296,0.5926939,0.653343,0.61474574,0.39870417,0.19379741,0.11527618,0.0,0.0,0.0007613152,0.01177118,0.0,0.0,0.010883838,0.0,0.014008544,0.004173994,0.0,0.0,0.0,0.0030160397,0.069506764,0.08396566,0.079547346,0.21790838,0.29962388,0.33967823,0.3553148,0.3705903,0.42082506,0.41908377,0.45541054,0.44707388,0.39654982,0.2738906,0.0,0.0,0.0,0.010568194,0.0,0.0,0.0027892143,0.0,0.009750254,0.0056052804,0.0,0.0,0.0,0.011376612,0.057409868,0.045074075,0.083951145,0.26331437,0.36132938,0.33297825,0.35183167,0.27997795,0.23708248,0.23546939,0.30635953,0.46553677,0.614502,0.559577,0.25939506,0.10129785,0.0,0.0,0.0,0.0,0.0,0.0010755956,0.006039731,0.016464844,0.0,0.0,0.0038207471,0.039993994,0.06299057,0.035979174,0.09866335,0.2851716,0.39763266,0.33306184,0.3479569,0.2333594,0.16123755,0.16890788,0.25597572,0.46538836,0.68589157,0.6894243,0.42143035,0.199161,0.0,0.0,0.0,0.0,0.0,0.014262706,0.0,0.03270416,0.0040918738,0.0027500242,0.0,0.032852396,0.068978,0.049700595,0.13898246,0.32692587,0.44864267,0.3562334,0.35469824,0.19696265,0.095965676,0.12563762,0.24057794,0.49429476,0.7663556,0.7865215,0.512058,0.22784963,0.0,0.0,0.0,0.0,0.0,0.024922073,0.0,0.044595473,0.024519138,0.01015716,0.0,0.026291236,0.10525949,0.10262863,0.20362203,0.3812688,0.4926207,0.38579524,0.35847068,0.18305172,0.056892335,0.08168754,0.19752562,0.47807246,0.7952624,0.8306139,0.5365725,0.17624505,0.0,0.0,0.0,0.0,0.0,0.037722863,0.0070125237,0.056404002,0.046908915,0.033571064,0.0107814595,0.052261278,0.16391775,0.18147142,0.29917476,0.44136572,0.5502886,0.41077942,0.35060492,0.18330497,0.037792042,0.050600074,0.13696587,0.39104885,0.7110058,0.7396277,0.45750237,0.10825652,0.0,0.0,0.0,0.0,0.0,0.051430494,0.025516301,0.06908019,0.0758416,0.07709859,0.04975026,0.07900925,0.21003006,0.2655025,0.40187216,0.52864265,0.669916,0.5034757,0.43210006,0.21552238,0.036462456,0.032363884,0.12289815,0.39506918,0.67672914,0.65025306,0.37621737,0.06079632,0.0,0.0,0.0,0.0,0.0,0.056730554,0.041636534],[0.018021226,0.0,0.0,0.0,0.04017611,0.0,0.034967974,0.0,0.0,0.0,0.0,0.0,0.09982492,0.5146757,0.82843506,0.8526603,0.54625446,0.2610581,0.0,0.0,0.0,0.04372047,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016239487,0.027449697,0.01774145,0.0,0.0,0.0,0.22475809,0.6098493,0.8894572,0.81865686,0.45866513,0.1916572,0.0,0.0,0.0,0.008785859,0.0,0.037822418,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.024941519,0.045026705,0.03304419,0.005931765,0.017304294,0.11138762,0.31419626,0.5778005,0.7956071,0.67872286,0.382299,0.10976721,0.0,0.0,0.0,0.0,0.0,0.022809677,0.0,0.0,0.003198266,0.0,0.0,0.0,0.0,0.0,0.0,0.008844994,0.023902267,0.08683069,0.09348902,0.13209116,0.1918126,0.2198448,0.33682263,0.45127463,0.6134729,0.55301774,0.44971645,0.18959206,0.0042330027,0.0,0.0,0.0,0.0,0.003964618,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026446827,0.016137868,0.15541248,0.24000917,0.35421026,0.4219879,0.34639663,0.3473569,0.25098863,0.27295202,0.3447113,0.48095042,0.39530873,0.20364079,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03192486,0.01506824,0.20574942,0.33068046,0.4715624,0.545653,0.40814894,0.33213192,0.12101779,0.10321599,0.26781017,0.4986391,0.6064337,0.5647454,0.221461,0.011353724,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04656885,0.03283777,0.24336408,0.39397103,0.53945774,0.6041154,0.413715,0.32125694,0.07506597,0.05393307,0.23126313,0.49779004,0.69868404,0.7569185,0.40358925,0.113082744,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0015288889,0.00059756637,0.0,0.0,0.0,0.06672015,0.07856541,0.29111332,0.4562869,0.6008115,0.6616189,0.41382158,0.30975017,0.037649967,0.036297344,0.21826446,0.5371756,0.8127393,0.90627617,0.4991324,0.10987825,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0004736185,0.0074758977,0.0,0.014967106,0.027066655,0.11225653,0.15060042,0.34115273,0.503707,0.6234082,0.6780012,0.41482377,0.3192656,0.0288238,0.02379699,0.18614945,0.568724,0.899822,0.9919905,0.50389916,0.011181973,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014763147,0.04475514,0.08050653,0.10168915,0.1792832,0.25537255,0.44262773,0.576348,0.6173842,0.62146235,0.38996977,0.31046867,0.048902765,0.011016965,0.13282599,0.53039455,0.8494995,0.92295307,0.40909332,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011226118,0.039844863,0.113645695,0.1472225,0.16327596,0.23238814,0.3328448,0.5428604,0.68125564,0.71353465,0.66218424,0.45001686,0.34955564,0.07033321,0.0,0.09867865,0.53378284,0.8492265,0.85362345,0.30197918,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.021455437,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04564324,0.39521694,0.8285995,1.0,1.0,0.54966915,0.09562172,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.036603786,0.0,0.022740081,0.023686662,0.0,0.0,0.0,0.0,0.035627842,0.0,0.0,0.0,0.06260983,0.38879406,0.8185023,1.0,0.9407281,0.47389448,0.06449883,0.0,0.0,0.0,0.0,0.0019177496,0.0,0.0,0.0,0.0,0.0209217,0.0,0.021898486,0.025800906,0.0,0.0,0.0,0.0,0.054712668,0.009665608,0.020305313,0.04529479,0.13471647,0.355166,0.6337703,0.87868637,0.7394891,0.37716132,0.06460752,0.0,0.0,0.0,0.0,0.018799983,0.0,0.0,0.0,0.0,0.005060345,0.0,0.01984787,0.013181254,0.0,0.0,0.0,0.0,0.09080091,0.07954179,0.15511811,0.19327144,0.19500147,0.27243328,0.41879869,0.5943728,0.58048666,0.45086032,0.2616928,0.0,0.0,0.0,0.0,0.057964817,0.002352208,0.0031763017,0.0,0.0,0.0,0.0,0.0029068142,0.0,0.0,0.0,0.0,0.010913171,0.13046253,0.24653766,0.41254658,0.43968916,0.32432523,0.23313361,0.16114944,0.24024385,0.34685463,0.5467798,0.5254508,0.18436906,0.0,0.0,0.0,0.058693543,0.017424129,0.017853454,0.0,0.0,0.0,0.0024710596,0.0,0.0,0.0,0.0,0.0,0.09239061,0.19251236,0.3949116,0.6230107,0.6567528,0.45439053,0.24147631,0.021175683,0.13708298,0.24345268,0.5920958,0.76850784,0.54906374,0.1950327,0.0,0.0,0.04173796,0.017577663,0.025782637,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017590024,0.008105665,0.16684529,0.27376142,0.50084424,0.73252666,0.74549156,0.47015464,0.23292384,0.0,0.11458688,0.20094451,0.6122836,0.8768669,0.7504098,0.35461736,0.049985647,0.0,0.032387286,0.0066305995,0.017273478,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034340784,0.04827118,0.24654478,0.3495164,0.57356775,0.792714,0.7760311,0.4580235,0.20588344,0.0,0.10656768,0.17579857,0.68400407,1.0,0.91308117,0.4130832,0.017418146,0.0,0.01157134,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.080886796,0.10637866,0.30798313,0.41037005,0.590976,0.75367236,0.7148525,0.42661417,0.20313534,0.0,0.11621741,0.13800652,0.76315916,1.0,1.0,0.39809906,0.0,0.0,0.0,0.0,0.00021496415,0.0,0.00557068,0.007491365,0.0,0.0,0.0075009167,0.0,0.13445985,0.18483107,0.39906174,0.51958925,0.62347347,0.637771,0.5749972,0.35079312,0.19789076,0.047639214,0.12592492,0.11267457,0.7609563,1.0,1.0,0.37322497,0.0,0.0,0.0,0.029336162,0.025595851,0.0,0.0055874735,0.001986742,0.0,0.0,0.04611092,0.04447648,0.1806589,0.26113063,0.48956484,0.62425375,0.7050166,0.6373506,0.5634587,0.34499142,0.20208552,0.026517235,0.094066136,0.08023499,0.778419,1.0,0.963242,0.31063098,0.0,0.0,0.0014045238,0.035268307,0.026945509,0.0,0.0,0.0],[0.07715812,0.058076955,0.032134935,0.0,0.0,0.0,0.0,0.01465743,0.0,0.0,0.0,0.20941734,0.58342415,1.0,1.0,1.0,0.46999764,0.0,0.0,0.0,0.0,0.0,0.004903868,0.032162525,0.0,0.0,0.0020166487,0.0,0.03705141,0.038047858,0.036380827,0.0013754666,0.0,0.0,0.0,0.03465324,0.012229443,0.0,0.0,0.16489993,0.46595615,0.9944296,1.0,0.99170834,0.38986707,0.0,0.0,0.0,0.0,0.0,0.030814506,0.05769659,0.004930854,0.0,0.0,0.0,0.009611174,0.027739264,0.040281467,0.021565698,0.0,0.0,0.0,0.029581174,0.03013181,0.04078666,0.053230636,0.16391967,0.3522036,0.6794371,0.95651215,0.7545257,0.30158138,0.0,0.0,0.0,0.0,0.0,0.012848146,0.04945465,0.007911585,0.0,0.0,0.0,0.0,0.0,0.008759342,0.012102671,0.0,0.0,0.0,0.01994393,0.06378111,0.11004353,0.1379152,0.16699217,0.23883465,0.38956773,0.5701678,0.55968696,0.40226108,0.14026639,0.0,0.0,0.0,0.0,0.008586265,0.03029842,0.00987839,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06263969,0.24046749,0.37646055,0.36797515,0.25829554,0.156555,0.07594254,0.12703346,0.34885067,0.5879187,0.57465136,0.27862504,0.0,0.0,0.0,0.0,0.015012175,0.015858568,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0044047236,0.029766947,0.020487629,0.16930614,0.48084295,0.72348803,0.63823354,0.38953596,0.1618335,0.0,0.0,0.25567216,0.657095,0.88788766,0.61361104,0.093285754,0.0,0.0,0.0,0.0069069266,0.022430524,0.0,0.0,0.01711186,0.0,0.0,0.0,0.0,0.00042684376,0.0800942,0.09943601,0.27859724,0.61768997,0.87206095,0.7294308,0.42409492,0.17074667,0.0,0.0,0.20440513,0.66351146,0.9943305,0.81205815,0.25396854,0.0,0.0,0.006829649,0.006228693,0.02638863,0.0,0.0,0.019912288,0.0,0.0,0.0,0.0,0.0,0.12343747,0.17913282,0.35795707,0.6908706,0.92307234,0.7598596,0.42465138,0.18228963,0.0,0.0,0.19820333,0.74009037,1.0,0.9315479,0.30988586,0.0,0.0,0.001269862,0.008132197,0.03295649,0.0030395687,0.005535662,0.024310656,0.0,0.0,0.0,0.0,0.013127461,0.1535996,0.23079804,0.3706939,0.66725945,0.8408185,0.7157924,0.407156,0.23266783,0.0009692311,0.0,0.19757429,0.8243744,1.0,0.9689646,0.29323405,0.0,0.0,0.0057051256,0.028958574,0.054833464,0.01335714,0.016264647,0.02828867,0.0,0.0,0.0,0.0,0.038240127,0.21536112,0.32825267,0.40814078,0.6173874,0.7043295,0.59196746,0.3261087,0.2665899,0.04850632,0.0,0.20683588,0.8494601,1.0,0.9512592,0.28937778,0.0,0.0,0.02284395,0.057986803,0.08433776,0.021429218,0.01687672,0.019938461,0.0,0.0,0.0,0.0143904835,0.085551314,0.3030421,0.41929477,0.4698395,0.64455664,0.69321805,0.5634904,0.29830253,0.24768585,0.03008683,0.0,0.2082708,0.8765645,1.0,0.90595686,0.2594623,0.0,0.0,0.032716177,0.07952357,0.093917236,0.0072398186,0.00040365756,0.012228586],[0.050782494,0.035921328,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035599425,0.016261175,0.31421095,0.6462481,1.0,1.0,1.0,0.12442363,0.0,0.0,0.0,0.0,0.00096824765,0.05621428,0.0,0.0,0.029919885,0.00554727,0.0,0.006602064,0.00541991,0.010551445,0.0,0.0,0.0,0.0,0.00434722,0.0,0.025599651,0.0,0.18824176,0.46765107,1.0,1.0,0.8853097,0.039840363,0.0,0.0,0.0,0.0,0.0149440095,0.06310854,0.0,0.0,0.009853348,0.016326562,0.0,0.0,0.0,0.027706943,0.0,0.0,0.0,0.0,0.009682305,0.034793153,0.044242777,0.030208327,0.1286328,0.32424405,0.74010533,0.9359609,0.69648314,0.117311046,0.0,0.0,0.0,0.0,0.00034037232,0.016218297,0.0,0.0,0.009305403,0.015419409,0.000036612153,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011613868,0.07593298,0.1132641,0.11948383,0.09701058,0.19528028,0.41004103,0.5759191,0.55633414,0.34665906,0.17021418,0.032354675,0.0,0.0,0.0044706464,0.002235666,0.0,0.0028504431,0.026781611,0.011675872,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07723762,0.26183128,0.39173824,0.35257748,0.13470039,0.101651326,0.10553672,0.19086948,0.38954592,0.63284975,0.63727546,0.2585192,0.0,0.0,0.0,0.0,0.0,0.033202916,0.03162943,0.016939677,0.0028868765,0.0,0.0,0.0,0.0,0.0,0.0,0.056636065,0.2403564,0.5297447,0.73362106,0.5765689,0.2015319,0.04316446,0.0015684962,0.018509276,0.2625382,0.70996875,0.89440393,0.49048322,0.0,0.0,0.0,0.0,0.022207074,0.061715238,0.022539668,0.03239762,0.011216983,0.0,0.0,0.0,0.0,0.0,0.030816235,0.14760047,0.3872909,0.6867691,0.8631035,0.6560064,0.21673572,0.022388965,0.0,0.0,0.19281465,0.6967072,0.9736794,0.63332117,0.10701668,0.0,0.0020886213,0.0086413175,0.027972057,0.07368094,0.01953128,0.034992352,0.014578901,0.0,0.0,0.0,0.0,0.0,0.06931937,0.22858691,0.46972078,0.764182,0.88772744,0.65726155,0.22906223,0.013399281,0.0,0.0,0.16803783,0.7495954,1.0,0.7315184,0.15479678,0.0,0.0,0.0014405102,0.038935862,0.081262246,0.015904315,0.040937148,0.0176453,0.0,0.0,0.0,0.0,0.0,0.09840643,0.25890565,0.43774408,0.69646,0.7777907,0.5669951,0.26660848,0.03935436,0.012998752,0.0,0.16524984,0.8338583,1.0,0.8191919,0.16378993,0.0,0.0054183304,0.0,0.06944278,0.08910996,0.0,0.030564904,0.014173031,0.0,0.0,0.0,0.0,0.0,0.17588867,0.33807802,0.42893225,0.5813478,0.63560665,0.44075066,0.27111784,0.06267695,0.051427595,0.0,0.17548627,0.8840849,1.0,0.88155997,0.202205,0.0,0.040875256,0.0050046146,0.10668918,0.10708249,0.0,0.022341289,0.0045859367,0.0,0.0,0.02237288,0.031153075,0.040458485,0.264736,0.40010297,0.43819976,0.5509581,0.6244095,0.38743234,0.27169222,0.054733954,0.042544417,0.0,0.1925016,0.9356358,1.0,0.9087498,0.20394793,0.0,0.061308652,0.026829481,0.13019443,0.11691812,0.0,0.019226752,0.004825473],[0.061591998,0.05891992,0.04402823,0.0,0.0,0.0,0.0,0.037228636,0.00036026537,0.00075536966,0.06823249,0.28854465,0.70689386,1.0,1.0,0.76662606,0.19844909,0.0,0.0,0.0,0.0,0.017107047,0.019448042,0.0,0.0,0.022080809,0.015161797,0.016028963,0.020572439,0.04927033,0.050423726,0.0036496222,0.0,0.0,0.0,0.039126806,0.025188059,0.017872445,0.06633562,0.16852486,0.51643085,1.0,1.0,0.7415187,0.11612662,0.0,0.0,0.0,0.0,0.04057297,0.038969457,0.0,0.0,0.0065354407,0.036716543,0.026537895,0.009373657,0.039252385,0.042564012,0.0017070919,0.0,0.0,0.0,0.024488837,0.035447575,0.03910239,0.08706247,0.090301365,0.32188743,0.71082246,0.9216348,0.65423065,0.1760016,0.0,0.0,0.0,0.0,0.031434856,0.02945587,0.0,0.0,0.0,0.026049644,0.01789841,0.0,0.0027540177,0.0068800002,0.0,0.0,0.0,0.0,0.018504329,0.072029665,0.12060347,0.17974396,0.09511193,0.17519464,0.38214087,0.614096,0.55985516,0.38186073,0.20237453,0.06893258,0.0,0.0,0.02984108,0.034125924,0.0,0.0,0.0,0.0073982924,0.0034570545,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07826111,0.26972848,0.40212113,0.3604311,0.13730815,0.091214895,0.13280691,0.31003642,0.5440476,0.72813344,0.56490815,0.20423524,0.0,0.0,0.02635789,0.04902532,0.0,0.0010276884,0.0039865375,0.004760444,0.004857123,0.0,0.0,0.0,0.0,0.0,0.0,0.03422065,0.25277805,0.5649914,0.6916584,0.50724405,0.18336806,0.049145997,0.0,0.073330835,0.47849315,0.8285979,0.8088354,0.3266226,0.0,0.0,0.0034371912,0.04369957,0.022462942,0.0457365,0.036616474,0.01765889,0.02167926,0.0,0.0,0.0,0.0,0.0,0.048353545,0.1276573,0.4187069,0.73011386,0.81880355,0.5630314,0.19958717,0.046980806,0.0,0.0,0.41210312,0.8300917,0.8996494,0.44257188,0.011117876,0.0,0.0,0.049360268,0.038926966,0.072145015,0.055265613,0.028641038,0.024554402,0.0,0.0,0.0,0.0,0.0,0.09829025,0.20985316,0.5342943,0.82854056,0.8875612,0.6026547,0.23133652,0.07907587,0.0,0.0,0.35861942,0.835424,0.9576223,0.53880906,0.07045089,0.0,0.0,0.054745123,0.046736546,0.08126071,0.061067544,0.040492803,0.030389942,0.0,0.00383842,0.0,0.0,0.0,0.13302858,0.24586639,0.552992,0.81590706,0.88558984,0.64592487,0.31625172,0.1442678,0.0,0.0,0.2867552,0.84710807,0.98510754,0.62891144,0.11163427,0.0,0.0,0.05223164,0.043637916,0.07646954,0.063474774,0.05256702,0.041664585,0.0,0.0042041093,0.0,0.0053237975,0.018779553,0.19793892,0.29757965,0.57966316,0.7827013,0.8156397,0.6240633,0.35903198,0.19396764,0.0,0.0,0.23016796,0.84144837,0.98021305,0.70881045,0.1654237,0.001487717,0.0,0.05504196,0.038002893,0.06459868,0.059144586,0.046356425,0.04087279,0.0,0.0,0.0,0.03180653,0.07150954,0.25693536,0.31981164,0.5813297,0.7669106,0.82053596,0.6535598,0.41298074,0.22303161,0.0,0.0,0.18534943,0.83165693,0.950545,0.7463104,0.18718255,0.047980793,0.015094034,0.085373074,0.055685677,0.048017345,0.049651057,0.046657056,0.047595136],[0.07628733,0.06841138,0.059976414,0.0,0.0,0.0,0.0030902028,0.0,0.011989661,0.0,0.0,0.08388008,0.46253532,0.90883654,1.0,0.5969531,0.075444765,0.0,0.04913239,0.0,0.027112864,0.0,0.0,0.0,0.0,0.014634252,0.050930135,0.0,0.04158678,0.03427729,0.04605612,0.0,0.0,0.0,0.0,0.0,0.025629707,0.0,0.0037624687,0.064680584,0.38065606,0.8955517,1.0,0.5872128,0.07600905,0.0,0.0,0.0,0.033842497,0.04496056,0.0154537335,0.0,0.0,0.039356515,0.08790913,0.0,0.020692952,0.018350609,0.028241418,0.0,0.0,0.0,0.0,0.012597129,0.04150738,0.037597284,0.048401326,0.09653288,0.27176726,0.75200474,0.94964105,0.60967934,0.1525159,0.007151425,0.0,0.0,0.03281139,0.061950758,0.03150049,0.0010966659,0.0,0.032071322,0.08005194,0.0,0.0007686019,0.0,0.011432253,0.0,0.0,0.0,0.0,0.04995378,0.10405579,0.18309978,0.18481055,0.20239803,0.21414188,0.5488573,0.7196213,0.65340984,0.3570019,0.19859418,0.06100723,0.0,0.04495942,0.07861403,0.053818338,0.012479827,0.0,0.020534582,0.05726479,0.0,0.001855731,0.0,0.009788051,0.0,0.0,0.0,0.0,0.11828683,0.29155394,0.48833084,0.3826825,0.30146447,0.22887343,0.38791966,0.5347751,0.76224434,0.7013727,0.4929222,0.15924367,0.0,0.030471973,0.10663526,0.08245474,0.020975828,0.01581075,0.023275778,0.04893189,0.0,0.0,0.0,0.019860603,0.0,0.00823532,0.015437789,0.026220933,0.27900392,0.5417007,0.79262197,0.52562064,0.3661489,0.2704986,0.26908815,0.3858899,0.70956385,0.8944583,0.7714713,0.31101513,0.018775545,0.0,0.06803949,0.10980659,0.04619155,0.06294772,0.042221494,0.05611583,0.028077371,0.0,0.0,0.02953802,0.0,0.009126402,0.07174233,0.1153811,0.40620756,0.67902946,0.93540984,0.59737027,0.41977578,0.3222586,0.21223752,0.32851666,0.6456178,0.96977574,0.9251299,0.43891263,0.09042503,0.0,0.053290866,0.12738594,0.06467895,0.08904659,0.058010273,0.05755382,0.033909865,0.0,0.0,0.034576066,0.0,0.004897639,0.120691665,0.19914354,0.5127299,0.7654981,1.0,0.68662405,0.50743306,0.4029408,0.18096653,0.2613011,0.5869232,1.0,1.0,0.535188,0.16597614,0.0024667382,0.05988638,0.14500512,0.067314155,0.099020675,0.06835374,0.07477896,0.0533116,0.0,0.0,0.034093834,0.0,0.0,0.1493497,0.27173954,0.57735306,0.7606323,1.0,0.77071345,0.6089767,0.47379124,0.14941792,0.14309902,0.5168604,1.0,1.0,0.61331785,0.24556562,0.036832497,0.07325795,0.16286202,0.064318135,0.09094129,0.073378906,0.10537005,0.080705725,0.0,0.0,0.022565693,0.0,0.012476996,0.17995216,0.36179346,0.66376346,0.7418509,1.0,0.7695202,0.6396404,0.49037766,0.12316909,0.04621561,0.47506237,1.0,1.0,0.6848397,0.3346193,0.08756103,0.09635155,0.17252977,0.06561608,0.080328956,0.07086445,0.124322645,0.09870511,0.0,0.0,0.003866449,0.0,0.04633613,0.20649156,0.39290106,0.7139989,0.7653654,1.0,0.8228986,0.6905514,0.48455602,0.10799495,0.0,0.44753367,1.0,1.0,0.7101653,0.40011764,0.14532354,0.1680312,0.21791501,0.08207717,0.07117678,0.06193518,0.14143471,0.11334256],[0.026373707,0.0669463,0.063920565,0.024435706,0.0,0.042806424,0.0141822845,0.011511773,0.0,0.0,0.0,0.0,0.2371876,0.6542842,0.73759973,0.5075467,0.21195504,0.12526806,0.120152496,0.026433274,0.027458593,0.044640727,0.0,0.0,0.0,0.046151772,0.015638813,0.0,0.011698961,0.04355909,0.048167557,0.03132175,0.0,0.023415565,0.011239529,0.0,0.0319708,0.0,0.0,0.0,0.23848617,0.7885196,0.89068365,0.5999625,0.16834727,0.055641316,0.064318374,0.0,0.04017465,0.08481223,0.0,0.0027958155,0.0,0.044181295,0.025901452,0.0,0.0,0.02180563,0.023071252,0.009917155,0.0,0.0,0.014976092,0.0,0.06091503,0.035982087,0.0,0.013385288,0.20057827,0.7038257,0.8715137,0.6475931,0.2397106,0.10218039,0.079428166,0.0,0.06313742,0.111206606,0.0468677,0.024726585,0.0,0.022543699,0.015022568,0.0,0.0,0.004205033,0.008785181,0.0,0.0,0.0,0.02417425,0.0,0.115237325,0.15686107,0.15110067,0.121832415,0.2187075,0.5286716,0.7162811,0.6160817,0.408795,0.24450938,0.13790551,0.0,0.07703932,0.11707344,0.075225696,0.025962964,0.0,0.0,0.0,0.0,0.0,0.012294538,0.0055159926,0.0,0.0,0.0,0.032357305,0.05611612,0.26747495,0.3767617,0.3697356,0.30968136,0.32921457,0.47155702,0.61380553,0.6550318,0.6630343,0.45056778,0.20021717,0.0,0.08677079,0.11645838,0.09937519,0.043268666,0.009254299,0.026040912,0.002040431,0.0,0.0,0.007297717,0.0043311417,0.0,0.0,0.0,0.063842624,0.1902541,0.5174462,0.68858445,0.6093555,0.49945003,0.4322505,0.35828072,0.43140024,0.5685072,0.81283355,0.6572643,0.31684053,0.057792127,0.097041935,0.09960236,0.123804286,0.08780785,0.10274158,0.10815662,0.047180153,0.0061398745,0.0,0.0,0.0023114383,0.0,0.0,0.0,0.1257531,0.30737674,0.6757809,0.87228084,0.7457626,0.61807144,0.50334114,0.3246972,0.3488873,0.5270298,0.90721756,0.82102853,0.44193828,0.10866438,0.110275924,0.09748419,0.14217529,0.11521155,0.14728884,0.1445048,0.063194096,0.012827553,0.0,0.0,0.0,0.0,0.0,0.03307666,0.212206,0.4439925,0.8202668,1.0,0.90586406,0.75451803,0.5962607,0.31315982,0.27765432,0.44900048,0.9347358,0.92332923,0.5490463,0.1651286,0.12568219,0.098026946,0.15310845,0.13405177,0.18127085,0.1866678,0.09152514,0.028794065,0.0,0.0,0.0,0.0,0.0,0.088357165,0.2985782,0.5558911,0.9137831,1.0,1.0,0.8629682,0.6547067,0.30368263,0.21315059,0.3460103,0.90324146,1.0,0.676009,0.24819183,0.15153706,0.07429445,0.14337347,0.13607065,0.21563798,0.2362043,0.12876004,0.052062683,0.0,0.0,0.0,0.0,0.0,0.13039243,0.3914079,0.69011253,1.0,1.0,1.0,0.8960102,0.6609147,0.33716106,0.2062294,0.3144193,0.87976104,1.0,0.7863483,0.35417834,0.22543946,0.078791544,0.14525487,0.131136,0.2353819,0.2632584,0.14797905,0.068312675,0.0,0.0,0.0,0.0,0.0,0.14109686,0.41925812,0.7618761,1.0,1.0,1.0,0.95016485,0.6984744,0.41879708,0.24654196,0.30561447,0.86700016,1.0,0.8343737,0.42595524,0.3459955,0.16894007,0.19231951,0.13630766,0.23066631,0.27819395,0.1624378,0.08160965],[0.026640654,0.0,0.065141164,0.013902858,0.021347024,0.058373548,0.062077813,0.0,0.0,0.0,0.0,0.0,0.13199994,0.5738859,0.5657198,0.42047006,0.25314412,0.24419919,0.24627301,0.043709166,0.030872189,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019874752,0.0,0.051281646,0.017960578,0.0030692965,0.020508334,0.03466641,0.0,0.0,0.0,0.0,0.0,0.1578347,0.7131646,0.7389539,0.52258384,0.23448525,0.15836373,0.16919066,0.0,0.012962647,0.0,0.0,0.0027834177,0.0,0.007950455,0.00527288,0.0,0.009931199,0.0,0.027346812,0.0,0.0,0.0,0.020707525,0.0,0.0,0.0,0.0,0.0,0.14093103,0.65757805,0.7501672,0.56395686,0.25135404,0.16325313,0.108979985,0.0,0.001036197,0.0,0.0,0.005466655,0.0,0.002329886,0.013241611,0.0,0.001694724,0.0,0.01516524,0.0,0.0,0.0,0.015723959,0.0005540997,0.0038005114,0.06100101,0.11927216,0.059003882,0.16506527,0.49907202,0.6104403,0.5495281,0.36714935,0.23530531,0.07763681,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0021720678,0.0,0.008237295,0.0,0.013116218,0.0,0.0,0.0,0.011528991,0.063380584,0.14811891,0.24457477,0.2961083,0.25242308,0.26033053,0.43079036,0.5344286,0.6086261,0.563846,0.3447349,0.07416758,0.0,0.0,0.003196299,0.0,0.0,0.014203377,0.0185114,0.016377307,0.0,0.008723274,0.0,0.014028132,0.0,0.0,0.0,0.028733559,0.179602,0.40288788,0.51587033,0.49999034,0.44816482,0.35507542,0.34284478,0.38140708,0.563815,0.69918644,0.4923209,0.14520656,0.03326726,0.0,0.016636439,0.006181486,0.03039001,0.1139396,0.104474075,0.06273,0.0013780594,0.0029150695,0.0,0.014372744,0.0,0.0035077035,0.028483018,0.074793085,0.26655853,0.54605275,0.67240036,0.62546283,0.55868274,0.4057808,0.30583334,0.30636317,0.5513422,0.80057853,0.66454804,0.26294038,0.07122491,0.0,0.019308835,0.005817488,0.046296924,0.15747695,0.14075045,0.0811708,0.005721219,0.0,0.0,0.012815788,0.0,0.015265435,0.062301286,0.14502656,0.38228178,0.6777117,0.8444105,0.8088991,0.7159642,0.4925173,0.28706676,0.23534554,0.47519547,0.8159839,0.783866,0.3924222,0.12427289,0.0029006302,0.017458051,0.0,0.054791436,0.18740505,0.18221372,0.11037477,0.013730086,0.0,0.0,0.0048107505,0.0,0.02983857,0.08149262,0.20915756,0.480946,0.75438446,1.0,1.0,0.88409406,0.57595986,0.2865783,0.18172234,0.36715388,0.78153,0.92041105,0.58010304,0.23368841,0.06787098,0.009199478,0.0,0.07141235,0.22753748,0.22207713,0.12498483,0.023414537,0.0,0.0,0.0040988177,0.0,0.02841688,0.08973241,0.27582926,0.5970107,0.83972204,1.0,1.0,0.9877213,0.66833365,0.35247457,0.21901923,0.33663413,0.7737148,1.0,0.77905405,0.40169084,0.19271919,0.06132131,0.031220213,0.085853145,0.25913078,0.23888078,0.113632716,0.032725282,0.0,0.0,0.0059011728,0.0,0.014520951,0.06655499,0.2967292,0.66873294,0.9333313,1.0,1.0,1.0,0.7833824,0.46511507,0.27956146,0.3307878,0.77936035,1.0,0.91759783,0.55783975,0.37655807,0.19535422,0.12249696,0.11327049,0.28868896,0.26686397,0.11988168,0.051456027],[0.006608568,0.0,0.07099809,0.059488967,0.06872548,0.037830792,0.027851634,0.0,0.0,0.0,0.0,0.008450888,0.16282663,0.28432077,0.33495134,0.2555918,0.30476135,0.26888958,0.20659898,0.10997213,0.056156166,0.0,0.0,0.043623783,0.018060088,0.030753374,0.0027773976,0.023807578,0.0014163703,0.0,0.055355452,0.05534759,0.05316759,0.013367318,0.00027999282,0.0,0.0,0.0,0.0,0.027352631,0.13685454,0.42965478,0.5775763,0.4999025,0.36033547,0.16065134,0.07061866,0.0,0.0,0.031824887,0.00094237924,0.048775755,0.008747183,0.031593613,0.0067357793,0.018967837,0.0,0.0,0.02065289,0.027527086,0.039523996,0.007125132,0.0,0.0,0.017058171,0.0,0.0,0.0,0.09691143,0.42778134,0.61289114,0.57435703,0.40527833,0.17657524,0.06408287,0.0,0.0,0.031189248,0.014873207,0.04364407,0.0045047104,0.024287313,0.0028352886,0.006155193,0.0,0.0,0.0040011406,0.017908953,0.022418909,0.008415498,0.0,0.0,0.02421356,0.0,0.006624505,0.0023130476,0.065282755,0.30386913,0.539644,0.54761493,0.47827166,0.23743665,0.06531306,0.0,0.0,0.007987089,0.013639249,0.031075284,0.0,0.009174675,0.0,0.0,0.000014707446,0.0,0.003214091,0.008038141,0.0,0.0,0.00094380975,0.00086668134,0.07917753,0.08691235,0.08254577,0.082433075,0.095790535,0.24635142,0.50779027,0.58604753,0.54102975,0.24399528,0.009862177,0.0,0.012953095,0.008302651,0.026670314,0.04982908,0.02036573,0.0152055025,0.0,0.0,0.0024265945,0.0,0.0,0.0,0.0,0.0,0.024806544,0.085574456,0.22294453,0.26083547,0.18073274,0.17368117,0.14035597,0.18182248,0.41620147,0.55171335,0.5459102,0.28312546,0.010242954,0.008291662,0.032956697,0.008027934,0.05022604,0.10337214,0.081575215,0.06507919,0.0,0.016970493,0.0038534552,0.0,0.0,0.0,0.0,0.01040078,0.049073204,0.1352828,0.29958984,0.35402527,0.23030728,0.21802434,0.1585652,0.13992636,0.3408552,0.5527745,0.64981145,0.42798203,0.07740234,0.014280461,0.0186126,0.0015922189,0.063155174,0.14166401,0.121145315,0.09083554,0.005378574,0.025735348,0.012050532,0.0,0.0,0.0,0.0,0.018686242,0.08110727,0.20212024,0.3882175,0.4655488,0.3356542,0.3297624,0.22645226,0.07858584,0.21008809,0.46871263,0.73074955,0.5866189,0.1843198,0.038329177,0.020373367,0.0116778985,0.08650508,0.17601794,0.15711303,0.124698944,0.022434555,0.037588954,0.020333253,0.0,0.0,0.0,0.0,0.01683639,0.09425682,0.2525292,0.46175045,0.58681923,0.506841,0.535513,0.3419947,0.07089528,0.12076381,0.38715208,0.79547614,0.84637207,0.47819752,0.21840848,0.0821946,0.055024788,0.11966806,0.19075347,0.19050673,0.15931451,0.047184497,0.0532222,0.028311625,0.0,0.0,0.0,0.0,0.026678704,0.12615809,0.30567062,0.54994965,0.70426166,0.6767055,0.74385035,0.46905792,0.1343539,0.1297431,0.3948757,0.8800495,1.0,0.77269447,0.422096,0.20432593,0.15544276,0.18700917,0.19380203,0.20034355,0.16597109,0.053774334,0.067640826,0.03606461,0.0,0.0,0.0,0.0,0.010609947,0.13122821,0.32999638,0.63835496,0.83112216,0.88076663,0.9874216,0.6327536,0.22587213,0.14552298,0.40861636,0.9547211,1.0,0.99416137,0.610943,0.38490576,0.32456055,0.28421745,0.25072533,0.23665154,0.1825449,0.070940614,0.08682516],[0.0,0.010271415,0.0701015,0.06342484,0.052417375,0.00914944,0.0,0.030875593,0.0,0.0,0.08162215,0.112800136,0.31361312,0.33109635,0.3175086,0.26149482,0.20276688,0.31943285,0.27516705,0.23272361,0.12741628,0.0,0.0,0.008443713,0.034664325,0.035937056,0.0,0.0232554,0.0,0.004221335,0.053701803,0.045520835,0.048067614,0.0,0.0,0.05079343,0.0022116601,0.0034630746,0.05950097,0.024357013,0.24635127,0.38317907,0.5209003,0.49944198,0.2875185,0.25499183,0.1305147,0.01894807,0.04853771,0.005169913,0.010231413,0.0,0.04328303,0.035046622,0.0,0.031110376,0.0,0.0,0.012078859,0.01752761,0.038530424,0.0,0.0,0.062557876,0.0061572567,0.024693958,0.03054367,0.0,0.14665917,0.32523072,0.5446891,0.59922,0.37639704,0.2584483,0.11384377,0.0,0.03757079,0.009018399,0.017850444,0.0,0.037711523,0.03002289,0.0,0.02802191,0.0,0.0,0.0,0.010001697,0.021292076,0.012768514,0.0022743344,0.037901558,0.0,0.0,0.0,0.0,0.040119916,0.21280715,0.4731593,0.60855025,0.47889847,0.2745984,0.09950877,0.0,0.021444902,0.0,0.0013988316,0.0,0.026749462,0.012198873,0.0,0.023850366,0.0,0.0,0.0,0.0053582788,0.0054857433,0.009498954,0.0,0.0059453025,0.007998042,0.012804046,0.0041045547,0.0,0.0055995136,0.13193588,0.4366619,0.6470767,0.49903303,0.16901328,0.02814538,0.0,0.021600537,0.0,0.0,0.0,0.03488747,0.0,0.0015300065,0.027443722,0.0,0.0,0.0,0.0009698272,0.002721414,0.028539777,0.0030991286,0.012722068,0.066479094,0.046433285,0.014188252,0.0,0.0,0.047170468,0.35012817,0.564907,0.45502394,0.09704116,0.0,0.007418491,0.0,0.0,0.0,0.022880323,0.08413125,0.0,0.033689648,0.055493854,0.00068053603,0.0,0.0,0.0,0.00621669,0.03319732,0.0012390912,0.026064306,0.09074016,0.062403195,0.019489862,0.0,0.0,0.0,0.27227116,0.57106656,0.5662917,0.20819454,0.030668043,0.0,0.0,0.0,0.0031547248,0.049780287,0.11233218,0.0,0.035545424,0.06647986,0.0102805495,0.0,0.0,0.0,0.01231163,0.015480287,0.00053836405,0.062852204,0.12488605,0.09824617,0.07920104,0.059380405,0.0,0.0,0.11277074,0.5050151,0.6972824,0.3898598,0.13347541,0.010062866,0.0,0.0,0.018290319,0.085075974,0.14422688,0.01952535,0.044738717,0.08397052,0.02265343,0.011852719,0.0,0.0,0.024989888,0.0,0.0,0.1048601,0.16416651,0.16850378,0.254547,0.236226,0.066102535,0.0,0.0,0.43388623,0.8324353,0.72593045,0.45142168,0.20060846,0.0084567,0.059513234,0.07042025,0.14051417,0.19092229,0.05649788,0.06391242,0.10973732,0.032181002,0.029570863,0.0,0.0,0.036551736,0.0,0.0,0.17189386,0.21260151,0.26415458,0.44953328,0.41798174,0.18864655,0.0,0.0,0.44904202,0.98365766,1.0,0.81213427,0.40667754,0.14517432,0.18687855,0.12456411,0.17277089,0.21255036,0.078846164,0.071031965,0.12696224,0.040660694,0.039041355,0.0,0.0,0.04407443,0.0,0.0,0.22303191,0.27511024,0.36354637,0.66732776,0.6475562,0.34090754,0.011273421,0.0,0.4692796,1.0,1.0,1.0,0.6369285,0.3481627,0.34548593,0.22011614,0.24999031,0.257145,0.10061893,0.07980593,0.14265567],[0.0,0.0,0.013325505,0.04051619,0.013968892,0.0,0.02389986,0.022384837,0.016679034,0.016415246,0.033948362,0.17062785,0.3182683,0.3416345,0.32587007,0.25962108,0.49591082,0.56827074,0.4031093,0.24279234,0.10259992,0.0,0.024014145,0.05566998,0.08594461,0.051793307,0.060086846,0.023716956,0.0,0.0,0.005713515,0.048624754,0.008618303,0.0,0.042401843,0.043275684,0.045420416,0.03102149,0.029295728,0.07371767,0.20712715,0.3876016,0.53516495,0.5095137,0.6137603,0.46556044,0.17448118,0.010071635,0.012200601,0.0,0.037352063,0.035912625,0.059620455,0.040863305,0.069661126,0.031633317,0.0,0.0,0.0,0.033693604,0.010155186,0.01650852,0.06507406,0.058488026,0.044694297,0.035696127,0.0056568086,0.034939952,0.09658307,0.3079797,0.55146325,0.634706,0.6641499,0.42367858,0.12690768,0.0,0.0,0.0,0.03493002,0.014959633,0.041797794,0.037445694,0.059242047,0.02377171,0.0,0.0,0.007927865,0.041167177,0.0135359615,0.030121423,0.0642841,0.05414,0.027565174,0.008983843,0.0,0.0,0.0,0.20598647,0.5082353,0.6657232,0.64565027,0.35623682,0.089523435,0.0,0.0,0.0,0.014293104,0.0,0.025008574,0.026132159,0.041284963,0.01669415,0.0,0.0,0.02770631,0.031821817,0.0,0.025532871,0.05498056,0.014529638,0.00561814,0.0,0.0,0.0,0.0,0.1851661,0.50453955,0.62124795,0.4607302,0.16377944,0.013998024,0.0,0.0,0.0,0.02235064,0.0,0.0,0.0,0.0122958645,0.0145915225,0.0,0.0037301928,0.044405147,0.028746456,0.0,0.02655761,0.04084602,0.0,0.0,0.0,0.0,0.0,0.0,0.11537147,0.3860529,0.44272745,0.24142767,0.0,0.0,0.0,0.004947081,0.0,0.035057783,0.0,0.0,0.014991276,0.03564524,0.037177816,0.0,0.009557202,0.04854308,0.018933423,0.0,0.024028227,0.03760971,0.0,0.0,0.0,0.0,0.0,0.0,0.037959523,0.30442378,0.43607813,0.3024315,0.03143607,0.0,0.0,0.0037402809,0.0,0.048059635,0.0,0.0,0.016727105,0.04437878,0.050744705,0.01144515,0.025162823,0.05246766,0.006254129,0.0,0.022869945,0.026022546,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15496913,0.39506888,0.4407732,0.17457832,0.07379998,0.0,0.0059952736,0.0004905462,0.063054524,0.0,0.0,0.02224636,0.05071634,0.06324909,0.03310936,0.04311043,0.05653636,0.0,0.0,0.016641013,0.020611212,0.0,0.0,0.0,0.05578105,0.04543431,0.0,0.0,0.018371783,0.37665385,0.63481474,0.51712674,0.38805455,0.09119342,0.027687669,0.01667945,0.081204005,0.03525538,0.024180658,0.0599738,0.06937295,0.07316622,0.04798902,0.05273976,0.06356288,0.0,0.0,0.02454096,0.03291087,0.0,0.019876435,0.0821383,0.19639961,0.12900957,0.0,0.0,0.0018255413,0.45329338,0.8968125,0.9048251,0.72727764,0.27708313,0.10881436,0.0644424,0.11286242,0.07888705,0.06541886,0.11932845,0.099979475,0.0751854,0.062370934,0.0601641,0.06693591,0.0,0.0,0.039109968,0.040735915,0.0,0.050900087,0.19943577,0.382823,0.28589866,0.017428525,0.0,0.01138714,0.5357549,1.0,1.0,1.0,0.52051336,0.26508474,0.15448752,0.1660728,0.14205517,0.10108267,0.15989734,0.12585853,0.079537414],[0.0,0.0,0.025769785,0.03372827,0.032830037,0.04020854,0.0,0.0,0.0,0.029540382,0.037638873,0.1197477,0.29065007,0.38327545,0.3138287,0.32162905,0.47546685,0.4992754,0.33473712,0.24415573,0.114749365,0.10990661,0.13735527,0.053631596,0.049940303,0.014959186,0.048135005,0.0,0.0,0.0,0.0,0.018318199,0.016524054,0.033072107,0.0,0.0,0.0,0.0,0.015231855,0.0,0.18979838,0.37940168,0.45874733,0.5011249,0.53551453,0.39341712,0.13893457,0.09826996,0.08484478,0.11301757,0.101340644,0.034351803,0.04417584,0.012962833,0.048047803,0.0,0.0015946776,0.0,0.0,0.010446273,0.0048308372,0.03991019,0.0,0.014244236,0.0,0.0,0.0,0.0,0.08609861,0.28347266,0.5088368,0.6211035,0.5768131,0.3517458,0.106446125,0.051489703,0.055401757,0.083265044,0.059568778,0.0003977269,0.032455117,0.016411975,0.039382078,0.0,0.0027953237,0.0,0.0,0.009187683,0.0,0.034819998,0.0,0.022845998,0.0,0.0,0.0,0.0,0.0,0.21452105,0.52080166,0.67123705,0.5717911,0.28925693,0.093853354,0.0,0.0,0.008763999,0.0030794889,0.0,0.024265237,0.01499407,0.028756984,0.0,0.0,0.0,0.0,0.0,0.0,0.039004073,0.0,0.013002694,0.009424135,0.0,0.0,0.0,0.0,0.2226344,0.5317113,0.60270756,0.38232124,0.13437043,0.04138186,0.0,0.0,0.004693359,0.0,0.0,0.0,0.0,0.00854817,0.0,0.0,0.0,0.014683068,0.0,0.0,0.034917973,0.0,0.0,0.040233694,0.0,0.0,0.0,0.0,0.17381461,0.3873939,0.41164792,0.14578827,0.01978638,0.001056835,0.0,0.011127457,0.0074987486,0.0,0.0,0.0,0.033312537,0.03849443,0.019858815,0.0,0.006620884,0.01936657,0.0,0.0,0.03415843,0.0,0.0,0.05230225,0.0,0.0,0.0,0.0,0.093808025,0.31993955,0.4086808,0.19794212,0.043241166,0.007501811,0.0,0.022271879,0.018628351,0.0035770386,0.0,0.0,0.046826296,0.060949013,0.039476268,0.007066071,0.022296444,0.023624435,0.0,0.0,0.028138392,0.0,0.0,0.07253815,0.0,0.0,0.0,0.0,0.0,0.20295003,0.40886277,0.3515191,0.17105368,0.0747717,0.0,0.035351,0.037097543,0.016670085,0.0,0.0,0.04812506,0.0608593,0.04175397,0.015746117,0.038194768,0.023839697,0.0,0.0,0.021293722,0.0,0.0,0.10011214,0.018088982,0.040997587,0.0,0.0,0.0,0.09658043,0.38270926,0.5254005,0.45629293,0.29207116,0.02363915,0.049072146,0.06479181,0.030290112,0.0077627525,0.0,0.06057576,0.048202902,0.019162051,0.01811371,0.047488943,0.020391345,0.0,0.0,0.011191055,0.0,0.0,0.11755175,0.09228052,0.11715643,0.0,0.0,0.0,0.07877817,0.41980606,0.75262856,0.79816645,0.537057,0.18468013,0.12994744,0.114234686,0.056179725,0.046615772,0.031374007,0.10468608,0.059927955,0.0,0.017662354,0.047228463,0.010939695,0.0,0.0,0.0008838773,0.0,0.0,0.13276109,0.17046992,0.2109575,0.056530908,0.0,0.0,0.06741587,0.46007162,0.96781296,1.0,0.82080925,0.42637557,0.26534504,0.19283243,0.09921891,0.10079008,0.07318927,0.13616416,0.071019866,0.0],[0.0075702667,0.009407893,0.027261183,0.0,0.0050088167,0.0,0.0,0.0,0.038324125,0.0,0.060688682,0.12855422,0.2449795,0.25869673,0.3024351,0.43236214,0.6895679,0.59058815,0.38920748,0.15666257,0.11837552,0.0797734,0.10424728,0.058609545,0.049728937,0.0077943653,0.024502262,0.030380204,0.0,0.008185886,0.013225593,0.0,0.0,0.0,0.0,0.004789576,0.052875526,0.0,0.040175207,0.04054462,0.10727048,0.20794992,0.3082406,0.5063229,0.70327073,0.5140695,0.2540658,0.059420966,0.05822119,0.06505729,0.07577282,0.028385095,0.02247066,0.0,0.018846825,0.03220182,0.0,0.007973716,0.0051192045,0.0,0.0,0.0,0.0068117008,0.022888489,0.03386212,0.0,0.0153239,0.0,0.031092301,0.20007095,0.35944274,0.5851932,0.6783169,0.46191442,0.19138855,0.02905503,0.02957847,0.05182018,0.03449332,0.0,0.004637435,0.008460738,0.0062937587,0.014573015,0.0,0.007386178,0.0,0.0027421266,0.0,0.0,0.009723626,0.019031636,0.02502849,0.0,0.0,0.0,0.0,0.19959193,0.40150458,0.602015,0.5748079,0.35890695,0.11246174,0.0,0.0,0.007815622,0.0,0.0,0.0,0.013211742,0.0,0.0,0.0,0.0,0.0,0.010367155,0.0,0.0,0.0,0.0,0.018618047,0.015325919,0.0,0.0,0.0,0.23296842,0.42602986,0.50067556,0.33200422,0.16435875,0.04216948,0.0,0.0,0.030705765,0.0066871196,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018147558,0.0,0.0,0.0,0.0,0.0072567686,0.041083097,0.0,0.0,0.0,0.21505246,0.32328933,0.29124904,0.081080526,0.019016586,0.009005606,0.0,0.020747952,0.053153545,0.03031616,0.0,0.0,0.0032532066,0.013857722,0.011148356,0.001322344,0.0,0.0,0.018530048,0.0,0.0,0.0,0.0,0.0074404553,0.04310129,0.0,0.0,0.0,0.14682743,0.24716787,0.25231028,0.06834225,0.021548532,0.017371945,0.0,0.02483745,0.060499147,0.039281912,0.0,0.0017283559,0.009552397,0.02464915,0.027574688,0.0056094825,0.0,0.0,0.012794159,0.0,0.0,0.0,0.0,0.03319957,0.05043851,0.0,0.0,0.0,0.048620746,0.13945779,0.25257862,0.16588181,0.10039393,0.050299414,0.0,0.028507128,0.07190883,0.048099175,0.0,0.0011117756,0.0056340992,0.017783508,0.03282404,0.013107657,0.0,0.0,0.0,0.0,0.0,0.0,0.0051212907,0.08015904,0.11899918,0.020961985,0.0,0.0,0.0,0.04043933,0.2825812,0.32945466,0.27574736,0.19179122,0.04730139,0.031577528,0.07904297,0.04635846,0.0,0.0018791109,0.004145533,0.0,0.018942073,0.019169927,0.0015112758,0.0,0.0,0.0,0.0,0.00075025856,0.044451356,0.10094617,0.1599325,0.05286473,0.0,0.0,0.0,0.025084853,0.40564603,0.56639135,0.52102274,0.40680742,0.1949472,0.08046164,0.094530575,0.04963003,0.012624532,0.02460052,0.019152768,0.0,0.004364699,0.019957617,0.013032615,0.0,0.0028853118,0.0052404255,0.0,0.005108699,0.069648184,0.118115485,0.19878589,0.09334398,0.0,0.0,0.0,0.054128915,0.5331895,0.7965034,0.76790935,0.62907284,0.37970835,0.17211041,0.15000191,0.068548664,0.052170187,0.04878258,0.036727406,0.0,0.0],[0.0,0.017205067,0.03144688,0.0,0.0011443794,0.0,0.0,0.0,0.049790896,0.059101276,0.05999559,0.11556468,0.33614182,0.4079603,0.5198181,0.7385499,0.8043408,0.5990774,0.21601334,0.09408189,0.04995042,0.09357533,0.05625713,0.03135609,0.032353707,0.0,0.027346976,0.054872468,0.0,0.019112468,0.042390637,0.0,0.0,0.0,0.023360275,0.0038534105,0.07057059,0.02256225,0.0,0.0,0.12290321,0.2317642,0.48707503,0.74044013,0.7282513,0.5113409,0.120685056,0.059625648,0.03304442,0.06970814,0.044594742,0.013671838,0.02794104,0.0,0.0083555505,0.053998798,0.0,0.013755143,0.022217743,0.0,0.0,0.0,0.028722309,0.0051809847,0.04975784,0.0,0.0,0.0,0.051843695,0.20103794,0.52123827,0.74520904,0.7163097,0.4643041,0.09504348,0.050947435,0.026192047,0.04866369,0.031437963,0.0039995164,0.038678333,0.000032648444,0.0,0.031398237,0.00012594461,0.008436233,0.0022593588,0.0,0.0,0.013234682,0.026648313,0.021773234,0.04234331,0.0,0.0,0.0,0.0,0.18942755,0.539111,0.693265,0.6138508,0.36465538,0.053081572,0.01513923,0.0,0.0,0.0,0.0,0.046258695,0.0071289316,0.0,0.014981963,0.007599041,0.0,0.0,0.016744256,0.0,0.01161392,0.027752012,0.03322553,0.057675764,0.007247664,0.0,0.0,0.031912304,0.21633705,0.5484186,0.5732397,0.42564267,0.21456146,0.055471852,0.026658334,0.010147154,0.01030726,0.0,0.0,0.03526669,0.0,0.0,0.008066997,0.011946395,0.0,0.0,0.034636267,0.0,0.0,0.027454734,0.03624776,0.06761671,0.03493382,0.014694206,0.0,0.104869425,0.2055336,0.4345649,0.37952822,0.23833102,0.1098351,0.085648924,0.022297062,0.034647375,0.042362228,0.013154261,0.0,0.040657774,0.00022219121,0.0,0.011171512,0.013717711,0.0,0.0,0.04437104,0.0,0.0,0.02386868,0.039868593,0.08572826,0.0496663,0.046776317,0.0,0.081206605,0.13863777,0.38081628,0.3420081,0.24411285,0.12842035,0.10348049,0.028459534,0.048925385,0.05267226,0.026207969,0.0026768893,0.03822341,0.0,0.0006849617,0.018869542,0.020137161,0.0,0.0,0.05060131,0.0,0.0,0.022287004,0.05222562,0.12534273,0.08459167,0.0830652,0.0,0.06473189,0.042183585,0.31533608,0.3300649,0.33764276,0.18583374,0.11797324,0.039387673,0.060523227,0.06649989,0.04368353,0.011483207,0.022090264,0.0,0.00056937337,0.019988671,0.033851452,0.0,0.0,0.05239214,0.0,0.0,0.051404037,0.08631,0.17016816,0.16207519,0.12688354,0.0,0.0357161,0.0,0.19567826,0.28386405,0.40867102,0.28455728,0.19434161,0.10179521,0.0781319,0.09885676,0.08347341,0.01505591,0.0,0.0,0.0,0.008053109,0.042499445,0.0,0.0,0.06413811,0.0,0.0,0.08022644,0.110549055,0.20684138,0.19095944,0.124378294,0.0,0.05208858,0.0,0.14672495,0.31342068,0.5170865,0.37438285,0.2767247,0.23153731,0.1092619,0.13611469,0.13603611,0.01992929,0.0,0.0,0.0,0.0,0.03905858,0.0050497353,0.0,0.08247669,0.008840106,0.0,0.11573308,0.13675013,0.23670313,0.22577465,0.12320718,0.0,0.0216695,0.0,0.11975307,0.35214567,0.621631,0.45009702,0.36790466,0.35840487,0.13352495,0.1649391,0.1606256,0.042483807,0.0,0.0,0.0,0.0],[0.0077282935,0.026410177,0.011302471,0.0,0.0,0.0,0.005881794,0.0,0.0,0.02875349,0.09186475,0.08014801,0.17201516,0.31611007,0.529814,0.5471661,0.61675775,0.43225998,0.24522921,0.01803606,0.09212233,0.16246429,0.08578116,0.005640015,0.0,0.0093555,0.042098135,0.04078436,0.00305067,0.019718602,0.01638969,0.0,0.0,0.0,0.0,0.0,0.0,0.032022573,0.017449781,0.0,0.014248341,0.15706633,0.4126839,0.5118925,0.61156124,0.4102897,0.22543754,0.0012564063,0.07735633,0.13993765,0.047221027,0.0,0.0,0.0,0.023517624,0.030874677,0.0,0.007629283,0.016696408,0.0026377887,0.0072350577,0.0,0.0,0.0,0.0,0.014510348,0.0,0.0,0.0,0.1391401,0.42571813,0.5589099,0.62653065,0.40086532,0.19327846,0.0,0.020319395,0.07733254,0.0020784289,0.0,0.0,0.00014230609,0.0076689944,0.0111467615,0.0,0.007970557,0.029712848,0.019840002,0.028953373,0.020835593,0.012396894,0.0,0.0,0.0,0.0,0.0,0.0,0.14880607,0.44434422,0.554581,0.5453006,0.30535215,0.11531629,0.0,0.0,0.0020825267,0.0,0.0,0.009520777,0.020206437,0.010102086,0.002809167,0.0,0.0077392682,0.02550038,0.01873637,0.026445381,0.028571129,0.020089135,0.0,0.002876848,0.0,0.0,0.0,0.013254553,0.21029764,0.49197906,0.50368613,0.4158845,0.19195528,0.061503276,0.0,0.0,0.011796057,0.0,0.0,0.008626461,0.032634333,0.02353958,0.0004799962,0.0,0.008258052,0.01912003,0.015086465,0.0254438,0.036957115,0.03541512,0.021321274,0.031392977,0.0,0.014439523,0.04116626,0.16674487,0.28717077,0.4609607,0.35993546,0.2673511,0.1363327,0.051576354,0.0,0.012735978,0.02988232,0.0,0.0054661334,0.008195117,0.013109326,0.0,0.0,0.0,0.011286579,0.017682113,0.010193527,0.021171696,0.033687226,0.042033352,0.03799825,0.045082055,0.0,0.02316615,0.055126734,0.15951383,0.24063933,0.41443115,0.33057344,0.29000765,0.16965136,0.0671562,0.0,0.018256806,0.025579207,0.0,0.011507049,0.009980649,0.0081933215,0.0,0.0,0.0,0.018517427,0.024024278,0.008126825,0.019588895,0.027612872,0.050544515,0.06073653,0.068466015,0.0,0.030882262,0.05095136,0.09168357,0.11557449,0.2930808,0.28541517,0.34231365,0.22424918,0.09723437,0.0,0.012150548,0.012270041,0.0,0.015242137,0.007066399,0.0024845898,0.0,0.0,0.006716065,0.038368843,0.042959623,0.010724723,0.025764167,0.027239785,0.050996326,0.076018825,0.094848655,0.0,0.011899762,0.02288583,0.0029522777,0.0,0.0911423,0.13158269,0.29201204,0.25162607,0.17701697,0.058182523,0.03878858,0.0,0.0,0.00039236248,0.0,0.0,0.0,0.0,0.023586772,0.047496676,0.055264883,0.010467082,0.033382393,0.0280779,0.059666567,0.10597878,0.1279542,0.0,0.0,0.0006367713,0.0,0.0,0.010484211,0.058752716,0.23253769,0.2659155,0.27553385,0.16994496,0.103539005,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.029021382,0.045973584,0.059142716,0.009827785,0.04302673,0.04545106,0.09828605,0.17642213,0.17793414,0.0,0.0,0.0,0.0,0.0,0.0,0.053382926,0.22535111,0.30713075,0.34984827,0.24803323,0.16394952,0.04100485,0.0,0.0,0.0,0.0,0.0,0.0],[0.008397341,0.020458527,0.029514238,0.010813378,0.0,0.012596123,0.0,0.0,0.034600146,0.0,0.0,0.0,0.0,0.13630839,0.09475088,0.07743955,0.12446572,0.112336665,0.015013158,0.0,0.0,0.10615396,0.016018696,0.0,0.0,0.02451446,0.0042422414,0.023941934,0.0039055347,0.0111876875,0.025457285,0.0,0.0,0.0,0.012671664,0.0,0.010768823,0.0,0.0,0.0,0.0,0.085548595,0.12087796,0.13876487,0.21420363,0.14419067,0.053287454,0.0,0.011478923,0.09094322,0.0,0.0,0.0,0.018659733,0.0,0.024962895,0.0,0.0,0.0022117794,0.0,0.0,0.0,0.019059427,0.0,0.0,0.0,0.0,0.0,0.0,0.10009769,0.23486272,0.27555048,0.3242842,0.21416621,0.10257699,0.00069220364,0.0034299046,0.051341362,0.0,0.0,0.0,0.019599788,0.0,0.014547341,0.0,0.0,0.005477503,0.0,0.0,0.012125738,0.046499386,0.003646478,0.0,0.0,0.0,0.0,0.0,0.12752447,0.31445503,0.3636548,0.35821372,0.21266481,0.104637265,0.00044730306,0.0,0.0007209927,0.0,0.0,0.011494249,0.025229521,0.0,0.007912971,0.0,0.0,0.0,0.0,0.0,0.009961538,0.05281484,0.030181669,0.00028724968,0.0,0.0,0.0,0.0,0.2306896,0.40752047,0.42190367,0.34559578,0.18307984,0.11987938,0.009623319,0.0,0.0069235116,0.0,0.002938524,0.025723584,0.03393928,0.0050281584,0.0,0.0,0.0,0.0,0.0,0.0,0.031477295,0.06496807,0.054762684,0.014847539,0.008574247,0.0015435219,0.055855073,0.11300346,0.3816911,0.44184113,0.41426575,0.34778416,0.20608547,0.15010056,0.022943638,0.009075187,0.020420581,0.010690957,0.01029297,0.021345094,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.041886896,0.07552228,0.0679356,0.019007094,0.013473868,0.015460759,0.07743063,0.12870964,0.37861413,0.4340129,0.44197595,0.40940285,0.2634797,0.18647029,0.036093317,0.0150686875,0.0217219,0.019819908,0.015782833,0.023957126,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05319871,0.08625691,0.0885309,0.0311905,0.007414095,0.020641066,0.05521348,0.057715073,0.24966767,0.32325327,0.41732633,0.4537328,0.31673136,0.20746598,0.054246396,0.023027785,0.018482834,0.028798752,0.015737526,0.021464579,0.0,0.0,0.0,0.0,0.0012454093,0.0,0.003834471,0.0,0.053254656,0.08204554,0.100433104,0.043670624,0.0,0.015772864,0.023434982,0.0,0.056477696,0.12723535,0.26107624,0.3664611,0.33913085,0.2737171,0.12181319,0.05381605,0.01015684,0.0050465465,0.0,0.019035704,0.0,0.0,0.0,0.0011285841,0.010995336,0.0,0.015054502,0.0,0.05104982,0.091013715,0.12477317,0.06752439,0.0,0.0,0.011123367,0.0,0.0,0.060259126,0.17238767,0.24682051,0.32001448,0.32612213,0.21174532,0.11952815,0.044161968,0.0,0.0,0.011885352,0.0,0.0,0.0,0.012211494,0.014319919,0.0,0.028843142,0.0,0.06293641,0.13409235,0.19623554,0.105199076,0.0,0.0,0.0039301366,0.0,0.0,0.026051097,0.11571174,0.15057465,0.31101778,0.35403758,0.28316212,0.1967963,0.10981378,0.03764072,0.0,0.024676688,0.0,0.0,0.0],[0.015486427,0.0,0.0,0.0,0.005907826,0.03196773,0.022652052,0.0,0.062127657,0.031604722,0.015390232,0.0,0.0,0.0,0.0,0.0,0.0,0.015941136,0.014022678,0.044325158,0.053968713,0.074852034,0.051533572,0.034885854,0.0,0.03590414,0.00574591,0.023190327,0.0029034913,0.0,0.0,0.0,0.0,0.0051451027,0.017628469,0.0,0.034470394,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019074656,0.04973173,0.048326902,0.028846137,0.027835876,0.02070836,0.0,0.0,0.0,0.040270478,0.011842065,0.023253657,0.0,0.0,0.0,0.0,0.0,0.0037304163,0.009892024,0.0,0.013956189,0.0,0.0,0.0,0.0,0.018592335,0.021595068,0.035677902,0.13878211,0.10869772,0.07554212,0.025880113,0.008288331,0.0,0.0,0.0,0.0,0.025177397,0.0,0.012562476,0.0,0.0,0.0,0.011974789,0.0,0.018214308,0.014651224,0.0,0.0038028061,0.0,0.0,0.0,0.0,0.043888286,0.12227445,0.16165003,0.20473099,0.11467174,0.060279503,0.0065005347,0.0,0.0,0.0,0.0,0.0,0.024432704,0.0,0.0054617375,0.0,0.0,0.0,0.016669624,0.0,0.028089441,0.021587595,0.0,0.0,0.0,0.0,0.0,0.0028638393,0.15231633,0.25831348,0.26899242,0.21850155,0.123453125,0.060942866,0.014925376,0.0,0.002812013,0.0,0.0,0.015521035,0.022801794,0.0,0.0,0.0,0.00017116964,0.009765454,0.014709681,0.0,0.044329263,0.027667828,0.0,0.0,0.0,0.0,0.0680776,0.19261903,0.31148136,0.3921023,0.37037343,0.24506316,0.16774003,0.079257205,0.014433876,0.00006689131,0.013758697,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0003733784,0.016962826,0.01220037,0.0,0.05091606,0.038002387,0.0,0.0,0.0,0.0,0.08970685,0.21939328,0.324723,0.4218371,0.41989917,0.3036164,0.22839761,0.113783225,0.023687057,0.0038268715,0.01924321,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0024986565,0.033714846,0.010258347,0.0,0.054600656,0.0501524,0.007597171,0.0,0.0,0.0058998615,0.084141344,0.16315043,0.22452724,0.3466812,0.38590902,0.33813226,0.2782963,0.16545704,0.054882668,0.023186155,0.023216866,0.009609602,0.0,0.0,0.0,0.0,0.0,0.0,0.007955708,0.06366668,0.01407744,0.0,0.038857594,0.049531125,0.03783238,0.0,0.0,0.005427107,0.06075257,0.077592246,0.06090989,0.17905077,0.24463147,0.30930996,0.28578416,0.23816866,0.111108266,0.056242526,0.006616205,0.019009955,0.0,0.013567582,0.0,0.0,0.0,0.0,0.029529385,0.0835025,0.016682051,0.0,0.038093068,0.0669601,0.08456018,0.0,0.0,0.0,0.05756791,0.081056,0.03359083,0.09747182,0.14694293,0.2506036,0.25091183,0.28629267,0.19612736,0.12627436,0.026778512,0.032302365,0.0,0.020623803,0.00050903857,0.0,0.0,0.0,0.0473082,0.09638722,0.013597965,0.0,0.056568846,0.10681279,0.13207649,0.0,0.0,0.0,0.051279977,0.08868195,0.054209575,0.048100784,0.07553269,0.20557342,0.21172073,0.29605275,0.28137183,0.22137046,0.08914548,0.07175592,0.0,0.027472734,0.005274415,0.0,0.0],[0.0,0.0,0.012169868,0.0668288,0.007370174,0.017665222,0.0,0.007990196,0.0,0.013889261,0.008384243,0.0,0.0,0.0,0.0,0.0,0.0,0.023352012,0.05072345,0.026932023,0.11662093,0.10629138,0.084439054,0.0,0.0013992637,0.011795096,0.0,0.015629478,0.0,0.0072117522,0.020525455,0.070567064,0.0043835193,0.0060519427,0.0,0.010474905,0.0,0.02740781,0.0,0.0,0.0,0.0,0.0,0.0,0.04296936,0.040313743,0.014942609,0.029727153,0.07741557,0.04746054,0.03650342,0.0,0.01011394,0.043598212,0.02151034,0.017617181,0.0,0.0,0.008599699,0.05499556,0.010071978,0.011135735,0.005633965,0.00046673417,0.0,0.023830324,0.0,0.0,0.0,0.0,0.0,0.0,0.08689357,0.04599555,0.0,0.02317246,0.02027718,0.010514289,0.023155436,0.0,0.03787662,0.03609763,0.022483692,0.012631379,0.0,0.006160021,0.021886356,0.033356763,0.007697426,0.02089756,0.02151785,0.0,0.0,0.01991456,0.0,0.0,0.0,0.011977926,0.04679498,0.016552113,0.09962267,0.030920565,0.0,0.003953144,0.0,0.0018969625,0.016560048,0.0,0.047463104,0.030944936,0.018642902,0.0072790533,0.0,0.014735177,0.015478291,0.01573287,0.003714174,0.03607975,0.04021422,0.0,0.0,0.016710423,0.0,0.0,0.042619035,0.12058922,0.13940792,0.053752422,0.10113484,0.025055282,0.0,0.0,0.0,0.0,0.0,0.015231229,0.051966913,0.03218969,0.012519211,0.0053426623,0.0,0.027249143,0.0189358,0.0,0.0050284863,0.03684151,0.050767295,0.0,0.0,0.028850265,0.0,0.058124796,0.1757469,0.25375825,0.2305488,0.11564499,0.12055323,0.030285187,0.0,0.0,0.0,0.0,0.0,0.019541144,0.03547945,0.0076943114,0.0,0.0,0.0,0.0370278,0.020423673,0.0,0.011845686,0.044220284,0.05968214,0.0,0.0,0.03713514,0.018542908,0.09107734,0.1988729,0.28413266,0.2602021,0.1455004,0.17132849,0.058250725,0.0,0.0,0.0,0.0,0.0,0.02573023,0.033866018,0.00885202,0.0,0.0,0.0,0.056392945,0.030123644,0.0034603477,0.010085367,0.049978852,0.0732701,0.0049088746,0.0,0.035638273,0.041625164,0.114971906,0.15667446,0.2151874,0.19777694,0.124977276,0.1961424,0.08833984,0.005995944,0.0,0.0,0.0,0.0,0.032185376,0.037202835,0.021749072,0.0,0.0,0.0,0.08361924,0.05291085,0.017301604,0.0007456541,0.041775495,0.0949066,0.032860562,0.017260417,0.03939779,0.056483738,0.12302875,0.05584103,0.05885458,0.047459006,0.051091902,0.17160076,0.08678414,0.028963566,0.0041218996,0.0,0.0,0.0,0.037698276,0.047942154,0.040240034,0.0,0.0,0.0002681613,0.106973425,0.06481656,0.03759951,0.0,0.03462922,0.12172927,0.075717404,0.04993432,0.035634436,0.05114997,0.1427253,0.046006568,0.006553471,0.0,0.0,0.11302376,0.044996545,0.03748198,0.05080077,0.040461406,0.0076885223,0.0,0.026400894,0.049135633,0.039251387,0.0,0.0,0.012421697,0.13370353,0.080821685,0.050755396,0.00096695125,0.04021538,0.15110113,0.101815134,0.059936136,0.022290438,0.031226806,0.14256236,0.045394488,0.0,0.0,0.0,0.047113195,0.0,0.04324112,0.11243948,0.1247508,0.05422792,0.014068693,0.017906837,0.04616774,0.042022876,0.0,0.0],[0.013222821,0.0,0.000024154782,0.04889057,0.02044534,0.07200024,0.036895826,0.0,0.0,0.0,0.044417813,0.057818614,0.0015747547,0.0,0.0,0.0,0.03305696,0.045110166,0.037521906,0.0,0.050811857,0.06433663,0.04667183,0.0,0.0,0.0,0.0,0.00084739923,0.015718408,0.02391284,0.017362766,0.032984883,0.0,0.070691705,0.049262352,0.0,0.0,0.0,0.024215437,0.04558494,0.0,0.0,0.0,0.0,0.020273536,0.033792846,0.039728165,0.0036514103,0.03841213,0.030488677,0.024203002,0.0,0.0,0.0,0.0,0.0,0.0065940395,0.018985696,0.009075239,0.015801542,0.0,0.056783028,0.040581487,0.0,0.0,0.0,0.008259006,0.027963467,0.0,0.0,0.0,0.0,0.0,0.0,0.017602772,0.0,0.008407459,0.008786216,0.021994814,0.0,0.00001566112,0.0,0.0,0.0,0.0013866425,0.009742357,0.0015270263,0.01058279,0.0,0.043498605,0.029836237,0.0,0.0,0.0,0.0,0.011087,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0022635907,0.017413229,0.0,0.010651417,0.0,0.0034005046,0.0,0.0,0.00068064034,0.0,0.0158723,0.0,0.025990024,0.021053992,0.0,0.0,0.0,0.0,0.01608342,0.0027312636,0.044227563,0.032552026,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0078716725,0.0,0.025890797,0.0022251606,0.009681076,0.0,0.00078321993,0.004716158,0.0,0.019013263,0.0,0.0,0.015350081,0.020798057,0.029839098,0.0,0.0,0.03652267,0.08505969,0.14472608,0.11648613,0.021529831,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0051927865,0.030691564,0.0068681613,0.010610297,0.0,0.0018565208,0.01290264,0.0072758123,0.026528083,0.0,0.0,0.01947195,0.037137322,0.050130136,0.0,0.0,0.04502026,0.105461285,0.17251903,0.14432046,0.034052618,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008449413,0.03598935,0.00993821,0.013963111,0.0,0.0009919703,0.02935727,0.0263535,0.04069005,0.0012495667,0.0,0.027139582,0.05419199,0.068019055,0.0,0.0,0.047706045,0.08999829,0.15082185,0.12762192,0.04260633,0.0056904703,0.0,0.0,0.0,0.0,0.0,0.0,0.014533594,0.046458207,0.008101121,0.011134252,0.0,0.0,0.054638684,0.058520943,0.059619993,0.004272133,0.0,0.040062815,0.076697186,0.07183282,0.0,0.0015864521,0.037677072,0.022162288,0.0593322,0.063179635,0.052328326,0.022624142,0.0,0.0,0.0,0.0,0.0,0.0,0.03396701,0.06691686,0.0,0.0,0.0,0.0,0.063360766,0.07793,0.065015666,0.010417782,0.0,0.051101804,0.096233815,0.06929973,0.0,0.007994778,0.04131552,0.0,0.0047279745,0.022595458,0.04533246,0.024905428,0.0,0.0,0.008023106,0.0054094344,0.0,0.0025640875,0.040177114,0.077871345,0.0,0.0,0.0,0.0008549392,0.06709506,0.09332885,0.0731983,0.017847836,0.0,0.04347699,0.10660124,0.06160014,0.0,0.006498143,0.038350157,0.0,0.0,0.0,0.039760567,0.0331525,0.0,0.0,0.03277625,0.04354251,0.0,0.010530636,0.045067236,0.09099464,0.0,0.0,0.0],[0.0125164315,0.0,0.016417734,0.0,0.050597638,0.028313145,0.021593742,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023877136,0.006955683,0.011487648,0.011951573,0.0,0.0,0.0,0.0,0.0,0.0035848469,0.012363739,0.0061943084,0.0,0.017347716,0.0,0.0017416179,0.0,0.034029834,0.020482525,0.026162617,0.0023023635,0.0,0.0,0.0,0.012142263,0.0,0.016169257,0.0,0.009293191,0.0,0.020679861,0.015326053,0.0,0.0,0.0,0.0,0.0,0.0,0.007082097,0.0,0.0,0.020900652,0.0,0.0,0.0,0.021562807,0.025688447,0.030883148,0.01452893,0.0,0.0,0.011974029,0.024219178,0.0,0.017291084,0.0,0.0013057888,0.0,0.012013845,0.009048246,0.0,0.0,0.0,0.0,0.0,0.0,0.0003876388,0.0,0.0,0.016483061,0.0,0.0,0.0,0.0070116073,0.014821671,0.005744472,0.0,0.0,0.0,0.0,0.0,0.0,0.003791079,0.0,0.0,0.0023605824,0.019941576,0.011992469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0133114755,0.0,0.0,0.0,0.0,0.0012646765,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00008550286,0.0,0.0,0.010554999,0.019657657,0.0,0.0,0.0,0.0,0.010542043,0.0,0.0,0.0,0.0,0.0,0.008842841,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00691361,0.018727973,0.0,0.0,0.0008341074,0.007101707,0.019337922,0.0,0.0,0.0,0.0,0.0,0.0060964525,0.0,0.0,0.0029026717,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0014394373,0.0,0.0,0.004033223,0.021647625,0.0040890127,0.0,0.00048349798,0.008215189,0.014113277,0.0,0.0,0.0,0.0,0.0,0.007465504,0.0,0.0,0.013154186,0.0032694787,0.0,0.0,0.007106304,0.006316647,0.0,0.0,0.0,0.016592644,0.0085066855,0.0032818317,0.0,0.0041930676,0.041222677,0.029512621,0.0,0.0,0.008346267,0.0,0.0049948245,0.014279507,0.0011579692,0.0,0.0,0.007501021,0.0,0.0,0.023248918,0.0066430345,0.0060044006,0.024968497,0.046047777,0.013638981,0.0018623471,0.0,0.0,0.036857814,0.00842528,0.008266658,0.0,0.007017277,0.061349876,0.040865473,0.0,0.0,0.009645507,0.0,0.011353597,0.030231386,0.008319832,0.0,0.0,0.006534867,0.0,0.0,0.03175275,0.0062486827,0.015286677,0.050302252,0.07229586,0.0050836504,0.0014824271,0.0,0.0,0.055184662,0.014635682,0.009638444,0.0,0.01630257,0.073298715,0.04514578,0.0,0.0,0.014663942,0.0,0.010198645,0.03550049,0.0021627545,0.0,0.0,0.003922522,0.0077140257,0.0,0.027640596,0.0,0.009175494,0.07097647,0.09490511,0.0050074905,0.004061386,0.0,0.0,0.07390447,0.022188343,0.012602679,0.0,0.019335546,0.075452924,0.042832218,0.0,0.0,0.022381961,0.0,0.0,0.016670972,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.09134336,0.07136403,0.049990945,0.0,0.0,0.0,0.0,0.0,0.007472299,0.0,0.026686557,0.07081106,0.055657372,0.019887209,0.0,0.027253374,0.0,0.0,0.0,0.0,0.021245904,0.055779375,0.055423193,0.0,0.0018343776,0.0,0.0,0.0,0.06360691,0.0597423,0.04944414,0.0,0.0,0.0,0.019869179,0.0,0.0018830299,0.0,0.040221624,0.04222046,0.0035791546,0.0,0.0,0.013117202,0.0,0.0,0.0,0.0,0.016820692,0.033277683,0.0422244,0.0,0.0,0.0,0.0,0.002748683,0.04532654,0.04735843,0.03891577,0.019316614,0.0,0.0,0.01202815,0.0,0.0,0.0,0.040273838,0.033454508,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010947689,0.0,0.011817694,0.0,0.0,0.0,0.0,0.0025911778,0.021734037,0.02169989,0.005669892,0.008921981,0.0,0.0,0.0,0.0,0.0,0.0012044758,0.00802321,0.004058242,0.0,0.004894972,0.010695368,0.0,0.0,0.0,0.0035883635,0.0,0.0044185817,0.0,0.005604923,0.0,0.0,0.0,0.0,0.0023813248,0.0050159693,0.0038389564,0.0,0.0,0.0,0.0,0.0,0.0,0.0008200854,0.018802434,0.0013038516,0.0,0.0,0.0,0.0057001263,0.0,0.0,0.0,0.0059828684,0.0,0.0,0.0,0.0035339594,0.0,0.0,0.0,0.0,0.0044030696,0.00018654764,0.0042529106,0.0,0.0,0.0,0.0,0.0,0.0,0.0016473085,0.015605368,0.0010226965,0.0009100884,0.002275005,0.0,0.0,0.0,0.015338615,0.0,0.019083038,0.0,0.0063387454,0.0,0.009122074,0.0,0.0,0.0,0.0,0.0029037595,0.005991295,0.010231338,0.0032953322,0.0,0.0,0.0,0.0,0.0,0.0019459724,0.016960792,0.008221954,0.0023217946,0.0036317408,0.0,0.0,0.0,0.021147504,0.003366083,0.020368189,0.0,0.024249889,0.013476551,0.020292796,0.0,0.0,0.0,0.0,0.0106872395,0.019728668,0.024787426,0.057640687,0.03552135,0.04314962,0.0,0.0,0.0,0.0117116645,0.0385319,0.031017289,0.0059373826,0.009355009,0.0,0.0,0.0,0.0172939,0.009165198,0.016032904,0.006888084,0.051794484,0.039508417,0.034351006,0.0031847656,0.0,0.002229318,0.0,0.017809309,0.031493895,0.043234825,0.117185764,0.08893578,0.10148049,0.0,0.0,0.0,0.048688307,0.045520917,0.043255754,0.008620478,0.017265953,0.0,0.0,0.0,0.012593374,0.014639482,0.008444138,0.023309067,0.07883695,0.062851205,0.042774327,0.0114066675,0.0,0.011651032,0.0055663735,0.02150432,0.033540986,0.053929493,0.15624407,0.1269221,0.13176432,0.0,0.0039767027,0.036216393,0.093401365,0.058369488,0.05774939,0.010709643,0.01837752,0.0,0.0,0.0,0.002435103,0.00911998,0.0,0.028370366,0.08299936,0.062502235,0.029706895,0.00343287,0.0,0.022933714,0.008446306,0.00091060996,0.018435575,0.050475925,0.19770941,0.18263277,0.17896116,0.00711821,0.047267705,0.07778083,0.1348774,0.075945556,0.0690729,0.0051152557,0.010427758,0.0,0.0,0.0,0.0,0.004998222,0.0,0.013642356,0.056930408,0.02957046,0.004163116,0.0],[0.0,0.00079891086,0.055704027,0.041195013,0.09749697,0.08781828,0.042499483,0.0,0.0,0.0,0.04943288,0.024229228,0.13889699,0.10606847,0.12630428,0.17035778,0.13828732,0.0068747103,0.0,0.0,0.0,0.0,0.0,0.0,0.030675285,0.03896959,0.012875989,0.0026108623,0.0,0.0006092936,0.04433231,0.019368745,0.06708558,0.072782084,0.05294417,0.0102758035,0.0,0.032772027,0.04517667,0.0,0.12622821,0.08552961,0.13289315,0.14756274,0.094119556,0.0,0.0,0.0,0.0,0.0,0.0022427142,0.010158867,0.03463646,0.02699434,0.018636167,0.008342423,0.0,0.0,0.040219508,0.022714421,0.048823945,0.03994482,0.045122094,0.038266085,0.0,0.033719108,0.031764165,0.0,0.06273719,0.0328608,0.11503322,0.13545951,0.053418502,0.013381116,0.0012364537,0.015306875,0.0,0.0,0.019187659,0.0220481,0.02875197,0.0043185353,0.0,0.016753882,0.0,0.013387658,0.03556154,0.014731012,0.023619093,0.012563437,0.026698783,0.034672618,0.0,0.025188103,0.027203783,0.0,0.052328788,0.00491789,0.058108978,0.06731013,0.022360831,0.040140226,0.025377281,0.028205805,0.023644418,0.0,0.029002406,0.0068430454,0.013481095,0.0060166866,0.0,0.0036507696,0.0,0.018365234,0.026963912,0.0036182553,0.0027765483,0.010299087,0.0089880675,0.017568775,0.008757502,0.00840044,0.009776391,0.0,0.050053984,0.0,0.01184006,0.0060430914,0.0,0.049725726,0.015320741,0.014599152,0.021292537,0.0,0.015713602,0.0,0.0044983476,0.012757666,0.0,0.009111337,0.0,0.018154562,0.01957091,0.0006236434,0.0,0.027033895,0.008904271,0.010768451,0.01864548,0.0,0.009895965,0.0,0.058075584,0.0,0.0,0.0,0.0,0.033533983,0.009485684,0.009591714,0.024914727,0.0,0.009737119,0.0,0.008039869,0.017903745,0.005238399,0.02404318,0.0,0.014696017,0.013942808,0.002532348,0.0029384196,0.043076396,0.022485122,0.01754009,0.03536722,0.0,0.017402612,0.0,0.0649415,0.0,0.0,0.0,0.0,0.026547834,0.010581709,0.00429295,0.021721669,0.0,0.0,0.004374355,0.025097534,0.034367606,0.024044424,0.03523189,0.00061531365,0.01927641,0.015854307,0.011793427,0.012757853,0.08198349,0.078348786,0.08860957,0.08443992,0.0,0.012900643,0.0,0.08400302,0.028957516,0.0028508455,0.0,0.0,0.018991388,0.014820918,0.0,0.001909852,0.0,0.0,0.011326544,0.04910545,0.05957985,0.05162525,0.04951819,0.003821835,0.018791176,0.011303909,0.017073631,0.017596118,0.12662458,0.13654874,0.1721749,0.14304316,0.0069408864,0.021461837,0.0050328225,0.12825744,0.042803757,0.016140275,0.0,0.0,0.0,0.01447425,0.0,0.0,0.0,0.0,0.017368436,0.073712006,0.08052072,0.07730262,0.06457232,0.004002318,0.022856288,0.00823161,0.014001384,0.010710724,0.15446496,0.17526285,0.22343996,0.19170415,0.03957665,0.06625931,0.06997843,0.1751948,0.056749187,0.022112198,0.0,0.0,0.0,0.004128605,0.0,0.0,0.0,0.0,0.020006701,0.075680934,0.079359084,0.07226497,0.058288656,0.0027671307,0.019629039,0.0,0.0030328035,0.0,0.16215833,0.22795224,0.3025178,0.2602953,0.094349116,0.11342276,0.13082503,0.21834533,0.06898576,0.025998138,0.0,0.0,0.0,0.0013924688,0.0,0.0,0.0,0.0,0.010383837,0.054066285,0.06305388,0.05674053,0.04201565],[0.0,0.02137468,0.0,0.009561501,0.13788846,0.09075938,0.025630541,0.0058822483,0.03863392,0.13238402,0.2199319,0.2033377,0.23835726,0.34153044,0.32184464,0.24605823,0.1427562,0.07269277,0.0,0.0,0.0,0.0,0.0,0.02432648,0.014965527,0.0,0.0,0.005597651,0.0014056712,0.026417889,0.0,0.0,0.09327982,0.07096942,0.031860292,0.018895477,0.0619321,0.103173554,0.14508104,0.104806766,0.16879217,0.2865166,0.28572097,0.2290177,0.08700217,0.036400393,0.0,0.0,0.0,0.0012207925,0.025448091,0.045742914,0.023039795,0.0,0.0,0.009939738,0.0027884394,0.036494464,0.0028497726,0.0,0.056917325,0.05143643,0.030972742,0.023823358,0.04969932,0.049439147,0.02964884,0.0,0.0728279,0.20450747,0.2343379,0.196805,0.04977403,0.022392124,0.0,0.0041602105,0.054054044,0.052220896,0.06395052,0.054578245,0.022414818,0.0,0.0,0.0030017942,0.0040376186,0.047953352,0.027475968,0.0,0.01306238,0.017863147,0.018849649,0.022522151,0.062588744,0.061173648,0.03226497,0.0,0.034853972,0.063878156,0.080559865,0.08348894,0.009700783,0.013765112,0.0,0.025218107,0.06680054,0.045114487,0.05292204,0.020137787,0.013593018,0.0,0.0,0.0,0.00045521557,0.027765281,0.019297488,0.0,0.0019420385,0.016629994,0.018452033,0.0031463802,0.043692723,0.044625558,0.025126219,0.0,0.016989596,0.014632016,0.0,0.0,0.0,0.024150334,0.005795695,0.020029068,0.03750626,0.0018773526,0.018381774,0.0,0.002150938,0.0,0.0,0.0,0.0,0.004621744,0.004963249,0.0,0.0,0.018830962,0.020055994,0.0,0.020218395,0.014758773,0.016543925,0.0,0.015984312,0.026187837,0.0,0.0,0.0,0.025231928,0.009356931,0.016513154,0.03652677,0.0015693903,0.0020322204,0.0,0.0,0.0142592415,0.020521834,0.008909218,0.0,0.0,0.0,0.0,0.0061792284,0.033884563,0.031808347,0.0,0.0125871375,0.0074902177,0.009742789,0.0,0.01685223,0.033703327,0.0,0.0,0.0,0.016285233,0.012435585,0.018210739,0.035898246,0.007417597,0.0,0.0,0.004161641,0.035154983,0.039384916,0.01399412,0.0020748973,0.0,0.009165898,0.0,0.036620267,0.09377122,0.09495367,0.03553073,0.023483977,0.008791298,0.010288745,0.0,0.020839185,0.06269505,0.02584333,0.02651994,0.016242325,0.021047525,0.020852752,0.015471585,0.019062608,0.006071292,0.0,0.0,0.014096133,0.06945873,0.06742849,0.021141902,0.005793765,0.0009544641,0.018016554,0.0,0.055566438,0.14865965,0.1621497,0.1013352,0.060371988,0.05374012,0.03775605,0.0,0.032435767,0.09352583,0.077337556,0.060083978,0.03724072,0.023562841,0.014809482,0.0,0.0,0.0,0.0,0.0,0.029178724,0.09707713,0.08632107,0.023909986,0.010083005,0.012409769,0.028826348,0.0,0.058117174,0.20047778,0.21634194,0.15624751,0.11182073,0.15206745,0.118973486,0.0,0.057028614,0.1241246,0.120132856,0.06807659,0.025259912,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.029963344,0.089233845,0.06878298,0.00699006,0.011269949,0.0013714433,0.02299083,0.0,0.05066014,0.2417785,0.29186332,0.2475409,0.210291,0.27005708,0.20274405,0.0,0.08836516,0.14991409,0.14954461,0.071345404,0.011403218,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015834458,0.06373616,0.03895668,0.0],[0.0,0.0,0.0,0.0,0.11241466,0.13741401,0.053530812,0.048501596,0.16578197,0.25315785,0.37136072,0.46779752,0.6089732,0.6653276,0.77523464,0.5034012,0.32157135,0.07932173,0.0254497,0.0,0.0,0.0,0.0,0.028919645,0.0,0.014070764,0.0,0.0,0.0,0.0,0.0,0.0,0.08779603,0.120821275,0.058360226,0.022491947,0.09932232,0.13673523,0.20761886,0.29255834,0.43916756,0.5647401,0.6429543,0.43865448,0.25274068,0.047952898,0.010187268,0.0,0.0,0.0,0.0,0.043396093,0.0,0.00777559,0.0,0.0,0.0,0.0,0.0,0.0,0.061131254,0.08337748,0.052415922,0.0,0.010622166,0.01402843,0.034256883,0.09167207,0.24507019,0.42973608,0.48367566,0.35723656,0.19430578,0.060426623,0.004037589,0.0,0.0,0.036944978,0.021497808,0.051253453,0.0,0.0,0.0,0.0,0.0,0.023526244,0.0,0.0,0.01670599,0.02772694,0.019939333,0.0,0.0029371977,0.012537509,0.0,0.015541151,0.087696135,0.19278447,0.22630307,0.19460264,0.097992025,0.040418766,0.023166709,0.0,0.0,0.025936455,0.0036957264,0.019385561,0.0,0.0,0.0,0.0,0.0,0.02075281,0.0,0.0,0.012075558,0.013544828,0.006295018,0.0,0.010637693,0.020841032,0.0,0.0,0.027078614,0.023793958,0.019711785,0.014238261,0.003174886,0.05127348,0.032892384,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011303224,0.0,0.0,0.014618427,0.007999934,0.0,0.0,0.0024936795,0.019972488,0.0,0.0,0.010461986,0.0,0.0,0.0,0.0,0.05026798,0.022300266,0.0,0.0,0.009344943,0.0,0.0,0.0,0.0069291145,0.020872168,0.0034880787,0.0,0.005946465,0.0,0.008616604,0.03322529,0.018018395,0.0003158301,0.0,0.00082339346,0.017887667,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035733446,0.016951583,0.0,0.0,0.033823855,0.009190038,0.0,0.0,0.025052823,0.032410875,0.003958747,0.0,0.013041541,0.0,0.030429512,0.07216496,0.060202964,0.047927186,0.0,0.018054724,0.040166274,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.048261143,0.021255396,0.0,0.0,0.055548877,0.027397633,0.0,0.0,0.054756686,0.050825603,0.0036600083,0.0,0.024355993,0.0,0.052909926,0.10916917,0.106057696,0.09898339,0.037831783,0.0596821,0.07929212,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.060781673,0.025787242,0.0,0.0,0.04445351,0.03601806,0.0,0.002387926,0.0829944,0.071653545,0.0064952746,0.0,0.04646051,0.0,0.056450002,0.12900716,0.15542236,0.14417759,0.0780081,0.10477062,0.17531124,0.07006276,0.0032154173,0.012258977,0.0,0.0,0.0,0.0,0.023363136,0.013182744,0.0,0.0,0.03998068,0.035775296,0.0,0.015849546,0.075177625,0.061625026,0.0,0.0,0.05023282,0.0,0.05254648,0.13685274,0.20814295,0.20586216,0.14509645,0.18550685,0.30014873,0.15742663,0.048498362,0.014075831,0.026500098,0.0,0.0,0.0,0.0,0.0008010417,0.0,0.0,0.023771979,0.023375638,0.0,0.010774985,0.05702965,0.036813617,0.0],[0.0,0.0,0.0,0.044218667,0.10001132,0.08669565,0.10950619,0.22616102,0.25111637,0.4765765,0.52394706,0.68469346,0.8138004,1.0,1.0,0.94034255,0.6335372,0.2539382,0.040968545,0.0,0.0,0.0,0.0,0.0,0.008642115,0.05482006,0.007971264,0.0,0.0,0.0,0.0,0.03379955,0.06727966,0.023647487,0.01438345,0.09369652,0.1337126,0.27234977,0.31135863,0.5199194,0.6781094,0.9117494,0.887394,0.7925583,0.4737035,0.13856712,0.0,0.0,0.0,0.0,0.0,0.00038662553,0.0006300509,0.04456286,0.016370289,0.0,0.0,0.003055051,0.003309235,0.033908404,0.04511995,0.0,0.0,0.017514683,0.036618985,0.094699636,0.079992644,0.24039732,0.4289224,0.70848066,0.7099432,0.6150822,0.33355096,0.050654,0.0,0.0,0.0,0.025570273,0.0,0.0005507171,0.0,0.02242478,0.004352182,0.0,0.0,0.0,0.0,0.008554682,0.008221015,0.0,0.0,0.006306164,0.023280337,0.025229387,0.0012165755,0.063916676,0.18745877,0.39597195,0.42288738,0.36728632,0.21388482,0.0458775,0.0,0.0,0.0,0.013695896,0.0,0.000012636185,0.0,0.01092957,0.0,0.0,0.0,0.0,0.0,0.0,0.010837756,0.0,0.0,0.0,0.0068509355,0.0,0.0,0.0,0.034228154,0.07351838,0.06254832,0.060656928,0.121015765,0.106634274,0.04884141,0.00959111,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0086082965,0.0,0.0,0.0,0.0,0.017433941,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07197197,0.15859552,0.15939404,0.10048146,0.05609119,0.00052277744,0.0,0.0,0.0,0.0,0.0,0.022211477,0.0,0.0,0.0,0.0,0.017891765,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016409732,0.14293486,0.1922847,0.16249683,0.106712155,0.025576644,0.014031969,0.0,0.0,0.0,0.0,0.025612332,0.0,0.0,0.0,0.0,0.02617503,0.019332178,0.034384824,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15889624,0.24659525,0.2541087,0.17374319,0.06919438,0.042617157,0.003566429,0.0,0.0,0.008894481,0.0326434,0.0,0.0,0.013070479,0.018496439,0.044214927,0.049757652,0.069203794,0.0,0.0,0.0,0.00536187,0.0,0.0,0.0,0.0,0.0,0.0,0.16970918,0.2880412,0.33298567,0.22610876,0.09508333,0.047816917,0.020137675,0.0048674494,0.015684903,0.025528632,0.038180627,0.0,0.025795482,0.03948427,0.036529146,0.055001855,0.07219146,0.10149218,0.0,0.06007863,0.0,0.034153663,0.0,0.0053263903,0.04302916,0.0,0.0,0.0,0.13120289,0.25571966,0.3270669,0.20654579,0.088115096,0.046925686,0.043993585,0.02958896,0.019530654,0.029505163,0.03173074,0.0029066354,0.035933606,0.051323175,0.048419133,0.062091194,0.11376321,0.15180522,0.059585415,0.17022818,0.10359209,0.10528896,0.029704608,0.08957039,0.11592754,0.0,0.0,0.0,0.14121947,0.25011277,0.32852584,0.18564105,0.07320006,0.026871584,0.05751977,0.037833713,0.018298224,0.023465946,0.017101869],[0.0,0.0067157075,0.03459943,0.08500793,0.12453013,0.13045792,0.121076114,0.292673,0.32132855,0.4789834,0.44458956,0.6057882,0.7910149,0.96099734,0.9690469,0.9550149,0.74686396,0.4123739,0.1454748,0.0,0.0,0.0,0.0,0.0,0.059961654,0.0,0.0,0.0,0.0,0.012465164,0.044141397,0.082519814,0.10104115,0.06649357,0.02042982,0.14913863,0.17431296,0.27541852,0.30050582,0.5158784,0.7405461,0.8840906,0.92251664,0.82890046,0.59557205,0.2742824,0.05458162,0.0,0.0,0.0,0.0,0.0,0.036597677,0.0,0.0018169284,0.0,0.0,0.02052413,0.051126517,0.07861972,0.0620986,0.036832288,0.0,0.0474127,0.05454857,0.095397845,0.11559518,0.25834727,0.53075033,0.73992485,0.80558485,0.7083309,0.4276809,0.15360907,0.0,0.0,0.0,0.0,0.0,0.0,0.007967636,0.0,0.0052232593,0.0035925508,0.0,0.0155450925,0.019691162,0.03899692,0.014548317,0.026004784,0.0023420453,0.019219123,0.02085682,0.015187718,0.052014448,0.12245446,0.29230645,0.480228,0.5689836,0.52650595,0.32313186,0.15190428,0.0,0.0,0.0,0.0,0.0,0.0,0.013728432,0.0,0.0,0.0069526285,0.0,0.009513117,0.0,0.020850837,0.0,0.0,0.015268862,0.010094099,0.01736772,0.007113561,0.01773978,0.06463645,0.087681524,0.15300037,0.23388922,0.29075474,0.24671233,0.2280591,0.05583936,0.012868553,0.0005066842,0.0,0.0,0.0,0.00917352,0.0,0.007871859,0.013385475,0.0,0.0,0.0,0.015414119,0.0008584112,0.0,0.023136199,0.01354181,0.0,0.0046885014,0.0073320046,0.034043536,0.03268688,0.0012406409,0.09455378,0.17976753,0.25286674,0.31703657,0.18180233,0.1368547,0.06399023,0.0,0.0,0.0,0.0017006844,0.0,0.013029538,0.014736846,0.0,0.0,0.0,0.012188077,0.0,0.0,0.02675698,0.018358268,0.004822284,0.017216273,0.008605227,0.019289903,0.019663095,0.0,0.061101772,0.13967448,0.21546975,0.30238062,0.24333775,0.22272125,0.09834655,0.0,0.0,0.0,0.0062266663,0.0,0.01268959,0.022150218,0.0,0.0,0.0,0.016147546,0.003916219,0.015944026,0.043994933,0.02888859,0.0060330927,0.01596298,0.022985712,0.0,0.0010246783,0.0,0.02375371,0.1184985,0.20572321,0.3227893,0.32939267,0.34968156,0.15388434,0.0,0.0,0.0033025444,0.02986382,0.011607006,0.015879333,0.03211257,0.0,0.008518934,0.0,0.031075403,0.014120087,0.030037396,0.07304568,0.057754144,0.050997056,0.036456205,0.040141977,0.0,0.010131054,0.0,0.021197103,0.08915943,0.1670732,0.30858377,0.39593607,0.45333344,0.2183035,0.0024960637,0.02220948,0.015555531,0.056306824,0.028623141,0.014345698,0.041186005,0.0,0.037848935,0.015163973,0.05280821,0.02873417,0.04448895,0.10377101,0.11501755,0.16255498,0.10280562,0.091972396,0.02196683,0.03803301,0.0,0.03159515,0.06538872,0.10409554,0.2357441,0.37487406,0.42006207,0.21549758,0.0,0.03937339,0.026242495,0.08662462,0.034476534,0.009008937,0.046544664,0.0,0.04949659,0.013553083,0.06424147,0.035779253,0.07606909,0.14684844,0.1867871,0.30584353,0.238599,0.24845335,0.12600543,0.11110383,0.03173676,0.055457428,0.07223016,0.10780896,0.24409497,0.40339798,0.39553183,0.1980735,0.0,0.04933256,0.040974922,0.11780568,0.036130473,0.000113114715,0.04054875],[0.0,0.018453836,0.031728372,0.0,0.007715851,0.059739016,0.11527536,0.19130336,0.12834018,0.11574475,0.081512645,0.036315262,0.20479786,0.43635863,0.6035327,0.6050525,0.51334554,0.27623641,0.16784158,0.0,0.0,0.0,0.0034555942,0.064569235,0.05130618,0.0,0.0,0.0,0.0,0.0,0.014979266,0.0021985471,0.016620599,0.014153875,0.039938733,0.09392179,0.06565987,0.08841084,0.094842814,0.09781876,0.32518333,0.5912872,0.7368686,0.64129585,0.40761578,0.14000055,0.029199965,0.0,0.0,0.0,0.006738603,0.055888638,0.04650235,0.0,0.0,0.0,0.0,0.00012587011,0.03395652,0.03644065,0.039036885,0.00043539703,0.01593694,0.038782485,0.027739815,0.030564703,0.050557956,0.07409026,0.31054798,0.630726,0.8230273,0.7259647,0.40866458,0.060504615,0.0,0.0,0.0,0.0,0.003658995,0.017327443,0.010289043,0.0,0.0,0.0,0.0,0.00089633465,0.017223582,0.027795792,0.035642236,0.027773425,0.017660514,0.013253666,0.012431636,0.027749889,0.0674454,0.110207304,0.281048,0.51299864,0.6838353,0.65380806,0.39107066,0.069904946,0.0,0.0,0.0,0.0,0.003872186,0.0,0.0,0.0,0.0,0.013583593,0.0,0.0072567165,0.009961158,0.02957204,0.027986065,0.03525237,0.023334816,0.011432767,0.047907285,0.07464417,0.10572979,0.12446899,0.20628344,0.29077905,0.3984326,0.48247248,0.4600348,0.30798745,0.11412561,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03319051,0.0,0.010119654,0.0033941865,0.038606018,0.03252971,0.034098253,0.030152373,0.000057205558,0.05319442,0.09992208,0.09070243,0.11419849,0.1260974,0.13494988,0.14767285,0.3010177,0.4810353,0.5120258,0.34134743,0.09801249,0.0,0.0,0.0028059632,0.0,0.0,0.0,0.0064328685,0.03868244,0.0,0.007348217,0.0,0.033692606,0.03444822,0.032934442,0.03379526,0.005318448,0.06613938,0.12484539,0.10907425,0.123570524,0.099206775,0.08077143,0.052184142,0.22340609,0.42515165,0.5397527,0.4397285,0.18245515,0.0,0.0,0.007502444,0.0,0.0,0.00055253506,0.015545167,0.04498093,0.0,0.027364224,0.0,0.014764622,0.036282524,0.026987538,0.05093708,0.027304955,0.0930478,0.16075051,0.14997818,0.1481801,0.07301257,0.00860329,0.0,0.20877178,0.445059,0.619568,0.57336986,0.28980052,0.016865037,0.0,0.0057634935,0.0,0.0,0.008809119,0.023829162,0.044362426,0.0,0.051264353,0.0023801923,0.014945082,0.0773766,0.057564244,0.09601766,0.057066433,0.13809012,0.20513484,0.20194823,0.17247356,0.08157097,0.0,0.0,0.14234078,0.3940603,0.61819625,0.67393404,0.40833956,0.058403037,0.0,0.00030128658,0.006104067,0.001326412,0.012059532,0.025252476,0.04624269,0.0,0.07992985,0.037514195,0.037132777,0.1139722,0.08727835,0.16759273,0.14712544,0.21945426,0.24673927,0.23431766,0.18010318,0.124507174,0.0,0.0,0.10655449,0.31551313,0.510308,0.5970354,0.34861135,0.018133387,0.0,0.014744267,0.027217247,0.012814984,0.014308818,0.0235838,0.047101006,0.0,0.10023176,0.06305995,0.05402966,0.13705394,0.1065704,0.23130453,0.2702003,0.35364807,0.39559716,0.38532943,0.28706655,0.21174826,0.0,0.0,0.12151663,0.36017698,0.5073947,0.5696778,0.3010246,0.0,0.0,0.014660776,0.046940833,0.03185314,0.025924563,0.027459651,0.04838378],[0.027758472,0.016090252,0.011413023,0.046089426,0.0058278143,0.018298067,0.15955898,0.05866261,0.0,0.0,0.0,0.0,0.0,0.2143569,0.40462565,0.50491554,0.44371992,0.2067967,0.040159337,0.0023074746,0.0,0.026524998,0.0300553,0.013972253,0.028152622,0.00059467554,0.0,0.044367544,0.010833308,0.0,0.0,0.051034145,0.0021409392,0.0,0.09212,0.02535098,0.0,0.0,0.0,0.0,0.06334532,0.40034664,0.5674176,0.5509089,0.3484894,0.10104917,0.0,0.0,0.0,0.025011495,0.03149128,0.016523264,0.03471493,0.0036628842,0.0,0.040806204,0.0,0.0,0.0,0.053457707,0.0,0.0,0.053994328,0.0,0.0,0.0,0.0,0.0,0.1735716,0.5561303,0.7573611,0.6690034,0.33915102,0.0448604,0.0,0.0,0.0,0.024907969,0.02182743,0.0,0.021010846,0.0046578497,0.0,0.035812087,0.0,0.0,0.0,0.028460026,0.0,0.0142879635,0.042119958,0.0,0.0,0.0057207122,0.05694162,0.06697731,0.27051443,0.55423117,0.70690733,0.6542598,0.3660757,0.092243,0.030378692,0.0,0.0,0.0,0.0060818493,0.0,0.0,0.0,0.0,0.030817933,0.0,0.0,0.0,0.0072853565,0.0,0.035452724,0.05260183,0.029647246,0.102208495,0.15579508,0.20952688,0.24344945,0.30433694,0.43615347,0.5206492,0.5643809,0.5169926,0.37789512,0.24116263,0.0,0.0,0.0,0.00087971985,0.0,0.0,0.0,0.0,0.024954595,0.0,0.0,0.0,0.0,0.0,0.03727285,0.04272928,0.04780057,0.1755021,0.25160575,0.25891045,0.29061818,0.274718,0.3072242,0.34329706,0.43506914,0.5693572,0.5933545,0.44689018,0.10370863,0.011010863,0.0,0.0028634667,0.0,0.0,0.0,0.0,0.008573495,0.00010967255,0.0,0.0,0.0,0.0,0.039511226,0.041513354,0.07604241,0.22933665,0.30912864,0.29389387,0.3180406,0.26702496,0.24447352,0.25131202,0.33991456,0.51189697,0.6334592,0.52432156,0.1812401,0.044031195,0.0,0.0,0.0,0.0,0.0,0.0,0.008497082,0.023763984,0.008096471,0.0,0.0,0.0,0.05796387,0.062750146,0.14198034,0.30098182,0.38440818,0.3306238,0.33957,0.23610139,0.1590869,0.17675194,0.31681675,0.5709073,0.7472464,0.63672525,0.2555904,0.061737955,0.0,0.0,0.0,0.0,0.0,0.01706104,0.008682638,0.04592122,0.026982993,0.0,0.0,0.021926798,0.11921013,0.10434611,0.187249,0.35902908,0.46790236,0.38014853,0.35265726,0.24304795,0.113599785,0.109808445,0.22851251,0.52908885,0.7642185,0.7050666,0.3383801,0.073357776,0.0,0.0,0.0,0.0,0.0,0.032594994,0.015398063,0.058468692,0.054666825,0.032296687,0.01347661,0.05663433,0.15985279,0.17908159,0.26211938,0.4006701,0.49872923,0.4030853,0.3601105,0.24811056,0.09798096,0.08160263,0.14567569,0.41708732,0.64404964,0.595766,0.27734464,0.038657434,0.0,0.0,0.0,0.0,0.0,0.038437538,0.0327124,0.06909154,0.0784802,0.06368623,0.025788888,0.06988718,0.18107161,0.23157528,0.34775504,0.49461818,0.6089807,0.51259637,0.44847506,0.2837993,0.09264256,0.067496285,0.13123092,0.42066723,0.5982446,0.5140594,0.22369966,0.0065125674,0.0,0.0,0.0,0.0,0.0,0.0416539,0.04419312],[0.015531227,0.0,0.0,0.0,0.008879207,0.0,0.01362589,0.0,0.0,0.0,0.0,0.0,0.0,0.39227164,0.7701499,0.89569426,0.66541916,0.34762233,0.10333198,0.024399653,0.0,0.032604188,0.0,0.0,0.0,0.0,0.0017908365,0.0,0.001635924,0.0,0.0,0.0,0.015000246,0.0,0.014337629,0.0,0.016017877,0.0,0.0,0.0,0.14327383,0.5652045,0.88139623,0.8507775,0.5224808,0.23344669,0.0,0.0,0.0,0.00023806095,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007898055,0.0,0.0031040162,0.0,0.014474027,0.019313946,0.019997582,0.0,0.0,0.0,0.20485812,0.63055605,0.9252221,0.84360445,0.46673107,0.13750565,0.0,0.0,0.0,0.0,0.0,0.039283894,0.012404628,0.0,0.007923499,0.0,0.0,0.0,0.017521687,0.0,0.009368241,0.0090266615,0.018554516,0.043344155,0.023711815,0.0,0.028692119,0.10359986,0.25602332,0.49320072,0.72710717,0.65049237,0.41740632,0.111733764,0.0,0.0,0.0,0.0,0.0,0.009677,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03136216,0.029768124,0.10458942,0.10159962,0.13057582,0.19754879,0.22186309,0.28830957,0.2764701,0.35436237,0.42161465,0.50177014,0.33066165,0.15150861,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.037100807,0.020566963,0.15282276,0.19408113,0.2723206,0.34636876,0.30679494,0.2903605,0.16161388,0.17339697,0.36283815,0.5753854,0.5536391,0.37346148,0.029902697,0.0,0.0,0.0,0.0,0.0027481616,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.038030088,0.017701067,0.1794273,0.2697597,0.37347218,0.44715142,0.3546698,0.30845577,0.12136085,0.10865674,0.29823846,0.5559302,0.61555797,0.50110024,0.12268184,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.064151935,0.059219502,0.23266977,0.3617565,0.45513195,0.5284936,0.32622528,0.25610024,0.023202077,0.037827507,0.26602846,0.651976,0.77541345,0.673312,0.19974193,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00042624772,0.012547113,0.0041250885,0.041142948,0.06455014,0.12953204,0.13661511,0.30645335,0.45048302,0.52125263,0.5582261,0.3245247,0.26486433,0.0,0.0034586042,0.19877511,0.67276,0.85639185,0.79220384,0.24096681,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0065394416,0.034183808,0.06153717,0.11042816,0.12332668,0.17953007,0.2157408,0.3698808,0.51691234,0.5424373,0.5283476,0.33983383,0.28485462,0.041773953,0.0034092814,0.12251436,0.59664387,0.7850765,0.74337524,0.18576033,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015312858,0.044704452,0.10144049,0.1500108,0.15930615,0.20689003,0.2582956,0.4240852,0.5983791,0.636321,0.5960384,0.4255026,0.34024662,0.08014819,0.0,0.10662324,0.5949196,0.7911263,0.69586176,0.11130321,0.0,0.0,0.0,0.0056954175,0.0,0.0,0.0,0.0],[0.0,0.023334578,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028022066,0.31875426,0.77451,1.0,1.0,0.62613165,0.17742293,0.004585266,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01453352,0.0,0.022245735,0.0084644705,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.041333415,0.36196244,0.8520231,1.0,1.0,0.514357,0.085280195,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016376562,0.0,0.035304047,0.022885002,0.0,0.0,0.0,0.0,0.027077243,0.0,0.0,0.0,0.028582036,0.33435014,0.7423866,1.0,0.89944607,0.43340218,0.05419682,0.0,0.0,0.0,0.0,0.027036488,0.011321731,0.016673356,0.0,0.0,0.0,0.0,0.031388775,0.023110002,0.0030364394,0.0,0.0,0.0,0.045128778,0.0,0.031804673,0.052202545,0.1324987,0.26779917,0.5046348,0.7480681,0.6730053,0.39354742,0.1421296,0.0,0.0,0.0,0.0,0.044985875,0.0,0.016532607,0.0,0.0,0.0,0.0019330829,0.013831221,0.0,0.0,0.0,0.0,0.0027352124,0.079791084,0.08986957,0.15718067,0.20891947,0.24420777,0.20152628,0.21416509,0.3397396,0.45113236,0.51657474,0.42242312,0.11697911,0.0,0.0,0.0,0.042525172,0.009602495,0.029112577,0.0,0.0,0.0,0.0054897964,0.0032444894,0.0,0.0,0.0,0.00015853345,0.035940975,0.11480748,0.21705662,0.34896994,0.40210962,0.35804558,0.1928038,0.06742287,0.19667573,0.34817308,0.6121361,0.6601723,0.33349937,0.044116378,0.0,0.0,0.045027398,0.036950856,0.051990815,0.0044166297,0.0,0.0,0.00014178455,0.0,0.0,0.0,0.0,0.0,0.06385596,0.15212812,0.30792463,0.49121922,0.52439386,0.41556704,0.22107273,0.03017468,0.1430895,0.2887613,0.631427,0.7553027,0.47161502,0.11137022,0.0,0.0,0.034496948,0.020150445,0.038652368,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04819911,0.056713283,0.167696,0.24349779,0.40684158,0.5751503,0.5464356,0.35644358,0.14241487,0.0,0.09373634,0.27777818,0.7753971,0.9447374,0.674341,0.16912508,0.0,0.0,0.0,0.0,0.0049554706,0.0,0.0,0.0,0.0,0.0,0.020434998,0.02457486,0.1290946,0.13585089,0.27627176,0.35263145,0.5049096,0.5818952,0.5022071,0.2994575,0.13223144,0.0,0.07369645,0.222316,0.8467208,1.0,0.8009177,0.18517585,0.0,0.0,0.0,0.0,0.007080972,0.0,0.0,0.0,0.0,0.0,0.04603193,0.061668083,0.16557795,0.19867551,0.3465308,0.42876148,0.54380035,0.528383,0.43969083,0.28339806,0.18242858,0.01872401,0.09443897,0.15873776,0.80580884,1.0,0.78774804,0.17479223,0.0,0.0,0.007601261,0.029064022,0.033697106,0.0,0.0,0.0,0.0,0.0,0.049034603,0.072584376,0.18839708,0.24824753,0.38319832,0.4869554,0.60422534,0.5627997,0.48100495,0.3290447,0.2149539,0.010019004,0.0751355,0.1268898,0.82632595,1.0,0.7563515,0.14162292,0.0,0.0,0.022282936,0.039451636,0.029664665,0.0,0.0,0.0],[0.05763197,0.035992637,0.042194545,0.0,0.0,0.0,0.0,0.0064117163,0.0,0.0,0.0,0.18251139,0.5586372,1.0,1.0,1.0,0.58365256,0.0065302327,0.0,0.0,0.0,0.0,0.0,0.0097017735,0.001268819,0.0,0.0255552,0.0,0.032071866,0.033402078,0.052936517,0.0,0.0,0.0,0.0,0.03048677,0.0,0.0,0.0,0.16166519,0.5262405,1.0,1.0,1.0,0.47619396,0.0,0.0,0.0,0.0,0.0,0.019431584,0.026600078,0.0,0.0,0.0,0.0,0.01205308,0.026660971,0.054659195,0.0098606795,0.0,0.0,0.0014006793,0.050799474,0.024196848,0.0,0.0,0.11531089,0.37232992,0.8693394,1.0,0.92219585,0.3624224,0.0,0.0,0.0,0.0,0.0,0.044303887,0.052302428,0.00933063,0.0,0.0,0.0,0.0,0.012346968,0.037546232,0.02159582,0.0,0.0,0.002912894,0.04273326,0.033399217,0.03048756,0.039462514,0.10851016,0.23983622,0.51755893,0.7625992,0.6679484,0.34942505,0.0,0.0,0.0,0.0,0.0,0.020452924,0.03104359,0.008668363,0.0,0.0,0.0,0.0,0.0,0.0,0.010442182,0.0037772506,0.0,0.0,0.03278196,0.066357985,0.108553335,0.1530949,0.1765869,0.16270086,0.16287678,0.26859105,0.45461893,0.5515961,0.39384484,0.14096756,0.0,0.0,0.0,0.0037461817,0.03204587,0.023642667,0.0,0.0,0.0065669417,0.0,0.0,0.0,0.00049729645,0.009914838,0.0,0.0,0.06689355,0.22646964,0.35415542,0.36743346,0.2707523,0.12776297,0.014257632,0.053543173,0.35584846,0.679364,0.738796,0.38838273,0.0,0.0,0.0,0.0061433986,0.045716427,0.038615614,0.0,0.0,0.018812671,0.0,0.0,0.0,0.0,0.011699535,0.0009559691,0.0,0.113331616,0.3606252,0.5459584,0.52718854,0.3479576,0.15699784,0.0,0.011502765,0.3276922,0.7172154,0.88324153,0.51890725,0.0032636523,0.0,0.0,0.0,0.015455864,0.023061246,0.0,0.0,0.016876519,0.0,0.0,0.0,0.00089390576,0.021862805,0.044961095,0.051768534,0.18435948,0.46927398,0.6103646,0.5757102,0.3308363,0.14200568,0.0,0.0,0.35302576,0.86719203,1.0,0.65188336,0.040305167,0.0,0.0,0.0,0.0,0.016479261,0.0,0.002213657,0.020052657,0.0,0.0,0.0,0.01952593,0.024953447,0.10890235,0.15083064,0.2514413,0.48844516,0.55392414,0.48942798,0.26264924,0.16030711,0.0,0.0,0.32185826,0.91307604,1.0,0.68625885,0.04652436,0.0,0.0,0.0,0.023739196,0.047132254,0.0044099987,0.012772128,0.025182247,0.0,0.0,0.0,0.028674752,0.024370998,0.15294173,0.22152467,0.29377377,0.46284556,0.48897856,0.41336793,0.22607899,0.2125642,0.0,0.0,0.26061463,0.86472416,1.0,0.6616462,0.07210789,0.0,0.0,0.0042415857,0.048904397,0.087935016,0.018525526,0.017243065,0.019945897,0.0,0.0,0.0,0.031460427,0.045110404,0.20238188,0.2809488,0.34052935,0.49125206,0.5195049,0.4374525,0.24707216,0.21453762,0.0,0.0,0.24598297,0.87588656,1.0,0.6497296,0.07699965,0.0,0.0,0.024508826,0.06806813,0.10220981,0.009362221,0.0022341907,0.014126159],[0.034079388,0.039097182,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035565466,0.0069627464,0.31838024,0.6591125,1.0,1.0,1.0,0.20193112,0.0,0.0,0.0,0.0,0.0,0.043973066,0.0,0.0,0.048968628,0.0,0.0,0.011983946,0.023023203,0.007820502,0.0,0.0,0.0,0.0,0.0015676022,0.0,0.0,0.0,0.23832142,0.57766014,1.0,1.0,1.0,0.14443342,0.0,0.0,0.0,0.0,0.022015572,0.06906819,0.0,0.0,0.011947997,0.0,0.0,0.0,0.011003569,0.02060891,0.0,0.0,0.0,0.0112413615,0.022346191,0.0,0.0,0.0,0.07991469,0.3613475,0.9543992,1.0,0.8396666,0.05770444,0.0,0.0,0.0,0.0,0.03271225,0.07167037,0.0,0.0,0.003579706,0.01070255,0.0,0.0,0.0,0.016330317,0.0,0.0,0.0,0.002603054,0.027785845,0.028620563,0.025674261,0.028357118,0.039105892,0.21315181,0.5871535,0.79267615,0.6478845,0.20046812,0.0,0.0,0.0,0.0047442317,0.017405137,0.0150859505,0.0,0.0,0.017104544,0.009165339,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0012116283,0.02366753,0.047677025,0.099454135,0.14107437,0.06761393,0.122162476,0.22343785,0.36614802,0.52610123,0.5453935,0.4125529,0.17601395,0.0,0.0,0.0,0.0,0.004947692,0.02821213,0.013634063,0.014586195,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013070859,0.085666746,0.21695375,0.3634823,0.33705515,0.109155335,0.05386798,0.05189012,0.112635486,0.39882338,0.7072076,0.74741673,0.34907278,0.0,0.0,0.0,0.0,0.028706595,0.045641117,0.0061569586,0.01660423,0.0034510642,0.0,0.0,0.0,0.0,0.0,0.0,0.03255952,0.15082692,0.37136185,0.5570842,0.4676932,0.17812377,0.05091478,0.01644408,0.06265847,0.3549881,0.77406,0.8882426,0.43263882,0.0,0.0,0.0,0.0,0.014211126,0.047702774,0.007383801,0.020288892,0.0036112666,0.0,0.0,0.0,0.0,0.0,0.0062413886,0.09402851,0.20727175,0.46068448,0.6060818,0.47531354,0.22224954,0.057062335,0.002712205,0.031022288,0.36227864,0.91782886,1.0,0.52415264,0.0,0.0,0.0,0.0,0.011834033,0.061379857,0.0,0.023537897,0.003964305,0.0,0.0,0.0,0.0016611218,0.0,0.07049161,0.17369354,0.2051594,0.41746753,0.50191575,0.36339647,0.23784108,0.07264378,0.012087852,0.015772358,0.33085847,0.9661929,1.0,0.5804489,0.0,0.0,0.0,0.0,0.05223041,0.08768447,0.0,0.030103542,0.009835646,0.0,0.0,0.0039864928,0.019384101,0.0,0.11937507,0.22288308,0.20879021,0.35415113,0.42042607,0.2841257,0.25586277,0.09394975,0.051905006,0.022544384,0.27798676,0.9408241,1.0,0.6186379,0.0,0.0,0.017369732,0.0,0.085363105,0.11376241,0.0,0.03437656,0.009373315,0.0,0.0,0.020210505,0.037997298,0.0,0.17459905,0.26497322,0.2309759,0.35714656,0.457273,0.30058193,0.28119957,0.106296696,0.047329515,0.02042941,0.2628464,0.96622103,1.0,0.65025425,0.0,0.0,0.031845354,0.0,0.098236635,0.10844446,0.0,0.021856628,0.00917127],[0.055770077,0.054581337,0.021669127,0.0,0.0,0.0,0.0,0.05993262,0.0,0.0,0.040895015,0.28715283,0.6994766,1.0,1.0,0.80065393,0.26812994,0.0,0.0,0.0,0.0036595166,0.01422815,0.026252113,0.0,0.0,0.0071200654,0.0,0.0,0.030604504,0.043002166,0.028549157,0.0,0.0,0.0,0.0027169585,0.044452257,0.016121231,0.0,0.00990434,0.21441238,0.62304455,1.0,1.0,0.83980846,0.20633094,0.0,0.0,0.0,0.0131525025,0.04395958,0.03416855,0.0,0.0,0.018271588,0.020872138,0.012089603,0.018420883,0.052620582,0.049464315,0.01841893,0.0,0.0,0.018091299,0.04029765,0.038091883,0.0,0.01299227,0.083325624,0.36814737,0.8666551,1.0,0.7728809,0.15743281,0.0,0.0,0.0,0.010686442,0.057504877,0.04885362,0.0,0.0,0.013022356,0.04642982,0.023742393,0.001613006,0.014176942,0.014053389,0.0010035783,0.0,0.0,0.013715535,0.021582976,0.04371073,0.030618273,0.046765335,0.024930507,0.18266186,0.53892654,0.7876877,0.6374894,0.24206454,0.014522143,0.0,0.0,0.0077565387,0.044795796,0.037638746,0.0,0.0,0.0076389685,0.020686984,0.0048793852,0.0,0.0,0.0,0.0,0.0,0.0,0.009330705,0.020126969,0.07055806,0.12647836,0.1423666,0.040346205,0.064115785,0.23022583,0.45103824,0.5974004,0.580866,0.35231864,0.11235094,0.0,0.0,0.034436584,0.047100432,0.00041775405,0.009242982,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014398456,0.07658288,0.2541146,0.37552118,0.3144034,0.08209893,0.015918933,0.052872404,0.20141228,0.5391905,0.7801584,0.63654184,0.22857295,0.0,0.0,0.0153706,0.043945618,0.010145344,0.03049165,0.010884702,0.0,0.0010113865,0.0,0.0,0.0,0.0,0.0,0.0,0.01773794,0.13982967,0.39730614,0.5402396,0.4323411,0.15176849,0.047995947,0.027781703,0.13963912,0.51083946,0.8306654,0.73470634,0.27102822,0.0,0.0,0.0020608008,0.033703,0.011911884,0.035405844,0.021645054,0.0058820844,0.010480858,0.0,0.0,0.0,0.0,0.0058325455,0.018036515,0.04764553,0.17926897,0.4522655,0.6258384,0.5293143,0.23510441,0.13481124,0.023746155,0.088325486,0.460837,0.8465189,0.77257085,0.31150222,0.0,0.0,0.0,0.035859026,0.023417182,0.0444657,0.0297243,0.022253267,0.026652,0.0,0.0,0.0,0.0,0.0007032752,0.06538348,0.099769644,0.21875587,0.44723797,0.61148965,0.5348241,0.28319722,0.20651613,0.011765458,0.029302187,0.39716685,0.8356307,0.7726149,0.34476465,0.0,0.0,0.0,0.038624696,0.034976117,0.060072616,0.04146274,0.050547764,0.043201365,0.0,0.0,0.007995464,0.0,0.009062611,0.09322764,0.13549617,0.26483387,0.43924898,0.6019918,0.553568,0.35455886,0.27121902,0.014023729,0.0,0.28612572,0.8001605,0.7611448,0.4118849,0.0,0.0,0.0,0.023379132,0.029525235,0.06241554,0.05581165,0.058836557,0.049224064,0.0,0.0,0.0032872856,0.010084651,0.042107753,0.1413444,0.15191853,0.2903775,0.45532978,0.6541914,0.6207602,0.43623775,0.3005547,0.011117063,0.0,0.21588099,0.79159456,0.7709818,0.48380774,0.0,0.0,0.0,0.019872896,0.033468194,0.045775615,0.042226866,0.056230515,0.053817637],[0.07482684,0.06817485,0.039327122,0.0,0.0,0.0,0.043973528,0.0,0.0,0.0,0.0,0.033763915,0.48218358,0.8731038,0.96413153,0.6372381,0.07030912,0.0,0.073455594,0.006282471,0.051472843,0.0,0.0,0.0,0.0,0.0,0.0015822649,0.0,0.05535417,0.050670527,0.04210121,0.0,0.0,0.0,0.030295461,0.0,0.0033403486,0.0,0.0,0.048146747,0.4840777,0.944486,1.0,0.70029217,0.09301995,0.0,0.0043756217,0.0,0.06113556,0.0,0.008135289,0.0,0.0,0.011252031,0.03490916,0.0,0.039463647,0.039507568,0.051848546,0.0,0.0,0.0,0.013267383,0.0067871287,0.017624982,0.0,0.0,0.010952577,0.27825588,0.83222336,1.0,0.6608865,0.11943609,0.0,0.0,0.0,0.06585904,0.063234374,0.04256478,0.0,0.0,0.04541684,0.08265146,0.0002220422,0.019983478,0.007977799,0.019880176,0.0,0.0,0.0,0.0075659156,0.035153165,0.04007817,0.026232317,0.031893298,0.043623313,0.1771106,0.64773214,0.8728008,0.646787,0.21091333,0.010095574,0.0,0.0,0.056878857,0.06815711,0.047765963,0.009223387,0.0,0.027752772,0.06356087,0.0,0.019804582,0.0,0.007357821,0.0,0.012919679,0.0,0.0040738434,0.074585944,0.10953832,0.19508037,0.14129123,0.12287988,0.12939641,0.45047677,0.6281962,0.7333835,0.50242376,0.25987655,0.038338542,0.0,0.04778894,0.07823707,0.06731687,0.012120284,0.0,0.0131243095,0.03323382,0.0,0.017228879,0.0,0.009461269,0.0,0.011296153,0.0,0.008280724,0.12669258,0.28283083,0.47457463,0.32591707,0.21158591,0.14680634,0.32786888,0.4741034,0.76868695,0.7350561,0.511537,0.14245437,0.0,0.0007081479,0.06946182,0.09094929,0.03032703,0.033036552,0.021045499,0.031018332,0.0027544051,0.0074167475,0.0,0.015041135,0.0,0.007341586,0.011583909,0.010969415,0.18564638,0.3968526,0.64267486,0.4518422,0.3143084,0.23396392,0.3103469,0.41647297,0.7422537,0.81737334,0.6158378,0.20528337,0.0,0.0,0.06879094,0.101118274,0.03981936,0.05041509,0.03115385,0.046603717,0.020126306,0.0,0.0,0.019144624,0.0,0.0,0.04472313,0.02538193,0.2012505,0.4312274,0.7755806,0.60930985,0.4696349,0.38352293,0.31328508,0.33177674,0.67425215,0.84805954,0.6505796,0.2359799,0.0149378255,0.0,0.08509612,0.13215025,0.057262607,0.06313284,0.042395562,0.07905945,0.051187344,0.0,0.0,0.014453128,0.0,0.0,0.07883331,0.110083036,0.2659737,0.4401756,0.822353,0.6778854,0.56576663,0.4629295,0.27057433,0.232178,0.6140413,0.87052345,0.6777914,0.26988855,0.0475543,0.0,0.094445266,0.1648873,0.07484326,0.06607003,0.05554901,0.117505595,0.0783329,0.0,0.0,0.012549318,0.0,0.0,0.10310523,0.18824548,0.37071356,0.47186887,0.8495099,0.723325,0.6265361,0.49587864,0.20837177,0.10252088,0.53281945,0.8795023,0.7075253,0.35218632,0.1179414,0.014429644,0.09837354,0.16588973,0.07838412,0.06602748,0.060479335,0.14169756,0.09810993,0.0,0.0,0.0011644512,0.0,0.0033826828,0.12526846,0.22309726,0.4323812,0.51811904,0.892995,0.80890495,0.6920407,0.501151,0.16762282,0.005147949,0.47111815,0.91321325,0.7762682,0.43708163,0.19408709,0.036166884,0.1126706,0.17683548,0.08216208,0.053058922,0.045705408,0.14977083,0.11291484],[0.02136308,0.06786745,0.040748037,0.0,0.0,0.070051625,0.046391964,0.021050349,0.0,0.0,0.0,0.0,0.24904051,0.6447804,0.7395335,0.55119467,0.23431073,0.099362805,0.10150553,0.05161109,0.012483656,0.0,0.0,0.0,0.0,0.04332129,0.007363111,0.0,0.018625706,0.056798942,0.04487747,0.007300861,0.0,0.04356242,0.037110545,0.003798157,0.0,0.0,0.0,0.0,0.28040993,0.8172213,0.9408057,0.6964029,0.22275849,0.030846953,0.045519076,0.01863733,0.033577546,0.030293584,0.0,0.0,0.0,0.03998921,0.01037547,0.0,0.013263591,0.043255396,0.049459122,0.02845551,0.0,0.01286485,0.03198158,0.0,0.013624541,0.0,0.0,0.0,0.1885152,0.81885636,0.99624366,0.70640486,0.17102447,0.0,0.01357764,0.008705378,0.08090626,0.09201877,0.03385195,0.0,0.0,0.041408822,0.024846427,0.0,0.0,0.0158872,0.020516232,0.008188769,0.0,0.0,0.028517172,0.0,0.047131866,0.023090087,0.0,0.0,0.15105933,0.6076391,0.8449122,0.6281209,0.21695824,0.017860062,0.021629728,0.004784003,0.07446775,0.09774405,0.06296215,0.0065084547,0.0,0.016345926,0.0074431077,0.0,0.0031584054,0.019877575,0.01681558,0.0,0.0,0.0,0.028320163,0.0,0.10463916,0.13253698,0.120711125,0.09653993,0.1919677,0.44594735,0.660477,0.6028471,0.42415744,0.20383888,0.08523061,0.01449655,0.07220628,0.090061724,0.07732299,0.01910568,0.0,0.017778069,0.0,0.0,0.007280655,0.018074557,0.012117133,0.0,0.0,0.0,0.03425484,0.041907273,0.2544054,0.35413063,0.34711847,0.2585328,0.2829093,0.3632071,0.5208862,0.5759778,0.5945059,0.3702727,0.1487168,0.027885646,0.07770355,0.087488264,0.09717761,0.05686626,0.06338563,0.07351944,0.019113258,0.0,0.005319655,0.012409732,0.0060708597,0.0,0.0,0.0,0.03935165,0.106492564,0.3799746,0.5305309,0.5188636,0.41483533,0.39082795,0.35852617,0.45605356,0.5215757,0.6630198,0.47894865,0.20841213,0.033579856,0.085808665,0.089965,0.11033408,0.076606296,0.093421966,0.10554761,0.043939866,0.0,0.0,0.0,0.0,0.0040614903,0.0,0.0,0.05991476,0.15615311,0.47786295,0.6917536,0.7425126,0.6348181,0.56108433,0.36288798,0.36517847,0.36294273,0.6274213,0.5356331,0.27057654,0.057183996,0.09190422,0.087149285,0.11773631,0.10772249,0.14838746,0.16417557,0.08229722,0.02412866,0.0,0.0,0.0,0.0,0.0,0.038919695,0.14907043,0.28546113,0.61753166,0.8233237,0.9014199,0.7514335,0.64259547,0.3560484,0.2906897,0.26766074,0.62327796,0.6080015,0.35506254,0.08856901,0.101787075,0.08397933,0.120459646,0.12274368,0.19087194,0.21480137,0.11906071,0.049447373,0.0,0.0,0.0,0.0,0.0,0.08636606,0.25656396,0.4380114,0.76408476,0.9578999,1.0,0.8336292,0.6678476,0.36627698,0.24323736,0.24038649,0.6539025,0.7062217,0.48009312,0.15935823,0.14987361,0.07878852,0.118478104,0.11617394,0.21010321,0.23877728,0.13782871,0.06368252,0.0,0.0,0.0,0.0,0.0,0.09916915,0.28472131,0.5157702,0.8557228,1.0,1.0,0.9230422,0.7072738,0.41414505,0.23901595,0.2394085,0.69725466,0.7882194,0.60299665,0.24473453,0.23261908,0.10896279,0.13349165,0.10504398,0.20554177,0.250062,0.15482369,0.08079652],[0.024827093,0.0,0.03513234,0.0,0.010819539,0.09234569,0.115677305,0.002936989,0.0,0.0,0.0,0.0,0.18827052,0.59251916,0.6304685,0.44865078,0.20706642,0.16131061,0.21054068,0.059721135,0.04448074,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026747912,0.0,0.037926614,0.004351616,0.003403157,0.061477594,0.0594483,0.0,0.0,0.0,0.0,0.0,0.23618604,0.74994755,0.83104306,0.60139173,0.2157569,0.08153772,0.13911639,0.015476726,0.034116343,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.027315319,0.0,0.040988185,0.019853555,0.0,0.02699408,0.033873618,0.0,0.0,0.0,0.0,0.0,0.21006355,0.8331032,0.9343049,0.61661404,0.18056868,0.035972416,0.08985628,0.0,0.027508326,0.0,0.0,0.0,0.0,0.011291847,0.012341298,0.0,0.019027993,0.0,0.01833608,0.0,0.0,0.0016736239,0.021858603,0.0,0.0,0.0,0.0,0.0,0.17321125,0.65408146,0.7891534,0.5582962,0.19019061,0.021520548,0.022549793,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008866899,0.0,0.023027785,0.0,0.014399223,0.0,0.0,0.0,0.021435708,0.013926871,0.017943509,0.045236178,0.06745056,0.051470548,0.19441254,0.49447072,0.60866886,0.5416065,0.3194662,0.1083692,0.0029756874,0.0,0.0,0.0,0.0018440783,0.0,0.0,0.0036680251,0.012824118,0.0,0.024346165,0.0,0.013513915,0.0,0.0,0.0,0.015387863,0.06340112,0.1642908,0.24989611,0.24873891,0.22363375,0.26898965,0.4027546,0.48770702,0.5344674,0.46011102,0.19629088,0.0,0.0006673485,0.0,0.02048514,0.027543187,0.02514521,0.07690766,0.058941357,0.035091266,0.0,0.018477619,0.0,0.015701026,0.0,0.0,0.0,0.01642067,0.116322726,0.28078148,0.404181,0.4117887,0.38570583,0.34433675,0.3760944,0.41222262,0.4958682,0.5333942,0.30506903,0.046772152,0.01597286,0.0,0.01955124,0.020748056,0.032180846,0.10772996,0.09384554,0.05474785,0.0,0.009125158,0.0,0.010839656,0.0,0.04894515,0.013166577,0.04814239,0.15505277,0.3538981,0.5696895,0.64031106,0.6355166,0.49058777,0.37390947,0.3009597,0.33662546,0.50583893,0.40252078,0.13042039,0.07195933,0.015778616,0.0075038373,0.021837458,0.055029362,0.15063877,0.150649,0.08394646,0.0036442876,0.0,0.0,0.0041569173,0.0,0.073240265,0.049889453,0.115308926,0.2540859,0.46828097,0.7345141,0.827488,0.79958636,0.57145786,0.364598,0.23144256,0.23857063,0.50335824,0.52441055,0.24570706,0.13600549,0.051349446,0.008397363,0.03673587,0.079663,0.19419655,0.19844852,0.10408496,0.016544148,0.0,0.0,0.0,0.0,0.06905541,0.07771163,0.19490623,0.38085753,0.59480137,0.9041355,0.9890323,0.9255058,0.6488384,0.38095194,0.21838313,0.22500339,0.540355,0.6799646,0.42966223,0.24769443,0.11153644,0.032979764,0.066654384,0.08907205,0.22033182,0.21599725,0.08692602,0.027262814,0.0,0.0,0.0,0.0,0.053620234,0.05998805,0.21940665,0.46636695,0.69636977,1.0,1.0,1.0,0.752439,0.45890975,0.25848028,0.24919122,0.614084,0.84321994,0.64911896,0.40992218,0.2433139,0.11530912,0.11815045,0.10252542,0.24441564,0.24254134,0.09529111,0.049468234],[0.013444029,0.0,0.042421766,0.029550418,0.07295291,0.07337396,0.07007049,0.0,0.0,0.0,0.0,0.041464992,0.26405323,0.36551645,0.37939394,0.18166754,0.18527356,0.2177223,0.17182004,0.08856633,0.026904717,0.0,0.0,0.026095346,0.0,0.0,0.0,0.01189781,0.011050902,0.0,0.053889133,0.037477277,0.06216628,0.045093186,0.039921075,0.0,0.0052066594,0.0,0.0,0.104003616,0.33552805,0.5958652,0.70801663,0.5187734,0.3044226,0.16073573,0.06937813,0.0,0.0,0.0,0.0,0.031028502,0.0061565638,0.006773047,0.0,0.0056348443,0.008163497,0.0,0.049999416,0.025918178,0.03550747,0.03416314,0.024153382,0.0,0.012563594,0.0,0.0,0.070942625,0.26432717,0.6874593,0.8821369,0.658725,0.27587622,0.05871305,0.015279196,0.0,0.0,0.031509683,0.009217389,0.027642421,0.003940314,0.009727679,0.0022569895,0.004398972,0.004145682,0.0,0.018992476,0.009960547,0.01804544,0.02141004,0.012230873,0.0,0.024136953,0.0,0.0,0.007967867,0.16518706,0.5649195,0.8031084,0.6084502,0.25154567,0.036196247,0.0,0.0,0.0,0.02606704,0.024594031,0.021041237,0.0,0.0,0.0,0.0,0.0028660148,0.0017606616,0.012384653,0.008591823,0.0,0.0062792525,0.010554001,0.0,0.022675946,0.0,0.0,0.026223533,0.13363178,0.41425997,0.6553894,0.5457033,0.25774267,0.035352983,0.0,0.0,0.023358084,0.024898216,0.03417582,0.031461917,0.0026269704,0.008725852,0.0,0.0,0.0039906055,0.0,0.0064234436,0.0019898415,0.0,0.0019343793,0.020562999,0.022107847,0.095316514,0.09413643,0.06703337,0.09498285,0.14983839,0.30404148,0.5268729,0.48511338,0.28132313,0.057468303,0.0,0.023984283,0.054068737,0.030408263,0.05028391,0.063317366,0.04234963,0.03211827,0.0,0.0,0.0023429692,0.0,0.0039189756,0.0,0.0,0.0,0.015470408,0.0520399,0.16296807,0.19277403,0.157513,0.16966973,0.16343306,0.2064981,0.41119683,0.44167233,0.36028585,0.13230747,0.0,0.029418819,0.06703278,0.028566398,0.058228128,0.081009224,0.06689103,0.05268631,0.0,0.011114322,0.0009419471,0.0,0.0024440736,0.013303325,0.0,0.0,0.009548962,0.06337208,0.21730697,0.32798862,0.34767377,0.38232696,0.29534745,0.105336204,0.1905786,0.24539274,0.38825017,0.2746756,0.044628777,0.05870641,0.09843975,0.056575857,0.094595894,0.12901753,0.12734538,0.108437225,0.02292201,0.02958972,0.014277257,0.0,0.00059342384,0.025356866,0.009705976,0.0,0.014533728,0.09838514,0.2988642,0.45081085,0.509458,0.5884824,0.40600532,0.059854053,0.08994677,0.1992352,0.49196672,0.5149196,0.26469988,0.16742769,0.13782774,0.090975,0.13040201,0.16281039,0.17380208,0.15429713,0.051179044,0.04902988,0.024326123,0.0,0.00085027516,0.023850948,0.00884489,0.024153553,0.045006044,0.15123941,0.39415145,0.60006404,0.70739216,0.8261955,0.5174939,0.102592684,0.085340805,0.24335974,0.6180962,0.7777037,0.532116,0.32929683,0.20942664,0.14614853,0.17650867,0.17760558,0.20309475,0.173905,0.0635956,0.061358057,0.030620769,0.00447841,0.0,0.018127576,0.006222293,0.016165182,0.06326552,0.18701631,0.48532587,0.7526744,0.9218297,1.0,0.6693434,0.19647023,0.112532355,0.30215,0.7427312,1.0,0.79898405,0.530759,0.3631444,0.280562,0.2523752,0.2129699,0.23158813,0.18863179,0.08347659,0.08508759],[0.0,0.0027522892,0.034474187,0.06811326,0.060697347,0.03397475,0.0,0.071101695,0.0,0.0,0.11922196,0.17969729,0.39122343,0.46190584,0.34058636,0.20516266,0.16723779,0.30995476,0.22515574,0.17035525,0.034928754,0.0,0.0,0.04022985,0.0066049322,0.034461737,0.0,0.006888561,0.0,0.007616207,0.040585034,0.05627185,0.041985154,0.018971138,0.011714712,0.061178677,0.0031501353,0.0,0.10702491,0.18465078,0.44667602,0.65509063,0.6649483,0.5263851,0.25514418,0.24799564,0.13193174,0.038902387,0.036706902,0.0,0.003916323,0.016232371,0.03105174,0.011901483,0.0,0.013395667,0.0,0.0131953955,0.021439813,0.020132527,0.029953942,0.0151435435,0.013195932,0.066565454,0.0,0.0,0.0623596,0.09319973,0.34528798,0.67992896,0.8325271,0.6307339,0.19094923,0.10252282,0.06084563,0.0,0.032665774,0.0,0.023116983,0.0,0.03459719,0.017500289,0.0,0.02484797,0.0,0.0,0.0,0.006606184,0.0127023235,0.020931937,0.01996772,0.05795165,0.0004631728,0.0,0.0040438175,0.013391703,0.20312974,0.5354233,0.75842917,0.5950471,0.17790127,0.05156768,0.023202904,0.0,0.02492249,0.0,0.017572366,0.0,0.022824176,0.0064689666,0.0024206638,0.016664743,0.002290666,0.0,0.0,0.01631888,0.0,0.02466058,0.013555832,0.018860877,0.0,0.0,0.0,0.0,0.116272196,0.3677074,0.607988,0.5255128,0.17720494,0.0,0.0,0.009092264,0.034742415,0.0,0.0027343333,0.0,0.028138593,0.0,0.0058892965,0.011641271,0.005044967,0.0,0.0,0.01317022,0.0,0.036203064,0.015577972,0.0045865923,0.033173703,0.009427503,0.0,0.0,0.06842485,0.23670045,0.47751576,0.457155,0.20259291,0.0,0.0,0.03213647,0.03369029,0.0,0.0,0.002472952,0.053237244,0.0,0.023032293,0.028694756,0.0035836995,0.0,0.0,0.009428509,0.0,0.019563898,0.00262177,0.008266918,0.05506599,0.042635843,0.027648807,0.0063565,0.011385828,0.08523992,0.3420154,0.4372717,0.29312134,0.0010007471,0.0,0.04421591,0.030938491,0.0,0.0,0.0153931305,0.0693956,0.0,0.030685447,0.046135977,0.0047236234,0.0026989877,0.0,0.018530332,0.013784081,0.0,0.0,0.012071691,0.077404484,0.11232161,0.20485076,0.18568623,0.06140828,0.0,0.0779874,0.28706273,0.39437538,0.15379393,0.07114148,0.09443292,0.062376544,0.04318185,0.04338236,0.0852513,0.14283675,0.045313023,0.051356293,0.07204552,0.017879143,0.021030113,0.0,0.025694303,0.042087317,0.0,0.0,0.04954338,0.108943485,0.17090665,0.3694705,0.37292942,0.13716717,0.0,0.0,0.28180775,0.56607145,0.45363837,0.3325742,0.22478756,0.11651786,0.114185475,0.09801635,0.14395498,0.20002934,0.09478432,0.067219436,0.10026631,0.027529068,0.03882958,0.0,0.01659707,0.056117997,0.0,0.0,0.10308519,0.16368052,0.27782315,0.5824652,0.59046364,0.25852042,0.0,0.0,0.32819483,0.7318587,0.7760362,0.65001595,0.40343654,0.21251786,0.20512272,0.15432738,0.19342151,0.23969278,0.1274362,0.07637437,0.11299186,0.037528254,0.05720547,0.0,0.008873366,0.06021463,0.0,0.0,0.15524523,0.22294776,0.38059953,0.7924993,0.8330783,0.40042645,0.02096396,0.0,0.37420303,0.92640024,1.0,0.98696864,0.6170707,0.37239444,0.33469838,0.22907263,0.2531124,0.2759237,0.14468192,0.09172544,0.13447452],[0.0,0.0,0.0,0.011372328,0.014464229,0.0,0.020791538,0.031026773,0.030205898,0.06173362,0.08866398,0.31963718,0.44685906,0.49512148,0.36774793,0.307845,0.45581216,0.45724612,0.30978766,0.09134999,0.0,0.0,0.0076326653,0.07850863,0.13113199,0.09357951,0.068251416,0.0116120875,0.0,0.0,0.004280776,0.022342302,0.012726188,0.0,0.026642151,0.034976594,0.046140626,0.017993264,0.046950497,0.24877909,0.49495673,0.7016939,0.7283325,0.6040792,0.54979855,0.35448268,0.13367999,0.0,0.0,0.0,0.026381597,0.056289367,0.075144306,0.046796806,0.058973365,0.018643178,0.0,0.0,0.0,0.025557458,0.0045024157,0.004750535,0.056573085,0.054958396,0.0371456,0.006322719,0.0097279325,0.10998185,0.34092242,0.69011897,0.893647,0.6915215,0.42098945,0.17952918,0.02622208,0.0,0.0,0.0,0.024382778,0.012747593,0.04154391,0.03929563,0.06637901,0.028016895,0.0,0.0,0.0,0.02603031,0.0008095652,0.015898056,0.057215363,0.05906502,0.032307103,0.0,0.0,0.030164413,0.196668,0.5415151,0.78572613,0.5984479,0.27767944,0.050579518,0.0,0.0,0.0,0.0,0.022991173,0.0,0.01622329,0.025822207,0.04435263,0.019178092,0.0,0.0,0.026637062,0.03571625,0.0,0.018729925,0.051720403,0.035178177,0.0073898137,0.0,0.0,0.0,0.074527495,0.3887695,0.6015369,0.40404743,0.122028984,0.0,0.0,0.0,0.012570739,0.00028572977,0.02700635,0.0,0.0,0.0,0.009694539,0.010285296,0.0,0.007357329,0.0413327,0.039047748,0.0,0.026667982,0.051389195,0.0,0.0,0.0,0.0,0.0,0.0,0.23626539,0.41519624,0.24611282,0.0567165,0.0,0.0,0.0,0.025426917,0.0090574175,0.026740521,0.0,0.0,0.0,0.011989221,0.01893834,0.0,0.012153007,0.050066657,0.038405314,0.0,0.029583193,0.04006999,0.0,0.0,0.0,0.0,0.0,0.0,0.105031624,0.30267614,0.2666155,0.11490045,0.0,0.0,0.0,0.024078421,0.0018809736,0.031403854,0.0,0.0,0.007838987,0.02349212,0.028463036,0.0061302036,0.023895346,0.057312153,0.020478621,0.0,0.0344728,0.024352029,0.0,0.0,0.0,0.048477195,0.025853723,0.0,0.0,0.03757544,0.16235411,0.19450611,0.043494947,0.0736569,0.020131461,0.046382234,0.0141402185,0.06012301,0.018813059,0.018796422,0.04348261,0.051233135,0.04169392,0.030570894,0.046079457,0.073661916,0.014283843,0.0,0.031447895,0.017013676,0.0,0.0,0.056282625,0.18449049,0.13397993,0.0,0.0,0.0,0.21449023,0.41741365,0.36709225,0.344789,0.13362604,0.08387174,0.040904216,0.089553535,0.04985231,0.05032499,0.07998474,0.07895784,0.058306612,0.04739269,0.059684776,0.085143134,0.0,0.0,0.024637409,0.010987848,0.0,0.037160836,0.21301103,0.37412238,0.25289124,0.0,0.0,0.0,0.32109457,0.6809908,0.735875,0.6627298,0.32320175,0.1618184,0.08654467,0.13021097,0.107566655,0.103600666,0.14127812,0.110044956,0.061727427,0.06551023,0.07180147,0.086156756,0.0,0.0,0.034109637,0.018758342,0.0,0.055470973,0.33566606,0.5773691,0.44326746,0.06867869,0.0,0.038036443,0.45164263,0.9353965,1.0,0.9884046,0.5474364,0.2904309,0.16625647,0.18956317,0.17775682,0.14186257,0.17907943,0.1397697,0.07454786],[0.0,0.0,0.02780994,0.037140384,0.034288064,0.081609644,0.029756963,0.0049099624,0.026733428,0.084139094,0.14385122,0.317199,0.5035782,0.55488306,0.48292047,0.43051505,0.5416366,0.44228703,0.18739538,0.035830356,0.0,0.0026238859,0.08579332,0.052413173,0.07779873,0.03246928,0.045042023,0.0,0.0,0.0,0.017111614,0.028793924,0.04386758,0.054149173,0.0,0.002807796,0.0,0.014495127,0.04666634,0.20161837,0.4579054,0.6768594,0.70073104,0.60329497,0.5201687,0.31894448,0.0785345,0.0,0.0,0.009225473,0.076883346,0.04770408,0.057782933,0.014362201,0.046054132,0.0,0.0,0.0,0.00050221384,0.009693883,0.018692754,0.050337806,0.0,0.010373011,0.0,0.0,0.0,0.026293643,0.3040158,0.66376776,0.7914845,0.62886494,0.34870756,0.14657743,0.025251642,0.02090203,0.001119569,0.01655002,0.04497695,0.016720995,0.047246777,0.009812683,0.049367264,0.0,0.001526162,0.0,0.0,0.0028448552,0.0,0.04323987,0.0033253431,0.022697963,0.0,0.0,0.0,0.0,0.17777944,0.5596917,0.7230363,0.5442949,0.21142381,0.05768712,0.012838952,0.0,0.0,0.0,0.01703307,0.0,0.024672993,0.0062015206,0.029212072,0.0,0.0,0.0,0.0014927536,0.0,0.0,0.040444568,0.0,0.018154673,0.0,0.0,0.0,0.0,0.10702569,0.45215052,0.55647534,0.34983274,0.041270524,0.010596126,0.00827682,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0030476898,0.0,0.0,0.0,0.017942756,0.0,0.0,0.032499976,0.0,0.00011175871,0.014874391,0.0,0.0,0.0,0.034104034,0.31093645,0.3593245,0.19840756,0.0,0.000532493,0.012527049,0.0,0.0,0.0,0.0,0.0,0.0,0.0018078685,0.0066295937,0.0,0.0,0.0,0.022208795,0.0,0.0,0.025811702,0.0,0.0,0.036922038,0.0,0.0,0.0,0.0,0.17136012,0.278257,0.24789202,0.029981531,0.008490764,0.01945147,0.0,0.007857099,0.0,0.0,0.0,0.0,0.015612081,0.013995998,0.0018134564,0.0,0.01447428,0.025871098,0.0,0.0,0.011114538,0.0,0.0,0.07447296,0.020530716,0.053086102,0.0,0.0,0.0,0.06747465,0.19070569,0.1199119,0.06744907,0.078535914,0.011790067,0.0454833,0.028407842,0.023657143,0.0,0.0,0.038301244,0.023750804,0.0,0.0036622286,0.037998036,0.034417704,0.0,0.0,0.001896739,0.0,0.009603284,0.10250701,0.09251238,0.14506967,0.0,0.0,0.0,0.030629948,0.21921143,0.33378628,0.35183027,0.28134233,0.08441559,0.08853662,0.07677393,0.0557229,0.011432812,0.015426904,0.0633128,0.035624214,0.0,0.0077203885,0.053265676,0.036867425,0.0,0.0,0.0,0.0,0.004848793,0.13030301,0.19917774,0.2506248,0.034775056,0.0,0.0,0.024825566,0.27272263,0.56894314,0.685172,0.5285159,0.24845448,0.16977347,0.12158349,0.08497809,0.056704134,0.070748344,0.11610483,0.057248577,0.0,0.010068968,0.054655567,0.016113319,0.0,0.0,0.0,0.0,0.004202783,0.12988885,0.2512071,0.3351491,0.14806941,0.0,0.0,0.037773825,0.36113006,0.8357652,1.0,0.82427603,0.46155983,0.28755707,0.20471877,0.13861875,0.13530266,0.11585387,0.14473197,0.07165995,0.0],[0.0065004975,0.0,0.004063472,0.0,0.030813828,0.0,0.0,0.0,0.04971055,0.07824072,0.2573657,0.39183336,0.51168305,0.5528362,0.5678927,0.62828404,0.7387777,0.46704304,0.20318413,0.0,0.0,0.0008325726,0.04644046,0.059082896,0.058199517,0.012996346,0.0060545653,0.011781737,0.0067275316,0.0,0.012981594,0.0,0.013120607,0.0,0.0,0.0,0.013515547,0.0,0.09262392,0.20408994,0.4008394,0.6135481,0.68749607,0.7254868,0.6898653,0.4027515,0.13471887,0.0,0.0,0.017759472,0.050706528,0.04507605,0.03246382,0.0,0.0,0.0068228394,0.0000449121,0.008667864,0.008404508,0.0,0.0,0.0,0.008344851,0.0,0.010091215,0.0,0.030167788,0.058388866,0.2300503,0.55306876,0.7110518,0.669977,0.5014954,0.2494927,0.05590654,0.0,0.004842013,0.0291735,0.041388586,0.013629422,0.007273361,0.0,0.0,0.0032511503,0.00627663,0.022471279,0.0077092424,0.0032199174,0.0,0.0,0.0143918395,0.013898581,0.008366309,0.0,0.006962791,0.0,0.16663674,0.48003346,0.6442382,0.53156376,0.3167224,0.12543775,0.02134221,0.0,0.0011667609,0.031484567,0.016531408,0.0,0.0,0.0,0.0,0.0,0.004533559,0.013353802,0.0,0.012904115,0.0,0.0,0.010696977,0.0068595186,0.0040154606,0.031252347,0.0,0.0,0.14764151,0.41601843,0.50805354,0.33266634,0.11021462,0.019081093,0.0,0.0,0.0131201,0.046274953,0.021184534,0.0,0.0,0.0,0.0,0.0,0.004200101,0.005101189,0.0,0.020557009,0.0,0.0,0.0045117736,0.0,0.0,0.051478118,0.0,0.0,0.10591977,0.30736345,0.31726784,0.14852546,0.0,0.0,0.0044789016,0.008454181,0.030492373,0.048227243,0.028119773,0.0,0.0,0.0,0.0,0.0,0.00035078824,0.0,0.0,0.017964289,0.0,0.0,0.0,0.0,0.016001143,0.051087007,0.0,0.0,0.014160551,0.19444862,0.24634409,0.17151052,0.0091322735,0.00026635826,0.014936127,0.005479932,0.03323003,0.057767563,0.037598982,0.0,0.0,0.0,0.0,0.0,0.009317175,0.0,0.0,0.0048002303,0.0,0.0,0.0,0.0050734878,0.073993795,0.08974546,0.026601627,0.0,0.0,0.0,0.040923588,0.14237417,0.073272675,0.048692055,0.05387634,0.024130814,0.044771366,0.088846035,0.05341894,0.0,0.0,0.0,0.0,0.0,0.021921657,0.010166898,0.0,0.010502569,0.0,0.0,0.0004092306,0.042731397,0.110401526,0.13871399,0.06812387,0.0,0.0,0.0,0.0,0.24446802,0.2812004,0.2548887,0.21000774,0.0830448,0.0683531,0.12446017,0.060628466,0.0,0.0,0.0008742213,0.0,0.0,0.026926652,0.030605257,0.0,0.01710648,0.0053476095,0.0,0.0008904487,0.06495496,0.13164763,0.18914704,0.10425665,0.0,0.0,0.0,0.009898163,0.3777512,0.52459854,0.48392534,0.42189533,0.23356014,0.10811563,0.13308752,0.058091693,0.018136546,0.027611285,0.041149154,0.0,0.0,0.02905111,0.036265567,0.0,0.016321257,0.015246667,0.0,0.0021963865,0.07955276,0.13474514,0.21847983,0.13509203,0.0,0.0,0.0,0.045771122,0.5132888,0.7763019,0.72563696,0.6286556,0.38368934,0.17812628,0.19745994,0.10850617,0.08051267,0.057539083,0.052785404,0.0,0.0],[0.0,0.0,0.005997412,0.0,0.03207214,0.0,0.003098026,0.0057600364,0.087439716,0.26003453,0.41022325,0.50374293,0.7042538,0.6856984,0.7985789,0.8812797,0.70767254,0.39543557,0.032220624,0.0,0.0,0.033984788,0.029627837,0.024952061,0.008340806,0.0,0.017803825,0.030055486,0.0,0.0,0.016074449,0.0,0.0063251853,0.0,0.0,0.0,0.038522564,0.045880035,0.11063102,0.22862658,0.5022616,0.6867577,0.8689576,0.87546456,0.6271602,0.33445933,0.0,0.0,0.0,0.020908467,0.004134655,0.02013079,0.009551965,0.0,0.0,0.03148824,0.0,0.002220884,0.013974577,0.0,0.0,0.0,0.02917023,0.0,0.04299912,0.0,0.0,0.0,0.24014555,0.5332948,0.7854601,0.76265806,0.46291226,0.21694487,0.0,0.009338371,0.0,0.01805251,0.0,0.007651001,0.033761688,0.0,0.0,0.03158246,0.00511539,0.018854938,0.009924494,0.0,0.0,0.009895951,0.028736107,0.0,0.030702092,0.0,0.0,0.0,0.18681487,0.47058207,0.67594755,0.6109008,0.32802823,0.15322076,0.0033397824,0.01865694,0.0019358844,0.014789537,0.0,0.0,0.036217958,0.0,0.0,0.01624766,0.012650952,0.012080334,0.0,0.0053199083,0.0,0.020270914,0.02246911,0.0298604,0.028158031,0.0,0.0,0.0,0.20376223,0.4137575,0.5082254,0.40658742,0.18229555,0.06990231,0.037228584,0.012733869,0.01637245,0.039953806,0.0,0.0,0.037276126,0.0040188283,0.0,0.00733871,0.018218294,0.0,0.0,0.020508088,0.0,0.006577581,0.026488155,0.040585987,0.049671285,0.025681458,0.019954666,0.01604911,0.2309759,0.32303134,0.3233879,0.22362417,0.10071997,0.064524926,0.07677238,0.009239823,0.032355264,0.047691777,0.017933115,0.0,0.042243205,0.009253837,0.0,0.0016512424,0.01637885,0.0,0.0,0.026050791,0.0,0.0,0.028444521,0.044693783,0.07698175,0.044785284,0.034668952,0.0,0.15820943,0.19423786,0.29833996,0.25661415,0.16209023,0.09052642,0.080295786,0.014721222,0.03135018,0.050067484,0.016596645,0.0,0.03763505,0.0049981624,0.0,0.003104195,0.033012524,0.0,0.0,0.029444046,0.0,0.0,0.042471856,0.08424569,0.15375169,0.12718794,0.099477716,0.0,0.069354,0.0,0.14711617,0.223919,0.22641724,0.14447485,0.0817795,0.03159877,0.042195477,0.08006418,0.045713603,0.015809141,0.010659635,0.0,0.0,0.0,0.050435357,0.0,0.0,0.04577948,0.0,0.0,0.08240259,0.11787941,0.1951829,0.17256597,0.11790085,0.0,0.052247375,0.0,0.14843357,0.26744425,0.3567605,0.28024983,0.16122904,0.087448195,0.074362084,0.11605777,0.08268001,0.024999037,0.0,0.0,0.0,0.0,0.05649011,0.026131816,0.0,0.059034996,0.0038958192,0.0,0.10287703,0.14344525,0.23312026,0.21388577,0.1260511,0.0,0.032630898,0.0,0.12655972,0.32245278,0.47818822,0.35857105,0.26510763,0.2006557,0.087676644,0.14860302,0.12268844,0.035568938,0.0,0.0,0.0,0.0,0.05525033,0.036057547,0.0,0.07109903,0.016764179,0.0,0.12397475,0.1585094,0.25093296,0.23361617,0.1217298,0.0,0.0,0.0,0.10085186,0.37026513,0.6012311,0.4393232,0.34873718,0.28022775,0.09373553,0.18486413,0.1646004,0.07025346,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.025805004,0.017264605,0.02228421,0.03954035,0.10315953,0.21545298,0.3591091,0.4147126,0.4692455,0.5513144,0.6698001,0.5989876,0.49002898,0.23038353,0.03149403,0.0,0.01061485,0.123750255,0.06301907,0.006117508,0.0,0.00029683113,0.021463655,0.020439528,0.0,0.0,0.0,0.0062780827,0.022981122,0.0,0.0,0.0,0.0,0.015511118,0.12469208,0.18260053,0.31901652,0.50082546,0.70248353,0.61296475,0.46630442,0.20411967,0.04067099,0.0,0.01638823,0.114687756,0.04876492,0.0,0.0,0.0,0.006289609,0.022627637,0.0,0.0,0.013629571,0.019524217,0.016939163,0.0,0.0,0.0,0.0,0.0,0.0044065863,0.0,0.10228077,0.36315402,0.64312327,0.59008306,0.42382097,0.1595891,0.043540105,0.0,0.0,0.08156375,0.020084701,0.0,0.0,0.0,0.0,0.013792589,0.0,0.0061533973,0.028844438,0.024379686,0.018243447,0.0005091876,0.0,0.0,0.0,0.0,0.0,0.0,0.11180823,0.37052464,0.60020375,0.51677555,0.30750334,0.09740995,0.020879745,0.0,0.0,0.033716656,0.0,0.0,0.0016533732,0.0,0.016975425,0.007836431,0.0,0.011046164,0.034566335,0.030180126,0.027978882,0.023325287,0.021448337,0.0,0.0,0.0,0.0,0.019187301,0.19731694,0.38479304,0.5144434,0.37859017,0.1723133,0.04318139,0.015333667,0.0,0.004460305,0.046199515,0.0,0.0,0.021442264,0.03818821,0.04385312,0.0073499307,0.0,0.010525845,0.022886746,0.014546283,0.020359837,0.038459554,0.042259492,0.009552985,0.012933552,0.0,0.026748851,0.10743992,0.30420947,0.34276527,0.3766281,0.24458167,0.099885225,0.046533257,0.0044394583,0.0,0.023196243,0.04244969,0.0009573549,0.008427501,0.020684734,0.027340457,0.021813542,0.0,0.0,0.008641802,0.024474956,0.017957836,0.02547887,0.03541959,0.04753696,0.025266543,0.03320586,0.0,0.019399442,0.048036188,0.1939194,0.24939078,0.35804033,0.2502568,0.16378264,0.09736952,0.038045384,0.0,0.015598454,0.02832941,0.0,0.004999146,0.012670942,0.019489482,0.0060811117,0.0,0.0,0.02109509,0.034552492,0.021451145,0.022147663,0.017340764,0.08267493,0.07053735,0.08817798,0.0,0.03820499,0.022220664,0.035690278,0.0028058738,0.14838573,0.13871737,0.22446972,0.19023854,0.103697866,0.0,0.007615924,0.0047332644,0.0,0.005265504,0.0057056397,0.012482442,0.0,0.0,0.014751837,0.034191944,0.046293616,0.01801245,0.028308228,0.033053502,0.123607785,0.11091371,0.12175044,0.0,0.013052478,0.014048487,0.0,0.0,0.093295455,0.0983518,0.24061532,0.2415579,0.19027574,0.069716424,0.031582057,0.0,0.0,0.0,0.0,0.0066578016,0.0,0.0,0.028638937,0.0399206,0.054289535,0.013892017,0.03292469,0.030743308,0.13907874,0.16701362,0.17693298,0.0,0.0,0.0,0.0,0.0,0.05862715,0.08132616,0.22995979,0.27058777,0.28046274,0.1576386,0.086479455,0.002041161,0.0,0.0,0.0,0.0027203858,0.0,0.0,0.033870988,0.04363426,0.051818527,0.0064650103,0.036902383,0.039732054,0.16125567,0.21669969,0.21098551,0.0,0.0,0.0,0.0,0.0,0.026195846,0.09337929,0.24948956,0.3294334,0.33267748,0.19053277,0.09476739,0.016498268,0.0060667694,0.01235614,0.0,0.0,0.0,0.0],[0.0,0.0,0.008362316,0.028170906,0.035697937,0.02428186,0.0,0.0,0.06390144,0.04312662,0.0815688,0.09405519,0.08297393,0.14645413,0.0889153,0.024998665,0.0,0.0013238043,0.0,0.0,0.004975304,0.09586674,0.0,0.000048577785,0.004314378,0.0039274693,0.0,0.003717631,0.0,0.0,0.014118552,0.021841988,0.03055317,0.0005482137,0.0,0.0,0.0,0.0,0.0,0.016067557,0.047902726,0.1795976,0.13925819,0.099134535,0.024751082,0.0010252744,0.0,0.0,0.024122514,0.09120956,0.0,0.0,0.0,0.00474523,0.0,0.018758789,0.0,0.0,0.027442552,0.013897009,0.011946827,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.20524806,0.26571375,0.21671444,0.08677667,0.0045252144,0.0,0.0,0.0068985894,0.06581885,0.0,0.0,0.0,0.0029187799,0.0,0.020460129,0.0,0.0023733974,0.020601168,0.0020947903,0.008689798,0.0009753704,0.021955773,0.0,0.0,0.0,0.0,0.0,0.0063924715,0.25490656,0.35195023,0.25914568,0.10913158,0.02378048,0.012149423,0.006137423,0.0027738512,0.016830094,0.0,0.0,0.0,0.016598746,0.0,0.018460892,0.0,0.0014074147,0.01334624,0.0,0.0,0.018775135,0.05182477,0.0,0.0,0.0,0.0,0.0,0.09638995,0.33269787,0.3778289,0.27275014,0.13938163,0.04061506,0.04409004,0.0,0.0,0.014224075,0.0,0.0,0.024230018,0.051768683,0.010187551,0.016407311,0.0,0.0,0.0,0.0,0.0,0.029665753,0.065263525,0.03933295,0.009331144,0.005673334,0.0,0.096901104,0.19221793,0.36212856,0.32888997,0.28150344,0.19743496,0.08411543,0.07223601,0.0,0.0,0.019674614,0.0,0.009673603,0.025024824,0.022282109,0.0013229102,0.0,0.0,0.0,0.0,0.0,0.0,0.03750691,0.0664263,0.051922195,0.016447544,0.0019268543,0.0,0.049606524,0.111619085,0.32418424,0.3398094,0.3095045,0.26196963,0.1489842,0.11543846,0.012582324,0.0,0.015419006,0.005749427,0.008008078,0.02043923,0.0052965134,0.0,0.0,0.0,0.0031481236,0.0,0.0072667897,0.0,0.05855433,0.09796107,0.089095734,0.046980925,0.007837854,0.033743106,0.03852567,0.0,0.09598414,0.15829116,0.21759698,0.2871678,0.23270385,0.1633049,0.040730834,0.006950453,0.0052310675,0.0041130185,0.003928691,0.018813178,0.0,0.0,0.0,0.0,0.006130047,0.0,0.022969559,0.0,0.08212274,0.13168305,0.12018461,0.05971592,0.0,0.010653265,0.018270716,0.0,0.044213958,0.11725055,0.17669386,0.25787598,0.28214452,0.24776113,0.11890494,0.047026142,0.0,0.0,0.0,0.012426674,0.0,0.0,0.0,0.011519119,0.011088029,0.00876046,0.036082894,0.0,0.08977642,0.16300549,0.17134798,0.103358805,0.0,0.0,0.0,0.0,0.020801611,0.08643855,0.13809492,0.17193386,0.2792079,0.29815948,0.1977326,0.12451703,0.05169729,0.0,0.0,0.019068219,0.0,0.0,0.0,0.022448488,0.016050287,0.016472943,0.04110474,0.0,0.09135863,0.19286416,0.22423348,0.13304165,0.0,0.0,0.0,0.0,0.006103441,0.05831998,0.09461625,0.1400024,0.3099925,0.30073112,0.23023865,0.16595864,0.09890373,0.040307567,0.0,0.026875809,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.026393518,0.026671,0.0,0.0,0.044895984,0.053179912,0.03360538,0.0,0.0,0.0,0.0,0.0,0.0,0.019658782,0.0021452904,0.07155671,0.086736694,0.108696535,0.08104696,0.080370545,0.0,0.011202276,0.0,0.015444666,0.0,0.0,0.0,0.008168265,0.021619268,0.021021359,0.0,0.0,0.025901936,0.040481105,0.015235536,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008854412,0.055074036,0.048799977,0.06770065,0.02918148,0.021132685,0.0,0.013125576,0.0,0.02318222,0.0,0.0,0.0,0.013799079,0.004442051,0.014264338,0.0,0.0,0.009645306,0.005671829,0.0,0.0,0.0,0.016984977,0.051068693,0.014826797,0.0,0.0,0.009708643,0.039967634,0.014805809,0.025111116,0.0,0.0,0.0,0.011132538,0.0,0.021822996,0.0,0.0,0.0,0.0053100735,0.0,0.021597266,0.0,0.0,0.0045961738,0.0,0.0,0.0,0.0,0.090903565,0.14048672,0.07340819,0.0053352863,0.0,0.0,0.018529162,0.0,0.0,0.0,0.0,0.0,0.008116074,0.0,0.01483991,0.0,0.009821303,0.0,0.0042131096,0.0,0.029939018,0.0115971565,0.0,0.010501385,0.0,0.0,0.0,0.08268252,0.21780908,0.26753104,0.15845951,0.02660007,0.0,0.0,0.0,0.0,0.0038828254,0.0,0.0,0.017573237,0.022265404,0.004326448,0.006060727,0.0,0.01126305,0.0,0.0,0.0,0.04957179,0.02109386,0.0,0.0,0.0,0.0,0.04430964,0.20808263,0.28461605,0.33752185,0.25127473,0.097453624,0.04163786,0.0,0.0,0.0,0.001414895,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009532876,0.010816775,0.01063133,0.0,0.057764232,0.030015357,0.0,0.0,0.0,0.0,0.051590554,0.18979666,0.26802588,0.3348605,0.28386852,0.16344483,0.10299761,0.045924716,0.00040335953,0.0,0.0018841624,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008650839,0.040386096,0.018637963,0.001251325,0.081035964,0.06903066,0.045983672,0.0,0.0,0.030444928,0.06711555,0.100732714,0.086139105,0.17647718,0.21386546,0.2154113,0.17504798,0.12882069,0.04189539,0.016748652,0.0,0.0,0.0,0.0030180216,0.0,0.0,0.0,0.0,0.01545836,0.060360573,0.017738529,0.0,0.08849074,0.10054849,0.10628602,0.0,0.0,0.005234793,0.047126256,0.072475865,0.029496714,0.10857476,0.18465325,0.24068046,0.22399081,0.21553895,0.10845861,0.052820176,0.0,0.003961593,0.0,0.021684267,0.0,0.0,0.0,0.0,0.039788045,0.07863958,0.023291744,0.0018789172,0.08703636,0.12761392,0.14084414,0.007096939,0.0,0.0,0.030004397,0.06852049,0.03571961,0.06395681,0.13739958,0.21853799,0.21547353,0.25964963,0.20256397,0.1466414,0.02506224,0.03605164,0.0,0.039302036,0.014155351,0.0,0.0,0.0,0.050662503,0.08528413,0.020125479,0.0,0.09601642,0.1598579,0.17918204,0.020411387,0.0,0.0,0.03024643,0.081768595,0.04873842,0.035862245,0.07985316,0.18897752,0.19204785,0.2597927,0.24186537,0.19880787,0.06477936,0.061935514,0.0,0.03749711,0.011178695,0.0,0.0],[0.0,0.0,0.0,0.045629725,0.0055031925,0.0,0.0,0.0,0.0,0.01036454,0.020916983,0.0,0.0,0.0,0.0,0.0,0.0,0.03336756,0.06301814,0.02347891,0.11945285,0.12932763,0.117900774,0.040816255,0.013032451,0.0,0.0,0.002186969,0.0,0.0,0.014875114,0.06090031,0.018661454,0.008941516,0.0,0.0,0.0,0.017580502,0.01246047,0.0,0.0,0.0,0.0,0.0,0.0,0.034598216,0.056320474,0.021167658,0.075257204,0.07423034,0.06604327,0.0,0.012570597,0.0,0.0,0.0083118975,0.0,0.0,0.019533738,0.06336087,0.010987237,0.009840637,0.0,0.0,0.0,0.032670766,0.0,0.0,0.0,0.0,0.0,0.0,0.020383984,0.016127773,0.02134648,0.024404757,0.027058177,0.03238886,0.031162277,0.0,0.01993712,0.014762305,0.009568818,0.010171108,0.0,0.0,0.00647188,0.03970027,0.0069277734,0.012311824,0.0,0.0,0.0,0.017524034,0.0,0.0,0.0,0.029596604,0.026571587,0.0,0.015881523,0.0,0.017432526,0.019166097,0.0,0.002711907,0.0034461021,0.0,0.027940683,0.014652006,0.015259773,0.0063193813,0.0,0.012157895,0.008096233,0.012124993,0.0009249002,0.017713405,0.024668314,0.0,0.0,0.013931036,0.0,0.0,0.07129907,0.15204668,0.11504266,0.0029639006,0.0,0.0,0.0,0.0,0.0011869669,0.0,0.0,0.015137501,0.046017326,0.026159503,0.022309639,0.0071261376,0.0,0.020579122,0.003881365,0.0,0.0,0.030038722,0.03479927,0.0,0.0,0.023571141,0.0,0.038703695,0.15625878,0.21674562,0.19723588,0.06850396,0.024585076,0.0,0.0,0.0,0.0,0.0,0.0,0.018462524,0.035328463,0.007848866,0.0,0.0,0.0,0.032297462,0.02017583,0.0,0.00019723177,0.043326072,0.051900774,0.0,0.0,0.015066728,0.0,0.046120748,0.15463287,0.20946923,0.19005741,0.07458289,0.064582184,0.0,0.0,0.0,0.0,0.0,0.0,0.018795721,0.037713066,0.008178994,0.0,0.0,0.0,0.059752904,0.049237646,0.022795469,0.0014260411,0.06391934,0.10019213,0.030903496,0.0,0.019061811,0.003831014,0.07460578,0.0745652,0.052833334,0.059750207,0.028382048,0.08654484,0.009919882,0.005948521,0.0,0.0,0.0,0.0,0.027300201,0.05063864,0.022883408,0.0,0.0,0.0,0.097128354,0.07635747,0.041642085,0.0055652857,0.068853654,0.14869268,0.07940606,0.035352618,0.022623628,0.0,0.08962257,0.036163583,0.0,0.0,0.003505677,0.08775073,0.027010515,0.026735075,0.008622862,0.0,0.0,0.0,0.03521081,0.060793705,0.044691883,0.0,0.0,0.008274898,0.124505475,0.093444124,0.06507613,0.009735562,0.061250173,0.17568532,0.10363753,0.050247222,0.017269447,0.0,0.09435004,0.03316827,0.0,0.0,0.0,0.05625476,0.0,0.022492379,0.07150574,0.05821067,0.002002865,0.0011838377,0.03481993,0.066940166,0.06253502,0.0,0.0,0.01743918,0.14096972,0.10615141,0.06797132,0.016759373,0.06620356,0.20390251,0.1328296,0.06965178,0.005692601,0.0,0.096565366,0.036113977,0.0,0.0,0.0,0.0233211,0.0,0.0393091,0.10416822,0.110182755,0.035711735,0.015103966,0.024778403,0.055719003,0.05932071,0.0,0.0],[0.0,0.0,0.0,0.03386736,0.022510648,0.0045182854,0.0,0.0,0.0,0.020392634,0.055447772,0.039605573,0.0,0.0,0.0,0.0,0.019803025,0.044075467,0.019999065,0.0,0.037286222,0.065602586,0.057271756,0.0,0.0,0.0,0.0,0.0,0.006065868,0.0,0.0,0.034353733,0.02006659,0.03495518,0.0,0.0,0.0,0.0,0.033042766,0.02791705,0.0,0.0,0.0,0.0,0.0142945275,0.027777769,0.018990107,0.0,0.024195984,0.041339986,0.03936083,0.0,0.0,0.0,0.0,0.0,0.011950746,0.0,0.0007057935,0.03428886,0.003217265,0.053540982,0.026181102,0.0,0.0,0.0,0.0059229806,0.016689256,0.0,0.0,0.0,0.0,0.0,0.0034108162,0.016203962,0.0,0.013218112,0.017298602,0.023516282,0.0,0.0,0.0,0.0,0.0,0.012035489,0.0,0.0,0.016950242,0.0,0.038963124,0.017811507,0.0,0.0,0.0,0.0,0.0007504076,0.0,0.009470917,0.007365465,0.0,0.0,0.0,0.0047777593,0.0,0.0039432943,0.002404511,0.016683996,0.0,0.0,0.0,0.0,0.0,0.009524964,0.0,0.0,0.008822724,0.0,0.02263479,0.015820064,0.0,0.0,0.0,0.0,0.0007445216,0.013745189,0.055495836,0.034594826,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007568039,0.00040875375,0.012892753,0.0,0.00415197,0.0,0.011086032,0.0,0.0,0.011318885,0.0,0.0044415146,0.009310067,0.008410424,0.0075317994,0.0,0.0,0.03758148,0.07981555,0.11753104,0.093832314,0.006599106,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0061871633,0.016098663,0.0,0.0026851445,0.0,0.007977046,0.0059000403,0.0003158599,0.018052004,0.0,0.0008970946,0.012807041,0.009267837,0.0142361,0.0,0.0,0.03298235,0.07988709,0.12982705,0.10297934,0.014765903,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0052429736,0.02460704,0.0019114017,0.006123781,0.0,0.0011985153,0.03244193,0.03593286,0.03219863,0.0,0.0,0.026703745,0.042494856,0.041348428,0.0,0.00055119395,0.038617767,0.041480906,0.07206646,0.057270683,0.03222449,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009683333,0.040122084,0.00024457276,0.004817337,0.0,0.0,0.0585441,0.06547109,0.04865011,0.0,0.0,0.049058728,0.07643664,0.057191968,0.0,0.0021103173,0.032515258,0.00015847385,0.018522486,0.018415414,0.03628517,0.0013551712,0.0,0.0,0.0017579347,0.0014003217,0.0,0.006735727,0.03081613,0.06133139,0.0,0.0,0.0,0.0,0.07050301,0.08263816,0.05884234,0.0,0.0029853284,0.054910325,0.09327674,0.055111147,0.0,0.0012698174,0.034179933,0.0,0.0,0.0,0.03351728,0.0126165,0.0,0.0,0.020529881,0.026233174,0.0,0.01049342,0.04209972,0.0835156,0.0,0.0,0.0,0.0,0.07021177,0.09795308,0.066605575,0.006431386,0.0069024116,0.058029324,0.10638331,0.053079583,0.0,0.0,0.034101665,0.0,0.0,0.0,0.032769054,0.019712083,0.0,0.0,0.029507644,0.04937014,0.006955005,0.016095944,0.047576353,0.09660958,0.0,0.0,0.0],[0.013289437,0.0,0.018812701,0.0,0.034407012,0.013866268,0.016995922,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0076966584,0.012694366,0.003853768,0.0022560358,0.0,0.0,0.0,0.0,0.0,0.0,0.009265751,0.007966906,0.0011317283,0.018683843,0.0,0.009029932,0.0,0.029689282,0.008153811,0.016131163,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00466156,0.008952126,0.008523561,0.014748491,0.0,0.0,0.0,0.0,0.0,0.0,0.007496603,0.0024215728,0.0,0.024493039,0.0,0.0,0.0,0.026018083,0.014450148,0.02045019,0.0029232502,0.0,0.0,0.0,0.016849771,0.0,0.0026610792,0.0,0.006001979,0.011137962,0.010714658,0.013425425,0.0,0.0,0.0,0.0,0.0,0.0,0.004828602,0.0,0.0,0.021163993,0.0,0.0,0.0,0.016099878,0.016806081,0.011341713,0.0,0.0,0.0,0.0217309,0.030519448,0.0,0.0,0.0,0.004941657,0.008022256,0.008458421,0.00012347102,0.0,0.0,0.0,0.0038700849,0.0,0.0,0.0004005432,0.0,0.0,0.015470922,0.0,0.0,0.0,0.0066040233,0.010555431,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002280265,0.014390811,0.011096589,0.0,0.0,0.0,0.0,0.018155806,0.0,0.0,0.0,0.0,0.0,0.013689175,0.0,0.0,0.0,0.0,0.0028750747,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020220675,0.025911145,0.0,0.0,0.0000061392784,0.00031885505,0.02006457,0.0,0.0,0.0,0.0,0.0,0.011235639,0.0,0.0,0.0009291321,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012612149,0.04184629,0.021654397,0.0,0.0,0.0052227676,0.0073052645,0.0,0.0,0.00066390634,0.0,0.0,0.011777632,0.0,0.0,0.00926543,0.0,0.002308771,0.0063636526,0.006579913,0.0036408901,0.0,0.0,0.0,0.002560839,0.0,0.0020236522,0.0,0.013792753,0.050288297,0.03693389,0.0,0.0,0.00813359,0.0,0.00025220215,0.017113991,0.011047557,0.0,0.0,0.011727586,0.0,0.0,0.014342241,0.0,0.007524587,0.028358102,0.03371784,0.012618899,0.013595156,0.0,0.0,0.021838777,0.0,0.007502109,0.0,0.012156598,0.060048677,0.051161632,0.0,0.0,0.008281246,0.0,0.00833039,0.03412482,0.019377224,0.0,0.0,0.009292878,0.0,0.0,0.019169211,0.0,0.0057105124,0.04293617,0.050678223,0.0038262606,0.013394155,0.0,0.0,0.04325127,0.0,0.009252243,0.0,0.018814102,0.063378334,0.049485825,0.0,0.0,0.009497017,0.0,0.0070756227,0.039983615,0.014569551,0.0,0.0,0.008414552,0.01454401,0.0,0.019267127,0.0,0.0,0.044150136,0.05321248,0.0075505376,0.02084484,0.0,0.0,0.06462128,0.0,0.0106692165,0.0,0.022373982,0.064166375,0.044078797,0.0,0.0,0.014636308,0.0,0.0039150566,0.031377316,0.00035110116,0.0,0.0],[0.0,0.0,0.0,0.0,0.06865783,0.055656314,0.04093533,0.0,0.0,0.0,0.0,0.0,0.0019027889,0.0,0.0,0.015642174,0.04399232,0.0065657794,0.0,0.023700804,0.0,0.0,0.0,0.0,0.008029804,0.053709634,0.05643311,0.0,0.005063534,0.0,0.0,0.0,0.060386688,0.049989447,0.040770106,0.0,0.0,0.0,0.0028669387,0.0,0.0,0.0,0.0,0.0,0.00012661517,0.0,0.0,0.025997333,0.0,0.0,0.0,0.0,0.008225128,0.03659539,0.045553423,0.0,0.0032772273,0.0,0.0,0.0064612925,0.06028147,0.043022953,0.032449573,0.0055655837,0.0,0.0,0.020325363,0.0,0.0,0.0,0.011947125,0.0,0.0,0.0,0.0,0.018674739,0.0,0.0,0.0,0.0,0.009372838,0.018872812,0.028813154,0.0,0.0,0.0,0.0,0.025238007,0.042721495,0.026996419,0.004979387,0.009967044,0.0,0.0,0.025122285,0.0,0.0,0.0,0.00529553,0.005646229,0.0,0.0,0.0,0.0040394664,0.0,0.0,0.020097576,0.0,0.004874155,0.0,0.00588014,0.0,0.0,0.0008737296,0.0,0.022003502,0.020945966,0.007912293,0.0,0.0,0.0,0.0,0.0,0.0,0.008293644,0.02035673,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017558277,0.0,0.0,0.0,0.0,0.0,0.0,0.0016133785,0.0,0.014166109,0.006167479,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014322348,0.0,0.0,0.0027828068,0.0028689057,0.00905475,0.0,0.003138125,0.0,0.012833722,0.0,0.0,0.0,0.0,0.0,0.0,0.009198293,0.0,0.0077469572,0.0,0.0,0.0,0.0,0.0012489557,0.0,0.0,0.0,0.0,0.03173425,0.009923585,0.0006785691,0.0006058961,0.0,0.009803288,0.0,0.0,0.0,0.0046031177,0.0,0.013885029,0.0,0.0014524907,0.0,0.0,0.009965867,0.0,0.0052342266,0.00022013485,0.008120641,0.034647144,0.013282403,0.02663882,0.0,0.0,0.0,0.010983363,0.038020164,0.021795899,0.0019442439,0.001860261,0.0,0.0,0.0,0.0,0.0067066476,0.003921926,0.0037735999,0.039026603,0.01838477,0.011081427,0.0,0.0,0.009980641,0.0,0.00218229,0.0026171803,0.024465539,0.08677763,0.048788443,0.06582224,0.0,0.0,0.004925117,0.05065783,0.035876475,0.02912984,0.0,0.0006566793,0.0,0.0,0.0,0.0,0.0062599555,0.0,0.019905046,0.07459284,0.049818993,0.022725731,0.0,0.0,0.011641376,0.0,0.0,0.0026213825,0.028652683,0.11422755,0.08316094,0.0974758,0.0,0.0,0.04112012,0.09495194,0.044791333,0.03631878,0.0,0.00095276535,0.0,0.0,0.0,0.0,0.0,0.0,0.024461918,0.08410464,0.05714342,0.014378913,0.0,0.0,0.020534962,0.0,0.0,0.0,0.009265661,0.13110706,0.12543851,0.15529571,0.013205089,0.03345655,0.07196042,0.12636454,0.054596566,0.0382265,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018383637,0.073140234,0.04403621,0.0012896061,0.0],[0.0,0.023066252,0.06808478,0.050798886,0.07791376,0.056644082,0.025549792,0.0,0.0,0.0,0.0540333,0.017616391,0.11548934,0.06450841,0.0543866,0.10055944,0.0994678,0.006047316,0.0,0.0024440289,0.0,0.0,0.0,0.0,0.033071212,0.047912166,0.0102918595,0.00019484758,0.0,0.011825614,0.047694124,0.023145892,0.063461624,0.06633378,0.036747046,0.0,0.0,0.008592546,0.04281517,0.0,0.100756824,0.042887866,0.0721439,0.07867396,0.081683114,0.0,0.0034936517,0.004122138,0.0,0.0,0.0,0.0,0.025452875,0.035193443,0.016190805,0.0055833757,0.0,0.0,0.045979634,0.029616952,0.059194386,0.057409093,0.04090178,0.031812042,0.002337858,0.017499954,0.04584586,0.0,0.082185954,0.021186814,0.099318035,0.1082187,0.08396013,0.016875349,0.005855523,0.018533975,0.0,0.0,0.018006593,0.017506443,0.023163624,0.017861404,0.010767892,0.019664824,0.0,0.0,0.045039915,0.026068144,0.037462115,0.029000305,0.02868373,0.04736861,0.0,0.024826162,0.053253084,0.0,0.07117769,0.0,0.08272225,0.090900004,0.041323677,0.03219819,0.0,0.035016917,0.011813924,0.00029087067,0.04319422,0.026295722,0.016024537,0.0,0.0,0.020337008,0.0,0.008272447,0.036713853,0.011757523,0.017010503,0.013880499,0.0010389835,0.019195534,0.0060642436,0.00939884,0.027606785,0.000010848045,0.049046397,0.0,0.02798406,0.02321563,0.0,0.048257902,0.0,0.02555792,0.015544154,0.0,0.035278797,0.010764465,0.0063464046,0.00007133186,0.0,0.00546512,0.0,0.018360995,0.032942668,0.0046532005,0.0020531565,0.015394211,0.0008750111,0.01574824,0.011400551,0.0,0.004610941,0.0,0.039728694,0.0,0.0047216117,0.0044866353,0.0,0.059298433,0.0032377094,0.020609073,0.02172181,0.0,0.023954384,0.0,0.0026922226,0.007305853,0.0,0.004768163,0.0,0.030310519,0.03481108,0.0000937134,0.0,0.028727412,0.018920816,0.020768926,0.026067242,0.0,0.0,0.0,0.041860484,0.0,0.0031938404,0.0,0.0,0.054186165,0.0019809008,0.010764562,0.02298949,0.0,0.012635298,0.0,0.010044843,0.015675679,0.0,0.012450904,0.0,0.02450198,0.022990689,0.0,0.0,0.060994953,0.044750787,0.053116247,0.050686955,0.0,0.000787735,0.0,0.06506611,0.010708429,0.014087461,0.0,0.0,0.025517233,0.0017826557,0.0,0.015231639,0.0,0.0,0.0,0.027886845,0.030797012,0.020159677,0.031159744,0.0,0.011806317,0.00640139,0.0,0.0,0.10163785,0.096226126,0.11999647,0.102789864,0.0,0.011855327,0.0,0.11483192,0.017233022,0.013991408,0.0,0.0,0.0,0.0129281655,0.0,0.002049014,0.0,0.0,0.0033304542,0.06461513,0.06321405,0.057286456,0.052971207,0.0024240315,0.012392938,0.0,0.0,0.0,0.118006326,0.14219591,0.18520948,0.15770358,0.026677229,0.04460389,0.05006183,0.15973166,0.020100445,0.021992616,0.0,0.0,0.0,0.01835858,0.0,0.0,0.0,0.0,0.011488117,0.07542065,0.07142147,0.058223166,0.048070997,0.003962368,0.007624924,0.0,0.0,0.0,0.11488141,0.19090566,0.27030218,0.24580958,0.10925671,0.09400211,0.09651798,0.19229092,0.03129536,0.02776102,0.0,0.0,0.0,0.0123504475,0.0,0.0,0.0,0.0,0.009673767,0.06970993,0.06668293,0.05302933,0.040541068],[0.0,0.051950634,0.0,0.0,0.065675855,0.034409508,0.008777037,0.01160986,0.038039774,0.11142448,0.17441244,0.14603633,0.17976213,0.22506487,0.21217805,0.17698063,0.15122238,0.07884806,0.0,0.0,0.0,0.0,0.0,0.012287609,0.013152793,0.0,0.0,0.0030451417,0.0,0.037934862,0.0,0.0,0.0609058,0.041070163,0.025010541,0.020876385,0.05197656,0.090390384,0.12811908,0.07698296,0.11879332,0.19126678,0.2030957,0.1700068,0.11517168,0.057031102,0.0,0.0,0.0,0.0,0.0008735955,0.019180752,0.018987626,0.0,0.0,0.0064156502,0.0,0.024096638,0.0,0.0,0.059392378,0.059929967,0.03937699,0.023856737,0.05365017,0.05691985,0.057491884,0.02014155,0.06734619,0.17782414,0.22524162,0.21617398,0.12262508,0.053187624,0.0,0.0,0.0,0.014595583,0.039496467,0.026566997,0.015183754,0.0,0.0,0.011138536,0.0,0.02634953,0.0,0.0,0.02848319,0.043791547,0.03145065,0.02477631,0.061360583,0.056746915,0.033495143,0.0,0.025017187,0.085826114,0.14367874,0.14770143,0.059801124,0.026391387,0.0,0.0,0.040516607,0.046308108,0.06656062,0.019318804,0.0032725185,0.0,0.0,0.0056726933,0.0,0.025316894,0.0056176484,0.0,0.010274656,0.044201344,0.03127625,0.0011069626,0.04160347,0.037527993,0.034235835,0.0,0.0018286407,0.004311487,0.0,0.03166634,0.021505155,0.04665398,0.0029846728,0.0,0.014833465,0.0,0.028979726,0.0,0.00066410005,0.0,0.0,0.0,0.0,0.020071298,0.00900396,0.0,0.0014960468,0.032433286,0.029437184,0.0,0.03526786,0.023291148,0.026288778,0.0,0.0,0.0,0.0,0.0033496618,0.0056185722,0.051562205,0.0116588995,0.006432928,0.027141802,0.0,0.0143257305,0.0,0.0014416128,0.0,0.0,0.0,0.0,0.016352117,0.017040528,0.0,0.016015202,0.04621928,0.037401862,0.0,0.02557794,0.007651478,0.011773564,0.0,0.0123407245,0.03129887,0.0,0.022568353,0.0,0.047477648,0.011118643,0.014809936,0.02702386,0.004322186,0.008655623,0.0,0.0052809864,0.019043602,0.0064059645,0.0,0.0027335435,0.012134075,0.017010137,0.0,0.03633581,0.075246215,0.06285463,0.009906739,0.016777761,0.014070906,0.0152830705,0.0,0.024775393,0.061121732,0.014638662,0.04794845,0.0,0.03260351,0.009820968,0.01643049,0.031173684,0.021029346,0.0051091015,0.0,0.012817889,0.049123988,0.03702706,0.007453397,0.0051709116,0.004868895,0.009811878,0.0,0.04629463,0.11507255,0.12465277,0.061014377,0.036466293,0.049425058,0.04164733,0.0,0.04061889,0.09643717,0.058996364,0.074677184,0.0028384626,0.033853613,0.0054887086,0.0,0.026594035,0.027263276,0.0,0.0,0.03782764,0.09299343,0.06774728,0.01685907,0.012392439,0.010363847,0.0062048063,0.0,0.046023495,0.16333634,0.18866274,0.13024378,0.08498649,0.1137488,0.09936622,0.0,0.054795705,0.10794946,0.09539233,0.081069365,0.0,0.0025796592,0.0,0.0,0.0,0.0,0.0,0.0,0.0396664,0.08153027,0.049644366,0.0025247186,0.015027933,0.0036482513,0.0007388145,0.0,0.036542214,0.19680618,0.25722992,0.22880277,0.2095813,0.2522604,0.19609061,0.0,0.07255107,0.11272283,0.12244866,0.08702951,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032495663,0.06863402,0.038614444,0.0],[0.0,0.0,0.012772307,0.0,0.04340455,0.061246805,0.03930255,0.037080556,0.15930443,0.22520542,0.31549639,0.3729238,0.5085155,0.55696523,0.68991435,0.49545622,0.39287508,0.16661543,0.06947283,0.0,0.0,0.0,0.0,0.0057720393,0.0,0.011926211,0.0,0.0,0.0,0.0,0.0,0.0,0.043079123,0.07062313,0.042796798,0.007973261,0.08604749,0.12998348,0.18791628,0.22946386,0.39178014,0.48968947,0.6223598,0.47287297,0.36389145,0.15068346,0.087154716,0.0,0.0,0.0,0.0,0.020533048,0.0,0.019368924,0.0,0.0,0.0,0.0,0.0,0.0,0.040909342,0.07569796,0.044039257,0.0,0.01414901,0.050435044,0.068870254,0.1050155,0.28010947,0.4292791,0.57287765,0.48957425,0.36939013,0.15601927,0.09935753,0.0,0.0,0.0024012327,0.0,0.024954826,0.0,0.005542457,0.0,0.0,0.0,0.0,0.0,0.0,0.019505128,0.044715032,0.018237486,0.0,0.0,0.023449793,0.0,0.024505839,0.1375303,0.24092951,0.3437946,0.33556068,0.26257697,0.12988982,0.10559152,0.0,0.0,0.015627459,0.0039554834,0.016522914,0.0,0.0,0.0,0.0,0.0,0.009732164,0.0,0.0,0.0095202625,0.023084767,0.0,0.0,0.0,0.019066885,0.0,0.0,0.02342949,0.012925856,0.060887866,0.1102694,0.1384269,0.1352356,0.11531533,0.005487621,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013234876,0.0,0.0,0.00627663,0.013985679,0.0011057556,0.0,0.0026037544,0.016188614,0.0,0.0,0.015796341,0.0,0.0,0.0023281723,0.047062017,0.10752664,0.08037568,0.004086718,0.0,0.0,0.0,0.0,0.0,0.0,0.0010938644,0.0,0.0,0.011779495,0.0,0.013711974,0.03827382,0.033995382,0.02042415,0.0,0.016212106,0.026641354,0.0,0.0,0.020089358,0.0,0.0,0.0,0.009326197,0.09535517,0.052914366,0.0,0.0,0.023677647,0.0025566965,0.0,0.0,0.00285545,0.007047564,0.0,0.0,0.009818651,0.0,0.038940303,0.086132795,0.0614596,0.039473988,0.0,0.030404046,0.051391073,0.0,0.0,0.0154146105,0.0,0.0,0.0028478205,0.0,0.081206344,0.0237647,0.0,0.01608935,0.07496746,0.037482,0.0,0.0,0.034529455,0.027121164,0.0,0.0,0.009589255,0.0,0.059303835,0.1211284,0.09618072,0.08602038,0.0,0.05212918,0.09067132,0.014098838,0.0,0.016876698,0.0,0.0,0.0158161,0.018136963,0.08559597,0.013647459,0.0,0.019272126,0.08908264,0.056665704,0.0,0.004711762,0.07441783,0.056010507,0.0030000955,0.0,0.024151184,0.0,0.06010417,0.13406366,0.14016908,0.13316378,0.04757002,0.08219844,0.14467794,0.06861174,0.021727584,0.011236012,0.007194586,0.01623384,0.015920773,0.019926049,0.046416536,0.0,0.0,0.0,0.055489257,0.03978567,0.0,0.019112319,0.06646749,0.045176387,0.0,0.0,0.03311959,0.0,0.06155447,0.14379486,0.18626964,0.1914695,0.1272206,0.19701406,0.28644437,0.162623,0.07669752,0.0031279027,0.035417624,0.047987588,0.014626056,0.021394908,0.02571933,0.0,0.0,0.0,0.029946864,0.01742316,0.0,0.017624855,0.056054935,0.029975377,0.0],[0.0,0.0,0.0,0.010220841,0.06032692,0.077597186,0.0725298,0.16611591,0.22454858,0.4254346,0.46899575,0.5961515,0.7312159,0.9741305,0.9787225,0.962342,0.7482304,0.4032153,0.18503305,0.010232493,0.0,0.0,0.0,0.0,0.0,0.032240912,0.0,0.0,0.0,0.0,0.0,0.008922473,0.04496956,0.043475114,0.008059345,0.06359826,0.104093425,0.2351862,0.26791024,0.4151953,0.5967915,0.8503036,0.89367896,0.91136277,0.677665,0.3202253,0.11170467,0.0,0.0,0.0,0.0,0.0,0.011412762,0.05774018,0.01791244,0.0,0.0,0.0,0.0,0.017973222,0.040735714,0.00496237,0.0,0.027812958,0.050799802,0.106729135,0.0922261,0.20089474,0.39322817,0.70220184,0.82401985,0.8743241,0.62177736,0.2623909,0.06313169,0.0,0.0,0.0,0.0,0.0,0.0,0.041378483,0.01008945,0.0,0.0,0.0,0.0,0.01688037,0.024631009,0.0,0.0,0.0,0.011803061,0.023859002,0.012614176,0.06521663,0.13489446,0.37128025,0.53725237,0.6706467,0.5197038,0.24356711,0.07455636,0.0,0.0,0.0,0.0,0.0,0.0,0.012912914,0.0,0.0061470345,0.0,0.0,0.0,0.0049934685,0.017451532,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.055398695,0.14706594,0.31112194,0.39245278,0.28107587,0.16900393,0.024757065,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010689177,0.0,0.0,0.0,0.0,0.020327553,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.068098485,0.2268216,0.23616612,0.16983868,0.05591467,0.0076623186,0.0,0.0,0.0,0.0,0.0,0.0,0.012418464,0.0,0.0,0.0067084283,0.0029681176,0.030144334,0.00045849383,0.02104523,0.0,0.0,0.0,0.01723919,0.0,0.0,0.0,0.0,0.0,0.085858315,0.14990938,0.1700689,0.13240968,0.0800506,0.042488977,0.031848893,0.0011268109,0.0,0.0,0.0,0.018693447,0.0,0.0,0.01628314,0.021902122,0.049616307,0.018270597,0.037463635,0.0,0.0,0.0,0.021389335,0.0,0.0,0.0,0.0,0.0,0.0,0.10160571,0.18232362,0.21552433,0.17970985,0.10802983,0.0695474,0.009774081,0.0,0.0,0.0022696406,0.027971566,0.0,0.0,0.030517213,0.0379475,0.06571728,0.040753648,0.056524076,0.0,0.0,0.0,0.027162112,0.0,0.02453579,0.020789206,0.0,0.0,0.0,0.11307268,0.2321325,0.30563384,0.2689512,0.15462881,0.07893384,0.01922109,0.0,0.0029174387,0.017869934,0.034467727,0.0,0.0074970275,0.041603953,0.043325834,0.07184711,0.059672922,0.07588874,0.0,0.0333343,0.0,0.07442567,0.014461458,0.10300424,0.09412232,0.0,0.0,0.0,0.07982846,0.19713116,0.26030847,0.21608973,0.11839302,0.062677786,0.036161743,0.014915779,0.0,0.016263008,0.025905997,0.0012791902,0.024434015,0.050567016,0.04557816,0.07303466,0.09471796,0.12086791,0.017856956,0.17398307,0.14268564,0.17271943,0.103905424,0.1878168,0.16859674,0.032560967,0.0,0.0,0.090413876,0.19776827,0.24802026,0.17502804,0.08161843,0.021464817,0.04004158,0.019469276,0.0,0.017496377,0.015740171],[0.0,0.0,0.020376436,0.060472913,0.092943236,0.10014954,0.068490654,0.20197004,0.27206048,0.44840807,0.42360038,0.5860021,0.74969435,0.9147737,0.95753515,0.9993137,0.84561026,0.57126904,0.288308,0.025403269,0.0,0.0,0.0,0.0,0.03356097,0.0,0.0,0.0,0.0,0.0,0.016746074,0.059125207,0.07310965,0.05681541,0.0,0.08951086,0.1334561,0.25643337,0.21686882,0.43287802,0.6571533,0.8445764,0.9530721,0.96885854,0.7964502,0.46739835,0.18554811,0.0,0.0,0.0,0.0,0.0029911846,0.056960754,0.013001494,0.007339075,0.0,0.0,0.003627494,0.026865467,0.065722056,0.06474018,0.036823697,0.0,0.04500279,0.06328903,0.105553016,0.035485804,0.17939802,0.44128072,0.7105127,0.8902308,0.92690474,0.7147421,0.38935918,0.12210468,0.0,0.0,0.0,0.0,0.0,0.0392308,0.0074585453,0.007671006,0.0,0.0,0.011595488,0.023680978,0.052912496,0.029677995,0.025662027,0.0,0.0035837442,0.0045993775,0.0045528114,0.0,0.030237779,0.1469591,0.37937653,0.62894845,0.7723656,0.58949214,0.35987473,0.08980139,0.0,0.0,0.0,0.0,0.0,0.010042481,0.0,0.0040413737,0.0,0.0,0.0053554773,0.0023386627,0.027794614,0.0051644742,0.0139141455,0.0021171868,0.0,0.0,0.0,0.0,0.011106677,0.02029606,0.09331751,0.29464447,0.50148135,0.4904225,0.43811876,0.15088774,0.0,0.0,0.0,0.0,0.0,0.0074357614,0.0,0.0065160766,0.0,0.0,0.008287214,0.0,0.024383478,0.0022088885,0.0,0.022069193,0.0,0.0,0.0,0.0,0.013494179,0.019857042,0.028978758,0.15194635,0.29793027,0.35329533,0.40640324,0.16720125,0.04893656,0.011706024,0.0,0.0,0.0,0.009041794,0.0,0.009510621,0.0,0.0,0.005958393,0.0035461932,0.030807793,0.0056239814,0.0074775666,0.04528223,0.006153837,0.012805618,0.013062604,0.0022833347,0.015715003,0.017308205,0.0,0.10104688,0.17572182,0.23440883,0.30768132,0.22988355,0.19381651,0.09543277,0.0,0.0007788241,0.0,0.022677228,0.0,0.006567538,0.00814043,0.0,0.0006276369,0.00030578673,0.044734426,0.015816368,0.019374318,0.056117408,0.010662422,0.019846678,0.018890783,0.01592753,0.014353678,0.009815276,0.0,0.069526926,0.11392959,0.15774179,0.25704572,0.2946099,0.3612972,0.20072365,0.028260075,0.023370482,0.00067584217,0.044703014,0.0,0.011071064,0.022565871,0.0,0.014667176,0.0070772544,0.0568104,0.030246139,0.027705997,0.07046598,0.026450135,0.04846946,0.028553233,0.028576344,0.022995137,0.011458814,0.0,0.06400614,0.07488759,0.117404476,0.2829364,0.38116187,0.48983896,0.29058266,0.04332833,0.04486739,0.02106554,0.07106256,0.011051081,0.008632198,0.027373374,0.0,0.03070955,0.019687593,0.06921841,0.044442825,0.03763341,0.076717004,0.060182407,0.13420069,0.11312267,0.13000992,0.10859759,0.07843076,0.02637899,0.08749872,0.06257953,0.07224781,0.23825413,0.34857276,0.41349137,0.24798578,0.009251483,0.05296074,0.034232326,0.08253801,0.01534871,0.0,0.030855335,0.0,0.046966717,0.022497915,0.070407294,0.050651096,0.061432645,0.118462354,0.1464733,0.29207313,0.2693833,0.30169183,0.21646509,0.16663274,0.07480216,0.116414204,0.085302696,0.09775661,0.27371672,0.3699507,0.3675102,0.20918897,0.0,0.0422166,0.033040628,0.099101014,0.029061936,0.0,0.03120093],[0.0,0.0021833628,0.019495435,0.0,0.0,0.017204814,0.041113593,0.15983544,0.1364834,0.15414093,0.12065412,0.079319514,0.22226807,0.4052447,0.57698077,0.5877946,0.60355985,0.41756147,0.3397393,0.08788395,0.0,0.0,0.00036872923,0.014115222,0.010058679,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.078970864,0.06842913,0.07644563,0.0396853,0.048824385,0.25819653,0.50701064,0.69039935,0.6533782,0.54681396,0.31572348,0.21815187,0.020803668,0.0,0.0,0.013276234,0.038822807,0.043660626,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006265402,0.0,0.053413466,0.039460905,0.003660217,0.0,0.0,0.20249848,0.5301383,0.76777923,0.7289507,0.5300414,0.23224193,0.11848806,0.0,0.0,0.0,0.0049390644,0.023423985,0.041207507,0.0,0.0,0.0,0.0,0.0065041184,0.00853093,0.020849451,0.0014243126,0.027722195,0.0056589544,0.019791327,0.0050141364,0.0,0.0,0.0,0.047756746,0.33309653,0.6572515,0.80592513,0.6124607,0.23595288,0.038677692,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012560114,0.0,0.015352562,0.003162548,0.019987613,0.009105124,0.03411314,0.012073517,0.0036628693,0.0047138184,0.0,0.0,0.0,0.0,0.14621001,0.4106983,0.66934747,0.70138454,0.48093206,0.20451194,0.0,0.0,0.0,0.0030601919,0.0,0.0,0.0,0.0,0.019714482,0.0,0.016236164,0.0065630823,0.027020797,0.018056184,0.02765245,0.019308418,0.0,0.02595757,0.03368862,0.0120911375,0.0005480945,0.02255261,0.10600274,0.26699877,0.50389916,0.63309073,0.5280681,0.2570679,0.0012500137,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021460049,0.0,0.019287713,0.011155501,0.014867619,0.008697525,0.012011528,0.031541035,0.0038500726,0.04622531,0.06127514,0.032637127,0.030487306,0.045601726,0.052488767,0.096151486,0.294735,0.47756928,0.5005657,0.37255704,0.12494384,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014790438,0.0,0.023863137,0.0057966635,0.0057064444,0.014071159,0.010272644,0.046571873,0.0075585917,0.053320237,0.091284074,0.056729652,0.05479677,0.039690576,0.0035042167,0.00637009,0.19330338,0.3900463,0.47878826,0.49465954,0.28284585,0.02833929,0.0,0.0,0.0006212741,0.0,0.006169945,0.0,0.018569253,0.0,0.0479855,0.01784078,0.009605244,0.05014793,0.03589587,0.07967865,0.031623326,0.08421072,0.124669656,0.091323845,0.087779835,0.06361614,0.0,0.0,0.1234754,0.3647214,0.52960634,0.6424478,0.4305796,0.08101253,0.0,0.0,0.017611086,0.009797655,0.014324948,0.00034853816,0.017753772,0.0,0.064955235,0.0335045,0.026306637,0.07976653,0.056951307,0.11937512,0.10267612,0.16361815,0.20402095,0.18967682,0.15787482,0.13293307,0.0,0.0,0.07273926,0.32877827,0.45664734,0.55999196,0.33018023,0.013891526,0.0,0.0,0.032561526,0.020778,0.020720117,0.0051289946,0.025122456,0.0,0.080660045,0.04688412,0.037692644,0.10664063,0.08660585,0.19257888,0.25180012,0.31395602,0.3543213,0.3430724,0.25581464,0.21175522,0.0,0.0,0.09897069,0.39408135,0.4620586,0.51930624,0.26095775,0.0,0.0,0.0,0.0417936,0.03177669,0.03405384,0.015527345,0.033211246],[0.0056027323,0.00914713,0.0012581944,0.043138325,0.00011718273,0.0,0.08550226,0.04950507,0.0,0.0,0.0,0.0,0.0,0.19814765,0.36390227,0.45956713,0.51032364,0.35267913,0.21048552,0.11237772,0.061567128,0.051781252,0.018356875,0.0,0.010103218,0.006889552,0.0,0.027055986,0.0,0.0,0.0,0.0310013,0.0,0.0,0.034006864,0.018289603,0.0,0.0,0.0,0.0,0.03454589,0.35604012,0.505764,0.52515954,0.4470666,0.25198194,0.09367462,0.030581087,0.05589895,0.05156573,0.032805257,0.002456382,0.030816473,0.0117762685,0.0,0.03066019,0.0,0.0,0.0,0.034369506,0.0,0.0,0.0011902899,0.0030587763,0.0,0.0,0.0,0.0,0.086602315,0.4651019,0.6559416,0.65308213,0.4271719,0.1601431,0.0,0.0,0.016280688,0.02270025,0.027699418,0.0,0.034476116,0.0146931335,0.0,0.04294301,0.0,0.0,0.0,0.025297418,0.0,0.00916633,0.0,0.0,0.0,0.0,0.0,0.0,0.0010582805,0.35721517,0.6666815,0.78823626,0.48599225,0.14177099,0.0063085705,0.0,0.0,0.0,0.018447645,0.0,0.004648447,0.0,0.0,0.05749829,0.0,0.0,0.0,0.0026891977,0.0,0.0136806,0.0,0.0,0.0,0.026418477,0.016257763,0.013647668,0.04425306,0.26638412,0.5182098,0.74642164,0.6857488,0.46001047,0.22804746,0.0,0.0,0.0,0.013757743,0.0,0.0,0.0,0.0,0.039733246,0.0,0.0,0.0,0.0035934746,0.0,0.024463207,0.015470929,0.010657825,0.047593504,0.10202691,0.09711183,0.09633249,0.115051836,0.26281953,0.42240566,0.63436043,0.704465,0.57058483,0.33385932,0.0122706145,0.0,0.0,0.0094535425,0.0,0.0,0.0,0.0,0.022020593,0.00023008883,0.004748985,0.0,0.0,0.0,0.030790716,0.03371206,0.05481486,0.12560606,0.16905992,0.14142741,0.14131317,0.14080541,0.19616413,0.26168454,0.44326192,0.6069114,0.6241349,0.4525746,0.0945598,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010050714,0.014375351,0.015113257,0.0,0.0,0.0,0.044052184,0.04131975,0.08168344,0.20501187,0.26243532,0.19446158,0.1659883,0.15156949,0.1414177,0.18483865,0.33488262,0.5441355,0.62746954,0.5531142,0.21174762,0.034532785,0.0,0.0,0.0,0.0,0.0,0.0,0.013012044,0.037694275,0.04037506,0.0,0.0,0.0,0.08008969,0.067698605,0.116486885,0.2818948,0.34151155,0.24815485,0.20140421,0.14889233,0.07662588,0.11598111,0.25549114,0.5398318,0.6870948,0.6624276,0.3190887,0.05975333,0.0,0.0,0.0,0.0,0.0,0.0,0.014684074,0.052065104,0.05308093,0.016128212,0.0,0.02882079,0.10654272,0.10831409,0.17271787,0.33000112,0.4056744,0.31230572,0.24711546,0.14739223,0.047669917,0.0749933,0.16959547,0.45540613,0.59542525,0.5504128,0.21945289,0.015165545,0.0,0.0,0.0,0.0,0.0,0.009833075,0.026240952,0.064918175,0.06324597,0.037067972,0.005688295,0.05729688,0.14708452,0.1789425,0.29512125,0.458551,0.516139,0.41835696,0.33033904,0.16620478,0.05172892,0.06377021,0.17789632,0.4821937,0.5763553,0.479226,0.14376973,0.0,0.0,0.0,0.0,0.0,0.0,0.024825752,0.037153356],[0.015388139,0.0,0.0,0.0,0.0,0.0,0.007111691,0.0,0.0,0.0,0.0,0.0,0.0,0.30040076,0.6431169,0.76575977,0.6686583,0.4148231,0.25129065,0.10390961,0.055718504,0.03530342,0.0,0.0,0.0,0.0,0.0,0.0,0.00069338083,0.0,0.0,0.0,0.0025168061,0.0,0.012052186,0.0,0.0,0.0,0.0,0.0,0.08939499,0.47098607,0.79347354,0.8046781,0.5830462,0.3043641,0.1194713,0.0304389,0.024378419,0.012940921,0.0,0.0,0.0,0.0,0.0,0.0,0.0047982335,0.0,0.010807976,0.0,0.010201529,0.0,0.020353504,0.0,0.0,0.0,0.0,0.0,0.12484489,0.54412556,0.8941453,0.8810152,0.5472819,0.21504715,0.0,0.0,0.0,0.0,0.0,0.0,0.004316345,0.0,0.0023383945,0.0,0.0052408427,0.0,0.016814828,0.0,0.00640399,0.0064474195,0.020526454,0.020799771,0.0,0.0,0.0,0.0,0.051979788,0.4202898,0.79796803,0.88783807,0.5738443,0.18409973,0.0,0.0,0.0,0.0,0.0,0.016163401,0.02151417,0.0073808953,0.0017959625,0.0,0.0017955005,0.0,0.0,0.0,0.008692481,0.02376452,0.03208629,0.050533265,0.009247698,0.0,0.022696331,0.0054284334,0.04320267,0.21043776,0.48060924,0.67439646,0.67869574,0.39732254,0.12564707,0.0,0.0,0.0,0.0,0.0,0.0011122972,0.0,0.0,0.0,0.0021567047,0.0,0.0,0.0,0.0041374266,0.033510506,0.034575187,0.08660152,0.054623485,0.047374688,0.08256428,0.06356668,0.10154639,0.14364761,0.28799567,0.50018823,0.6670167,0.5008959,0.24098846,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.054140046,0.05182425,0.12532903,0.11583119,0.11488588,0.15419367,0.08126043,0.10970226,0.06368351,0.14081109,0.3573349,0.6804781,0.62575537,0.40448797,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.056015484,0.045685284,0.15071188,0.19911101,0.18771854,0.22831036,0.092481196,0.11185573,0.030899838,0.07802588,0.25743747,0.66256654,0.6931255,0.55277264,0.0676175,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0003733188,0.018199451,0.008984692,0.033577293,0.041597523,0.07743241,0.07558279,0.22050507,0.32108325,0.29446292,0.29680693,0.1130534,0.11982512,0.0,0.02000191,0.21113223,0.71463645,0.803438,0.69268364,0.12322533,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00598523,0.030519754,0.047074325,0.09085186,0.08830484,0.09528703,0.10396895,0.24481001,0.3854192,0.38511086,0.34099638,0.18485337,0.161303,0.004943043,0.0,0.16669595,0.6692585,0.7491752,0.6229866,0.04217878,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01592344,0.036947787,0.07572684,0.1338866,0.13457033,0.1390821,0.15689602,0.29603964,0.4826759,0.51399696,0.43163007,0.27139467,0.20126243,0.032694817,0.0,0.17313509,0.6799137,0.7593984,0.5719509,0.0,0.0,0.0,0.0,0.00864058,0.0,0.0,0.0,0.0],[0.0,0.021934032,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05451124,0.2717098,0.6584525,0.9698169,0.9444822,0.63502496,0.29155496,0.16352934,0.023142114,0.0,0.019198991,0.0,0.0,0.0,0.0,0.0,0.0010083616,0.0,0.015493162,0.010009006,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.054910317,0.30753794,0.7664633,1.0,0.966688,0.53620183,0.18175489,0.05419691,0.009225428,0.0,0.0043831766,0.0,0.0,0.0,0.0,0.0,0.0049761534,0.0,0.030199394,0.018864684,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020210452,0.27812576,0.7336316,1.0,0.99417824,0.4925323,0.09325148,0.0,0.0,0.0,0.0,0.0014049113,0.0,0.0,0.0,0.0,0.011182241,0.0,0.02633769,0.01096186,0.0,0.0,0.0,0.0,0.0072676465,0.0,0.0,0.0,0.0,0.13897717,0.5336864,0.9250339,0.92902714,0.4999885,0.11139466,0.0,0.0,0.0,0.0,0.016548254,0.02422773,0.051300302,0.015400432,0.0034576952,0.000057518482,0.0,0.012835763,0.00037764013,0.020506889,0.00475882,0.0,0.0059568584,0.030456834,0.0,0.015058078,0.052391954,0.049104862,0.04545383,0.25856203,0.565194,0.73134094,0.63650006,0.3904124,0.059228808,0.0,0.0,0.0,0.01619783,0.007969588,0.042293362,0.0,0.0,0.0,0.0,0.012257829,0.0,0.018266514,0.0051477402,0.008417964,0.020314999,0.058961503,0.059460156,0.082644604,0.11130519,0.1267002,0.064071596,0.13167962,0.34975404,0.5393775,0.6517113,0.539547,0.1729984,0.0,0.0,0.0,0.024148628,0.007555686,0.039264917,0.0,0.0,0.0,0.0,0.0068178996,0.011524372,0.0061650947,0.014487423,0.04218304,0.05098293,0.08693538,0.10183723,0.1711498,0.13568427,0.14110442,0.06574319,0.040962934,0.22382742,0.4324085,0.7685267,0.7377715,0.3493411,0.0,0.0,0.0,0.03750056,0.0,0.028089106,0.0,0.0,0.0,0.0,0.003640309,0.021047637,0.010443263,0.038377173,0.05763357,0.07780453,0.12239641,0.18288359,0.24899723,0.15863979,0.13413884,0.073468655,0.013338156,0.17224285,0.36055425,0.822525,0.8788596,0.5450642,0.059180878,0.0,0.0,0.02077458,0.0,0.021913916,0.0,0.0,0.00492844,0.0,0.0020075887,0.046825998,0.060351416,0.10749147,0.10385932,0.15099539,0.22690323,0.32766744,0.33183128,0.19217041,0.11886822,0.06365125,0.0,0.13267794,0.31704283,0.902079,1.0,0.67991704,0.086503044,0.0,0.0,0.0044760555,0.0,0.024246737,0.0,0.0,0.016082972,0.0,0.0,0.051518537,0.082604975,0.1418278,0.1422028,0.18880594,0.25716156,0.39014018,0.360202,0.22931719,0.16815485,0.1068634,0.013602674,0.114404574,0.25733197,0.8866828,1.0,0.6481721,0.054753147,0.0,0.0,0.014249645,0.01590883,0.043051325,0.0,0.0,0.0076794624,0.0,0.0,0.045906186,0.09446657,0.1804632,0.19830234,0.2433918,0.30378485,0.45743984,0.42546904,0.30467328,0.20251569,0.12381249,0.0,0.07673325,0.223992,0.92725974,1.0,0.5986072,0.0008698702,0.0,0.0,0.026569456,0.027779162,0.03874988,0.0,0.0,0.0058894306],[0.041656345,0.02078063,0.027204335,0.0,0.0,0.0,0.0,0.0143677,0.0,0.0,0.0,0.19804546,0.52470684,1.0,1.0,1.0,0.6177234,0.12472879,0.05774319,0.0,0.0,0.0,0.0,0.0,0.0,0.015823364,0.041727528,0.0,0.022683382,0.028890327,0.056651875,0.0,0.0,0.0,0.0,0.03047014,0.0,0.0,0.0,0.17401724,0.513111,1.0,1.0,1.0,0.5542729,0.0401697,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017852746,0.0,0.0071946084,0.028812185,0.07270844,0.0070206746,0.0,0.003983468,0.0,0.040575482,0.0,0.0,0.0,0.096187264,0.38615763,0.9495287,1.0,1.0,0.4814849,0.0,0.0,0.0,0.0,0.0,0.038112767,0.017638646,0.0,0.0,0.0,0.0,0.0,0.0097064,0.05585368,0.010567941,0.0,0.011543445,0.0070497245,0.055642202,0.004766479,0.0,0.0,0.028397575,0.21208875,0.6819498,1.0,0.9207991,0.44277084,0.0,0.0,0.0,0.0,0.0,0.04045496,0.06003765,0.045787342,0.0,0.007628754,0.0,0.0,0.0,0.025798187,0.016724065,0.0024610013,0.011482,0.008004583,0.049842827,0.01949028,0.012989894,0.023720935,0.049139425,0.0919034,0.3040893,0.5580646,0.70759183,0.609396,0.27843082,0.03493139,0.0,0.0,0.0,0.009099089,0.055302,0.04009883,0.0,0.007449761,0.023072995,0.0,0.0,0.000914678,0.012412652,0.0118056685,0.0044847727,0.011197887,0.04611504,0.0506548,0.063171014,0.09225251,0.09953421,0.08438099,0.11592992,0.27209997,0.5325734,0.6728708,0.49021244,0.16736318,0.0,0.0,0.0,0.0,0.05249869,0.04078871,0.0,0.00269261,0.022984535,0.0,0.0,0.0,0.029510252,0.019305728,0.0042815953,0.019921847,0.056799218,0.1102171,0.1324573,0.16053882,0.13657305,0.09485008,0.023687057,0.15178199,0.5126653,0.84534734,0.7649169,0.33939213,0.0,0.0,0.0,0.0,0.031543918,0.033751316,0.004613921,0.002368793,0.01948268,0.0,0.0,0.0,0.042967565,0.018202126,0.011418402,0.029352449,0.082919315,0.18845056,0.2214576,0.21877661,0.14959966,0.11014053,0.0,0.076181605,0.470706,0.9130933,0.9581235,0.48663282,0.0,0.0,0.0,0.0,0.009280294,0.032360755,0.01769311,0.01646325,0.025901884,0.0,0.0,0.0,0.053609855,0.015360184,0.06582288,0.09979065,0.16107383,0.2677552,0.29631242,0.23811214,0.13452494,0.10219347,0.0,0.016096182,0.43935728,0.9743312,1.0,0.5267489,0.0,0.0,0.0,0.0,0.027626112,0.06452894,0.027889267,0.02577816,0.031183943,0.0,0.0,0.0,0.054293387,0.0024710894,0.092953,0.13267794,0.19269863,0.2928365,0.31542277,0.24331397,0.14557204,0.14737463,0.0,0.014078043,0.36976364,0.9352304,1.0,0.49703926,0.0,0.0,0.0,0.005298242,0.044418983,0.09629453,0.02484963,0.019228756,0.022287376,0.0,0.0,0.0,0.04478497,0.0,0.11777237,0.1678266,0.24601531,0.36084297,0.36444038,0.2709009,0.14720817,0.13739079,0.0,0.0,0.3397314,0.9487482,1.0,0.48765093,0.0,0.0,0.0,0.016908877,0.055976436,0.10402072,0.015516996,0.009136856,0.019326918],[0.024353355,0.01973927,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030890495,0.036889635,0.3551668,0.64687496,1.0,1.0,0.98851967,0.33427233,0.0,0.0,0.0,0.0,0.0,0.019149542,0.0,0.0,0.057588063,0.0075156987,0.0,0.005950071,0.02845376,0.004605964,0.0,0.0,0.0,0.0,0.0011384636,0.0,0.0,0.0,0.2743138,0.6057069,1.0,1.0,1.0,0.2602655,0.0,0.0,0.0,0.0,0.0,0.044123642,0.0,0.0,0.037540905,0.0,0.0,0.0,0.02590558,0.016856886,0.0,0.0,0.0,0.009351678,0.014570288,0.0,0.0,0.0,0.120803624,0.43390238,1.0,1.0,0.9638933,0.1549799,0.0,0.0,0.0,0.0,0.033407398,0.071290456,0.0,0.0,0.019142471,0.0,0.0,0.0,0.00097458065,0.013781771,0.0,0.0,0.0,0.013880603,0.029763907,0.0,0.0,0.0,0.0,0.24406765,0.83568794,1.0,0.8467738,0.1485247,0.0,0.0,0.0,0.023104556,0.03424053,0.051105894,0.0,0.0115133375,0.028972656,0.014958113,0.0,0.0,0.0,0.0047831237,0.0,0.0,0.0,0.0060376003,0.03387507,0.008108035,0.024560697,0.029219948,0.0,0.1087636,0.4434086,0.7032181,0.72248316,0.47575748,0.19560401,0.052658774,0.0,0.0,0.00087326765,0.0,0.013971806,0.024229452,0.0005016029,0.026533604,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006187737,0.032429233,0.02865465,0.061873026,0.08572137,0.0,0.059861958,0.22857414,0.39904922,0.5960351,0.6183629,0.42874503,0.17342338,0.0,0.0,0.0,0.0,0.020454831,0.03939897,0.0035359561,0.025470458,0.0,0.0,0.0,0.0,0.0026079416,0.0,0.0,0.007799372,0.03553147,0.063200645,0.09684111,0.11791331,0.052174777,0.031277604,0.12202682,0.25705397,0.58625484,0.81922305,0.6693289,0.27954662,0.0,0.0,0.0,0.0,0.004668787,0.05588506,0.010501556,0.027277969,0.0,0.0,0.0,0.0,0.026401564,0.0,0.0,0.031868823,0.053462528,0.1175928,0.18009108,0.1648918,0.11537073,0.040937543,0.07847701,0.16425511,0.53864145,0.9385045,0.84108835,0.3596092,0.0,0.0,0.0,0.0,0.0,0.06902878,0.0007697493,0.032826602,0.0051083416,0.0,0.0,0.007079713,0.03966923,0.0,0.045384496,0.1108875,0.07215753,0.15055509,0.2244635,0.15612997,0.16231726,0.06020034,0.051050216,0.11395652,0.5035415,1.0,0.92008483,0.3924049,0.0,0.0,0.0030366778,0.0,0.027229398,0.10144637,0.0,0.04279939,0.012969345,0.0,0.0,0.009710573,0.036882594,0.0,0.087710634,0.14853014,0.09056088,0.16399203,0.2283119,0.13866079,0.19857454,0.079397015,0.047892347,0.08854568,0.4404229,1.0,0.90098053,0.40474778,0.0,0.0,0.023187205,0.0,0.06245309,0.12143325,0.0,0.045910463,0.0145775005,0.0,0.0,0.0032477677,0.030186497,0.0,0.11277154,0.16909626,0.13187525,0.22057953,0.26583984,0.13798949,0.19975793,0.09988062,0.029920429,0.089508496,0.40981454,1.0,0.9311195,0.4358588,0.0,0.0,0.030416854,0.0,0.06668761,0.102089345,0.0,0.027372107,0.014470771],[0.041151114,0.0203242,0.0,0.0,0.0,0.0,0.008340895,0.056683287,0.0034864098,0.0036146492,0.06441282,0.32685983,0.7090584,1.0,1.0,0.7950998,0.39564437,0.06788765,0.0065684766,0.0,0.0,0.0,0.0,0.0,0.0,0.010361202,0.0,0.0,0.03281054,0.028318599,0.0,0.0,0.0,0.0,0.016612165,0.047995895,0.010860175,0.0,0.012162223,0.25673726,0.6563788,1.0,1.0,0.8331665,0.3036961,0.0,0.0,0.0,0.0026094913,0.0130180195,0.01910524,0.0,0.0,0.012271866,0.0,0.0,0.021332465,0.034667194,0.011189215,0.0,0.0,0.0,0.024508841,0.045637883,0.013376631,0.0,0.0,0.13080302,0.4793514,1.0,1.0,0.86502516,0.24032745,0.0,0.0,0.0,0.023920752,0.05964551,0.039745674,0.0,0.008056596,0.017957404,0.024416968,0.011542454,0.0065367445,0.027871504,0.008858323,0.0075433925,0.0,0.0,0.030135505,0.033563808,0.025522247,0.002820313,0.0,0.022076078,0.23892649,0.74567086,1.0,0.7435088,0.18765885,0.0,0.0,0.0,0.022776969,0.05935546,0.0466685,0.0,0.029037364,0.026326157,0.033713557,0.0035016388,0.00079894066,0.00078733265,0.0,0.0,0.0,0.0,0.027140208,0.016169406,0.030635454,0.054770328,0.03758122,0.0,0.06696273,0.40774745,0.667464,0.6914826,0.41837138,0.13823536,0.0053043813,0.0,0.0,0.03513749,0.033867806,0.0,0.037888326,0.009928666,0.008156374,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028956607,0.025611304,0.04615002,0.09361426,0.0801529,0.0,0.02175641,0.23624825,0.45491993,0.6391277,0.5759046,0.32742745,0.0875774,0.0,0.0,0.027061477,0.03349918,0.009731807,0.04061328,0.009605095,0.0,0.0,0.0030356944,0.0,0.0,0.0,0.0,0.016546354,0.03873054,0.028383777,0.07743865,0.1480543,0.17044213,0.034518197,0.056451418,0.15231177,0.35172027,0.6161275,0.7010234,0.46288633,0.13073099,0.0,0.0,0.016174093,0.026920885,0.022108585,0.0409685,0.020362921,0.0,0.0,0.008349985,0.005087629,0.01020173,0.0,0.0044317693,0.035770677,0.0453867,0.044123538,0.13289407,0.24085444,0.2733637,0.12723684,0.14374052,0.12798806,0.27328247,0.5530569,0.73032373,0.5289352,0.16278301,0.0,0.0,0.0,0.016522117,0.023913547,0.0500784,0.03689088,0.020545408,0.02078905,0.005864188,0.008108221,0.021483228,0.0,0.012024038,0.044894263,0.04654432,0.048118226,0.13949502,0.2858703,0.32923996,0.20863348,0.2299908,0.12842779,0.22107983,0.50838923,0.7425208,0.5424686,0.17055213,0.0,0.0,0.0,0.007691577,0.03349738,0.0637905,0.048808113,0.048459634,0.04095707,0.00010204315,0.0,0.017904855,0.0,0.0070653036,0.045494497,0.06737601,0.08166591,0.16557086,0.3261413,0.37470645,0.2795471,0.2858774,0.1155379,0.15039109,0.4145586,0.72690475,0.5593926,0.20666051,0.0,0.0,0.0,0.0,0.033155985,0.07329004,0.0587141,0.06996346,0.049566433,0.0,0.0,0.000746727,0.0,0.014873296,0.058214292,0.09268451,0.13272701,0.2207137,0.4039802,0.43671829,0.34103206,0.30698973,0.10807217,0.11651264,0.39838016,0.79980886,0.62723786,0.26112413,0.0,0.0,0.0,0.0,0.025681756,0.050125904,0.041300096,0.068420745,0.057400435],[0.052195683,0.033175774,0.014944695,0.0,0.0,0.0,0.056883372,0.0,0.0,0.0,0.0,0.11083093,0.5434262,0.844759,0.8816018,0.67092,0.20317292,0.096248046,0.119724445,0.0023163408,0.018737853,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.048901394,0.028023273,0.016716987,0.0,0.0,0.0,0.05418861,0.0,0.0,0.0,0.0,0.079235435,0.5512472,0.92859715,1.0,0.7307827,0.1520045,0.0,0.04077573,0.0,0.05789031,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.043639883,0.027440965,0.029780336,0.0,0.0,0.0,0.045173407,0.0,0.0,0.0,0.0,0.02870483,0.4402985,0.91017276,1.0,0.7430916,0.12375809,0.0,0.0,0.0,0.09144607,0.021378674,0.035022423,0.0,0.0,0.009462476,0.024918482,0.0,0.027165473,0.0060997084,0.027236626,0.0,0.0,0.0,0.02861289,0.01835554,0.0,0.0,0.0,0.0,0.23172992,0.8010203,1.0,0.634335,0.10238904,0.0,0.0,0.0,0.084944405,0.044573143,0.046829857,0.012030914,0.0,0.041709572,0.046383634,0.0,0.024193302,0.0,0.0018830001,0.0,0.0043417066,0.0,0.025665991,0.03798362,0.023762904,0.028650664,0.041348957,0.024652027,0.1278627,0.5978652,0.7959941,0.6815945,0.28646842,0.062362045,0.0,0.0,0.070576295,0.036422335,0.045162633,0.018455945,0.014423154,0.020684406,0.027823888,0.0,0.02460371,0.0,0.0003412664,0.0,0.012545407,0.0,0.026424699,0.0602597,0.06519176,0.124710746,0.08105757,0.061010897,0.09876085,0.46826953,0.6397126,0.72181344,0.45501894,0.20595768,0.0,0.0,0.051390782,0.046244808,0.05891992,0.03020066,0.029004045,0.016660444,0.015484728,0.0,0.013983376,0.0,0.007743597,0.0,0.007933058,0.008384787,0.022803761,0.058794193,0.09984791,0.2584955,0.214899,0.18397856,0.1948623,0.42701292,0.5539737,0.7413827,0.57573944,0.2702334,0.008893505,0.0,0.021015704,0.07454229,0.08102984,0.037863538,0.04542727,0.022492401,0.038374446,0.010431275,0.0021479279,0.0,0.01898022,0.0,0.0,0.032159314,0.017441161,0.06805869,0.14307198,0.4031731,0.367858,0.343551,0.31766528,0.41711235,0.45828766,0.6956279,0.62769943,0.32112172,0.045811407,0.0,0.007935651,0.081608586,0.1079365,0.058984034,0.06077171,0.036546215,0.078495435,0.03971681,0.0,0.0,0.021345966,0.0,0.0,0.037786677,0.01801899,0.08362074,0.16081543,0.4916166,0.48357183,0.46563083,0.41554725,0.4075532,0.3737356,0.64984345,0.6774323,0.3631554,0.06415287,0.0,0.0062887073,0.08622302,0.13793762,0.082374185,0.07005359,0.051127203,0.12410047,0.07328418,0.0,0.0,0.018268712,0.0,0.0,0.05174472,0.075105764,0.15857017,0.21607451,0.5489356,0.5526123,0.53304446,0.46213317,0.3534152,0.24645889,0.57220304,0.7165887,0.42787486,0.12494863,0.017560445,0.0012187511,0.09358585,0.1483879,0.09539729,0.06846134,0.06152267,0.14917612,0.091957465,0.0,0.0,0.0042879432,0.0,0.0,0.069654286,0.1252245,0.23949856,0.29143167,0.63343245,0.6140784,0.57593536,0.4899432,0.3195455,0.16589841,0.57592684,0.8274582,0.5224677,0.18962583,0.04498931,0.0,0.09868336,0.1474431,0.08871178,0.05185455,0.04414665,0.15405512,0.10807922],[0.005601287,0.05589713,0.03333454,0.0,0.0,0.06060207,0.044339724,0.0,0.0,0.0,0.0,0.0598668,0.34122786,0.6417159,0.6931946,0.5403269,0.30792248,0.17696233,0.14473829,0.04320789,0.0,0.0,0.0,0.0,0.0,0.036870226,0.0025666207,0.0,0.0071188286,0.046417676,0.027298793,0.0,0.0,0.050203912,0.042790033,0.0,0.0,0.0,0.0,0.04049409,0.35377827,0.8131637,0.91087955,0.7080787,0.27226853,0.046915412,0.055436708,0.028662108,0.020929106,0.0,0.0,0.0,0.0,0.03836812,0.0010393113,0.0,0.007558875,0.042778395,0.042836025,0.007292703,0.0,0.04568354,0.04728441,0.0,0.0,0.0,0.0,0.0,0.29964948,0.92358667,1.0,0.8032402,0.23344183,0.0,0.0089586,0.02308105,0.06538016,0.041321263,0.021151386,0.0,0.0,0.03643977,0.013207726,0.0,0.0011628419,0.018434726,0.03627433,0.015315682,0.004844457,0.017848738,0.048278593,0.0,0.0,0.0,0.0,0.0,0.20592237,0.80543107,0.960437,0.62685037,0.13035095,0.0,0.006794706,0.034773335,0.07505879,0.059247166,0.05178521,0.0,0.0,0.030765906,0.014924757,0.0,0.0012941062,0.011958189,0.019978017,0.0,0.0,0.0,0.03782732,0.0,0.037438534,0.022320949,0.0,0.012846984,0.17685845,0.5669743,0.75616163,0.5365007,0.20748296,0.0442466,0.034547687,0.032159574,0.058514766,0.056984715,0.065488294,0.014111087,0.014467843,0.024710238,0.0,0.0,0.0053685457,0.017509237,0.017112128,0.0,0.0,0.0,0.038534224,0.0,0.07360816,0.07656214,0.06861746,0.0668517,0.18790978,0.44171453,0.6379001,0.52067775,0.33275303,0.14366734,0.06357557,0.026365586,0.058060937,0.06349366,0.073211424,0.03871832,0.04260561,0.040433556,0.0,0.0,0.00886295,0.015488394,0.014899045,0.005421087,0.0,0.0,0.026881061,0.0,0.12598887,0.20831883,0.2993898,0.28122973,0.3604673,0.4375497,0.55678856,0.41789973,0.35543987,0.18703777,0.0804183,0.022803016,0.05960597,0.07242988,0.08331328,0.07009818,0.08031915,0.09211376,0.026152387,0.0,0.013566025,0.002828315,0.0020690262,0.0130752325,0.0,0.0,0.016885497,0.03911463,0.23799273,0.39586478,0.54380286,0.4966401,0.5141655,0.43022114,0.461344,0.2856767,0.32572585,0.2107614,0.10042501,0.024392687,0.0658283,0.07383776,0.08893375,0.097222164,0.13497718,0.1484985,0.0662079,0.018322736,0.0072121844,0.0,0.0,0.0,0.0,0.0027992576,0.031931214,0.08808285,0.3368196,0.5270447,0.7134263,0.6486713,0.62594444,0.42431337,0.37876588,0.20769635,0.32999516,0.25835317,0.14020698,0.02004575,0.070531905,0.0778951,0.096869074,0.11650149,0.18435888,0.20455927,0.112525865,0.051098213,0.0013650805,0.0,0.0,0.0,0.0,0.04499598,0.120443165,0.20055106,0.45870316,0.64922255,0.8510098,0.74059755,0.6795462,0.4391786,0.33630675,0.19982894,0.3989367,0.37109685,0.22475305,0.03524214,0.092794955,0.07040231,0.096916154,0.11208199,0.19594769,0.21721318,0.13174638,0.06667365,0.0,0.0,0.0,0.0,0.0,0.08227365,0.18576285,0.3042735,0.58884233,0.78542364,0.9698719,0.7871359,0.700026,0.4827369,0.3463114,0.24317521,0.51287365,0.49904746,0.32147518,0.079130776,0.12868427,0.082037434,0.099989936,0.092279896,0.18413353,0.22105291,0.146481,0.081075944],[0.017785959,0.0,0.018322952,0.0,0.0,0.07789293,0.08154604,0.012926713,0.0,0.0,0.0,0.028392702,0.2769255,0.5716343,0.57124394,0.45243102,0.26139957,0.23216388,0.23428005,0.078731656,0.032939322,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022082701,0.0,0.016150586,0.0,0.0,0.062437564,0.055609807,0.009764224,0.0,0.0,0.0,0.04719852,0.34534788,0.7703016,0.8314437,0.60557914,0.22366245,0.075247854,0.1129508,0.023357257,0.03046842,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02729845,0.0,0.026599988,0.0052345395,0.0,0.04781215,0.052012198,0.00042536855,0.0,0.0,0.0,0.014947496,0.36546052,0.9332783,1.0,0.6931132,0.17948383,0.0,0.06817414,0.0,0.03200025,0.0,0.0,0.0,0.0,0.0022106916,0.0034852326,0.0,0.028775997,0.0,0.020975769,0.011066616,0.0,0.027501538,0.052057475,0.0,0.0,0.0,0.0,0.0,0.3397423,0.88074434,0.9193262,0.5093395,0.08494485,0.0,0.04154662,0.0,0.004559189,0.0,0.0,0.0,0.0,0.0049939007,0.018300392,0.0,0.031103224,0.0,0.009530418,0.0,0.0,0.0012414306,0.032814704,0.0023689717,0.0009200722,0.0,0.0,0.0,0.2834711,0.66461277,0.72040284,0.4405806,0.11038591,0.019476607,0.009065174,0.0,0.0,0.022273347,0.034923986,0.000081807375,0.016363889,0.0,0.02193556,0.0,0.031693093,0.0,0.008891381,0.0,0.0,0.0,0.030509919,0.010134213,0.0073719993,0.013988517,0.018542863,0.043033145,0.25069317,0.5364013,0.60238296,0.4502313,0.21374872,0.06594603,0.0,0.0,0.0,0.025346644,0.04649248,0.023842148,0.050604515,0.011990942,0.010957383,0.0,0.02764269,0.0,0.017029762,0.0,0.0,0.0,0.024751335,0.013733543,0.0373869,0.14082702,0.22878599,0.29353148,0.38321972,0.51541287,0.50102806,0.3501661,0.2335988,0.08819367,0.0,0.028776884,0.01216428,0.010853767,0.043302417,0.049596064,0.08772579,0.06692699,0.032044165,0.0,0.02402582,0.0,0.013054013,0.0,0.049038477,0.0,0.03785848,0.048852473,0.1444675,0.3475086,0.4742629,0.5231958,0.48159564,0.47289908,0.3761253,0.2146486,0.19346344,0.10713722,0.023445748,0.062756605,0.026268698,0.007558197,0.05337303,0.078106835,0.13701046,0.12108255,0.060284354,0.0021318048,0.015995018,0.0,0.0056435764,0.0,0.08081022,0.024929658,0.08369808,0.10510578,0.24775799,0.50485104,0.664524,0.7066528,0.5600457,0.44144934,0.29322487,0.13538444,0.2033799,0.18636148,0.0841364,0.09226787,0.044071034,0.011212826,0.07576613,0.100886874,0.17909703,0.18080474,0.08596501,0.02183783,0.0028716177,0.0,0.0,0.0,0.08555332,0.053872824,0.14669994,0.21065858,0.36063105,0.66521245,0.83062786,0.85619336,0.6516178,0.45873606,0.28062192,0.14560175,0.2742325,0.3261469,0.18341842,0.14126307,0.060830206,0.02474165,0.107705496,0.10902546,0.19659907,0.2016471,0.07566857,0.031083025,0.0,0.0,0.0,0.0,0.08276585,0.06419006,0.1879153,0.31835097,0.4892689,0.8330387,0.98373765,0.9640201,0.7279912,0.5130692,0.3215427,0.19493935,0.37977156,0.47401512,0.31621233,0.22882915,0.11195922,0.05737915,0.14337817,0.113073915,0.20885068,0.22061089,0.08081956,0.045122415],[0.011618979,0.0,0.0195973,0.015449129,0.039012536,0.04757624,0.04911656,0.0,0.02233418,0.0,0.03331402,0.089267075,0.25843823,0.31882244,0.29708055,0.16635065,0.24875918,0.29611522,0.2541951,0.11196454,0.041349,0.0,0.0,0.015067756,0.0,0.0,0.0,0.0,0.011007212,0.0,0.022471294,0.015640795,0.043642372,0.047504522,0.047860466,0.0,0.038153738,0.0,0.017899156,0.1460824,0.41829258,0.64029807,0.7025189,0.47736853,0.27370095,0.1689553,0.08599308,0.0,0.0,0.0,0.0,0.02886428,0.0,0.0,0.0,0.0,0.010259345,0.0,0.043958932,0.017532282,0.042488694,0.043966755,0.033913672,0.0,0.025037088,0.0,0.00032413006,0.17892624,0.5264868,0.876732,0.97628194,0.6361638,0.18563107,0.042661548,0.016274631,0.0,0.0,0.0,0.0,0.02114302,0.0,0.0,0.0,0.0017769784,0.007782683,0.0,0.039298065,0.007155925,0.017960168,0.042425863,0.033546224,0.0,0.027446538,0.0,0.0,0.13603413,0.48890787,0.8453811,0.8714205,0.4648792,0.045112588,0.0,0.0,0.0,0.0,0.017677508,0.009440415,0.017322086,0.0,0.0036112666,0.006707579,0.004772231,0.007447824,0.0066161156,0.03454289,0.007997796,0.0,0.023440577,0.019449942,0.0031489134,0.027356125,0.0,0.0,0.08687726,0.39094168,0.7080573,0.72833043,0.3889656,0.053579673,0.0,0.0,0.014174603,0.03410896,0.044810027,0.042768903,0.024927273,0.0,0.0038212836,0.0,0.0,0.007201284,0.0023254305,0.020933792,0.003991887,0.0,0.01471211,0.018243402,0.002570808,0.02018556,0.0,0.0,0.06743667,0.29040566,0.5484194,0.63630605,0.38885808,0.10813643,0.011581443,0.0,0.031436197,0.053728573,0.050573595,0.05223871,0.0348223,0.011609577,0.0069543496,0.0,0.0,0.0044142157,0.0,0.026686862,0.004607767,0.0,0.0,0.0077245533,0.0,0.032374844,0.06725634,0.17876796,0.28797513,0.3621066,0.35131532,0.38030016,0.20056888,0.095667765,0.021799728,0.0,0.0551956,0.092831835,0.071293235,0.07222141,0.052763678,0.04816766,0.040738888,0.0,0.0048814565,0.0027254075,0.0,0.02881831,0.02149035,0.0022075921,0.0,0.011356421,0.013711445,0.113402456,0.20381306,0.37199318,0.48043042,0.41456956,0.17514332,0.1639015,0.0639885,0.08729409,0.05447387,0.0,0.07928938,0.13275008,0.094497815,0.103090525,0.09791702,0.10772121,0.09790166,0.027425908,0.026953481,0.010689549,0.0,0.025583826,0.04003471,0.026231855,0.009071544,0.024270795,0.05917205,0.22211498,0.36090496,0.57607365,0.7070965,0.49831527,0.101378694,0.060798608,0.014619529,0.14446852,0.17799656,0.07872705,0.14196777,0.1859915,0.1242276,0.14319898,0.15855071,0.17799702,0.1655347,0.06982453,0.051597595,0.020227648,0.0012299567,0.02315659,0.040582262,0.02841691,0.033281505,0.047599167,0.09711802,0.3056525,0.52546024,0.78704333,0.9530179,0.6042082,0.1454286,0.061871678,0.062790066,0.28267348,0.41533363,0.2900151,0.2599204,0.24763921,0.16672094,0.1948146,0.18099576,0.21204802,0.1812763,0.08367655,0.062576495,0.024200998,0.007670015,0.019845605,0.04320643,0.033877254,0.053045742,0.069718465,0.14114073,0.39702398,0.68413395,0.95806897,1.0,0.7096756,0.22470072,0.107924365,0.15352425,0.4527278,0.65748274,0.5213895,0.41345942,0.3228223,0.22300495,0.23241597,0.20409806,0.23336807,0.18975674,0.09650397,0.07917966],[0.0,0.0018346608,0.020597033,0.046901412,0.05114916,0.028077975,0.0,0.07818341,0.017904207,0.028240219,0.16605431,0.19847544,0.32196665,0.33131814,0.26585948,0.22308877,0.26677746,0.4261003,0.30493093,0.19929396,0.014282852,0.0,0.0,0.04768639,0.0,0.024149746,0.0,0.0,0.0,0.0,0.023441814,0.048858993,0.044647947,0.036393315,0.015976578,0.08343747,0.0025698096,0.0,0.15837964,0.25805756,0.48632276,0.68309826,0.6464351,0.509077,0.2683372,0.28525954,0.12810442,0.02187363,0.0,0.0,0.0,0.03702601,0.023660615,0.0037694126,0.0,0.0035644025,0.0,0.007952325,0.016585276,0.037833497,0.031138092,0.024491385,0.03239567,0.07281348,0.0,0.0,0.11188311,0.28609645,0.6029496,0.97062254,0.89250684,0.56860185,0.123064145,0.094719686,0.04563245,0.0,0.0,0.0,0.009608485,0.011610903,0.022872426,0.0014599115,0.0,0.0012489408,0.0,0.011491716,0.0,0.004327148,0.0,0.027328938,0.02442903,0.07437405,0.0,0.0,0.045577116,0.17438954,0.5579188,0.95128244,0.7939856,0.3554025,0.0,0.0,0.0,0.0,0.01904399,0.0,0.017695181,0.0,0.023595057,0.009975493,0.010355569,0.008212566,0.0061520413,0.013033479,0.0,0.013337754,0.0,0.021749325,0.019326374,0.055421755,0.0028021634,0.0,0.0,0.09569554,0.45025104,0.7859834,0.6722256,0.2963546,0.0,0.0,0.0,0.03932684,0.049382433,0.010286108,0.0110607,0.0,0.027402595,0.0018738061,0.026195318,0.0016191304,0.006997809,0.0027229637,0.0,0.014522307,0.0,0.024570249,0.02182085,0.035601653,0.0,0.0,0.0,0.050598755,0.3139267,0.577129,0.5825873,0.31089425,0.037838966,0.0,0.0,0.056201264,0.06788356,0.016786449,0.0068029985,0.0,0.033302516,0.0,0.016040191,0.004966438,0.007013507,0.013354063,0.0,0.024260737,0.0,0.0,0.0040007085,0.018582895,0.0022125691,0.043385148,0.17302197,0.22944027,0.27362227,0.25973582,0.29070696,0.15925677,0.07176511,0.0,0.0,0.108829394,0.11514987,0.061869144,0.028671786,0.021075174,0.065437295,0.009100877,0.028074302,0.03100653,0.008606009,0.026380502,0.0,0.04552836,0.020471372,0.0,0.0,0.014710128,0.040271126,0.12613437,0.34846717,0.38902658,0.22612752,0.02302511,0.058600217,0.089744255,0.13619635,0.032395735,0.0668671,0.16735265,0.15558943,0.11411182,0.08011535,0.09005993,0.14117754,0.070308,0.052819513,0.058265552,0.017918669,0.04253511,0.0,0.063988194,0.06014073,0.0,0.0,0.055749625,0.097815916,0.21970391,0.5500285,0.59605455,0.24681148,0.0,0.0,0.06091602,0.21790645,0.17303701,0.22041333,0.27579,0.21839938,0.18120182,0.15860145,0.18428253,0.23558414,0.14452122,0.08703336,0.08770962,0.025036871,0.054735146,0.0,0.0546856,0.073232524,0.0,0.0,0.10275489,0.14233564,0.324804,0.755381,0.8108283,0.3466802,0.0,0.0,0.1131539,0.39440745,0.46839225,0.49460042,0.45034128,0.32642353,0.27211392,0.2294014,0.24717343,0.27512926,0.16934243,0.09783895,0.10309746,0.03182228,0.06810776,0.0,0.04755844,0.08323766,0.0,0.0,0.14459471,0.2047192,0.43486768,0.92040133,0.9877612,0.457496,0.07925345,0.0,0.22051361,0.6105265,0.77680147,0.7850544,0.6501836,0.43196625,0.3499443,0.28229666,0.2890453,0.29568022,0.17480513,0.104816504,0.12166116],[0.0020139664,0.0,0.0,0.0,0.016243257,0.0,0.023488872,0.010938525,0.037298083,0.12287773,0.13041592,0.26302007,0.31926292,0.33033907,0.31242627,0.3657496,0.54760426,0.53881747,0.3766749,0.08681812,0.0,0.0,0.003906876,0.07570404,0.12906569,0.09595515,0.06301592,0.0019922107,0.0,0.0,0.0,0.0045642853,0.017386697,0.0,0.023294188,0.032113954,0.056465507,0.082387626,0.13195193,0.3427958,0.5471239,0.73854274,0.7336182,0.63865244,0.52725834,0.32144582,0.12858674,0.0,0.0,0.0,0.024172075,0.06445956,0.09083183,0.06045594,0.05367253,0.0055797547,0.0,0.0,0.0,0.0,0.0021473765,0.0,0.015996166,0.041029304,0.05745952,0.01050999,0.08289258,0.36274213,0.673269,0.9898443,0.9643014,0.61671084,0.24395669,0.05079715,0.0030196607,0.0,0.0,0.0,0.015557215,0.032244146,0.047498286,0.0396934,0.05307825,0.01346834,0.0,0.0,0.0,0.0,0.0,0.0,0.0476093,0.058669724,0.034312166,0.0,0.010447361,0.25606483,0.6183196,0.909359,0.76790124,0.25073028,0.013324186,0.0,0.002546817,0.0,0.0,0.0,0.007664405,0.0,0.01976297,0.034244798,0.057095766,0.022419475,0.0,0.0,0.0063285083,0.008768007,0.0,0.0045383126,0.044925123,0.038899034,0.010535151,0.0,0.0,0.19216415,0.5315312,0.74153423,0.54623234,0.060899183,0.0,0.0,0.0044547766,0.034512177,0.032264866,0.014693499,0.012122199,0.0,0.0,0.0067333654,0.024660341,0.014067836,0.0001603812,0.0,0.017966248,0.014694482,0.0,0.015163019,0.049289517,0.022854723,0.0,0.0,0.0,0.09261763,0.34464234,0.5397971,0.44938678,0.055256754,0.0,0.0,0.010189213,0.04133346,0.046198174,0.021024004,0.018621713,0.0,0.0,0.0,0.0055660605,0.009126395,0.007513158,0.018146113,0.04339741,0.029654078,0.0,0.033597335,0.04207471,0.0,0.012927525,0.0,0.095951304,0.14092444,0.1410939,0.1239102,0.09993236,0.0,0.0,0.0,0.059573337,0.072374135,0.076103106,0.01896967,0.023210324,0.0,0.0,0.008081615,0.021449275,0.021209419,0.015111588,0.037602983,0.07068516,0.041222885,0.0,0.0417881,0.034044273,0.0,0.01958301,0.07117206,0.2434735,0.21462841,0.020132191,0.0,0.0,0.0,0.022093222,0.010061115,0.12259281,0.1201356,0.10457012,0.03244693,0.052184112,0.016786985,0.028047264,0.047601536,0.051299416,0.034264974,0.03244777,0.060963966,0.09413247,0.043557033,0.0,0.042788066,0.032741576,0.0,0.050504506,0.22542861,0.44140625,0.33803484,0.0,0.0,0.0,0.0,0.1277172,0.18709311,0.29468966,0.2075679,0.16517885,0.099159695,0.14112043,0.10293592,0.0895015,0.095581815,0.090269014,0.05176776,0.048951432,0.07359981,0.10556002,0.035625704,0.0,0.0343588,0.03458053,0.0,0.0823116,0.37834713,0.65141493,0.5130579,0.06229896,0.0,0.0,0.10313391,0.37582833,0.5474182,0.62924296,0.43076867,0.28315905,0.1901987,0.222372,0.18097675,0.15021953,0.14216827,0.11953445,0.05895152,0.065247126,0.08638079,0.115965925,0.035584927,0.0,0.03079988,0.034754634,0.0,0.114553966,0.50246817,0.8345461,0.66082805,0.1526508,0.0,0.023408107,0.2685006,0.6521635,0.90838253,0.9743283,0.67246974,0.39565247,0.23852915,0.25208455,0.21381985,0.16987401,0.16037528,0.13654438,0.06890335],[0.0,0.0,0.013638228,0.021253936,0.018550746,0.10184547,0.070180185,0.030013815,0.08638451,0.13396978,0.19731688,0.27295703,0.3586356,0.4387337,0.46534103,0.5164852,0.6552779,0.5302137,0.22485189,0.0,0.0,0.0,0.05729261,0.04990597,0.07658424,0.04031056,0.05050031,0.0,0.0,0.0,0.008913711,0.026171796,0.034115218,0.07549934,0.033764794,0.016365625,0.03494998,0.09696382,0.1603123,0.33848578,0.56262016,0.75408316,0.79205656,0.6643963,0.54654443,0.3095224,0.048260726,0.0,0.0,0.0,0.05860705,0.042018265,0.06879543,0.024912737,0.042851485,0.0,0.0,0.0,0.0,0.00538224,0.025809199,0.05051638,0.006537199,0.016095549,0.0,0.03091047,0.11187964,0.3663483,0.66018814,0.93184483,0.89108664,0.5246548,0.19119015,0.08461362,0.0014574826,0.0,0.0,0.0,0.030640714,0.029722013,0.067653,0.015712522,0.045664333,0.0,0.0,0.0,0.0,0.0,0.0105484575,0.051895432,0.01782956,0.017201297,0.0,0.0,0.0356856,0.23589316,0.60291684,0.8512604,0.6468161,0.18365903,0.0,0.03452594,0.034998134,0.0037036836,0.0,0.0,0.0,0.00017808378,0.047662906,0.007662736,0.04291153,0.0006542951,0.0,0.0,0.004984513,0.0,0.0,0.03852406,0.004915595,0.0045134723,0.0,0.0,0.030306913,0.19368866,0.5385808,0.70444125,0.42839742,0.0021531582,0.0,0.009036966,0.04475464,0.021336816,0.014846593,0.0,0.0,0.0,0.010866381,0.0,0.008223675,0.0,0.0,0.0,0.007309139,0.0,0.0,0.032296397,0.0,0.0037887096,0.0,0.0,0.0,0.07785761,0.36761087,0.5480776,0.3496555,0.00547719,0.0,0.0030945241,0.043324202,0.021006592,0.014159702,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0113814175,0.0,0.0,0.006528385,0.0,0.014496386,0.03058128,0.036121666,0.10755573,0.059001252,0.103766955,0.175904,0.067379266,0.0,0.0,0.02453342,0.07097767,0.049544998,0.034675628,0.0,0.0,0.0,0.0,0.0,0.00016400218,0.0,0.0,0.010515131,0.020249136,0.0,0.0,0.0,0.0,0.03503295,0.06841959,0.11689328,0.21731733,0.07304936,0.0,0.0,0.0,0.0,0.0,0.037145287,0.116214916,0.096450664,0.072638474,0.025906786,0.031669267,0.0,0.00891044,0.018059902,0.012454547,0.0,0.0,0.032962464,0.03120298,0.0,0.0,0.0,0.0,0.059626684,0.121362135,0.24481435,0.35700458,0.116421126,0.0,0.0,0.0,0.0,0.11416341,0.20565666,0.26491344,0.17548932,0.1594793,0.12030645,0.1367711,0.061729185,0.052621007,0.050398745,0.026420772,0.0,0.0,0.04760795,0.03441614,0.0,0.0,0.0,0.0,0.053941727,0.13329095,0.32056266,0.4623314,0.22106619,0.0,0.0,0.0,0.060498692,0.35637957,0.5663172,0.5723015,0.3891071,0.29382393,0.22880736,0.22202444,0.14433537,0.1081988,0.09096673,0.0424843,0.0,0.0011654645,0.055299774,0.029831044,0.0,0.0,0.0,0.0,0.045908548,0.14933595,0.38089275,0.55432945,0.3123463,0.0,0.0,0.0,0.17671615,0.6381284,0.9486927,0.904007,0.6183353,0.4034866,0.29452157,0.24782655,0.18570338,0.1352915,0.1063696,0.047612496,0.0],[0.0019559562,0.0,0.0,0.0,0.037653647,0.017475903,0.033258647,0.020615935,0.13440223,0.18842264,0.32815966,0.4232779,0.51305073,0.56993836,0.6329548,0.70693094,0.75270027,0.44895393,0.18609104,0.0,0.0,0.0005660206,0.027152784,0.055958323,0.0639179,0.022502936,0.0,0.0,0.0,0.0,0.0,0.0,0.02780521,0.0,0.0,0.0,0.052684642,0.08341083,0.263959,0.4148484,0.57148606,0.75222653,0.8075782,0.77952594,0.62660176,0.29337984,0.07357669,0.0,0.0,0.0045532137,0.028492361,0.046609245,0.044448555,0.0014286637,0.0,0.0,0.0035947412,0.0,0.0,0.0,0.010767393,0.0,0.0,0.0,0.013867743,0.032072477,0.20420128,0.3494227,0.5913256,0.8142164,0.83059984,0.5893869,0.31896418,0.07821861,0.006452866,0.0,0.0,0.012219682,0.023392662,0.028069526,0.014181763,0.0,0.0,0.0,0.01375062,0.009979948,0.0,0.0,0.0036815703,0.017388701,0.02117315,0.0004977137,0.0,0.00026777387,0.07350488,0.21135524,0.5341066,0.6848864,0.6033446,0.326667,0.16105822,0.020588577,0.0,0.0,0.00067031384,0.018004641,0.010503046,0.0020876825,0.0,0.0,0.0,0.0,0.015893169,0.023949511,0.0,0.013360828,0.0,0.017299801,0.025096484,0.017344221,0.0,0.009907588,0.05658453,0.22620532,0.53828293,0.56470424,0.3215698,0.035203874,0.0,0.0,0.0,0.01854299,0.01370728,0.024896368,0.0002478212,0.0015922934,0.0,0.0,0.0,0.0,0.013816267,0.019706145,0.0,0.016551547,0.0,0.0010689348,0.022518113,0.013584606,0.0,0.02539564,0.022688307,0.12729181,0.39227176,0.44082642,0.25493586,0.011736497,0.0,0.0,0.0,0.026799917,0.02666679,0.033379443,0.010620415,0.00038181245,0.0,0.0,0.0,0.0,0.0138902515,0.01553607,0.0,0.009565115,0.0,0.0,0.0,0.01708448,0.048689306,0.10285095,0.1161198,0.06390136,0.10259911,0.060217485,0.040769346,0.015033305,0.0,0.0,0.026784211,0.043202847,0.0527678,0.06144175,0.031617574,0.0,0.0,0.0,0.0,0.0,0.015391789,0.012941614,0.0,0.0004387051,0.0,0.0,0.0,0.02566152,0.09445091,0.16981114,0.15731227,0.03342583,0.0,0.0,0.0,0.07058486,0.055379413,0.05140066,0.08810578,0.058216646,0.0649935,0.09920355,0.054301903,0.0,0.0,0.0,0.0,0.0,0.030352801,0.03432118,0.0,0.006100826,0.0,0.0,0.0,0.04559931,0.12578356,0.2190248,0.20591967,0.05151672,0.0,0.0,0.0,0.15332817,0.20782757,0.19380552,0.22304823,0.12654665,0.10966926,0.17659256,0.111183226,0.01259876,0.0,0.0,0.0,0.0,0.03510517,0.05133003,0.0,0.011834472,0.0,0.0,0.008407868,0.0626937,0.13232076,0.2517088,0.24166013,0.061478578,0.0,0.0,0.0,0.28599542,0.44101828,0.43591654,0.45639497,0.3084175,0.1979112,0.24073958,0.16262078,0.071285814,0.032760568,0.020704076,0.0,0.0,0.036223046,0.061408907,0.0052787364,0.016207643,0.009462528,0.0,0.013689727,0.08304335,0.15565857,0.29658374,0.2667817,0.06653354,0.0,0.0,0.0,0.40719968,0.6721175,0.694181,0.695986,0.48142105,0.27570754,0.27635527,0.18727414,0.110298306,0.062747374,0.029518269,0.0,0.0],[0.0,0.0,0.0011395663,0.0,0.027475886,0.0,0.024181105,0.0739647,0.2073577,0.39543974,0.537889,0.6306464,0.76490015,0.74391705,0.838575,0.8736139,0.65803045,0.31985116,0.026282333,0.0,0.0,0.02238588,0.026440151,0.021311782,0.008184753,0.0,0.018534929,0.008234456,0.0,0.0,0.0064936057,0.0,0.023863152,0.0,0.0,0.011682689,0.09414521,0.24350253,0.39829284,0.5479958,0.753338,0.8194451,0.93140733,0.8408934,0.49918693,0.18364814,0.0,0.0,0.0,0.007682793,0.0013575256,0.019571543,0.0,0.0,0.0031314492,0.015608892,0.0,0.0,0.0015366077,0.0,0.009439439,0.0,0.0,0.0,0.04751616,0.10793496,0.2354514,0.38764548,0.66469324,0.8128972,0.83906037,0.62382996,0.24109906,0.06052146,0.0,0.0,0.0,0.0,0.0,0.002327174,0.0030375123,0.0,0.0,0.01639364,0.00096955895,0.0,0.0,0.0,0.0,0.0103486255,0.025482103,0.0,0.023548178,0.013147853,0.04663886,0.22765589,0.5423897,0.64063936,0.5464231,0.4044866,0.13299085,0.028001122,0.0054014474,0.0,0.017712392,0.014179066,0.0,0.0,0.023014814,0.0031499863,0.0,0.019260481,0.017539777,0.017508015,0.0,0.0,0.0,0.01959128,0.02950973,0.023149207,0.02271521,0.012638383,0.07040223,0.2879322,0.58666855,0.5016395,0.20467877,0.103490934,0.030136064,0.028167374,0.05436202,0.0,0.025689848,0.019701377,0.0017312318,0.0,0.03132359,0.01292067,0.0,0.010538869,0.023770414,0.015571959,0.0,0.0074948817,0.0,0.020941556,0.026635759,0.03974302,0.042131357,0.01220955,0.027134076,0.17539433,0.4499411,0.38800716,0.15241042,0.08071172,0.01799237,0.027472503,0.0608064,0.0,0.030830309,0.03222984,0.013412498,0.0,0.032684945,0.009678118,0.0,0.003947392,0.036569282,0.011894621,0.0,0.00573352,0.0,0.001785636,0.039598048,0.078751296,0.13324098,0.124541186,0.11930705,0.08627933,0.1716542,0.037725344,0.039204285,0.10482163,0.10295913,0.0645827,0.055969916,0.01703374,0.033538252,0.063744746,0.028597645,0.012057796,0.021782078,0.0,0.0,0.002602592,0.044735678,0.0,0.0,0.012106985,0.0,0.0,0.07611081,0.09211454,0.18834421,0.18183918,0.15015891,0.0,0.027446464,0.0,0.013070241,0.17291962,0.17843212,0.13382004,0.06421238,0.019582681,0.02863571,0.08986048,0.052954637,0.030581564,0.012672551,0.0,0.0,0.00004656613,0.06692942,0.020470828,0.0,0.032522008,0.0,0.0,0.11883881,0.112546094,0.22464123,0.22277583,0.18709365,0.0,0.0,0.0,0.03113196,0.23372614,0.28580502,0.2449989,0.14498128,0.07072812,0.08866402,0.14452577,0.110231586,0.052356094,0.0,0.0,0.0,0.0,0.071508646,0.044159062,0.0,0.04059539,0.0,0.0,0.14040577,0.12610036,0.23142043,0.23891135,0.18322702,0.0,0.0,0.0,0.034786195,0.2912229,0.39677346,0.34393007,0.25926584,0.16050892,0.11193964,0.1834769,0.1400339,0.07228257,0.0,0.0,0.0,0.0,0.06828442,0.054818854,0.0,0.04677484,0.0,0.0,0.15991007,0.13868205,0.24258173,0.25501418,0.17398475,0.0,0.0,0.0,0.04676979,0.33647287,0.5175631,0.45996702,0.38434064,0.25754088,0.12224603,0.20300403,0.15270449,0.09759933,0.015030071,0.0007723719,0.0,0.0],[0.0,0.0,0.0,0.006609425,0.036817126,0.019892529,0.009870432,0.090518326,0.21719918,0.3673283,0.52204823,0.58384347,0.6104766,0.6416806,0.65781856,0.5367112,0.39967734,0.16595921,0.012930073,0.0,0.0,0.08383344,0.03633018,0.002016157,0.0,0.006701231,0.014520355,0.010673642,0.0,0.0,0.0,0.0,0.032903127,0.011624232,0.0,0.006403759,0.094959915,0.23980525,0.39847487,0.4769889,0.55947363,0.649179,0.71278673,0.531691,0.33072996,0.10530516,0.0,0.0,0.0,0.07903127,0.027904212,0.0,0.0,0.0,0.0,0.0176114,0.0,0.0,0.0,0.0,0.0042369813,0.0,0.0,0.0,0.0,0.053546317,0.20877132,0.3150053,0.4917451,0.61861056,0.6745453,0.4270966,0.19682217,0.016644612,0.0,0.0,0.0,0.076329365,0.0261828,0.0,0.0,0.0,0.0,0.00688082,0.0,0.0,0.0038645715,0.012969278,0.0068539083,0.0,0.0,0.0,0.0,0.0,0.055531472,0.16511296,0.39491338,0.49382257,0.47592193,0.26240838,0.09171614,0.0023692101,0.006601788,0.0,0.0,0.06390482,0.018258952,0.0,0.010590553,0.0,0.018159978,0.007767491,0.0,0.008822329,0.02865813,0.026752539,0.01312685,0.012141243,0.011343658,0.0,0.0,0.0,0.10545975,0.2758115,0.49800652,0.38213617,0.20829332,0.04233037,0.0,0.00037615,0.0044867545,0.0,0.006237954,0.039024003,0.0,0.001071766,0.030604519,0.027897581,0.04223109,0.0075640455,0.0,0.014853351,0.037644543,0.029314928,0.015947767,0.017572507,0.031644024,0.0,0.0,0.0,0.060815603,0.20040652,0.40934986,0.31344748,0.18552077,0.0479206,0.0,0.0,0.0,0.0,0.01581224,0.039555907,0.0,0.006582074,0.029201552,0.03265143,0.038393274,0.0028525442,0.0,0.013136283,0.0348391,0.02412723,0.025262795,0.02268669,0.07091662,0.024121776,0.048817977,0.02372963,0.10026241,0.08434641,0.13316414,0.07002562,0.117493026,0.0744815,0.057647705,0.06584339,0.04112169,0.0,0.011703394,0.027680308,0.0,0.0,0.015906207,0.028775394,0.018067665,0.0,0.0,0.0149321705,0.040779494,0.03326522,0.028771505,0.00042711198,0.088405766,0.051819496,0.101234056,0.021341138,0.063310735,0.011734255,0.008936256,0.0,0.11788387,0.09875013,0.13591711,0.13827497,0.092515215,0.0063435882,0.0080075115,0.0039149374,0.0,0.0,0.00053294003,0.018135421,0.0,0.0,0.019849412,0.025334135,0.04859455,0.026956804,0.0292935,0.012022592,0.12395227,0.094058976,0.14004458,0.017171085,0.056271613,0.026044354,0.0,0.0,0.091618136,0.10075441,0.1894888,0.19913335,0.18928595,0.087654874,0.031709515,0.0,0.0,0.0,0.0,0.000328362,0.0,0.0,0.0326296,0.038226448,0.054496966,0.017333113,0.027684115,0.018539555,0.14794661,0.13702717,0.1697523,0.008410238,0.028831244,0.013683334,0.0,0.0,0.0665463,0.10402095,0.21657774,0.2535697,0.25045174,0.12786826,0.041887708,0.0,0.0110064,0.003665343,0.0,0.0009834021,0.0,0.0,0.03505949,0.042781174,0.04699014,0.0,0.01622904,0.021197692,0.16685995,0.16977614,0.18708433,0.0,0.0,0.0,0.0,0.0,0.053246573,0.12428164,0.26292014,0.34854543,0.3375902,0.17503548,0.048254304,0.0,0.023364164,0.028024152,0.0,0.0025758296,0.0,0.0],[0.0,0.0,0.0,0.03726557,0.040943764,0.0,0.0,0.0,0.057083137,0.103541315,0.15110502,0.17960712,0.16652267,0.15139684,0.07766672,0.0,0.0,0.0,0.0,0.0,0.020238452,0.074304014,0.0,0.0,0.00533849,0.0,0.0,0.0,0.0,0.0,0.0,0.015184075,0.04815241,0.0009524971,0.0,0.0,0.029724538,0.06494437,0.120476276,0.14640315,0.1777094,0.2056118,0.11660029,0.010575898,0.0,0.0,0.0,0.0,0.03896548,0.07205887,0.0,0.0,0.0,0.0,0.0,0.013140008,0.0,0.0,0.0,0.0,0.02126465,0.0,0.0,0.0,0.0,0.0,0.0371477,0.09287011,0.19645643,0.24663809,0.12585233,0.012525439,0.0,0.0,0.0,0.0,0.035572343,0.06769809,0.0,0.0,0.0,0.0,0.0,0.01260291,0.0,0.0,0.019966692,0.0,0.009957679,0.0,0.0,0.0,0.0,0.0,0.0,0.036787257,0.15752728,0.21005997,0.092953764,0.019159563,0.0,0.0,0.0,0.0,0.014572009,0.04889492,0.0,0.0,0.0,0.017187469,0.0,0.020837873,0.0,0.01106675,0.025113165,0.0,0.0061087683,0.0011043847,0.013741806,0.0,0.0,0.007667482,0.014406085,0.18932348,0.26217183,0.19286278,0.030693442,0.0071715564,0.00991299,0.011078976,0.010755114,0.0,0.0,0.006861806,0.0,0.0,0.028097883,0.042712636,0.0,0.019331165,0.0,0.01337339,0.022409365,0.0,0.0,0.012129433,0.03332845,0.0,0.0,0.008985095,0.00034868717,0.1617606,0.22877884,0.21300101,0.08458368,0.059497617,0.046830885,0.0020822436,0.014032006,0.0,0.0,0.013930991,0.0,0.006170012,0.030164212,0.040365875,0.0051021725,0.013422847,0.0,0.0077502057,0.01831936,0.005601689,0.0,0.043676756,0.055883422,0.026734509,0.0028746426,0.040859006,0.016445272,0.048781075,0.035616495,0.09124941,0.097592995,0.10547906,0.12566476,0.06259802,0.057299018,0.0,0.0,0.009192459,0.0,0.003967643,0.02636934,0.026791543,0.010224767,0.0034132153,0.0,0.0059043244,0.015804984,0.037721507,0.0,0.048455633,0.07172189,0.045452677,0.027937077,0.019068532,0.0,0.0,0.0,0.06256774,0.11696358,0.13019082,0.16412607,0.14198348,0.10584379,0.029311605,0.0,0.0012087524,0.0,0.0001423955,0.019853003,0.0028235912,0.009366415,0.0,0.001400277,0.012668408,0.01658304,0.04862252,0.00391075,0.06662117,0.10896219,0.08233455,0.057003528,0.015157461,0.0,0.0036577582,0.0,0.039140873,0.10184732,0.12840828,0.15795714,0.20369735,0.19985238,0.12879533,0.052672118,0.024367198,0.0062108114,0.0009790957,0.018538348,0.0,0.0,0.0,0.020533726,0.023403026,0.023323566,0.055607274,0.007074788,0.08583614,0.1535593,0.12691244,0.09524206,0.0,0.0,0.019358702,0.0,0.0280229,0.081372604,0.102388404,0.13751931,0.24252707,0.22963679,0.16388473,0.101817,0.05827122,0.015649788,0.0,0.022681095,0.0,0.0,0.0,0.031315923,0.033492014,0.020380609,0.047969177,0.0,0.09549628,0.18929034,0.16549806,0.120347776,0.0,0.0,0.013729721,0.0,0.035025038,0.07338728,0.09927644,0.16910538,0.32697833,0.2818411,0.20771766,0.13439909,0.07801978,0.03953114,0.0,0.030092418,0.0,0.0,0.0],[0.0016534328,0.0,0.0,0.005602196,0.02566135,0.012482494,0.0,0.0,0.0065314695,0.043092832,0.026477166,0.0,0.0,0.0,0.0,0.0,0.0,0.034546904,0.004657507,0.059896618,0.086013265,0.08505175,0.044216707,0.05170352,0.0,0.011206597,0.0,0.010050669,0.0,0.0,0.0,0.0030260682,0.027478479,0.017736427,0.0,0.0,0.008279391,0.046989292,0.021743745,0.0,0.0,0.0,0.0,0.0,0.0,0.022277296,0.0,0.051769838,0.062284127,0.07108862,0.03303963,0.039798073,0.0,0.0,0.0,0.021660388,0.0,0.0,0.0,0.0,0.0024803132,0.0,0.0,0.0,0.0009767264,0.041649416,0.009684145,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.043649577,0.041042984,0.06291842,0.014815778,0.010587059,0.0,0.0,0.0,0.022599302,0.001191929,0.0120070875,0.0,0.0,0.00089147687,0.0076827854,0.0,0.0,0.00487113,0.010725744,0.0,0.0,0.0,0.03877087,0.0,0.0,0.0,0.0,0.0,0.018248722,0.013796061,0.031910688,0.0,0.0,0.0,0.0,0.0,0.016649798,0.004129663,0.018495888,0.0,0.0,0.0,0.041983,0.0,0.0,0.023130037,0.022628188,0.0030562282,0.026608773,0.110654324,0.09673154,0.04540112,0.0029940158,0.0,0.00014659762,0.0,0.0,0.0,0.0,0.0,0.0,0.008311294,0.0074479654,0.0,0.00597129,0.0,0.0223255,0.0,0.0,0.0,0.049178116,0.008192755,0.008446515,0.021468066,0.018944673,0.0144235715,0.049644142,0.16314012,0.14243233,0.12898996,0.05479034,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010222591,0.0,0.0,0.0,0.0,0.023226075,0.017161027,0.0103070885,0.002467677,0.051853128,0.016403213,0.010674156,0.0,0.014611676,0.038911127,0.040319048,0.060006365,0.034536034,0.077150434,0.056796625,0.039396808,0.043624066,0.022971705,0.0,0.0,0.0,0.0,0.0,0.015286855,0.0,0.0,0.0,0.0,0.024274334,0.04078065,0.024060152,0.005295858,0.051146373,0.02541425,0.03920728,0.0,0.0,0.009170204,0.019773893,0.032316588,0.028098889,0.073420614,0.098193824,0.102081195,0.087880775,0.08067587,0.03757509,0.009362586,0.0,0.0,0.0,0.011248715,0.0,0.0,0.0,0.0,0.037444584,0.06319949,0.027329005,0.002796203,0.059602752,0.056637928,0.0948966,0.0039713234,0.0,0.0070283115,0.036563568,0.043700963,0.008773759,0.04547452,0.10699505,0.1468617,0.13774382,0.17361161,0.11644543,0.07591808,0.0,0.021352395,0.0,0.017166786,0.0,0.0,0.0,0.0,0.060700692,0.08297262,0.04009348,0.0040648878,0.07512309,0.1050242,0.1340472,0.01700499,0.0,0.0021939427,0.048782714,0.06701212,0.022547454,0.032931373,0.08828984,0.15583405,0.16187894,0.21865737,0.16998015,0.12935354,0.010596961,0.038209066,0.0,0.034616306,0.0055459887,0.0,0.0,0.0,0.06338142,0.08839536,0.033619717,0.0,0.08879833,0.14039937,0.16034515,0.022968434,0.0,0.0,0.04901635,0.0817099,0.03360402,0.030057177,0.06837947,0.16978669,0.19117433,0.25968152,0.2133147,0.17012583,0.027307771,0.050307937,0.0,0.03765478,0.0075287744,0.0,0.0],[0.0,0.0,0.0070244297,0.02570185,0.008243792,0.0,0.0,0.0,0.0,0.00831978,0.019532546,0.0,0.0,0.0,0.0,0.0,0.0,0.037618585,0.05353438,0.011013508,0.099774234,0.09050393,0.07304807,0.02954819,0.008635797,0.0,0.0,0.0015738457,0.0,0.0,0.0034203827,0.032971635,0.022180364,0.0,0.0,0.0,0.0,0.012717597,0.0141855255,0.0,0.0,0.0,0.0,0.0,0.0,0.039090924,0.03728947,0.018369831,0.06985077,0.070065394,0.061846927,0.024286427,0.023785003,0.0,0.0,0.009044908,0.0,0.0,0.0,0.03364054,0.002798438,0.0,0.0,0.0,0.0,0.024891034,0.018034063,0.0,0.0,0.0,0.0,0.0,0.0,0.007178277,0.013150893,0.026646607,0.053955175,0.055912144,0.042330973,0.007867008,0.021710172,0.0,0.0,0.0073312446,0.0,0.0,0.0,0.03903649,0.0,0.0,0.0,0.0,0.0,0.039083093,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013397336,0.021637619,0.043333843,0.020269945,0.0005929321,0.0,0.012657389,0.0,0.0006055683,0.0025299191,0.0,0.0048297495,0.0,0.012109414,0.0,0.005190909,0.005748093,0.0029917508,0.0,0.038275324,0.0,0.0,0.052204892,0.017927676,0.0,0.0,0.012679942,0.0,0.00875587,0.0,0.011970989,0.0,0.0,0.010969788,0.02961377,0.009575538,0.0070097297,0.0019066483,0.0,0.016790278,0.0021541864,0.0030084848,0.0,0.017975613,0.02767457,0.011285581,0.0,0.02921556,0.0,0.025136493,0.10080485,0.08481086,0.06839829,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01974614,0.036759533,0.012629561,0.005482018,0.0,0.0,0.042422727,0.035488956,0.025710337,0.005592555,0.03318356,0.056791976,0.008837402,0.0,0.006045662,0.0,0.01695875,0.031805612,0.0,0.017533861,0.0,0.0,0.0,0.008856922,0.0,0.0,0.0,0.0,0.019320056,0.051368356,0.02310329,0.0021962076,0.0,0.0012318194,0.07424477,0.074642636,0.04805067,0.010667168,0.03713908,0.068414316,0.03158345,0.0,0.0,0.0,0.021282353,0.007967293,0.0,0.0,0.0,0.0,0.0,0.0028966367,0.0,0.0029898137,0.0,0.0,0.020421669,0.056571133,0.025250241,0.0,0.0,0.0106071085,0.11903896,0.107071936,0.068005614,0.011931121,0.037220456,0.101043686,0.07360312,0.023887634,0.003776446,0.0,0.066442534,0.013994917,0.0,0.0,0.0,0.0,0.0,0.023351029,0.023479968,0.018075459,0.0,0.0,0.0182129,0.05362484,0.04807011,0.0,0.0,0.02510348,0.14585845,0.1276223,0.087728895,0.022390537,0.048833422,0.14166202,0.102344364,0.04225868,0.0075214654,0.0,0.07576153,0.015764035,0.0,0.0,0.0,0.0,0.0,0.03622227,0.06407988,0.04598976,0.0,0.0,0.022466473,0.059705786,0.0632777,0.0,0.0,0.031872377,0.15170975,0.13312367,0.09174156,0.029824428,0.05795011,0.16639021,0.11955424,0.060172677,0.005175099,0.0,0.07412523,0.012375675,0.0,0.0,0.0,0.0,0.0,0.063976586,0.10230996,0.086015284,0.015896402,0.003869906,0.018296383,0.051486835,0.067755714,0.0,0.0],[0.0,0.0,0.0,0.021194004,0.020155385,0.0007146597,0.0,0.0,0.0,0.019832447,0.045792565,0.025660276,0.0,0.0,0.0,0.0,0.010290049,0.04235875,0.011471778,0.0,0.01642292,0.03775096,0.037439726,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022755869,0.023002192,0.00059740245,0.0,0.0,0.0,0.01539284,0.037189834,0.018429242,0.0,0.0,0.0,0.0,0.0,0.028147027,0.008168116,0.0,0.007075146,0.0340472,0.044104956,0.0,0.0,0.0,0.0,0.0,0.01119785,0.0,0.0,0.02995763,0.018476322,0.0042553544,0.0,0.0,0.0,0.0,0.016977586,0.006637849,0.00011463463,0.0025584847,0.0,0.0,0.0,0.0037698597,0.00024212897,0.0,0.0149859935,0.030554444,0.03868915,0.0,0.0,0.0,0.0,0.0,0.019026265,0.0,0.0,0.031295,0.0105882585,0.029415585,0.0044175833,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015890077,0.009978317,0.021264091,0.0,0.0,0.0,0.0,0.0,0.018945083,0.0,0.0,0.00831151,0.0,0.015539348,0.014829539,0.010341473,0.0,0.0,0.0,0.0,0.006209716,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016630277,0.0,0.0,0.006062947,0.0,0.010430358,0.01565934,0.017147869,0.0,0.0,0.0,0.036981255,0.04976382,0.032377966,0.021351077,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00041811168,0.0080934465,0.006419815,0.0,0.0,0.0,0.010477006,0.009336583,0.012138687,0.021670237,0.004869625,0.010334477,0.014222428,0.004156351,0.0,0.0,0.0,0.017315932,0.0064844936,0.0072626993,0.0020880103,0.00988818,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004236266,0.019983388,0.0,0.0019523352,0.0,0.004182726,0.035591222,0.040694468,0.024693571,0.0,0.0,0.0071655214,0.017780945,0.017660752,0.0,0.004613459,0.025201187,0.0,0.0005570799,0.0,0.014440909,0.0,0.0,0.0,0.00070144236,0.0015033484,0.0,0.0011803806,0.00043146312,0.029880159,0.0,0.0,0.0,0.0017804056,0.06447818,0.06984031,0.040101364,0.0,0.0,0.017585963,0.049377084,0.03847146,0.0,0.018810816,0.052723914,0.0,0.0,0.0,0.017873235,0.0,0.0,0.0,0.016266763,0.022442572,0.010020368,0.013173319,0.015672557,0.050203227,0.0,0.0,0.0,0.0060915872,0.08319893,0.091081,0.059233487,0.0,0.0,0.033954494,0.07147984,0.03836301,0.0,0.008844808,0.04701522,0.0,0.0,0.0,0.021771088,0.0,0.0,0.0,0.026084222,0.036997937,0.012050159,0.017920777,0.031281844,0.074699745,0.0,0.0,0.0,0.0037035644,0.07957724,0.10511655,0.069467604,0.0,0.0026893765,0.04133314,0.08842908,0.038304918,0.0,0.0,0.039638266,0.0,0.0004516244,0.0,0.016847245,0.0,0.0,0.0,0.038911343,0.0608045,0.025913484,0.024519376,0.040861472,0.09146108,0.0,0.0,0.0],[0.013679169,0.0,0.020414472,0.0,0.027496025,0.007148549,0.015013516,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0004401505,0.02118171,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009812884,0.008322202,0.0028626025,0.01946389,0.0,0.0116567165,0.0,0.01690714,0.0,0.0143243,0.00090254843,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002075985,0.01566948,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0048511475,0.0028547198,0.0,0.02446609,0.0,0.003473103,0.0,0.010454707,0.0,0.0056791455,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.005931586,0.016804218,0.005651295,0.007944971,0.0,0.0,0.0,0.00026494265,0.0,0.0,0.002398923,0.0,0.0,0.022138946,0.0,0.0,0.0,0.013715856,0.007869631,0.0,0.0,0.0,0.002934739,0.010118015,0.01425086,0.0,0.0,0.0,0.0066525117,0.008894503,0.0,0.0,0.0,0.0,0.0,0.010758117,0.0,0.0,0.0015383363,0.0,0.0,0.019173928,0.0,0.0,0.0,0.014370926,0.013055801,0.0,0.0,0.007256113,0.011056751,0.035771273,0.036360525,0.0,0.0,0.0,0.00064349174,0.013003491,0.0,0.0,0.0,0.0,0.0,0.020415917,0.0,0.0,0.0,0.0,0.0,0.014701441,0.0,0.0,0.0,0.0052419156,0.007192686,0.0,0.0,0.0,0.0,0.013133258,0.01840379,0.0,0.0,0.0,0.0,0.01148463,0.02111552,0.020034842,0.0,0.0,0.0,0.010028876,0.0,0.0,0.0,0.0,0.0,0.01462359,0.0,0.0,0.0,0.0005559176,0.0029919893,0.0074207634,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0006211549,0.0,0.0042288452,0.036038652,0.043010727,0.0,0.0,0.0,0.00069086254,0.0,0.0,0.0,0.0,0.0,0.014412619,0.0,0.0,0.0054059178,0.0,0.0058270767,0.023570575,0.00012800097,0.0,0.0010755211,0.0,0.0,0.002924636,0.0,0.00032186508,0.0,0.0061946735,0.042712845,0.047963694,0.0,0.0,0.00064462423,0.0,0.0,0.011882685,0.0069774166,0.0,0.0,0.015583098,0.0,0.0,0.011463873,0.0,0.0066728666,0.035649337,0.016651727,0.014066234,0.024810836,0.0,0.0,0.007959984,0.0,0.004393071,0.0,0.0066869035,0.046417832,0.05141093,0.0,0.0,0.0015842319,0.0,0.00404343,0.02751188,0.01719141,0.0,0.0,0.016281776,0.0058199614,0.0,0.011306293,0.0,0.0,0.034504652,0.02043219,0.019809477,0.036255725,0.0,0.0,0.023969784,0.0,0.0065025836,0.0,0.011808112,0.047488406,0.050888777,0.0,0.0,0.0030834079,0.0,0.0121093765,0.044191338,0.028362177,0.0,0.0,0.016340919,0.023072027,0.0,0.006356865,0.0,0.0,0.0262388,0.019919172,0.027806863,0.0417054,0.0,0.0,0.048433825,0.0,0.0073833466,0.0,0.017779104,0.05148451,0.04742647,0.0,0.0,0.0066270605,0.0,0.015963838,0.046052814,0.035673633,0.0,0.0],[0.0009847283,0.0,0.0,0.0,0.05500105,0.03860236,0.032493636,0.0,0.0,0.0,0.0,0.0,0.0038393438,0.0,0.0,0.0,0.028327137,0.0,0.0,0.011417322,0.0,0.0004053563,0.0,0.0,0.0052535087,0.0482855,0.048379846,0.0,0.0066810846,0.0,0.0,0.0,0.04256531,0.033570208,0.033559173,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020947367,0.0,0.0,0.0,0.0,0.0,0.035687923,0.045926414,0.0,0.009329826,0.0013651252,0.0,0.0,0.03804677,0.022552684,0.021072254,0.011671931,0.0,0.0,0.0022923946,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012254454,0.0,0.0,0.0,0.0,0.0,0.016634956,0.031065494,0.0,0.0,0.006093733,0.0,0.023023374,0.040378936,0.01843974,0.0,0.0076368153,0.0,0.006243117,0.025857292,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0064301193,0.004696414,0.0028819889,0.03616979,0.0021163076,0.0,0.0,0.010356739,0.0,0.0,0.0029081553,0.0,0.04193528,0.040792666,0.015326783,0.0,0.0,0.0,0.0102385655,0.04356017,0.0,0.01073274,0.011459909,0.0,0.0,0.0,0.0,0.004739076,0.0061123446,0.0068384856,0.0,0.03885559,0.0,0.0,0.0,0.00014419854,0.0,0.0,0.0113609955,0.0,0.030615374,0.022882037,0.0,0.0,0.0,0.0,0.0,0.007837214,0.0,0.009619631,0.02139701,0.0022845715,0.0,0.0,0.004341036,0.022993684,0.0,0.0,0.0,0.029810853,0.0,0.0008056611,0.0,0.0,0.0,0.0,0.012938358,0.0,0.009266816,0.0077025965,0.0,0.0037295967,0.0,0.0,0.0,0.0,0.0,0.0080630705,0.0276964,0.005824603,0.0,0.0,0.014892466,0.04084739,0.0,0.00786148,0.00886111,0.010617368,0.0,0.00810574,0.0,0.0,0.0,0.0,0.015901312,0.0,0.0025929809,0.0,0.0049627423,0.024345785,0.0,0.006532714,0.0,0.0,0.0,0.020453252,0.02940052,0.008353308,0.0,0.0,0.006085515,0.027796544,0.0,0.010196246,0.027322814,0.006088361,0.006420769,0.02697333,0.0,0.0,0.0,0.0,0.02128812,0.0,0.001971975,0.0,0.0089269355,0.05471024,0.0034446865,0.04108476,0.0,0.0,0.01633937,0.038905583,0.015556321,0.008301809,0.0,0.0,0.0,0.00073456764,0.0,0.0008428544,0.025587343,0.0,0.018298917,0.04763174,0.014384799,0.0,0.0,0.0,0.023781188,0.0,0.0036202818,0.0,0.005459115,0.06686098,0.023953646,0.069785476,0.0,0.0,0.031638898,0.065086626,0.009134673,0.0056117326,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.027289912,0.07630694,0.04102502,0.00048102438,0.0,0.0,0.03332326,0.0,0.0,0.0,0.0,0.07383551,0.054400302,0.11337633,0.008234233,0.01445277,0.06265097,0.10680277,0.019920811,0.008689612,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028889261,0.086777456,0.047881007,0.0,0.0],[0.0,0.01667779,0.05225973,0.04040017,0.060384966,0.03183169,0.017156683,0.0,0.0,0.0,0.05418863,0.020643562,0.09388647,0.032307237,0.012565501,0.051983446,0.05593305,0.0,0.0,0.0106558055,0.0,0.0,0.0018737763,0.0,0.037884735,0.048240863,0.0066161007,0.0,0.0,0.012020662,0.04199873,0.02448932,0.045022853,0.040323667,0.02894739,0.0022390485,0.024983734,0.0,0.02148769,0.0,0.08573075,0.016439408,0.031982116,0.034008496,0.056425795,0.0,0.0016506314,0.011850961,0.0,0.0,0.0,0.0,0.026841156,0.043631315,0.0127163455,0.0017802268,0.0,0.015586406,0.043677308,0.027725108,0.040457368,0.03793914,0.030903362,0.032242827,0.02582395,0.0023154914,0.026814096,0.0,0.061094746,0.0,0.043010354,0.04637549,0.06181953,0.0072425306,0.025702871,0.019858591,0.0,0.0,0.008845143,0.003322482,0.0181581,0.0288236,0.012509845,0.009450719,0.0,0.0041291863,0.04066935,0.024746165,0.03595779,0.028067432,0.016397893,0.034643687,0.016972058,0.01481656,0.048069596,0.0,0.05733961,0.0,0.050655656,0.05408714,0.028618082,0.028802276,0.007756874,0.048653826,0.035653517,0.01972714,0.05307836,0.022417955,0.0094083175,0.004841447,0.0,0.016389295,0.0,0.0,0.047907054,0.025064684,0.03279417,0.01980827,0.0,0.016305111,0.008800201,0.015544727,0.07019201,0.0,0.06536795,0.0,0.03523285,0.0126467645,0.0,0.05451978,0.015919484,0.059820026,0.040139094,0.041219175,0.057405926,0.010676689,0.0027612448,0.0,0.0,0.019651875,0.0,0.011180088,0.05698899,0.024559155,0.019378819,0.027915806,0.016719803,0.022521421,0.0,0.007242076,0.041788198,0.0,0.0388712,0.0,0.02533079,0.0058395118,0.0,0.05950611,0.0,0.040530823,0.045435183,0.044632226,0.049641006,0.0038534254,0.0020314008,0.0,0.0,0.016169824,0.0,0.011698082,0.037368223,0.0057824403,0.0051641464,0.05149164,0.029229775,0.0095914155,0.007453926,0.0,0.012602039,0.0,0.030276,0.0,0.011247002,0.0,0.0,0.06988335,0.0,0.030520424,0.056635596,0.041252658,0.029046394,0.0,0.011051744,0.0025608838,0.0,0.009292498,0.0,0.0025375932,0.022100262,0.0,0.0,0.06755394,0.037089914,0.01930181,0.02075655,0.0,0.0017568618,0.0,0.051047288,0.0,0.009259492,0.0,0.0,0.053762674,0.0,0.020279549,0.063457064,0.054662257,0.0210635,0.0,0.024176061,0.014753215,0.0,0.017622583,0.0,0.0,0.011804767,0.0,0.0,0.08917674,0.07021411,0.067348994,0.067445815,0.0,0.014309421,0.0,0.09407765,0.0,0.012279287,0.0,0.0,0.022017412,0.0,0.011095807,0.053015113,0.049445547,0.009753503,0.0,0.03433235,0.024298586,0.01895246,0.027122594,0.0,0.0064269304,0.01275067,0.0035642982,0.0,0.096810475,0.10956313,0.12659112,0.12497309,0.018449925,0.02321963,0.01125709,0.12280901,0.0,0.023133345,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0048220903,0.06696397,0.048544206,0.03725572,0.036851235,0.002752781,0.015060887,0.0015591532,0.0,0.0,0.08947219,0.14825898,0.19724938,0.19816335,0.088524744,0.06080413,0.064348675,0.16145454,0.0106465295,0.028111316,0.0,0.0,0.0,0.0043074787,0.0,0.0,0.0,0.0,0.008492179,0.0828239,0.056046948,0.041374013,0.03681933],[0.0,0.04925268,0.0,0.0,0.019818462,0.005953826,0.0078243315,0.014940433,0.029569909,0.072418526,0.11485493,0.09741567,0.13087709,0.13491312,0.11775458,0.09938671,0.12416569,0.06896816,0.030861713,0.0,0.0,0.0,0.0,0.0032857805,0.01819732,0.0,0.0,0.0,0.0,0.04221899,0.0,0.0,0.015054926,0.008828685,0.026577838,0.029214367,0.051397458,0.054980613,0.076223195,0.040857494,0.08255547,0.121850766,0.12360669,0.1161431,0.12087927,0.06173715,0.026139908,0.0,0.0,0.0,0.0,0.0059704185,0.015350856,0.0,0.0,0.0023186654,0.0,0.044670813,0.0075477213,0.0,0.016743504,0.027230062,0.041230746,0.031387694,0.06170088,0.05958212,0.04938893,0.01273413,0.033665754,0.08298173,0.10467607,0.10376628,0.08472234,0.041926704,0.024731167,0.0,0.0,0.008752979,0.024418734,0.008868001,0.01747115,0.0,0.0,0.002590999,0.0,0.024870485,0.0,0.0,0.02197627,0.059946008,0.04971058,0.025701493,0.054908663,0.052031033,0.03466267,0.0,0.007914953,0.036462568,0.072822616,0.06663777,0.04110959,0.030822925,0.026811056,0.0,0.05422429,0.046413727,0.06469954,0.0,0.000011757016,0.0,0.0,0.007294245,0.0,0.010015413,0.0,0.0,0.019353606,0.07057983,0.04983197,0.008038163,0.037125297,0.045595057,0.046826616,0.0142811015,0.014076054,0.01385805,0.0137691945,0.032338344,0.02381865,0.050157458,0.05177605,0.017132476,0.06693282,0.03314086,0.0527078,0.0,0.0,0.0,0.0,0.019542113,0.0,0.028394558,0.011499234,0.0,0.030041069,0.06309995,0.049943864,0.01279781,0.032545477,0.02008538,0.020195045,0.0,0.015250407,0.025434442,0.0,0.020821504,0.0105602145,0.044146642,0.05013907,0.040252626,0.075430185,0.03057658,0.038042657,0.0,0.0,0.008862056,0.0,0.014562279,0.0,0.024510205,0.0093292445,0.0,0.041642398,0.0627733,0.042361394,0.0,0.018789,0.0065260082,0.010565236,0.0,0.018836103,0.03909094,0.0,0.02925969,0.0,0.036513723,0.042639993,0.07149165,0.09790288,0.03943651,0.018186338,0.0,0.00004862249,0.026614003,0.00082570314,0.0044953227,0.0,0.013657458,0.0010354519,0.0,0.040636986,0.06688694,0.050565124,0.0,0.00475733,0.009649195,0.018297464,0.0,0.032107502,0.05918269,0.014842436,0.045997307,0.0,0.020426586,0.027761422,0.08958414,0.12678629,0.074170664,0.023863502,0.0,0.0021442026,0.048883967,0.019730657,0.003906712,0.0,0.008739628,0.000048205256,0.0,0.043829054,0.088295415,0.09618801,0.03437359,0.024767213,0.047632217,0.04403293,0.0,0.04303761,0.0795519,0.046393603,0.07243623,0.0,0.021271579,0.012760691,0.08245586,0.13476783,0.093432896,0.030703083,0.0,0.004860252,0.05869893,0.030610554,0.0027923882,0.007533163,0.019937098,0.004036635,0.0,0.043841206,0.11468424,0.1448493,0.074499026,0.06272458,0.09006452,0.079280004,0.0,0.05100388,0.08519316,0.082428664,0.09323621,0.0,0.01211898,0.0,0.008532688,0.052574866,0.050019264,0.012149662,0.0,0.027555056,0.069167264,0.034884,0.0,0.018375382,0.023430586,0.005905099,0.0,0.031939007,0.13954218,0.19594517,0.13608454,0.14012307,0.19307443,0.19505855,0.03218533,0.08152707,0.081430495,0.1057021,0.10025921,0.0019937307,0.0,0.0,0.0,0.010082886,0.015776828,0.0,0.0,0.034979343,0.061505973,0.030750334,0.0],[0.0,0.0,0.020713106,0.0,0.005742088,0.023164026,0.031989284,0.027740054,0.12287762,0.16329303,0.24317238,0.28396815,0.4143579,0.4697094,0.59284526,0.45901078,0.440098,0.23538136,0.14432013,0.0,0.0,0.006132737,0.0,0.0,0.0,0.010245286,0.0,0.0,0.0,0.0,0.006522082,0.0,0.0,0.025402553,0.03278067,0.005599767,0.067447655,0.07432244,0.12358017,0.15292567,0.3167066,0.41154093,0.5463794,0.46374148,0.42378604,0.23385191,0.15824908,0.0,0.0,0.0,0.0,0.0,0.0,0.013136409,0.0,0.0,0.0,0.00037679076,0.009586059,0.0,0.0,0.028107725,0.02815628,0.0,0.022552125,0.04850336,0.054075368,0.07083222,0.22534917,0.30688915,0.42842668,0.39459914,0.34943372,0.1902656,0.14602908,0.010345705,0.002594933,0.0028039068,0.0,0.007470764,0.0,0.01791817,0.0046732873,0.0,0.0,0.0,0.0,0.0,0.0,0.03287913,0.011069372,0.0,0.0,0.02532059,0.010584742,0.024713144,0.11837876,0.1616766,0.25557792,0.26299655,0.2672317,0.18468349,0.19633242,0.062457778,0.03211049,0.008385375,0.0017404705,0.0,0.0,0.0,0.0018170476,0.0,0.0,0.0,0.0,0.0,0.003751412,0.035461478,0.0018263608,0.0,0.0,0.019458763,0.0,0.00220415,0.061140858,0.034346692,0.094676256,0.15243955,0.2107903,0.23409161,0.265753,0.12569846,0.06855559,0.0,0.0,0.0,0.0,0.0,0.012213349,0.008436002,0.0,0.0043992996,0.0,0.0,0.027842328,0.048414536,0.015140355,0.0,0.005546987,0.0182551,0.0,0.0,0.04478006,0.0,0.03340084,0.10692431,0.16181597,0.21953365,0.27243948,0.16236435,0.10729872,0.0,0.0,0.0,0.0,0.0,0.005033493,0.00026777387,0.0,0.005776815,0.0,0.01812397,0.072464064,0.05709052,0.024809092,0.0,0.031390317,0.036892645,0.0,0.0034073144,0.03572102,0.0,0.0,0.06761893,0.10413787,0.17178649,0.22217941,0.17622747,0.14961314,0.048114777,0.01989089,0.0,0.0,0.007362917,0.0,0.0,0.0,0.0,0.0,0.038109653,0.09686522,0.06712889,0.037847996,0.0,0.038019933,0.06528948,0.006200865,0.0058056265,0.028165951,0.0,0.0,0.049144678,0.06789383,0.121851064,0.15652116,0.17576027,0.1893794,0.11294027,0.048612937,0.0,0.0,0.03153745,0.012153611,0.0,0.0,0.0,0.0,0.058142163,0.117936805,0.09040903,0.07380313,0.0,0.05793786,0.09536116,0.029831849,0.012533456,0.01211787,0.0,0.005981751,0.052870743,0.07786194,0.11936174,0.11729229,0.16400999,0.19683751,0.15473221,0.06466096,0.0,0.0,0.05578708,0.02590084,0.0,0.0,0.012897141,0.0,0.059441835,0.11728593,0.106743045,0.103261925,0.008467905,0.083468094,0.1420632,0.068592824,0.050414853,0.015367292,0.030209944,0.04760077,0.06941245,0.102132745,0.09689602,0.030846484,0.04904311,0.10083552,0.1261895,0.05942703,0.0,0.002258718,0.067295596,0.03367202,0.0,0.0006222129,0.028927289,0.0,0.05397121,0.11500666,0.13710755,0.15042004,0.05059003,0.15090752,0.25228018,0.18476118,0.14181109,0.022406146,0.05934868,0.078739524,0.089444,0.1374142,0.09344411,0.0,0.0,0.015940495,0.07263767,0.013341829,0.0,0.012653224,0.05832304,0.033550173,0.0039393157],[0.0,0.0,0.0,0.0,0.041661836,0.062689535,0.037348866,0.10284679,0.1656633,0.32329115,0.37859797,0.5120023,0.66571105,0.8691161,0.90314615,0.9580838,0.8189496,0.5429947,0.34651178,0.14360508,0.031777494,0.0011687577,0.0,0.0,0.0,0.007869318,0.0,0.0,0.0,0.0,0.0,0.0,0.024322577,0.042335346,0.01143302,0.04367131,0.07289457,0.16544233,0.19557497,0.3315122,0.5217572,0.76575816,0.8471173,0.94807273,0.8005222,0.5007277,0.30167288,0.10369967,0.0,0.0,0.0,0.0,0.0,0.03355965,0.0,0.0,0.0,0.0,0.0,0.0,0.015419722,0.025321476,0.004950255,0.03585065,0.04981324,0.093076214,0.080626965,0.15546331,0.3189233,0.56346315,0.71409434,0.8421226,0.7127041,0.43498152,0.23868683,0.047634393,0.0,0.0046217144,0.0,0.0,0.0043334216,0.045598596,0.015287086,0.0,0.0,0.0,0.0,0.006936386,0.018516153,0.0045015067,0.0,0.0038641691,0.008162692,0.02411931,0.010785185,0.040143125,0.06861578,0.2310386,0.43132085,0.67550045,0.64984727,0.4262389,0.25166517,0.053499192,0.0,0.0,0.0,0.0,0.0,0.010529965,0.0,0.00024551153,0.0,0.0,0.0,0.014640138,0.016385153,0.0,0.0,0.0,0.0,0.0,0.0,0.005505398,0.0,0.056660727,0.19546747,0.491512,0.6086238,0.5342883,0.39523923,0.14679736,0.0026457608,0.0,0.0,0.0,0.0,0.008087374,0.0,0.010649785,0.0,0.0,0.008029647,0.021017574,0.021582872,0.0,0.0,0.0,0.0,0.0,0.0006029904,0.0,0.0,0.011878662,0.07626789,0.29882818,0.4412666,0.44944924,0.43540525,0.26992366,0.08987126,0.0,0.0017563999,0.0,0.0,0.0049071163,0.0,0.014102824,0.0,0.0,0.021394849,0.031321153,0.04449132,0.0008416176,0.01735714,0.0,0.0077596754,0.0,0.027228005,0.0,0.020307317,0.0,0.0,0.07443084,0.22721325,0.3229648,0.40845704,0.36236334,0.20769176,0.08659099,0.059124358,0.0,0.0,0.0,0.0,0.01943028,0.0,0.0,0.025177166,0.03822986,0.057717882,0.0069660395,0.026673116,0.0,0.0,0.0,0.044916265,0.01792039,0.077261746,0.028721131,0.0,0.0,0.07346563,0.22118428,0.3775832,0.42340058,0.3141448,0.16999792,0.100903265,0.0,0.0,0.0014288127,0.0034199208,0.028051056,0.0,0.0,0.037303016,0.05087138,0.070776924,0.0123062655,0.041331492,0.0,0.00034590065,0.0,0.055854753,0.028429776,0.11785124,0.071088254,0.0,0.0,0.013668075,0.16481188,0.3566438,0.44728106,0.37992352,0.21849386,0.11490505,0.0,0.0,0.0037099123,0.0088952705,0.027099468,0.0,0.0,0.037630267,0.052722238,0.07492304,0.025928274,0.045695685,0.0,0.044353016,0.043699272,0.11231432,0.095324576,0.19501957,0.14135563,0.034510322,0.0,0.0028606653,0.08464572,0.23025581,0.30882514,0.30012,0.18785554,0.093157426,0.0064778104,0.0018094927,0.0,0.009542897,0.02194558,0.0,0.008487016,0.04392726,0.052850515,0.075069726,0.051842734,0.06317772,0.0,0.14754769,0.17546988,0.22312303,0.19476292,0.27294728,0.22629979,0.12375438,0.0034887046,0.05847811,0.098746665,0.18502201,0.24040703,0.21732907,0.11465408,0.040262893,0.014914177,0.0077294856,0.0,0.012062855,0.016499028],[0.0,0.0,0.0037788004,0.044667855,0.065056436,0.06971511,0.03557664,0.1355528,0.20542791,0.37268206,0.38152784,0.5718676,0.71599,0.8453448,0.9149386,0.99772084,0.8859184,0.7122019,0.4829527,0.22285314,0.12054316,0.05678431,0.028684251,0.0152238235,0.013345875,0.0,0.0,0.0,0.0,0.0,0.0,0.039051645,0.05068648,0.044007055,0.0,0.060245633,0.0878227,0.2112723,0.18208715,0.3952638,0.6005917,0.7942536,0.9387176,1.0,0.8969298,0.6654463,0.41227794,0.15021937,0.07788241,0.059345007,0.03044425,0.0011708289,0.027728483,0.0064694583,0.001861155,0.0,0.0,0.0,0.0,0.041554414,0.035572648,0.03671263,0.0,0.040759847,0.052858226,0.11918833,0.034402683,0.19220734,0.3957215,0.6333067,0.8376757,0.9551844,0.84048635,0.60139155,0.3248763,0.059858374,0.045545734,0.06555748,0.03068626,0.0026558042,0.039642565,0.014326237,0.012937166,0.0,0.0,0.0,0.0,0.03286101,0.02556149,0.032607324,0.0,0.012436293,0.0035420507,0.019489542,0.0,0.039112307,0.110973805,0.29030806,0.55903506,0.8272654,0.77463895,0.58974844,0.27718967,0.0,0.008516163,0.0063649565,0.0,0.0,0.004049197,0.0,0.00069767237,0.0,0.0,0.0060094222,0.0,0.022026852,0.009311661,0.029029846,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06786811,0.32510883,0.6548978,0.72751904,0.7051826,0.3659389,0.0187416,0.0,0.0,0.0,0.0,0.02080065,0.0,0.0030854344,0.0,0.0,0.013547733,0.013036579,0.03407511,0.010389239,0.025996163,0.028134882,0.0,0.0,0.0,0.0,0.011026628,0.0,0.0,0.19793083,0.44687867,0.5609314,0.62330425,0.47013587,0.19927569,0.053121053,0.0,0.0,0.0,0.012433037,0.0,0.0000044852495,0.0,0.0,0.011496738,0.018557556,0.05729711,0.02651205,0.016088784,0.058318853,0.004281193,0.020181924,0.0,0.0048470944,0.05774381,0.03361091,0.0,0.112268865,0.22655433,0.35846654,0.51508117,0.5204229,0.38463742,0.1838664,0.029663913,0.023668475,0.0,0.019032158,0.0,0.0,0.0,0.0,0.007493116,0.014800705,0.06280009,0.02995406,0.006580852,0.053223655,0.0127494335,0.03733261,0.018521257,0.022403091,0.08595507,0.056880362,0.0,0.085119575,0.10395434,0.20822546,0.45267576,0.5420127,0.52975947,0.3090007,0.07554228,0.04344704,0.0,0.028101973,0.0,0.0,0.0094230175,0.0,0.016837455,0.016233236,0.07063453,0.033583015,0.0,0.056680806,0.029001392,0.07376019,0.040212564,0.024105862,0.08695826,0.06636809,0.008990072,0.08047427,0.06078793,0.13086168,0.40554434,0.53597796,0.61257446,0.37153617,0.08587144,0.054056235,0.0033208579,0.049996704,0.006207928,0.0,0.013946921,0.0,0.018318929,0.01653909,0.07542668,0.04076495,0.0,0.05440829,0.04817141,0.14008915,0.124301404,0.14445192,0.17596559,0.1293575,0.062489025,0.11384308,0.05701592,0.084452644,0.3104007,0.3884303,0.47668976,0.31815672,0.045509726,0.050937697,0.029708922,0.05764681,0.0045446306,0.0,0.011071578,0.0,0.021205693,0.013576299,0.07489008,0.046523884,0.017255716,0.0623457,0.090174735,0.25830323,0.26453534,0.3145557,0.27642563,0.2157194,0.13559015,0.18463357,0.14173178,0.13653456,0.32949945,0.35678476,0.4142511,0.26044405,0.0,0.02613765,0.034267396,0.067814834,0.01659657,0.0,0.006668769],[0.0,0.0,0.015402608,0.0,0.0,0.0144338235,0.010060839,0.13391155,0.14070916,0.17840347,0.15107746,0.14078571,0.27825752,0.41033036,0.5417592,0.5329615,0.61850226,0.50238764,0.49870503,0.24191749,0.07159578,0.0,0.0142350495,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006717719,0.0,0.07690641,0.07128145,0.0710463,0.045651823,0.09730922,0.29838258,0.50687814,0.6715403,0.62162143,0.62598103,0.4447183,0.41252863,0.15469891,0.02787193,0.0,0.015908249,0.0036695004,0.014615037,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02075281,0.0,0.04869566,0.046586342,0.024591811,0.0,0.01614967,0.23610868,0.5338856,0.7586573,0.72456145,0.66329396,0.43086588,0.3241787,0.0706013,0.018309727,0.0,0.02175346,0.006314382,0.024021193,0.0,0.0,0.0,0.0,0.0026845485,0.0,0.0,0.0,0.031550214,0.0021970868,0.024098203,0.00799717,0.0,0.0,0.0,0.028932683,0.29820046,0.62890464,0.81802684,0.8007507,0.51279193,0.27969515,0.0053822845,0.014662661,0.0,0.0070747733,0.0,0.0,0.0,0.0,0.0,0.0,0.017218553,0.0,0.0015721172,0.0,0.03742381,0.0016950369,0.007745415,0.0,0.0,0.0,0.0,0.0,0.075169064,0.40147913,0.7940131,0.9052683,0.6899852,0.3412161,0.0,0.0,0.0,0.016548298,0.0,0.0,0.0,0.0,0.0,0.0,0.032187417,0.011570662,0.0034271628,0.0,0.022666857,0.008583024,0.0,0.004314542,0.0,0.0,0.0,0.0,0.0074572563,0.21074176,0.546895,0.7160181,0.6758208,0.43441868,0.080091,0.0,0.0,0.016843908,0.0,0.0,0.0,0.0,0.0,0.0,0.033358775,0.021999076,0.010758765,0.0,0.016625844,0.026254721,0.0,0.0,0.0,0.015035532,0.040773705,0.031179667,0.0,0.053487986,0.28743413,0.5179766,0.6244263,0.55191183,0.24550954,0.0023964942,0.0,0.00811667,0.0,0.0,0.0,0.0,0.0,0.0,0.024312332,0.017578177,0.0058649927,0.0023582429,0.0051338077,0.038086154,0.0029890686,0.00690531,0.010166481,0.053092718,0.08988598,0.07060678,0.0,0.0,0.16814497,0.41504145,0.5820012,0.63794434,0.38547307,0.072988614,0.0,0.0012675375,0.0026334673,0.010022394,0.0046106875,0.0,0.0,0.0,0.029600933,0.01821936,0.0,0.014803581,0.0052628517,0.06293012,0.032653466,0.053196833,0.057895713,0.080807365,0.09830505,0.09791538,0.0,0.0,0.10012855,0.34769025,0.52899075,0.68996096,0.4767815,0.104883164,0.0,0.0,0.028317131,0.037891082,0.027055077,0.0,0.0,0.0,0.04224734,0.02162826,0.0,0.035936505,0.01992724,0.083466,0.099403605,0.14324456,0.16057979,0.17078236,0.15721548,0.17469497,0.0,0.008218221,0.06477092,0.31842482,0.42674786,0.5849385,0.38176054,0.04994379,0.0,0.0,0.04591824,0.04393512,0.026066504,0.0,0.0,0.0,0.055927575,0.032967404,0.009334214,0.0637646,0.04238078,0.13171557,0.2110022,0.26849663,0.28863013,0.275079,0.22346017,0.25818813,0.06187436,0.099258475,0.15294379,0.40680254,0.438555,0.54252356,0.3196319,0.0,0.0,0.0,0.056256972,0.0515493,0.030968674,0.0,0.00055898726],[0.0,0.004807934,0.0,0.02145961,0.0058919936,0.0,0.036595955,0.041365467,0.0049716383,0.0052064657,0.0,0.0,0.0,0.20521933,0.31439358,0.38958257,0.50670165,0.44131708,0.37617272,0.23710582,0.11792739,0.06492839,0.0,0.0,0.0,0.010335207,0.0,0.010244466,0.0,0.0,0.0,0.0065889508,0.0030666888,0.0,0.010807149,0.020076364,0.0,0.0,0.0,0.0,0.11797363,0.35220596,0.45986092,0.46557325,0.46631557,0.37788808,0.29666555,0.16170251,0.117564954,0.05992037,0.007910289,0.0,0.015479565,0.021046795,0.0,0.015482768,0.0,0.0,0.0,0.0024469793,0.0,0.0,0.0,0.01591754,0.0,0.0,0.0,0.0,0.19245023,0.50549126,0.6540144,0.62690294,0.5225156,0.35004455,0.18938501,0.07600264,0.10106393,0.052065335,0.024186462,0.0,0.022306643,0.0167002,0.0,0.019179627,0.0,0.0,0.0,0.0014512688,0.0,0.0,0.0,0.0009122193,0.0,0.0,0.0,0.0,0.042216636,0.37944266,0.6618435,0.79998004,0.66307515,0.39208132,0.15464842,0.017074265,0.022559628,0.008885726,0.028505743,0.0,0.0063042343,0.0,0.0,0.043105617,0.0,0.0,0.0,0.0,0.0,0.0033041686,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15535435,0.49050653,0.8491469,0.79416114,0.5500147,0.21557821,0.0,0.0,0.0,0.05230715,0.0,0.0,0.0,0.0,0.055395298,0.0,0.014776215,0.0,0.0,0.0,0.007265106,0.0,0.0,0.0,0.0042453706,0.0,0.0,0.0,0.06244278,0.309761,0.6527835,0.7146524,0.62179035,0.31951824,0.012567282,0.0,0.0,0.031125702,0.0,0.01107116,0.0,0.0,0.03793575,0.0,0.024405025,0.0,0.0,0.0,0.019475177,0.0,0.0,0.0,0.06616112,0.022533096,0.04134097,0.0069319233,0.034336016,0.17365475,0.440283,0.6160806,0.67201877,0.4690854,0.12730221,0.0,0.0,0.0,0.0,0.016373895,0.0,0.0,0.012635104,0.010652803,0.027695559,0.0,0.0,0.0,0.03331711,0.0062625706,0.01998014,0.08431754,0.14397934,0.0934909,0.08414783,0.027540222,0.026921675,0.1301451,0.3364385,0.56704086,0.6602272,0.5669307,0.23593235,0.031195737,0.0,0.0,0.0001064986,0.034898043,0.001489237,0.0,0.001908943,0.029631324,0.036338553,0.0,0.0,0.0,0.05171965,0.033922568,0.06308778,0.18331686,0.22581765,0.17505968,0.12729116,0.05289883,0.010889366,0.12397471,0.26091886,0.51333493,0.6273745,0.632599,0.31352174,0.058615446,0.0,0.0,0.0056967884,0.03710424,0.0027632862,0.0,0.0036002398,0.045952477,0.04371667,0.0,0.0,0.0,0.06807356,0.04468786,0.11627579,0.27335554,0.30824178,0.24601719,0.17019501,0.0789168,0.0034222454,0.10641953,0.20576826,0.47954196,0.56271,0.54600906,0.25528297,0.047583774,0.0,0.0,0.0002836585,0.026498802,0.0,0.0,0.01350449,0.05705592,0.053308398,0.017500259,0.0,0.025900222,0.108234815,0.08972979,0.21543857,0.39026612,0.3953607,0.3140983,0.2177163,0.10403536,0.028652258,0.13659191,0.2620703,0.5242409,0.5529089,0.4761021,0.20337582,0.011384174,0.0,0.0,0.0,0.019087262,0.0,0.0,0.022895776],[0.012739487,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015102655,0.19944948,0.47617364,0.6158094,0.6341889,0.4939301,0.4049031,0.19242686,0.059847787,0.015391484,0.0,0.0,0.0,0.0,0.0,0.0,0.008760005,0.0,0.002168402,0.0,0.0,0.0,0.0050616413,0.0,0.0,0.0,0.0,0.0,0.10059485,0.35703167,0.6202566,0.65221554,0.555091,0.40757573,0.30939642,0.14996916,0.06157189,0.011147238,0.0,0.0,0.0,0.0,0.0,0.0,0.007434383,0.0,0.0015538931,0.0,0.0,0.0,0.019137181,0.0,0.0,0.0,0.0,0.0,0.16912432,0.49589008,0.7961527,0.77976733,0.56161314,0.3266052,0.18669656,0.07226833,0.05760531,0.018959492,0.0017184615,0.0,0.0,0.0,0.0,0.0,0.008450009,0.0,0.0074119642,0.0,0.0035699755,0.0,0.026921302,0.019211762,0.0,0.0,0.0,0.0,0.06854184,0.4108823,0.7774271,0.91318107,0.6909253,0.3479188,0.08210468,0.0,0.039790027,0.020769015,0.0,0.0,0.0,0.0,0.0,0.0,0.007074952,0.0,0.0,0.0,0.0,0.0,0.025148116,0.027629614,0.0,0.0,0.0,0.0,0.0,0.18982011,0.5739698,0.9068685,0.82034117,0.43885297,0.057155,0.0,0.007932395,0.038343564,0.0089224875,0.0028382838,0.03895185,0.030466825,0.0,0.0,0.007305503,0.0,0.0,0.0,0.0,0.01258453,0.024635248,0.042863816,0.0,0.0,0.0,0.0,0.0,0.080245644,0.38554442,0.7406473,0.83293426,0.55011463,0.1825274,0.0,0.0,0.0,0.0,0.0024579763,0.017269075,0.011875793,0.0,0.0,0.0054469258,0.0,0.0,0.0,0.0,0.028297283,0.024291039,0.06214875,0.011984259,0.0,0.029220738,0.0,0.0,0.01780238,0.18612131,0.49597216,0.7962782,0.6764273,0.38209897,0.0,0.0,0.0,0.0,0.0029530972,0.0,0.0,0.0,0.0,0.005112335,0.0,0.0,0.0,0.0,0.033918478,0.022943027,0.09407935,0.09493205,0.07354085,0.100415304,0.0,0.0,0.0,0.092203595,0.3587528,0.77020246,0.7422232,0.5162147,0.03466539,0.0,0.0,0.0,0.0028982013,0.0,0.0,0.0,0.0,0.0055636168,0.016798541,0.0,0.0,0.009699665,0.040071234,0.023367941,0.14570591,0.21948795,0.18889207,0.17686526,0.040735953,0.0,0.0,0.048729464,0.2791334,0.74272865,0.7578914,0.62032175,0.08619508,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013260506,0.034010738,0.028282732,0.056048833,0.051191308,0.043780603,0.027582996,0.15712935,0.29317033,0.27175206,0.22916731,0.11846277,0.057881624,0.0031725913,0.013990812,0.23235992,0.7055734,0.7281626,0.57973546,0.04174108,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022299983,0.04586,0.05903448,0.10590857,0.10192606,0.08328955,0.06921178,0.18880658,0.37186068,0.36462575,0.27181667,0.1588348,0.085278526,0.04877007,0.021100536,0.25761428,0.7190726,0.76069176,0.56468767,0.007048361,0.0,0.0,0.0,0.0052983165,0.0,0.0,0.0,0.0],[0.0,0.019870326,0.0047471225,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09209444,0.22499564,0.51034164,0.7794081,0.8276619,0.6728916,0.4470722,0.33314794,0.09116833,0.0,0.016833872,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.024705283,0.023539476,0.0019141883,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10636464,0.2729724,0.6114876,0.860831,0.82588613,0.56499046,0.33765113,0.25207153,0.10203994,0.018376134,0.025424533,0.0,0.0,0.0,0.0,0.0,0.004577562,0.0,0.015875876,0.010107234,0.011477947,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09744063,0.27111503,0.6420566,0.9285847,0.89072853,0.5090582,0.22947237,0.13986073,0.08106041,0.048079424,0.05245144,0.022878744,0.0,0.0,0.0,0.0,0.010120861,0.0,0.0106517,0.00042930245,0.01535736,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023429446,0.1477584,0.5182765,0.8905072,0.96909183,0.5793537,0.23365578,0.015414283,0.013090387,0.010291539,0.024939843,0.0070163757,0.0,0.0080556795,0.0,0.0,0.015109792,0.0,0.0,0.0,0.0033547878,0.0,0.0,0.0007702708,0.002086699,0.0,0.0,0.0,0.0,0.0,0.31268072,0.74410546,0.98898304,0.7281229,0.34133142,0.0,0.0,0.0,0.019355185,0.014826611,0.02398602,0.073850796,0.02291049,0.0007157326,0.010015979,0.0,0.009874918,0.0020776987,0.01036834,0.003265068,0.0076631755,0.005805239,0.01688654,0.0,0.0,0.00035746396,0.0,0.0,0.19284372,0.5505911,0.89034384,0.8429802,0.50217223,0.09361328,0.0,0.0,0.0,0.027268812,0.0037898272,0.043203227,0.011399306,0.0,0.010842137,0.0,0.004777938,0.0032993704,0.0041762292,0.01151105,0.028484218,0.01207383,0.04751972,0.013975203,0.04956036,0.027299553,0.0,0.0,0.10275073,0.33637655,0.69603103,0.9013318,0.69079673,0.2744184,0.0,0.0,0.0,0.045267157,0.0,0.023760393,0.0043557137,0.0,0.0,0.0,0.008964345,0.02282793,0.015975036,0.030034795,0.04695589,0.03150735,0.081439316,0.09114256,0.13444142,0.051517956,0.0,0.0,0.051208295,0.22962704,0.5649257,0.9306882,0.825934,0.44579577,0.0,0.0,0.0,0.042440146,0.0,0.025992148,0.0052870214,0.0,0.0052433014,0.0,0.010833047,0.04680372,0.049318403,0.065540165,0.07054028,0.049711898,0.13544163,0.2017627,0.2069217,0.07603873,0.011605389,0.016060777,0.018650569,0.18499014,0.47325093,0.9469193,0.91889143,0.5842009,0.052185126,0.0,0.0,0.016918682,0.0,0.020978913,0.0027144551,0.0,0.018692404,0.0,0.0059404,0.060094744,0.08809696,0.107583165,0.09162678,0.05529117,0.13893858,0.24615654,0.23736113,0.11344057,0.08072321,0.050870456,0.0043893456,0.13859667,0.38773036,0.93390363,0.9072877,0.5767632,0.05262979,0.0,0.0,0.015444405,0.0,0.030906022,0.0,0.0,0.023268886,0.0,0.0053055584,0.059117533,0.102471784,0.14883217,0.13753049,0.091294125,0.1486744,0.28687677,0.26930952,0.13538751,0.09872953,0.056461222,0.000540331,0.11118762,0.34427488,0.9505024,0.94367194,0.56070614,0.045443296,0.0,0.0,0.028408453,0.008047618,0.031013057,0.0,0.0,0.023327932],[0.028152034,0.014376491,0.026697755,0.0,0.0,0.0,0.0,0.019781291,0.0,0.0,0.022923551,0.2496556,0.4965611,0.8661067,0.9890029,0.90604365,0.68773794,0.2987998,0.21610254,0.0,0.0,0.0,0.0,0.0,0.0,0.03129281,0.052148968,0.0,0.02719406,0.028450586,0.042869262,0.0,0.0,0.0,0.0,0.026010305,0.0,0.0,0.021075457,0.21636525,0.47770345,0.88962543,1.0,0.91780764,0.60244113,0.20057541,0.13041906,0.0,0.0,0.0,0.0,0.0,0.0,0.00851392,0.040507227,0.0,0.0054416507,0.020005777,0.053349137,0.0011467636,0.0,0.003816709,0.0,0.034230307,0.0,0.0,0.0,0.15042359,0.39003408,0.8211426,1.0,0.9081415,0.52030885,0.09565257,0.060707875,0.012749493,0.037598945,0.016428463,0.009444885,0.0,0.0,0.0,0.00891979,0.0,0.0,0.009821802,0.056911983,0.010329515,0.0,0.01340352,0.0001347959,0.041456066,0.0,0.0,0.0,0.04156278,0.21019495,0.66327053,0.98295236,0.92522365,0.5417692,0.06481887,0.0,0.0,0.030646361,0.021910533,0.009141982,0.0039675683,0.0011819601,0.0,0.008620344,0.0054352283,0.0,0.0,0.03241262,0.005033821,0.0,0.020107917,0.0021968782,0.04615698,0.0,0.0,0.0,0.0,0.09022637,0.49021238,0.85729307,0.95117116,0.657064,0.15841816,0.0,0.0,0.0,0.016192302,0.02670502,0.08381274,0.07704407,0.020228982,0.014358923,0.018361732,0.0,0.0,0.030119248,0.016778246,0.0,0.017257273,0.012729816,0.045771003,0.0,0.0003786534,0.0,0.0,0.034482703,0.33241466,0.69272727,0.89986545,0.7745081,0.3443858,0.04014927,0.0,0.0,0.0,0.010038711,0.06075692,0.060810782,0.021467075,0.017483033,0.013971023,0.0,0.0,0.0,0.014164567,0.0,0.011832871,0.02737917,0.05084382,0.01643189,0.042036742,0.030178681,0.026605457,0.003164649,0.1492412,0.441859,0.7816124,0.88979477,0.5882971,0.18430305,0.0,0.0,0.0,0.0,0.03397087,0.035851747,0.0103511065,0.010537572,0.01105053,0.0,0.0,0.0,0.019982412,0.0,0.018569544,0.042721413,0.06624088,0.07362609,0.11478154,0.0854391,0.04243978,0.0,0.044041432,0.28317258,0.7225566,0.98363775,0.7912806,0.30107075,0.0,0.0,0.0,0.0,0.03223075,0.04661128,0.02504374,0.021772705,0.019011177,0.0,0.0,0.0,0.030117609,0.0,0.031606145,0.061714172,0.1187676,0.15125439,0.17831615,0.12632117,0.068449415,0.019062445,0.0,0.18635616,0.65673935,1.0,0.927165,0.39563733,0.0,0.0,0.0,0.0,0.019745052,0.06175954,0.03343334,0.028186038,0.026115522,0.0,0.0,0.0,0.046032757,0.0,0.03776534,0.06740376,0.13847736,0.18445183,0.20556939,0.1536406,0.08964166,0.06264665,0.0,0.1121462,0.5345846,0.9573311,0.945963,0.3978501,0.0,0.0,0.0,0.0,0.027995273,0.08336671,0.025801055,0.02636996,0.02702786,0.0,0.004664317,0.0,0.041961715,0.0,0.05693674,0.07147661,0.15137109,0.21120754,0.21908686,0.15637895,0.09731186,0.0710894,0.0,0.058670096,0.46649373,0.9515862,0.97068274,0.41107494,0.009485289,0.0,0.0,0.014430545,0.03609363,0.08632468,0.008583158,0.016235337,0.025175385],[0.012329377,0.014788039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022797309,0.08369528,0.40441656,0.6620324,1.0,1.0,0.9376641,0.47883135,0.18924823,0.052942112,0.0,0.0,0.0,0.0044678748,0.0,0.0,0.054218873,0.014793649,0.0,0.010411479,0.02365829,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004429117,0.02741523,0.32769966,0.6160938,1.0,1.0,0.938771,0.3875171,0.087614335,0.0,0.0,0.0,0.0,0.02066163,0.0,0.0,0.044568643,0.007905915,0.0,0.0,0.019568227,0.005835913,0.0,0.0,0.0,0.00012212992,0.0045713633,0.0,0.0,0.0,0.20608467,0.48445165,1.0,1.0,0.9032903,0.29906335,0.007906802,0.0,0.020015232,0.0,0.0060091913,0.039552562,0.0,0.0,0.016155638,0.0,0.0,0.0,0.0122149885,0.015993342,0.0,0.0,0.0,0.009586923,0.013326339,0.0,0.0,0.0,0.03242825,0.2717036,0.8484049,1.0,0.87062716,0.2888415,0.0,0.0,0.0,0.030511998,0.020456873,0.030342989,0.0,0.0,0.0094331205,0.012927569,0.0,0.0,0.0,0.00068101287,0.0,0.0,0.0,0.009325407,0.019540682,0.0,0.0,0.0,0.0,0.14567219,0.6782107,1.0,0.8912713,0.3975932,0.0,0.0,0.0,0.029724509,0.01914166,0.033811875,0.02961561,0.054678425,0.031008951,0.047969535,0.00429292,0.0,0.0,0.0118345395,0.0,0.0,0.0,0.0055749565,0.010506429,0.0,0.0,0.0,0.0,0.056555383,0.5204092,0.8905241,0.8841945,0.5357599,0.12121996,0.0,0.0,0.0,0.022222884,0.0,0.007216163,0.055964038,0.026494414,0.0462844,0.0024628788,0.0,0.0,0.0,0.0,0.0,0.0,0.007430561,0.0026585907,0.0,0.009477347,0.012807377,0.0,0.012024112,0.3347301,0.6581703,0.8385775,0.7412234,0.35963053,0.07878393,0.0,0.0,0.0074189007,0.0,0.0,0.047150277,0.006742567,0.037382364,0.0053859055,0.0,0.0,0.0,0.0056739002,0.0,0.0,0.027211778,0.0,0.0036230683,0.05755475,0.07112257,0.05553157,0.027194768,0.23149438,0.51465076,0.815436,0.90826017,0.5556466,0.16113624,0.0,0.0,0.004129216,0.0,0.0,0.064472616,0.004280135,0.03991904,0.015720658,0.0,0.0,0.0,0.018346377,0.0,0.02264107,0.058380827,0.025464937,0.038535222,0.090639696,0.07929962,0.10545909,0.051061034,0.14893629,0.41089022,0.757209,1.0,0.69945717,0.24354143,0.0,0.0,0.011657149,0.0,0.001092121,0.08631844,0.0,0.040674232,0.022397034,0.0,0.010887735,0.004081458,0.039292872,0.0,0.046245478,0.074128866,0.036918707,0.064961165,0.105400994,0.0754942,0.12266618,0.049474113,0.083449334,0.2844916,0.638954,1.0,0.7496932,0.26773596,0.0,0.0,0.025104553,0.0,0.026594289,0.09896742,0.0,0.04200358,0.020085685,0.0,0.016899511,0.0,0.040576585,0.0,0.071979985,0.087015584,0.05462774,0.09545399,0.10978866,0.061228693,0.123278484,0.07418311,0.056591913,0.20923917,0.56780744,1.0,0.787865,0.31184787,0.0,0.0,0.030397832,0.0,0.031555407,0.07741523,0.0,0.019893847,0.014146514],[0.022916578,0.0,0.0,0.0,0.0,0.0,0.017215848,0.052505486,0.013511643,0.039499797,0.1204089,0.3808477,0.7096659,0.98541254,1.0,0.8146042,0.54501283,0.21120064,0.10003789,0.0,0.0,0.0,0.0,0.0,0.024831325,0.019290425,0.0,0.0,0.025526471,0.0,0.0,0.0,0.0,0.0,0.019716762,0.040655926,0.00839632,0.0060015395,0.056711942,0.3192939,0.67387265,1.0,1.0,0.83016396,0.42918056,0.09491394,0.020864978,0.0,0.0,0.0,0.0,0.0,0.024386495,0.01762423,0.0,0.0,0.01804161,0.0025122166,0.0,0.0,0.0,0.0,0.022049844,0.0398198,0.009674236,0.0,0.014134809,0.21913436,0.5424191,0.98426116,1.0,0.8482094,0.36318296,0.04249513,0.0,0.0,0.019116797,0.021395355,0.005668521,0.0,0.016747817,0.0053393543,0.0007956624,0.0021137148,0.011850938,0.008071013,0.0,0.0,0.0,0.0,0.018851496,0.024962015,0.0039070398,0.0,0.0,0.05165439,0.28483447,0.77929276,1.0,0.80873126,0.31028235,0.015390329,0.0,0.0,0.032770246,0.047493644,0.02349621,0.0,0.037750408,0.012576655,0.024867117,0.008123934,0.007245548,0.0077270567,0.0,0.0021667778,0.0,0.0,0.031945996,0.016478948,0.0064262897,0.009118557,0.0,0.0,0.098505616,0.611811,0.8919489,0.7678949,0.310881,0.0052089244,0.0,0.0,0.008210458,0.043717176,0.025424622,0.00013053417,0.07650789,0.036874495,0.030818112,0.006574288,0.011693001,0.004555434,0.0,0.0,0.0,0.0,0.019450545,0.005878754,0.0,0.0,0.0,0.0,0.07654923,0.50216717,0.81222624,0.7643077,0.3780126,0.056590177,0.0,0.0,0.0,0.029496863,0.012276538,0.0077939034,0.061786987,0.030911915,0.019823842,0.0036673993,0.010522716,0.0,0.0,0.0,0.0,0.000813812,0.02852492,0.008401647,0.0,0.005851187,0.0014741719,0.0,0.072149955,0.4022236,0.6864259,0.7670396,0.5119328,0.19241235,0.00511913,0.0,0.0,0.004760042,0.0,0.019918919,0.04965116,0.017824031,0.008021131,0.0056400597,0.011003926,0.0,0.0012716502,0.0,0.0018621981,0.013679586,0.030259944,0.009820238,0.0,0.047356337,0.06413005,0.024900608,0.14581582,0.37246972,0.61122686,0.7792899,0.6240832,0.31138393,0.030877396,0.0,0.0,0.0,0.0,0.025228038,0.045829922,0.023447536,0.022025287,0.02342213,0.005156979,0.004214868,0.011286952,0.0,0.0078643635,0.012981296,0.034784757,0.004042402,0.0,0.08114109,0.12124506,0.11738141,0.23080505,0.3581121,0.5259545,0.73120326,0.6771167,0.37693778,0.061834842,0.0,0.0,0.0,0.0,0.020785168,0.04172387,0.021311782,0.04495973,0.04224574,0.005169049,0.0143452585,0.032654934,0.0,0.0080398545,0.00619334,0.031513587,0.0030274987,0.00076007843,0.115145706,0.16042987,0.16607931,0.25612092,0.29469365,0.4083113,0.6349314,0.685075,0.42386425,0.088865235,0.0,0.0,0.0,0.0,0.020010456,0.055912837,0.03497845,0.069570065,0.051877387,0.0018863827,0.0,0.022058673,0.0,0.015739404,0.015871331,0.0490805,0.033146866,0.034228712,0.15859048,0.19881551,0.18924263,0.26191434,0.24652947,0.33487445,0.58675563,0.75151104,0.5158923,0.15848774,0.0,0.0,0.0,0.0,0.0131756365,0.0424079,0.028265893,0.07587631,0.061062455],[0.030609734,0.006386541,0.005643323,0.0,0.0,0.0,0.05928296,0.0,0.0,0.0,0.009924047,0.1807592,0.5762798,0.7919178,0.7991104,0.7011395,0.3534579,0.24797583,0.19855365,0.034912832,0.01946909,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03362885,0.001764223,0.002836585,0.0,0.0,0.0,0.051521868,0.0,0.0,0.0,0.0,0.16643956,0.60834193,0.89259374,0.9304373,0.76372135,0.2702266,0.0785972,0.07968815,0.0,0.04091747,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032899857,0.0034566224,0.011046678,0.0,0.0,0.0,0.04390189,0.0,0.0,0.0,0.0,0.11537081,0.53376734,0.8864799,1.0,0.7975057,0.23321977,0.0182885,0.03338463,0.0,0.060022585,0.0,0.0,0.0,0.0,0.0,0.0012191087,0.0,0.030552022,0.002343744,0.015131183,0.0043548793,0.0077364445,0.0,0.026486702,0.0036908388,0.0,0.0,0.0,0.022140302,0.33333975,0.81028986,1.0,0.7270341,0.19143438,0.0,0.0,0.0,0.08772731,0.014169894,0.027608,0.012418866,0.0064615607,0.01555907,0.017206132,0.0,0.024703525,0.0,0.013185017,0.0058501214,0.010235108,0.0,0.022419773,0.01188083,0.0,0.0,0.0,0.0,0.16343161,0.7521879,0.9762142,0.6603702,0.16820899,0.0,0.0,0.0,0.10611349,0.012509309,0.040096253,0.042277247,0.050212517,0.054643914,0.030883156,0.0,0.018479012,0.0,0.0044678897,0.0,0.008354023,0.0,0.017743565,0.0052212477,0.0,0.0,0.0,0.033165142,0.18341501,0.7098295,0.9064118,0.66323406,0.22688323,0.0,0.0,0.0,0.0687052,0.025488734,0.03561856,0.035025798,0.046706147,0.048126712,0.035406105,0.0,0.011703096,0.0,0.008928381,0.0,0.021501243,0.0,0.00763949,0.002575636,0.0,0.034234606,0.0389665,0.09363394,0.21268865,0.6681623,0.80973136,0.7021657,0.3467482,0.02805452,0.0,0.0,0.01920756,0.043990932,0.053936683,0.04044336,0.051659957,0.035866447,0.041026272,0.009359643,0.004419431,0.0,0.015205391,0.0,0.0077410564,0.008211404,0.0,0.002477616,0.0010357052,0.114043884,0.13119903,0.19155194,0.2929445,0.645602,0.7435852,0.72817904,0.45449567,0.07460038,0.0,0.0,0.0,0.05313641,0.08237245,0.049505614,0.056140594,0.03976251,0.07172921,0.032720298,0.0,0.0,0.02175378,0.0,0.0,0.011782214,0.0,0.004672453,0.0,0.16838169,0.21280763,0.28488708,0.35973382,0.62019867,0.6373606,0.7020601,0.52432454,0.12203159,0.0,0.0,0.0,0.050366327,0.10233584,0.058879167,0.05211386,0.045281634,0.10914931,0.063188076,0.0,0.00050002337,0.04221409,0.0,0.0,0.015477203,0.0,0.017044328,0.016931914,0.23257288,0.26604182,0.34333223,0.38749522,0.5383509,0.4945231,0.65478873,0.5874588,0.18605356,0.0,0.0,0.0,0.04945866,0.11041963,0.073829494,0.054268107,0.05927764,0.13801694,0.08391532,0.0,0.0,0.03594242,0.0,0.0,0.030229539,0.021532528,0.08517146,0.07996982,0.3117235,0.31380042,0.36971033,0.40519035,0.4666447,0.38805556,0.65729666,0.6942051,0.31416285,0.046188407,0.0,0.0,0.043435603,0.09962173,0.07775216,0.04413455,0.050615825,0.14889257,0.101269305],[0.0,0.041873254,0.03238573,0.0,0.0,0.04813472,0.034367904,0.0,0.0,0.0,0.0,0.12084604,0.3884008,0.5949968,0.6232832,0.5044802,0.39591134,0.3022453,0.23712459,0.07640982,0.0037282705,0.0,0.0,0.0,0.0045529455,0.025858447,0.0,0.0,0.0,0.036786877,0.030439004,0.0,0.0,0.039037324,0.023631014,0.0,0.0,0.0,0.0,0.14532152,0.4489575,0.79466856,0.85893613,0.6733938,0.32964072,0.12492415,0.09672577,0.031746507,0.011601061,0.0,0.0,0.0,0.0,0.028031632,0.0,0.0,0.0,0.031525068,0.033175707,0.0,0.0,0.03794241,0.028915316,0.0,0.0,0.0,0.0,0.078421995,0.39947093,0.8984441,1.0,0.8344188,0.31815994,0.04568235,0.040435404,0.020540133,0.03710203,0.010330647,0.015420742,0.0,0.0,0.031461462,0.0026188642,0.0,0.0,0.028032497,0.04219055,0.012969196,0.0,0.038469076,0.04097341,0.0,0.0,0.0,0.0,0.011326812,0.30871814,0.86884695,1.0,0.72398466,0.2133286,0.0,0.01912655,0.038168125,0.06372233,0.035567716,0.056356557,0.0,0.0,0.028049745,0.012186445,0.0,0.0040147007,0.025485247,0.049907617,0.018287003,0.0,0.0,0.023862049,0.0,0.0,0.0,0.0,0.0,0.23106578,0.75573426,0.8833602,0.538717,0.102175824,0.0,0.009479053,0.043888934,0.061212048,0.0374035,0.06436242,0.021607906,0.05696751,0.046107166,0.010939211,0.0,0.003194496,0.015200242,0.032764032,0.016899735,0.0,0.0027145147,0.031047292,0.0,0.0,0.0,0.0,0.0863277,0.33426455,0.761225,0.8315667,0.46516347,0.082880005,0.0,0.0016628355,0.028738923,0.04530081,0.037756488,0.06266742,0.03207551,0.06974743,0.06844284,0.028040215,0.0,0.002530545,0.0151927695,0.030086555,0.02158995,0.0,0.0,0.018893115,0.0,0.013352722,0.042091317,0.119341,0.21983333,0.45456988,0.71839947,0.7427317,0.38727832,0.106787935,0.0,0.0050155967,0.019329317,0.03670215,0.04162611,0.059510484,0.044486426,0.08604004,0.099287495,0.04616174,0.0,0.004063219,0.002495706,0.009690985,0.019012593,0.0,0.0029286444,0.014391668,0.0,0.036223322,0.096482724,0.24400595,0.3317493,0.53451663,0.66348064,0.66740936,0.3152955,0.14233436,0.015622921,0.008651376,0.015346713,0.032746717,0.05188696,0.059769087,0.057541296,0.110158235,0.14153196,0.08819211,0.016342267,0.0038548857,0.0,0.0,0.008889124,0.0,0.004197955,0.0061949864,0.0,0.089718446,0.17599696,0.37262917,0.4535631,0.6221296,0.62623996,0.57995045,0.24216136,0.16075625,0.043505467,0.022946663,0.011570841,0.036119744,0.060397737,0.06475373,0.066012,0.13743539,0.17502753,0.13152605,0.047518805,0.009763606,0.0,0.0,0.0,0.0,0.019967593,0.01644653,0.035578847,0.17886148,0.28330928,0.4833815,0.5263552,0.65987843,0.5782606,0.49908185,0.20128077,0.19024262,0.07621687,0.047482386,0.0072731674,0.052629903,0.06663857,0.07404072,0.068491235,0.15608007,0.19295788,0.14897591,0.06419341,0.0,0.0,0.0,0.0,0.0,0.05588577,0.0694023,0.12261398,0.3189165,0.41023856,0.58946526,0.5599245,0.66409963,0.5691897,0.47684473,0.25209206,0.3178283,0.20719898,0.12580852,0.019978635,0.06276276,0.07032491,0.07226083,0.067977734,0.15699342,0.19634691,0.15358049,0.077543356],[0.006381996,0.0050728023,0.015454732,0.0,0.0,0.06446623,0.055422664,0.0019366145,0.036642134,0.0,0.008801706,0.07182317,0.32664835,0.5113806,0.45955062,0.42389417,0.31869698,0.33985543,0.2953478,0.115496695,0.022211008,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011867046,0.007371448,0.011469036,0.0,0.0,0.04195694,0.023150057,0.0,0.018447757,0.0,0.032160245,0.13163377,0.42423868,0.7470807,0.750989,0.5735911,0.26212505,0.151477,0.12191976,0.044497415,0.019486949,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018324122,0.0043549687,0.0072817504,0.0,0.0,0.028358206,0.021641627,0.0,0.0156404,0.0,0.018728785,0.100271665,0.45527464,0.91829896,1.0,0.72519726,0.24430576,0.031033754,0.025408179,0.0,0.017175198,0.0,0.0,0.0,0.0,0.0,0.0017843992,0.0,0.024860732,0.0046070814,0.013470672,0.0,0.0,0.023974277,0.041920282,0.0,0.00093096495,0.0,0.0,0.042954832,0.4619782,0.9636691,1.0,0.6047307,0.13194542,0.0,0.008164771,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020764343,0.005973421,0.03163635,0.0045582056,0.019136705,0.007643737,0.0,0.0006714165,0.03795869,0.0,0.009338349,0.0,0.0,0.0109463185,0.4373771,0.877678,0.8465191,0.3998717,0.008383572,0.0,0.017052777,0.0,0.0,0.036555864,0.041612476,0.0062298775,0.030780762,0.005017221,0.046670288,0.0,0.03435123,0.0,0.016390346,0.0,0.0,0.0,0.047344096,0.0,0.0,0.0,0.014620386,0.120794624,0.4926386,0.8527878,0.769951,0.31148276,0.0,0.0,0.011484988,0.0069774836,0.017586164,0.03160052,0.043550484,0.011383593,0.047595352,0.036077492,0.043457508,0.0,0.031011157,0.0,0.02107346,0.0,0.0,0.0,0.041818872,0.0,0.0,0.020996831,0.11019328,0.29176688,0.5408532,0.77476686,0.6550766,0.24047583,0.0,0.0,0.0038090348,0.040780224,0.04687403,0.024044447,0.058431633,0.0349465,0.06953553,0.07094371,0.04467023,0.0,0.027754955,0.0,0.011941895,0.00076434016,0.0332957,0.0,0.05007092,0.0,0.0,0.09153722,0.23169032,0.44089103,0.5850109,0.71132797,0.55235267,0.16477707,0.0,0.0,0.0,0.06417896,0.05384905,0.01578629,0.06992276,0.061420247,0.101923175,0.12142207,0.06124056,0.0,0.023866154,0.0,0.005542293,0.0,0.07325639,0.0074585676,0.07421828,0.0064368322,0.022845872,0.21791482,0.4037919,0.604145,0.662526,0.6665914,0.46197516,0.10894427,0.002664268,0.011071011,0.02253171,0.0898781,0.058956683,0.01786387,0.09235813,0.076481335,0.12613505,0.16555062,0.08103326,0.015788987,0.018745512,0.0,0.0,0.0,0.075534865,0.027027525,0.105252184,0.08039032,0.13860454,0.37964624,0.58050245,0.7349349,0.73295164,0.6362302,0.42870337,0.10106258,0.05242517,0.037329577,0.05325234,0.10376996,0.05177687,0.031094827,0.11839674,0.0872485,0.15488389,0.19069606,0.07818295,0.023970388,0.0,0.0,0.0,0.0,0.08749385,0.043284178,0.15363982,0.1911508,0.293329,0.54846364,0.72852534,0.81689346,0.7739245,0.63848495,0.4578423,0.1749784,0.19235578,0.17946474,0.1298925,0.1231303,0.05871658,0.0390668,0.13932367,0.10109327,0.17776512,0.2116254,0.07978156,0.031531215],[0.010566004,0.0,0.0050904304,0.0067466423,0.007911161,0.014139906,0.020718724,0.00737188,0.04691524,0.04858478,0.09791188,0.10958543,0.22164814,0.2462114,0.19032665,0.15390146,0.3264274,0.38498133,0.3604983,0.16188543,0.07022345,0.0,0.0,0.0073130727,0.0,0.0,0.0,0.0,0.010473162,0.0,0.0016759634,0.0039512813,0.011711039,0.014134817,0.015990853,0.004517138,0.05995512,0.052123487,0.103978425,0.18727107,0.4022854,0.57938015,0.60107625,0.45681834,0.33825934,0.23547027,0.14239052,0.0,0.0,0.0,0.0,0.02390252,0.0,0.0,0.0,0.0,0.009586982,0.0,0.011393018,0.0,0.0102066025,0.028384805,0.018562607,0.0,0.046645954,0.0,0.045936763,0.21134177,0.55043525,0.8804198,0.95220375,0.64905125,0.22971758,0.059483483,0.030237712,0.0,0.0,0.0,0.0,0.018155873,0.0,0.0,0.0,0.0,0.00859677,0.0,0.03726133,0.009050414,0.009533927,0.033849552,0.016598925,0.0,0.04152502,0.0,0.0,0.23510736,0.68088746,0.99994177,0.9418037,0.49627972,0.04757542,0.0,0.0,0.0,0.0,0.0,0.0,0.0155977085,0.0,0.0028483719,0.0039700717,0.0024405867,0.0074501187,0.002123326,0.042518996,0.010013729,0.006350234,0.031883284,0.016312756,0.008922368,0.048444845,0.0,0.0,0.24272487,0.7194946,0.9859936,0.7872979,0.2799943,0.0,0.0,0.0,0.0,0.002684176,0.02713772,0.017925441,0.026858203,0.0,0.000085130334,0.009778,0.0,0.007768959,0.0017550886,0.04424788,0.009973325,0.0,0.030000106,0.019954816,0.010452665,0.023505747,0.0,0.11187227,0.39955604,0.78887963,0.8542856,0.5702535,0.13964032,0.0,0.0,0.0,0.013525911,0.03060998,0.036770202,0.031706907,0.02782029,0.020481497,0.024540171,0.022282667,0.008108228,0.0052800328,0.0,0.043274857,0.012979962,0.0,0.018901743,0.011145949,0.0,0.0005785227,0.039562844,0.29655892,0.59388065,0.807143,0.66160625,0.3725953,0.043780558,0.0,0.0061046258,0.0,0.037229694,0.06887767,0.056079358,0.049915954,0.038343385,0.041829117,0.042519644,0.022082575,0.009899162,0.005589202,0.0,0.041931644,0.024796627,0.0,0.013959467,0.012891255,0.0,0.014332093,0.124889284,0.46852642,0.7278201,0.77363086,0.47687143,0.22517881,0.0,0.0,0.023606852,0.0,0.053272925,0.09620645,0.07388382,0.08924475,0.077872016,0.08794586,0.08840303,0.05219216,0.02762761,0.013408013,0.0,0.042717293,0.0486309,0.01364857,0.022955887,0.020043254,0.0,0.09749599,0.24548021,0.64417666,0.8687681,0.7600166,0.34498173,0.13449076,0.0,0.00091178715,0.058743067,0.0,0.088358216,0.13858856,0.1040289,0.13594572,0.12523079,0.1436457,0.15110724,0.10029787,0.0529425,0.022084914,0.011843808,0.037980497,0.051587082,0.016731732,0.040541895,0.046193987,0.062165126,0.21391407,0.40209645,0.8065719,1.0,0.7862634,0.32127208,0.13109748,0.0,0.09622383,0.16401674,0.09359531,0.16490676,0.19806908,0.14593597,0.1931215,0.17495841,0.1980033,0.18663873,0.12004739,0.064834066,0.021368422,0.0147717595,0.035167158,0.058288418,0.029804967,0.07615529,0.08715558,0.14308754,0.3481233,0.58000445,0.9299817,1.0,0.80935603,0.35597712,0.1754701,0.088194676,0.28927097,0.38855022,0.28297877,0.2800188,0.26442826,0.18736352,0.22128183,0.2155215,0.2311022,0.2048479,0.13036035,0.073920175],[0.0,0.0,0.0013283342,0.024339005,0.035975806,0.01982946,0.0,0.101238854,0.08654018,0.12837067,0.20036511,0.17735927,0.23756987,0.18203494,0.17443445,0.24745819,0.38489068,0.56475985,0.40406364,0.23801376,0.014219448,0.0,0.0,0.04811731,0.0,0.018059723,0.0,0.0,0.0,0.0,0.0,0.021884829,0.02293311,0.022690803,0.0148435235,0.10186212,0.058828443,0.12732393,0.22151887,0.27387047,0.4083467,0.52849627,0.5535771,0.53744656,0.38204712,0.38852346,0.1648116,0.022914305,0.0,0.0,0.0,0.049071275,0.020948887,0.0,0.0,0.0,0.0021790713,0.0,0.0,0.01601506,0.019669674,0.031820685,0.020415701,0.065678455,0.02554334,0.05150859,0.16643101,0.32770544,0.58915406,0.90244967,0.86366546,0.611557,0.18325585,0.12543765,0.044290856,0.0,0.0,0.0,0.004576847,0.02370809,0.018556714,0.0,0.0,0.0,0.005469173,0.010417208,0.0052574575,0.01734192,0.0,0.026518099,0.008946389,0.069849655,0.010226548,0.0,0.10416694,0.34156346,0.76447487,1.0,0.85235727,0.35298365,0.0,0.0,0.0,0.0,0.0,0.0,0.010769084,0.009345509,0.01679577,0.0,0.0030278414,0.0,0.0045193136,0.014507055,0.0,0.01640381,0.0,0.0031974465,0.005720623,0.09940269,0.033421062,0.0,0.116107784,0.32687786,0.81866425,1.0,0.69810736,0.15362579,0.0,0.0,0.0,0.013667211,0.02421087,0.0,0.015623078,0.0,0.023980044,0.0041291714,0.017276652,0.0,0.009222373,0.021587126,0.0,0.0132798925,0.0,0.004269272,0.0105050355,0.07307937,0.010004528,0.026522182,0.25745368,0.5062898,0.82913244,0.8968005,0.44124085,0.057226308,0.0,0.0,0.0,0.053975217,0.06231658,0.01377517,0.016902417,0.006883256,0.040167123,0.022745475,0.034639075,0.011737533,0.010278657,0.026184022,0.0,0.02468194,0.0049359053,0.0,0.0116941035,0.041318938,0.0,0.10278901,0.42460525,0.67692584,0.74818474,0.58858895,0.23797715,0.009541824,0.0,0.0,0.011463523,0.10653129,0.1114904,0.06452275,0.046296887,0.03778758,0.07242584,0.03389223,0.038202904,0.027182914,0.012702338,0.035149507,0.0,0.04512947,0.033956222,0.0,0.018088587,0.018549018,0.0,0.20282152,0.57735807,0.77420723,0.62834865,0.34209996,0.095130414,0.0,0.011721671,0.03910899,0.06934921,0.15698057,0.15441869,0.12597841,0.1211722,0.11552202,0.14151782,0.083277375,0.064898126,0.050603576,0.02229502,0.05618491,0.0,0.06650691,0.07231503,0.0,0.019123845,0.042820327,0.05494359,0.30536014,0.7265155,0.85552824,0.53169364,0.14404559,0.013359211,0.0,0.06973864,0.07902531,0.13723806,0.2400572,0.2148722,0.19442445,0.20029683,0.19696997,0.23196301,0.16867475,0.11372444,0.07912293,0.029431112,0.07098457,0.0,0.06629068,0.09172141,0.0,0.025501788,0.10741547,0.1540901,0.41325587,0.8538151,0.9553926,0.5318795,0.13216391,0.03103587,0.0478047,0.21196473,0.27419555,0.33539557,0.38670236,0.33262813,0.28395152,0.28981483,0.2831661,0.30594254,0.21310678,0.1320457,0.09779667,0.031439632,0.08043121,0.0,0.060758032,0.106589034,0.03211344,0.04335878,0.17402557,0.26303446,0.53517205,0.96204114,1.0,0.5792057,0.19147068,0.079095826,0.15693495,0.41093522,0.5426125,0.5886149,0.5690719,0.43793142,0.35399354,0.347579,0.34204626,0.34622866,0.2289978,0.13745879,0.1132195],[0.015988857,0.0,0.0,0.0,0.019166514,0.00509955,0.044090055,0.050160162,0.09981294,0.18732776,0.13820462,0.17053482,0.16458653,0.16757011,0.2580737,0.43303162,0.66034573,0.6409379,0.46242577,0.08310286,0.0,0.0,0.0,0.06627179,0.1189663,0.098652706,0.06512205,0.0,0.0041167885,0.0,0.0,0.0,0.02466748,0.012196332,0.032155044,0.017022803,0.06752932,0.14614092,0.18448037,0.2876805,0.39666504,0.5536288,0.66107744,0.6945159,0.6262035,0.40136385,0.1685341,0.0,0.0,0.0,0.025999375,0.05681751,0.08429594,0.056656256,0.047007427,0.0005776584,0.0,0.0,0.0,0.0,0.018592812,0.009714372,0.014607623,0.0182423,0.059384584,0.08305851,0.16153869,0.39127064,0.6359046,0.8991842,0.9030874,0.63505346,0.28286707,0.072960466,0.010765925,0.0,0.0,0.0,0.019580953,0.031305015,0.04145994,0.02738399,0.03387645,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0037457645,0.031219967,0.044167906,0.0013518333,0.11482021,0.49651116,0.907262,1.0,0.7342168,0.15688184,0.0,0.0,0.0,0.0,0.0,0.0,0.0031162798,0.0006213486,0.013693541,0.018559977,0.030754738,0.0060660243,0.0,0.0,0.0,0.0,0.0,0.0,0.017566107,0.04040493,0.021957673,0.0,0.090605766,0.5367656,0.9967235,1.0,0.5655834,0.0,0.0,0.0,0.0065825805,0.031954832,0.0030014366,0.011459425,0.00096926093,0.0,0.0,0.011596352,0.03030274,0.008007996,0.0,0.006024927,0.0,0.0007670969,0.0,0.0082920045,0.018984102,0.02067063,0.020643063,0.043578543,0.29066345,0.66668785,0.88077915,0.73117274,0.2720655,0.0,0.0,0.0,0.01605133,0.055805102,0.026503317,0.0091066435,0.0016958117,0.0,0.0,0.010034241,0.030170105,0.019684419,0.00667955,0.018609628,0.021363005,0.006085962,0.0,0.030593812,0.020697206,0.0008018911,0.021039814,0.17073825,0.49692523,0.7308232,0.64926887,0.37678725,0.053075723,0.0,0.0,0.0,0.047589064,0.0897941,0.06272439,0.011140838,0.012623772,0.0,0.0,0.011562765,0.028749332,0.022191614,0.017114393,0.035396747,0.05046905,0.021046996,0.0,0.041971684,0.025714613,0.018394276,0.086308256,0.32580876,0.642708,0.71028525,0.41195935,0.10907566,0.0,0.0,0.0,0.01335413,0.10958197,0.15144697,0.10986304,0.062156543,0.08635451,0.044350997,0.044347554,0.04316877,0.051140048,0.034381144,0.034805775,0.05999005,0.081697494,0.036392547,0.0021732152,0.043815203,0.050772607,0.072090134,0.19563141,0.50772345,0.7648709,0.6812978,0.22662163,0.0,0.0,0.0,0.007549837,0.073387414,0.20220453,0.21828607,0.16673271,0.12617338,0.18859535,0.14617755,0.1280687,0.10311741,0.0947315,0.049479842,0.050190702,0.07757747,0.10060024,0.04278604,0.0037170947,0.047115497,0.08034031,0.11414019,0.27767456,0.6525724,0.88972443,0.71779203,0.18822923,0.0,0.0,0.03275819,0.24224678,0.38639688,0.48468918,0.4056236,0.30905008,0.24093506,0.29476655,0.24103722,0.2144752,0.16868807,0.13288291,0.059907943,0.062175587,0.09468643,0.1263764,0.055831805,0.010171816,0.04329166,0.08897907,0.14172414,0.3433537,0.749179,1.0,0.79588366,0.22666663,0.0,0.016215518,0.19350514,0.5092282,0.7274988,0.8226462,0.6470448,0.43276584,0.30340737,0.33709407,0.28575557,0.2428787,0.19367819,0.15140682,0.0678498],[0.0,0.0,0.0,0.00220941,0.023936763,0.1213823,0.15542753,0.15119621,0.21670276,0.23436424,0.23877394,0.19251978,0.22639695,0.35078898,0.47303516,0.626742,0.7997632,0.63605815,0.28267616,0.0,0.0,0.0,0.0330835,0.04713589,0.0693337,0.04650981,0.05829501,0.0,0.0,0.0,0.0,0.0042855293,0.028905883,0.10163809,0.08383119,0.055969797,0.1094248,0.17034823,0.2283822,0.29596993,0.41774786,0.64052737,0.7583492,0.74053055,0.6614674,0.39349306,0.0688111,0.0,0.0,0.0,0.04332599,0.03273268,0.054636277,0.022317842,0.032442003,0.0,0.0,0.0,0.0,0.0,0.01623714,0.058924258,0.03189832,0.019543447,0.037435435,0.12343054,0.23009828,0.441593,0.6669412,0.89142674,0.87381595,0.55772084,0.24643391,0.11130039,0.0,0.0,0.0,0.0,0.021648765,0.015930742,0.041052192,0.004785508,0.023519777,0.0,0.0,0.0,0.0,0.0,0.0084337145,0.038659662,0.013866022,0.0015158653,0.0,0.048616722,0.23916349,0.58292735,0.9283044,0.9833746,0.6157496,0.0814268,0.0,0.019360125,0.022636428,0.0,0.0,0.0,0.0,0.0047101527,0.040631898,0.0,0.024032094,0.0,0.0,0.0,0.0,0.0,0.0,0.019950628,0.0029599369,0.0,0.0,0.0,0.23780096,0.6018724,1.0,0.92441666,0.42960113,0.0,0.0,0.0,0.04690882,0.00041921437,0.012797326,0.0,0.0,0.0,0.032098517,0.0,0.019235857,0.000094130635,0.0,0.0,0.0,0.0,0.0,0.0,0.0049038976,0.0036570877,0.0,0.11949873,0.41855532,0.6478775,0.8128872,0.58817375,0.17536445,0.0,0.0,0.0,0.033939973,0.02106551,0.023718916,0.0,0.0,0.0,0.031143732,0.0,0.022311464,0.007927686,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.024970353,0.04740274,0.2486684,0.53719604,0.59144956,0.48834932,0.24901974,0.0,0.0,0.0,0.0,0.038819425,0.055688128,0.041566446,0.0,0.0,0.0,0.018737204,0.0,0.011395492,0.0069773346,0.0,0.0,0.003691852,0.0,0.0,0.0,0.0,0.08316991,0.15462361,0.38612604,0.598545,0.4763949,0.17674065,0.0028012544,0.0,0.0,0.0027510077,0.0050979555,0.099721186,0.1189061,0.08587915,0.053460903,0.07715885,0.033171065,0.041263692,0.0,0.01127518,0.0022550374,0.0,0.011173785,0.011716634,0.0,0.0,0.0,0.0,0.16226119,0.2736338,0.525228,0.6576453,0.38455176,0.0,0.0,0.0,0.0,0.0635622,0.08864345,0.22550943,0.20211583,0.16226116,0.14229393,0.20959982,0.12732679,0.10304145,0.03827864,0.024782427,0.0,0.0,0.026081271,0.01610922,0.0,0.0,0.0,0.012177393,0.19843498,0.32288462,0.59017,0.7032185,0.37418705,0.0,0.0,0.0,0.020667307,0.28267002,0.4091608,0.49211043,0.40261048,0.32733175,0.29602128,0.33031696,0.22120586,0.17677465,0.092086874,0.039979495,0.0,0.0,0.042336576,0.02990745,0.0,0.0,0.0,0.012163751,0.21423155,0.3658195,0.63882136,0.76109797,0.43172604,0.0,0.0,0.0,0.12318543,0.5143375,0.75566524,0.807692,0.6319633,0.4538427,0.38101757,0.37200242,0.26247865,0.20632441,0.11616212,0.044257082,0.0],[0.0,0.0,0.0,0.0,0.040462077,0.051895946,0.13655515,0.21538246,0.34133366,0.33648735,0.38259864,0.42574382,0.50089675,0.58789665,0.6945151,0.7854478,0.78474855,0.4542296,0.1913089,0.0,0.0,0.00019676983,0.012267776,0.059122317,0.07272591,0.039823562,0.0037012547,0.0,0.0,0.0,0.0,0.0,0.027330995,0.017747417,0.035415605,0.040549204,0.16062908,0.21903326,0.35377926,0.44701803,0.5350245,0.719061,0.8225244,0.8163891,0.64325327,0.28533733,0.063156515,0.0,0.0,0.00086423755,0.011832781,0.04477319,0.04591187,0.008796163,0.0,0.0,0.0,0.0,0.0,0.0,0.016593672,0.00051657856,0.0,0.0,0.073356934,0.14454694,0.3195004,0.4793768,0.636371,0.81840295,0.80901426,0.5937956,0.2919073,0.051903144,0.0,0.0,0.0,0.0177171,0.014004149,0.024785586,0.0069069266,0.0,0.0,0.0,0.005756192,0.0,0.0,0.0016767681,0.022185884,0.016870037,0.0,0.0,0.011561237,0.11701846,0.32103857,0.5938816,0.8460678,0.8048389,0.52708346,0.2073803,0.074210525,0.0,0.0,0.0022613257,0.0111547485,0.015449263,0.0010191947,0.008897543,0.0,0.0,0.0,0.0,0.006458655,0.0,0.0,0.008998983,0.007123567,0.037228897,0.03209178,0.025099963,0.0,0.09811588,0.31965593,0.6500008,0.9013402,0.7131738,0.29015005,0.0,0.0,0.0,0.0,0.012730524,0.01685626,0.0068273544,0.0,0.013497181,0.0,0.0,0.00086443126,0.0,0.009502023,0.0075072497,0.0,0.019696206,0.01551491,0.0,0.0,0.021359839,0.05747568,0.2412319,0.4976195,0.63544166,0.63614386,0.37054443,0.0807221,0.0,0.0,0.0,0.0040121824,0.024268143,0.026064254,0.019764498,0.0057026222,0.006471589,0.0,0.0,0.000406906,0.0,0.010624059,0.0092396885,0.0,0.0034868866,0.0,0.0,0.0,0.014289059,0.124012046,0.33884743,0.5623419,0.5131154,0.3122101,0.068783164,0.0,0.010060407,0.004899472,0.0,0.01896397,0.03905884,0.050531156,0.04500231,0.023106411,0.0,0.0,0.0,0.0,0.0,0.011294246,0.007755168,0.0,0.0,0.0,0.0,0.0,0.06686832,0.23055154,0.43061435,0.5498253,0.3769359,0.09004377,0.0,0.0,0.049628593,0.054955088,0.025998577,0.07990554,0.074499115,0.07738301,0.109850965,0.078748584,0.0,0.0,0.0,0.0,0.0,0.024442121,0.040001772,0.0,0.0034679621,0.0,0.0,0.020574585,0.1408993,0.32690004,0.49407285,0.5030596,0.28431565,0.0,0.0,0.0,0.088640705,0.11956809,0.10787526,0.20315057,0.11979512,0.11318791,0.185361,0.165859,0.051373966,0.019738555,0.0,0.0,0.0,0.032875314,0.06003479,0.0,0.0064605474,0.0038009882,0.0,0.040878236,0.1819771,0.35847414,0.5008344,0.43675798,0.20997083,0.0,0.0,0.0,0.18920273,0.30716738,0.31591833,0.41384482,0.2957281,0.24197519,0.29049712,0.23705,0.12164244,0.07207236,0.02699358,0.0,0.0,0.03485346,0.079595886,0.022862487,0.017731085,0.020808406,0.0,0.05109273,0.21172327,0.38844693,0.5182815,0.42342895,0.19345996,0.0,0.0,0.0,0.30807853,0.5176677,0.5553556,0.6565589,0.480774,0.33557743,0.34431928,0.2708762,0.16878203,0.10300304,0.03973054,0.0,0.0],[0.0,0.0,0.0048461407,0.0,0.020231038,0.052409485,0.1607126,0.2644664,0.41565377,0.55148745,0.64024,0.71586496,0.7763346,0.7908033,0.83922404,0.83811,0.6012618,0.28339142,0.020870507,0.0,0.0,0.014051445,0.026540652,0.022279099,0.015510388,0.001730755,0.015629828,0.0,0.0,0.0,0.0025573373,0.0,0.019725375,0.006748773,0.045386307,0.1106698,0.24588507,0.42398196,0.5551101,0.6803774,0.76054704,0.83283454,0.89759123,0.7955671,0.4540131,0.13676089,0.0,0.0,0.0,0.0,0.0011129081,0.014210612,0.0,0.0,0.0015595555,0.0045334697,0.0,0.0,0.0014593303,0.0,0.017269768,0.0,0.0,0.03973957,0.13969815,0.3027036,0.45456004,0.6179784,0.7816234,0.82134265,0.7724281,0.5486382,0.1829102,0.006687291,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0015933961,0.0029895306,0.0,0.0,0.0,0.0225285,0.003666252,0.0,0.017818496,0.049718358,0.1771389,0.38631243,0.6736255,0.8952827,0.713633,0.39998358,0.22820786,0.050828636,0.0,0.042089283,0.0,0.012379393,0.0027169287,0.0,0.0,0.004413247,0.009738743,0.0,0.0029872358,0.00044427812,0.0,0.0,0.0,0.012816377,0.031108335,0.0400865,0.030933268,0.047115706,0.18098448,0.4118206,0.7271443,0.91463566,0.5704348,0.123859406,0.0470443,0.0,0.0,0.06251173,0.0,0.029980011,0.0,0.0,0.0,0.0139927715,0.013983011,0.0,0.008590244,0.023667954,0.0,0.0,0.0053207874,0.0076028034,0.011113189,0.036073387,0.071327075,0.16070215,0.33227873,0.5264456,0.6070607,0.58251697,0.21438593,0.0,0.047395453,0.06988087,0.030172668,0.055603534,0.0,0.016085371,0.021027915,0.0015900284,0.0,0.008923493,0.014055185,0.0,0.013405494,0.042045742,0.0,0.0,0.0010541081,0.0,0.0,0.03342157,0.10511389,0.25230783,0.42483592,0.5561802,0.41851497,0.24642089,0.0,0.0,0.08226791,0.09875928,0.02302213,0.027309671,0.01096414,0.020426579,0.050425917,0.021468557,0.0068080276,0.012573227,0.0033976585,0.0,0.01254002,0.045744047,0.0,0.0,0.010313548,0.0,0.0,0.08207364,0.14954466,0.3260923,0.4632879,0.5111934,0.24706283,0.046156712,0.0,0.0,0.14733826,0.16144258,0.07463647,0.03953427,0.018136822,0.027745053,0.10598013,0.05881311,0.0297513,0.0050642192,0.0,0.0,0.008300014,0.064708054,0.016535014,0.0,0.03547968,0.0,0.0,0.14794002,0.18032596,0.37026685,0.4371636,0.41942972,0.13486546,0.0,0.0,0.016333818,0.20237201,0.23467591,0.18858896,0.12667988,0.036708787,0.06619216,0.15922025,0.117219254,0.076548174,0.013545871,0.012656368,0.0,0.0,0.074195266,0.04187964,0.0,0.039803736,0.0077208504,0.0,0.17223242,0.18168923,0.36247396,0.38196683,0.30258745,0.04777985,0.0,0.0,0.05038891,0.23804682,0.32416752,0.29239953,0.22401018,0.12273461,0.11909982,0.20051703,0.14733385,0.11161129,0.033380643,0.025143117,0.0,0.0,0.06978543,0.060636528,0.0,0.048910238,0.018729202,0.0,0.18314563,0.19370595,0.36302564,0.34903228,0.24796839,0.02188623,0.0,0.0,0.077325374,0.30036545,0.4326396,0.4239868,0.3636635,0.22210625,0.1435154,0.2261208,0.1585828,0.13817495,0.04702747,0.028031558,0.0,0.0],[0.0,0.0,0.0,0.0007880181,0.03909739,0.06350468,0.06625453,0.18683304,0.3597574,0.5039915,0.65606886,0.677174,0.6511199,0.62137794,0.5819331,0.44159073,0.30854404,0.11223995,0.0,0.0,0.0,0.0427342,0.00889913,0.00046947598,0.0006235689,0.021448292,0.022495322,0.010658391,0.0,0.0,0.0,0.0,0.037520394,0.024136804,0.0070582703,0.10136878,0.25888953,0.42109144,0.578344,0.6207656,0.6184472,0.6334848,0.6207486,0.43609822,0.2563277,0.056712396,0.0,0.0,0.0,0.040382862,0.003728807,0.0,0.0,0.0,0.0065073445,0.01646816,0.0,0.0,0.0,0.0,0.012589708,0.0,0.0,0.009902336,0.15029848,0.27755195,0.4387529,0.52939165,0.61000735,0.6217177,0.5647982,0.29664284,0.109628424,0.0,0.0,0.0,0.0,0.05224745,0.015320852,0.0,0.0,0.0,0.0,0.0035802126,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0362558,0.14380069,0.34898022,0.5388096,0.6554925,0.50982535,0.30486673,0.09563754,0.0,0.0,0.0,0.0,0.0053263754,0.06229505,0.020290092,0.0,0.015412226,0.0,0.009883888,0.0,0.0,0.0,0.0,0.013809763,0.0054712743,0.013189472,0.0027990788,0.0,0.03037835,0.16642997,0.37615842,0.57485807,0.63311267,0.34008193,0.048254333,0.0,0.0,0.0,0.0,0.0,0.0,0.030801006,0.0,0.006439887,0.03355646,0.0028170198,0.022748187,0.0,0.0,0.0,0.007090956,0.014578491,0.014005154,0.0,0.024384826,0.034055747,0.11432884,0.263767,0.41270554,0.42631418,0.34428418,0.11070853,0.0,0.0,0.0,0.024947807,0.0,0.0,0.0,0.01924698,0.0,0.0,0.018097177,0.01678802,0.021066517,0.0020023882,0.0,0.0,0.013186134,0.012999706,0.013620481,0.0,0.052872777,0.07580045,0.16626875,0.2764594,0.3629594,0.23198043,0.089233845,0.0,0.013052061,0.0073737726,0.0,0.021146588,0.0023970753,0.0,0.0,0.011626154,0.0,0.0,0.001611188,0.01772891,0.00936453,0.00048325956,0.0,0.0,0.024281703,0.01922445,0.0188689,0.0,0.0805234,0.078860685,0.19419199,0.24541774,0.26982516,0.13853961,0.0,0.0,0.052892134,0.067035265,0.049061887,0.037960693,0.027351193,0.00789912,0.002508834,0.010964178,0.004099056,0.0,0.0,0.007959895,0.0,0.0,0.014800139,0.007808812,0.038978808,0.02505058,0.03412252,0.0035782903,0.12724063,0.11211076,0.23016527,0.21810532,0.20980197,0.12397127,0.0,0.0,0.08540105,0.13050784,0.15295097,0.12693594,0.12283845,0.050495505,0.009185769,0.0,0.012628034,0.0,0.0,0.00943362,0.0,0.0,0.02797056,0.019010484,0.04340113,0.0157227,0.03501994,0.014737256,0.14264952,0.12476105,0.22189817,0.13323249,0.10389033,0.084256396,0.0,0.0,0.08693535,0.13436943,0.19163072,0.20215976,0.187458,0.0865276,0.00082345307,0.0,0.023117706,0.018480845,0.0048829466,0.013165936,0.0,0.0,0.030927084,0.02622047,0.04141423,0.0020323396,0.02870892,0.03156349,0.1582797,0.14875707,0.2186638,0.06373463,0.027428485,0.04837721,0.0,0.0,0.099377975,0.15221627,0.25634667,0.32918048,0.29573983,0.13616343,0.0012114942,0.0,0.0368651,0.041447915,0.0030603707,0.0098533705,0.0,0.0],[0.0,0.0,0.0,0.027150638,0.030643046,0.008139841,0.006254025,0.0085418075,0.06925365,0.14498176,0.20150721,0.2229485,0.16318023,0.10142721,0.050525054,0.0,0.0,0.0014091432,0.0,0.0,0.024811998,0.037762403,0.0,0.0,0.007143125,0.013529338,0.006265886,0.0080073625,0.0,0.0,0.0,0.006112568,0.038713872,0.0,0.0,0.0,0.047062963,0.13730407,0.20141882,0.21863484,0.17854089,0.15986758,0.08813381,0.0,0.0,0.0,0.0,0.0,0.045933537,0.0418379,0.0,0.0,0.0,0.01044745,0.000959605,0.014016256,0.0,0.0,0.0,0.0,0.030556224,0.0,0.0,0.0,0.03814719,0.09429682,0.1747713,0.20869264,0.25146526,0.2117685,0.0901182,0.0,0.0,0.0,0.0,0.0,0.046210833,0.05010794,0.0,0.0,0.0,0.0073138773,0.0,0.007039368,0.0,0.0,0.0,0.0,0.0048864484,0.0,0.0,0.0,0.0023059398,0.08675744,0.1560299,0.2728266,0.32167768,0.15807544,0.0,0.0,0.0,0.010339864,0.0,0.0,0.021578886,0.045590825,0.0,0.0,0.005360529,0.018913083,0.0,0.0037836134,0.0,0.0,0.005962044,0.0,0.009649359,0.0,0.0,0.0,0.0,0.14655143,0.19211131,0.3290804,0.28657782,0.049745195,0.0,0.0,0.0,0.017289102,0.0,0.0,0.0,0.0035496354,0.0,0.0,0.02888079,0.03078653,0.0,0.008529797,0.0,0.0,0.0035677701,0.0,0.0038118958,0.0,0.0,0.010519974,0.034864813,0.20444684,0.18262151,0.19454059,0.100430086,0.0,0.0,0.0,0.03041748,0.009861067,0.0,0.0,0.0,0.009489924,0.0,0.0022824258,0.025584623,0.03241591,0.0,0.017629772,0.0,0.0,0.0027990043,0.0,0.0,0.011559464,0.033539824,0.061668575,0.06927076,0.20242417,0.1386515,0.037370905,0.0,0.0,0.015835121,0.018163078,0.0101772845,0.0,0.0120323375,0.0,0.0,0.013603099,0.0,0.0058773756,0.029645257,0.027585208,0.01345817,0.01608289,0.0,0.0,0.0029377788,0.028029732,0.017516837,0.03469477,0.057612814,0.04753694,0.09067534,0.15902552,0.09070308,0.0,0.0,0.00025433302,0.07814002,0.07116549,0.03384468,0.018857442,0.033029154,0.021413378,0.0,0.025620788,0.0,0.00834702,0.029310502,0.0025940537,0.011556245,0.0,0.0,0.0013794601,0.0015586466,0.057629026,0.045555048,0.06709707,0.10168262,0.081634164,0.12528741,0.1469353,0.090005875,0.00372459,0.0,0.026243538,0.13392581,0.13937275,0.11163404,0.120289385,0.119300365,0.08351453,0.028037041,0.041560367,0.02867312,0.015584886,0.035319515,0.0,0.0067612007,0.0,0.015412457,0.01364743,0.0,0.063610174,0.059701897,0.09174782,0.13636062,0.08841078,0.13330008,0.07464333,0.036339194,0.017526045,0.0,0.035577625,0.13348864,0.12818517,0.13892895,0.19901872,0.17248149,0.122225165,0.051199846,0.03956689,0.028814308,0.011326015,0.04256332,0.0,0.0047006607,0.0,0.03139049,0.03537053,0.0018311292,0.060213774,0.051497713,0.11096772,0.18558162,0.12015523,0.13951778,0.015445963,0.0,0.026545636,0.0,0.06203816,0.13132212,0.1396574,0.1934239,0.3048497,0.24463019,0.16885516,0.07556322,0.048069164,0.039551765,0.0030644834,0.03810001,0.0,0.0,0.0],[0.00085674226,0.0,0.0,0.004083574,0.028885089,0.012816571,0.0,0.0,0.0,0.03549765,0.023092575,0.003536567,0.0,0.0,0.0,0.0,0.0,0.026931614,0.0,0.035979196,0.06314362,0.049144097,0.013432071,0.041134708,0.011466965,0.0365676,0.0067233667,0.012568504,0.0,0.0,0.0,0.0,0.023644067,0.008001149,0.0,0.0,0.0,0.033766687,0.02047319,0.011652179,0.0,0.0,0.0,0.0,0.0,0.034546264,0.0,0.036474265,0.049666926,0.0400097,0.012093313,0.035446756,0.0,0.009887382,0.0,0.017302655,0.0,0.0,0.0,0.0,0.0032867193,0.0,0.0,0.0,0.011285812,0.04984981,0.028160565,0.029353581,0.0,0.0,0.0,0.0,0.0,0.008169815,0.0,0.030821852,0.039844394,0.041844763,0.0056851655,0.011347078,0.0,0.0,0.0,0.016329408,0.004722759,0.0028491467,0.0,0.0,0.0,0.002800867,0.0,0.0,0.026222527,0.06488808,0.036239363,0.052387573,0.036476545,0.021108128,0.0,0.0,0.0,0.019635625,0.0,0.010163672,0.018815987,0.031046122,0.0,0.0,0.0,0.0,0.0,0.0093939155,0.007845633,0.010271631,0.0,0.0,0.0009369552,0.04539924,0.0,0.0,0.03653028,0.08047743,0.05052519,0.09697805,0.0697398,0.010135002,0.0,0.0010217726,0.0,0.02570603,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0051808804,0.0,0.008417934,0.0,0.0,0.0014042407,0.03577619,0.0,0.021910712,0.038136974,0.07475543,0.048256025,0.07650027,0.006459959,0.0,0.0,0.0,0.0,0.03418223,0.0,0.0,0.0,0.0,0.0,0.0,0.01346568,0.0,0.0,0.0,0.0,0.016102687,0.0,0.0,0.0059390813,0.030613415,0.00071564317,0.03289015,0.02043762,0.04769069,0.018428557,0.031880677,0.0,0.0,0.0,0.0,0.0,0.011987068,0.00297907,0.0,0.0,0.0,0.0,0.0,0.019889124,0.0,0.0,0.0,0.0,0.023473375,0.021291234,0.0094558075,0.011939742,0.016560912,0.0,0.03619711,0.012260854,0.010477617,0.0,0.012033835,0.002204448,0.0,0.014948972,0.016594201,0.0025669783,0.020056903,0.02851028,0.014510669,0.0030115992,0.0,0.004822865,0.0,0.0122962,0.0,0.0,0.0,0.0,0.04448794,0.050844394,0.0292397,0.01658599,0.030171923,0.020005882,0.07065264,0.02435711,0.001854226,0.00032043457,0.021809414,0.044748507,0.016625874,0.068801865,0.092263676,0.08113233,0.076893836,0.10835449,0.08209479,0.050139815,0.0,0.023338445,0.0,0.019312553,0.0,0.0,0.0,0.0,0.05432891,0.06657091,0.043650918,0.021487124,0.05302029,0.049921803,0.08320755,0.020942584,0.0,0.0063172877,0.0356303,0.063707195,0.012582123,0.06621672,0.09637074,0.11439401,0.120082825,0.1614083,0.111406356,0.069095716,0.0,0.031916194,0.0,0.03417991,0.0,0.0,0.0,0.0,0.067436986,0.08105295,0.037351765,0.018431433,0.07089296,0.09666675,0.11819354,0.030863822,0.0,0.019392043,0.058812387,0.084010184,0.015227392,0.08223103,0.11592991,0.1707824,0.16722842,0.22446743,0.16755058,0.11934487,0.006263934,0.04839,0.0,0.03127546,0.0,0.0,0.0],[0.0,0.0,0.0,0.0069226325,0.026825905,0.0,0.0,0.0,0.0,0.026351042,0.025964856,0.0,0.0,0.0,0.0,0.0,0.0,0.029887877,0.038066506,0.0017712712,0.06803753,0.0532225,0.046147987,0.03382881,0.02659326,0.0,0.0,0.004516676,0.0,0.0,0.0,0.0043993294,0.031168647,0.0,0.0,0.0,0.0,0.021985509,0.012406573,0.0,0.0,0.0,0.0,0.0,0.0,0.040543586,0.025369726,0.007167816,0.0451964,0.03762065,0.039974533,0.029748611,0.028268605,0.0,0.0,0.009415746,0.0,0.0,0.0,0.005540386,0.012903936,0.0,0.0,0.0,0.0,0.027629279,0.015636988,0.0,0.0,0.0,0.0,0.0,0.0,0.014792234,0.009198666,0.018843658,0.042787388,0.040398695,0.03133378,0.021243267,0.03960099,0.0,0.0,0.011689976,0.0,0.0,0.0,0.011471845,0.0,0.0,0.0,0.0,0.0,0.03993702,0.010893896,0.0,0.0,0.0,0.0,0.0,0.01631707,0.0026620328,0.0043048263,0.013697788,0.049558803,0.02173388,0.0,0.01533585,0.017616816,0.0,0.0,0.007696204,0.0,0.0,0.0,0.014690444,0.0,0.0036812872,0.0,0.01226528,0.0,0.0533624,0.018150106,0.0,0.0,0.0,0.0,0.024074398,0.07973237,0.0,0.0,0.0,0.03349474,0.0,0.0,0.011448517,0.011618331,0.0,0.0,0.0074993595,0.0,0.00096581876,0.0,0.016506903,0.0,0.0033474565,0.01660838,0.027325265,0.0,0.018752016,0.008739561,0.0,0.0,0.0,0.0,0.0,0.026107535,0.0,0.007071048,0.0,0.013595507,0.0,0.0,0.0036385953,0.023338929,0.01123476,0.0,0.0,0.0,0.030073479,0.019308247,0.04555098,0.004917845,0.01200106,0.04929752,0.031096019,0.0,0.0,0.0,0.0,0.0024864972,0.0,0.0,0.0,0.0,0.0,0.0038158894,0.0,0.003948137,0.0,0.0,0.005339116,0.03714546,0.023340613,0.0,0.0,0.0023842007,0.06097568,0.057235785,0.06181752,0.015948199,0.0086437315,0.04419764,0.037938513,0.010391943,0.0,0.0,0.01682543,0.010831058,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0058906004,0.0,0.0,0.00429897,0.036045887,0.025230058,0.0,0.0,0.019755945,0.112516925,0.10640636,0.08217549,0.021420114,0.011261895,0.05419123,0.0623648,0.032023408,0.012051292,0.0,0.050233416,0.019352116,0.0,0.0,0.0,0.0,0.0,0.0116135925,0.012271114,0.017835699,0.002208829,0.0,0.009999551,0.03999108,0.04772774,0.0,0.0,0.029416494,0.13760483,0.13303818,0.10546237,0.034430787,0.027154163,0.06945803,0.064300194,0.02644208,0.017948315,0.0,0.060715146,0.016612366,0.0,0.0,0.0,0.0,0.0,0.028444149,0.039471194,0.023084693,0.0005913526,0.0,0.01836788,0.053797446,0.063315146,0.0,0.0,0.04107491,0.15295528,0.14609402,0.10547892,0.04174003,0.030794822,0.081713006,0.07759629,0.031836875,0.023515046,0.0,0.072192654,0.022995792,0.004641086,0.0,0.0,0.0,0.0,0.05836886,0.09083632,0.065679945,0.021072954,0.010377273,0.019147843,0.048793487,0.06213326,0.0,0.0],[0.0,0.0,0.0,0.011102393,0.028007507,0.0072605014,0.0,0.0,0.0,0.0109504685,0.03451754,0.01095973,0.0,0.0,0.0,0.0,0.0,0.038019374,0.00924243,0.0,0.001349777,0.016996771,0.027589247,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01094453,0.02357325,0.0,0.0,0.0,0.0,0.009186648,0.028378047,0.009231672,0.0,0.0,0.0,0.0,0.0,0.02437649,0.0027118623,0.0,0.0,0.014852703,0.039268002,0.0,0.0,0.0,0.0,0.0,0.0048404783,0.0,0.0,0.012721039,0.019652523,0.0,0.0,0.0,0.0,0.0018552542,0.016536005,0.0,0.0,0.0,0.0,0.0,0.0,0.0016512573,0.0,0.0,0.0019274652,0.030687563,0.055295385,0.0051659644,0.0,0.0,0.0,0.0,0.015851125,0.0,0.0,0.020685717,0.017506473,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0024089813,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0028063357,0.012819484,0.036975995,0.0,0.0,0.0,0.0,0.0,0.023762785,0.0,0.0,0.02165924,0.01206506,0.0016703606,0.0007406771,0.010407016,0.0,0.0,0.00087173283,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003684625,0.0,0.0,0.0,0.0,0.0,0.018394932,0.0,0.0,0.005722843,0.0,0.003363043,0.0064292625,0.004729107,0.0,0.0,0.0024615228,0.0003659129,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0046088547,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011152349,0.009747572,0.012608916,0.016607597,0.0,0.0,0.003413275,0.0,0.0,0.0,0.0008007586,0.01523155,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00946372,0.0070857927,0.0,0.0,0.0,0.012366645,0.0,0.0,0.0,0.004172057,0.033071786,0.038122416,0.020718426,0.0,0.0,0.0,0.0,0.0065809786,0.0,0.013379052,0.037448473,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013032362,0.015112884,0.0,0.0,0.0,0.019747995,0.0,0.0,0.0,0.007919878,0.06556906,0.06632622,0.03542211,0.0,0.0,0.0,0.0169757,0.022399485,0.0,0.023848258,0.055280037,0.0,0.012859844,0.0,0.012032352,0.0,0.0,0.0,0.018783756,0.02369897,0.012561291,0.001179263,0.0,0.04245407,0.0,0.0,0.0,0.0085256845,0.087045774,0.09107933,0.058719635,0.0,0.0,0.0,0.034060657,0.024259716,0.0,0.017588131,0.053607844,0.0022685975,0.021145657,0.0,0.022933267,0.0,0.0,0.0,0.024813883,0.036201276,0.018161736,0.009594083,0.016806766,0.06858069,0.0,0.0,0.0,0.012690738,0.08810809,0.10656342,0.06555193,0.0,0.0,0.0,0.04807382,0.01935444,0.0,0.0121819,0.05069959,0.010181591,0.028433636,0.011651501,0.027757794,0.0,0.0,0.0,0.04603564,0.06701026,0.04499474,0.028440744,0.026508242,0.0807749,0.0,0.0,0.0],[0.026148893,0.0,0.02522131,0.0,0.023255289,0.0,0.013170496,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028062016,0.0,0.0,0.0,0.0,0.008106098,0.0032203645,0.0,0.0,0.012722753,0.009026244,0.0045935065,0.02300866,0.0,0.015064679,0.0,0.014263555,0.0,0.012626186,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022368133,0.0,0.0,0.0,0.0,0.0019218326,0.0048383623,0.0,0.0,0.006073028,0.0027839988,0.0,0.02093517,0.0,0.0038414448,0.0,0.00842458,0.0,0.005809076,0.0052298307,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014478572,0.0,0.0,0.0,0.0,0.0,0.006965108,0.0,0.0,0.0013185889,0.0,0.0,0.019700825,0.0,0.0,0.0,0.0071041062,0.003840208,0.0,0.0,0.011371687,0.017923735,0.0,0.0,0.0,0.0,0.0,0.0003248453,0.0074774474,0.0,0.0,0.0,0.0,0.0028971136,0.018380746,0.0,0.0,0.0,0.0,0.0,0.016536757,0.0,0.0,0.0,0.0054623783,0.0,0.0,0.0,0.0032530874,0.012355953,0.016599871,0.021303669,0.0,0.0,0.0,0.0,0.006691523,0.0021335334,0.006505728,0.0,0.0,0.0,0.011393592,0.0,0.0,0.0,0.0,0.0,0.015940063,0.0,0.0,0.0,0.00041881204,0.0,0.0025008768,0.0,0.0,0.0,0.013252407,0.033458672,0.0,0.0,0.00393793,0.0,0.00014308095,0.017859139,0.029303446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016702682,0.0,0.0,0.0,0.0,0.0,0.01716911,0.0,0.0,0.016221136,0.0,0.025934264,0.0024743676,0.0,0.009602077,0.0,0.0,0.011247642,0.029534273,0.0,0.0,0.0,0.0,0.0,0.0008407533,0.0018216223,0.0,0.0,0.02046422,0.0,0.0,0.0,0.0,0.0,0.028587446,0.0,0.009506471,0.038069308,0.0,0.008666441,0.014520757,0.0,0.012396075,0.0,0.0,0.0145704895,0.04080531,0.0,0.0,0.0,0.0,0.0,0.011499874,0.009351976,0.0,0.0,0.024048522,0.0029305369,0.0,0.0,0.0,0.0,0.029751986,0.0,0.03470055,0.06297221,0.0,0.0,0.017662212,0.0,0.009206325,0.0,0.0,0.023352586,0.051811486,0.0,0.0,0.0,0.0,0.0,0.019773558,0.016777553,0.0,0.0,0.025191948,0.012507893,0.0,0.0,0.0,0.0,0.025679573,0.0035407394,0.05007253,0.074739546,0.0,0.0,0.019287176,0.0,0.014085501,0.0,0.0,0.031747326,0.054046296,0.0,0.0,0.0,0.0,0.010680877,0.036588155,0.036367513,0.0,0.0,0.0243643,0.029852055,0.0,0.0,0.0,0.0,0.01583466,0.0069948956,0.059094198,0.07977322,0.00029334426,0.0,0.035380006,0.0,0.019283094,0.0,0.0052554905,0.03790056,0.054870762,0.0,0.0,0.0,0.0,0.019807227,0.042188548,0.046198986,0.0,0.0],[0.012269825,0.0,0.0,0.0,0.04638572,0.02594208,0.028400809,0.0,0.0,0.0,0.017870925,0.0,0.0,0.0,0.0,0.0,0.028643094,0.0,0.0,0.0,0.0,0.015482344,0.0008198172,0.0,0.0073723122,0.037543476,0.031286933,0.0,0.010636307,0.0,0.0,0.0,0.03524001,0.018868193,0.02415298,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014858589,0.0,0.0,0.00054076314,0.001240477,0.02588021,0.009266175,0.0,0.0,0.027222432,0.034440607,0.0,0.008251719,0.0,0.0,0.0,0.034017153,0.011600785,0.01751583,0.0069298446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0011865199,0.0,0.011105925,0.0073987395,0.0,0.0,0.010949545,0.02782195,0.0,0.0015420914,0.015578248,0.0,0.027960308,0.033966288,0.012005858,0.004401818,0.010769278,0.0,0.010687076,0.024462402,0.0,0.005018458,0.0056543946,0.0054592937,0.0,0.0,0.0,0.0,0.0,0.0048003495,0.017798938,0.03809298,0.0,0.0,0.0,0.011401534,0.0,0.0,0.018827759,0.002493441,0.039115608,0.030028217,0.0,0.0,0.0,0.0,0.008472055,0.012782402,0.0,0.011023611,0.01346612,0.0066400245,0.0,0.0,0.0,0.008788608,0.0010029674,0.003982812,0.00843557,0.040846482,0.00033457577,0.0,0.0,0.007648833,0.0,0.0,0.011912465,0.0,0.03331936,0.027987376,0.0,0.0,0.0,0.0,0.0,0.0030786693,0.0,0.008345306,0.016473584,0.0073475093,0.0,0.0,0.011257961,0.026372604,0.0047124326,0.007102743,0.017888956,0.03424248,0.00097078085,0.0040231496,0.0,0.0,0.0,0.0,0.0124677345,0.0,0.022386394,0.017408602,0.0,0.01069954,0.0,0.0,0.0,0.0,0.0,0.008969404,0.008234046,0.008458637,0.0,0.0,0.01131288,0.020507798,0.0,0.009633608,0.037585407,0.032716326,0.008585341,0.018611267,0.0,0.0,0.0,0.0,0.016249098,0.0,0.0038991272,0.0,0.0,0.020255856,0.0,0.013926774,0.0,0.0,0.017245516,0.016972356,0.008081317,0.009982295,0.0,0.0,0.0138626695,0.026246294,0.0,0.007527977,0.043052852,0.023763292,0.012158036,0.035133325,0.0,0.0,0.0,0.0,0.022820212,0.0,0.0,0.0,0.0,0.025016919,0.0,0.048935033,0.0,0.0,0.028133132,0.023719788,0.0,0.0016756356,0.0,0.0,0.0,0.014925726,0.0,0.0,0.0188789,0.0009786338,0.015603118,0.04848498,0.008075595,0.0,0.0,0.0,0.024547659,0.0,0.0,0.0,0.0,0.034259327,0.0,0.076603174,0.0,0.0,0.036280178,0.047954544,0.0,0.00079515576,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025984116,0.06674153,0.019883484,0.0,0.0,0.0,0.032593317,0.0,0.0,0.0,0.0,0.036373578,0.013667621,0.12255052,0.02339127,0.013218701,0.052528866,0.09247796,0.0,0.0023248643,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02789031,0.071622,0.017733537,0.0,0.0],[0.0015907884,0.010540448,0.046153873,0.03760629,0.050527073,0.025623046,0.015555926,0.0,0.01676464,0.0,0.050461717,0.01051756,0.06641937,0.006019756,0.004125476,0.038059533,0.03743709,0.0,0.0,0.013140395,0.014887415,0.01562722,0.018553175,0.0,0.034336224,0.031399876,0.0020134747,0.0033503473,0.0,0.00024186075,0.028562106,0.019197457,0.03530602,0.02857329,0.023491994,0.0,0.0375579,0.0,0.012800917,0.0,0.060636654,0.0,0.01966028,0.02463954,0.051095307,0.0,0.003405869,0.020991668,0.023210794,0.018320248,0.013398372,0.0,0.027652487,0.035196528,0.010311097,0.0017188936,0.0,0.003635794,0.033601888,0.028687231,0.03581459,0.0324592,0.027185336,0.022929132,0.04549188,0.0,0.012828678,0.0,0.052108787,0.0,0.033611916,0.023415051,0.05381482,0.0,0.019264363,0.022855714,0.015761375,0.0,0.008175343,0.0,0.017619282,0.029500008,0.013678119,0.0037228018,0.0,0.011653744,0.042068385,0.03603494,0.03216874,0.029512078,0.0040700138,0.020972252,0.04239007,0.0,0.037637323,0.0012450963,0.049704492,0.0,0.03719019,0.034159057,0.02640441,0.010082573,0.019721314,0.03577345,0.03800048,0.036518715,0.04430505,0.000032752752,0.0,0.0038048774,0.0,0.004284367,0.0,0.018638171,0.061542332,0.037674643,0.026192412,0.026417866,0.011741824,0.020524837,0.013542898,0.004940212,0.039445043,0.0,0.039853454,0.0,0.02609609,0.0050698966,0.008635916,0.05081881,0.0019526333,0.053083666,0.054956913,0.0601649,0.05805055,0.0032809526,0.001373589,0.0,0.0,0.012555659,0.0,0.0007364154,0.06490294,0.042846926,0.03309343,0.051506147,0.02892737,0.00425224,0.0,0.0,0.040262148,0.0,0.030780062,0.0,0.020647347,0.0,0.005500421,0.05860909,0.0,0.040265538,0.06406925,0.09256974,0.053274058,0.0036359727,0.007963508,0.0,0.0,0.02512595,0.0,0.0,0.050226994,0.03584612,0.021473236,0.06341117,0.031010717,0.0,0.0,0.0,0.02722682,0.0,0.019218914,0.0,0.0075446367,0.0,0.0029142797,0.057598248,0.0,0.02744162,0.08584396,0.12987386,0.04667098,0.004526183,0.02807182,0.0,0.0,0.027023077,0.0,0.0,0.03195799,0.018224023,0.0,0.06893156,0.033386327,0.0032840818,0.012288868,0.0,0.034350336,0.0,0.03738883,0.0,0.01573988,0.0,0.0,0.056336403,0.0,0.025171734,0.094525546,0.13904527,0.03728073,0.0057225823,0.042887837,0.005005032,0.00891716,0.023207761,0.0,0.0,0.019650236,0.012697779,0.0,0.06995319,0.0440135,0.03521003,0.062641695,0.0,0.036742263,0.0,0.07456535,0.0,0.02344083,0.0,0.0,0.034990497,0.0,0.0065018535,0.056917243,0.09447375,0.021435708,0.001530543,0.053537033,0.024008669,0.024754964,0.014791302,0.0,0.0,0.016266607,0.017130129,0.0,0.06818602,0.06028828,0.07286404,0.10997485,0.009929709,0.03616193,0.006397687,0.103983216,0.0023165047,0.03425499,0.0,0.0,0.011830658,0.0,0.0,0.023155347,0.046744607,0.015111215,0.0032132566,0.06659987,0.024533063,0.024576224,0.009977497,0.0,0.0,0.0054075867,0.00025485456,0.0,0.038845338,0.09332741,0.14562555,0.18620859,0.059130818,0.0375883,0.05021935,0.14600661,0.005341962,0.028483637,0.0,0.0,0.0,0.0,0.0,0.0,0.016259387,0.010662153,0.0020223558,0.06922287,0.019190907,0.01893264,0.015556678],[0.0,0.034779213,0.0,0.0,0.0126954615,0.0057588294,0.019202068,0.015163414,0.017438643,0.038027726,0.064947866,0.056657575,0.073982656,0.078591,0.05347023,0.040402412,0.07831785,0.046568677,0.044519573,0.0,0.028552651,0.04001438,0.00023308396,0.0012653023,0.022605315,0.0,0.0,0.0,0.0,0.024356276,0.0,0.0,0.0069353357,0.0025746822,0.029712953,0.02353952,0.03150084,0.030773774,0.02982957,0.008824572,0.032076575,0.07252315,0.063611045,0.06864737,0.10178795,0.06804296,0.067900576,0.0,0.033562616,0.044420958,0.008716896,0.00040401518,0.020341538,0.0010101497,0.0,0.0,0.0,0.03314928,0.010596894,0.0,0.013998486,0.026706465,0.04827617,0.035224617,0.051647708,0.051807925,0.036575504,0.014773026,0.010783009,0.055539966,0.071660206,0.046505064,0.04157859,0.025891937,0.04052928,0.007027507,0.02291891,0.02367337,0.012240395,0.0,0.0155910775,0.0040076226,0.0,0.0,0.0,0.029719286,0.0103350505,0.0,0.01662141,0.061225936,0.06243261,0.02346465,0.04180024,0.050603457,0.040909015,0.015408076,0.0,0.018340416,0.048144653,0.01431451,0.013219386,0.031172164,0.04266642,0.03721267,0.07481187,0.0488012,0.043725185,0.0,0.005672112,0.0,0.0,0.005384475,0.0,0.03209977,0.012645543,0.0,0.027834639,0.06824795,0.05868905,0.015445948,0.02906479,0.022654958,0.014736153,0.0,0.009222113,0.014304481,0.0,0.00082851946,0.00263834,0.035742104,0.06336687,0.057082526,0.09627263,0.049184166,0.04815892,0.0,0.0,0.0067261606,0.0,0.015416525,0.0,0.029648185,0.016650893,0.0,0.060365997,0.08606401,0.061274566,0.0036020875,0.011205159,0.0071367845,0.010831267,0.0,0.019501157,0.03646718,0.0010134429,0.020025626,0.006370932,0.009583168,0.039685167,0.087296695,0.14591043,0.08873573,0.048800208,0.0,0.0,0.024378903,0.004879147,0.024493985,0.0,0.021051973,0.0043739974,0.0,0.0644982,0.08942218,0.0608456,0.0,0.0,0.0,0.0,0.0,0.02574914,0.044647507,0.0057129636,0.020086013,0.0,0.0,0.01787825,0.1323353,0.20966047,0.14151075,0.05410532,0.0,0.0007404536,0.03979429,0.0061834976,0.019442342,0.0,0.014526494,0.0,0.0,0.058986597,0.08606281,0.07250734,0.0,0.0,0.0,0.013619721,0.0023246557,0.04339218,0.07032998,0.03659749,0.052460805,0.008180171,0.0,0.023465246,0.1805433,0.25038534,0.16310027,0.0555595,0.0,0.005143091,0.048857607,0.0019248575,0.004365012,0.0,0.008894078,0.0,0.0,0.05750084,0.07950891,0.08502032,0.00824073,0.0096934065,0.03243134,0.040193327,0.004791692,0.057408847,0.08759685,0.06470988,0.0830521,0.017572448,0.0,0.004673049,0.15587588,0.21704987,0.13767353,0.045830958,0.0,0.00982964,0.05834587,0.0005790293,0.0,0.0,0.01481092,0.0,0.0,0.057099164,0.07948979,0.10054101,0.019482017,0.03695947,0.06478972,0.06666847,0.011799179,0.067251176,0.092144,0.096869595,0.11294023,0.033788063,0.0,0.0,0.08679767,0.14901316,0.10923237,0.041864447,0.0,0.008309469,0.050505526,0.0,0.0,0.0073579177,0.016801871,0.0,0.0,0.02923841,0.08639054,0.1352367,0.0760632,0.09122279,0.11474432,0.15531503,0.062533766,0.119096175,0.113122046,0.1268614,0.1171358,0.03194365,0.0,0.0,0.02897916,0.08914003,0.06596191,0.024088807,0.0,0.016857177,0.042588368,0.0009493381,0.0],[0.0,0.0,0.015002623,0.0,0.0,0.010882802,0.019673191,0.011397302,0.05763741,0.08057371,0.153871,0.18430312,0.29284588,0.36331916,0.46399724,0.39184844,0.42256635,0.2840109,0.21693714,0.09682833,0.079335265,0.065231994,0.0,0.0022648424,0.0,0.0,0.0,0.0,0.0,0.0,0.007344544,0.0,0.0,0.006269306,0.0133868605,0.0,0.03199836,0.027201489,0.050545804,0.07160868,0.21850556,0.2968181,0.4094956,0.39769727,0.40952528,0.31167996,0.25287727,0.12490997,0.09053558,0.044448063,0.0,0.0,0.0,0.0070322827,0.0,0.0,0.0,0.0015494078,0.016798593,0.0,0.0,0.010386646,0.012460396,0.0,0.028828561,0.04043459,0.04242663,0.04801692,0.17127275,0.21246018,0.30569428,0.28405014,0.2767276,0.21809152,0.20889178,0.12041684,0.07508506,0.017083615,0.0,0.0,0.0,0.0067450926,0.0,0.0,0.0,0.008762434,0.009192094,0.0,0.0,0.018989287,0.012048945,0.0,0.0,0.03292726,0.024007678,0.018847823,0.07305221,0.09476194,0.15281445,0.15828031,0.19671786,0.19247068,0.22761226,0.15103883,0.091908365,0.015510015,0.0013247132,0.0,0.0,0.0,0.0063931197,0.0021678507,0.0,0.0068302974,0.0,0.0,0.0021821856,0.039487496,0.011808448,0.0,0.0007291436,0.014707528,0.0,0.012566529,0.05414337,0.014983922,0.05720289,0.10334869,0.17040023,0.2207866,0.29987454,0.19705063,0.12525967,0.011757955,0.0025732964,0.0,0.0,0.0,0.008665279,0.0,0.0,0.006377913,0.0,0.012178659,0.05543851,0.07060726,0.031629547,0.0,0.014813162,0.029028274,0.0,0.017550185,0.055274807,0.0,0.036544383,0.122232705,0.1597245,0.20908852,0.330886,0.27205065,0.22826211,0.060299315,0.037647463,0.0,0.0,0.0048023015,0.0033685267,0.0027854592,0.0,0.0,0.0,0.020012327,0.07495613,0.08591093,0.044956945,0.0,0.024008013,0.044715516,0.009360671,0.034335777,0.04806552,0.0,0.023609556,0.119157545,0.14031878,0.17605063,0.3434338,0.3535303,0.35033864,0.1398282,0.087859094,0.0,0.0,0.008443713,0.0,0.0,0.0,0.0,0.0,0.024700485,0.09765531,0.095254764,0.05298493,0.0,0.03888586,0.07259332,0.02580624,0.034125842,0.03134109,0.007903606,0.016470648,0.12826386,0.13448052,0.16538313,0.33381394,0.4040084,0.42519522,0.19789153,0.11570949,0.0,0.0,0.018872224,0.0,0.0,0.0,0.0,0.0,0.040579222,0.11803336,0.09760833,0.050596036,0.0,0.053863518,0.10795754,0.0378424,0.03984818,0.020600803,0.027486391,0.026225843,0.12697487,0.14550427,0.17778751,0.2746904,0.3602913,0.3847816,0.200558,0.10922658,0.0,0.0,0.03643482,0.0,0.0,0.002654925,0.0,0.0,0.048196293,0.12334873,0.09630955,0.058574498,0.0,0.0715065,0.13111259,0.07835315,0.08165817,0.022513166,0.06886392,0.06538172,0.14146467,0.16730261,0.16493173,0.16002294,0.23033142,0.2803942,0.1819077,0.0803161,0.0,0.0,0.043792747,0.0,0.0,0.005675614,0.008695565,0.0,0.03167057,0.10044392,0.104086086,0.10108805,0.021155171,0.10857153,0.18543509,0.1799151,0.18645515,0.07239725,0.1300875,0.11919615,0.1602862,0.19733313,0.15938896,0.07700469,0.11016671,0.15398243,0.11112802,0.020040981,0.0,0.0028529465,0.051076382,0.008810319,0.0],[0.0,0.0,0.0,0.0014376342,0.040412292,0.053559795,0.0070456862,0.036511786,0.08253129,0.2028012,0.2806911,0.4098227,0.5567352,0.73127824,0.7854413,0.88176984,0.8283041,0.66805077,0.50575185,0.33506024,0.22097698,0.1189337,0.058086246,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0012128055,0.03163947,0.04054019,0.0017476678,0.019273818,0.032985434,0.09842281,0.13658482,0.25228706,0.4073252,0.6078449,0.7032263,0.83771235,0.7969797,0.65234625,0.5023145,0.32768947,0.19658074,0.10222935,0.034215212,0.0,0.0,0.014962025,0.0,0.0,0.0,0.0,0.0,0.0072389394,0.017800547,0.027268343,0.0028990954,0.02259411,0.02368313,0.07181242,0.07480328,0.13481131,0.24354044,0.41705585,0.5586368,0.707742,0.6818113,0.5732068,0.43760973,0.23850037,0.11715924,0.07489041,0.022989333,0.0,0.0,0.03805603,0.005687341,0.0,0.0,0.005155161,0.0,0.004947111,0.015674062,0.019923247,0.0,0.0151491985,0.0,0.015680633,0.010827184,0.0042669624,0.010518961,0.1232299,0.31284547,0.5496985,0.6255548,0.5509666,0.41016406,0.20137133,0.098606594,0.042664565,0.0044600964,0.0,0.0,0.02485244,0.0,0.006364502,0.0,0.0,0.0,0.0072180256,0.015213348,0.0059769377,0.0,0.0,0.0,0.0,0.0009652823,0.0,0.0,0.027653478,0.119324975,0.3666398,0.5127902,0.54240894,0.49989676,0.32508373,0.13023615,0.019614242,0.0065581203,0.0,0.0,0.012814559,0.0,0.009278685,0.0,0.0,0.019720644,0.035593115,0.03170602,0.0,0.000023260713,0.0,0.008955106,0.0,0.020611838,0.018195458,0.008744486,0.010328487,0.047689296,0.23858795,0.39766306,0.49254346,0.57979673,0.4880489,0.25658673,0.082456246,0.048239782,0.0,0.0,0.007047616,0.0,0.020918034,0.0,0.0,0.019607738,0.035767682,0.042203523,0.0,0.016182408,0.0,0.025112912,0.00037902594,0.042348303,0.054264612,0.058907367,0.02263987,0.015003495,0.1296928,0.28456312,0.4534722,0.6651891,0.6806675,0.45966017,0.21919677,0.115706,0.0,0.0,0.0,0.0,0.012514971,0.0,0.0,0.017006136,0.039073706,0.05646395,0.0019808114,0.036677197,0.0,0.03910926,0.0043646395,0.056824744,0.0704993,0.098920174,0.05471441,0.0071092397,0.06307238,0.19880801,0.40975553,0.68831646,0.7802108,0.5831339,0.30468446,0.16389412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01795689,0.046116106,0.07145846,0.0000012516975,0.041642755,0.0,0.034252822,0.006806597,0.061416984,0.0880279,0.15593438,0.11412603,0.031594977,0.043476723,0.15713543,0.35324004,0.64030206,0.74978286,0.5845324,0.29153416,0.17585526,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019524775,0.04619074,0.07642537,0.0,0.031773195,0.0,0.050361916,0.041484587,0.111807585,0.15243809,0.25243333,0.20062038,0.10799144,0.07506545,0.13587634,0.24727061,0.49316657,0.6074424,0.49763244,0.23466745,0.14342874,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020201579,0.04181394,0.07204743,0.00500679,0.031257465,0.0,0.12887314,0.15796274,0.23486087,0.2696833,0.36308047,0.3071134,0.21210605,0.1366367,0.17867324,0.20415184,0.3792356,0.44138902,0.33824086,0.12150528,0.07574144,0.0,0.0070775747,0.0,0.0,0.0043601543],[0.0,0.0,0.0032284409,0.041899644,0.05578693,0.051663972,0.0007341504,0.053530194,0.10462346,0.26979655,0.32725614,0.5306365,0.66362375,0.7766161,0.85737944,0.94496435,0.907106,0.8246165,0.67068994,0.4713068,0.359258,0.23058853,0.10119791,0.0441026,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.040236153,0.047577888,0.03812989,0.0,0.037467077,0.04687938,0.14374508,0.16462505,0.36199898,0.53241616,0.70496756,0.852483,0.9409313,0.9204503,0.80827,0.644583,0.43845755,0.3131172,0.20365739,0.08186257,0.03080266,0.015384845,0.0,0.0,0.0,0.0,0.0,0.0,0.03587515,0.022346452,0.02046185,0.0,0.02441699,0.02286598,0.1008715,0.07217447,0.20734581,0.34009022,0.5494926,0.7339248,0.86357254,0.876925,0.76253855,0.557394,0.31518295,0.24707103,0.17632101,0.08325322,0.012497358,0.03642086,0.0274771,0.02118703,0.0,0.0,0.0,0.0,0.021513164,0.014345489,0.012683004,0.0,0.016176127,0.0,0.03501927,0.008275889,0.046637908,0.08234565,0.270176,0.4869721,0.75984365,0.8451147,0.77003103,0.4846763,0.21984869,0.18115933,0.109426595,0.050267465,0.0,0.01737155,0.0,0.010895647,0.0,0.0,0.005572483,0.0014144778,0.02195789,0.009657748,0.022676393,0.019347824,0.0,0.0,0.0,0.0,0.025098301,0.009414867,0.06830433,0.25111035,0.525558,0.67223597,0.73402554,0.5600027,0.27289623,0.11543235,0.032848544,0.018893495,0.0,0.01200366,0.0,0.0,0.0,0.0,0.014435932,0.021691404,0.051961243,0.020182624,0.01546783,0.036449514,0.0078782365,0.018833607,0.0,0.0,0.049484283,0.013806835,0.0,0.12749548,0.3232558,0.51567036,0.69733363,0.6792192,0.43592876,0.18292487,0.040337183,0.021619849,0.0,0.012312867,0.0,0.0,0.0,0.0,0.012034781,0.030198708,0.066473514,0.034558542,0.005563244,0.046805,0.029341273,0.03415239,0.0,0.0,0.09275313,0.057459287,0.0005042553,0.052213743,0.16009487,0.38688934,0.72630346,0.8283078,0.6780902,0.36920708,0.14506136,0.06387746,0.0,0.018768378,0.0,0.0,0.0,0.0,0.004110709,0.0309074,0.076145455,0.046035364,0.0,0.056879386,0.0456782,0.051049627,0.0,0.0012644976,0.10636159,0.08070681,0.027971342,0.045661487,0.08368993,0.27987063,0.71559834,0.8908771,0.8364966,0.48449695,0.20206803,0.086250946,0.0,0.035440646,0.0,0.0,0.0,0.0,0.0,0.020613983,0.07655749,0.04416535,0.0,0.050364472,0.05048413,0.08758299,0.024285384,0.019066319,0.11340387,0.094851464,0.059412412,0.07241115,0.07509908,0.2097932,0.65929866,0.83641315,0.8714738,0.48340124,0.1693875,0.07509717,0.009610318,0.05921609,0.0,0.0,0.0,0.0,0.00078718364,0.017549932,0.07534632,0.047475502,0.0,0.033834763,0.06062983,0.13507232,0.10056724,0.11976315,0.19665697,0.16711742,0.12004932,0.13304205,0.09488724,0.14896914,0.53706104,0.6695613,0.78304034,0.43177402,0.107740834,0.05142752,0.01805456,0.050239034,0.0,0.0,0.0,0.0,0.003719002,0.01170481,0.07411455,0.05024574,0.0,0.024755329,0.08079268,0.2237727,0.23960862,0.29434317,0.3065716,0.26434258,0.20290211,0.22279549,0.18046278,0.19065377,0.5082222,0.5534308,0.6405714,0.32294446,0.011142105,0.01716894,0.030598275,0.04253544,0.00011743605,0.0,0.0],[0.0,0.0,0.014941737,0.0,0.0,0.014066905,0.0,0.074759126,0.11848848,0.19617362,0.22519118,0.2730443,0.3952496,0.45785385,0.52878094,0.50412047,0.6256344,0.57041246,0.60800505,0.4245047,0.2873175,0.14139968,0.08791658,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0010892302,0.0,0.0,0.012038082,0.0,0.052411787,0.062467687,0.100303814,0.11719953,0.20288418,0.38542712,0.52707857,0.6230792,0.5604917,0.6382787,0.5438043,0.57459724,0.3764978,0.26590297,0.14982271,0.09183982,0.016766325,0.019464895,0.0,0.0,0.0,0.0,0.0046676397,0.0,0.0,0.0,0.014350615,0.0,0.026016906,0.034006484,0.055887394,0.04376518,0.09573421,0.30191478,0.54198414,0.7173381,0.68093616,0.73075306,0.56717676,0.5268327,0.2799042,0.22022024,0.13268586,0.10323958,0.035051197,0.039768584,0.022996068,0.003994018,0.0,0.0,0.01363156,0.0,0.0,0.0,0.03391292,0.0,0.0075262636,0.009325273,0.033559173,0.0,0.0,0.10455526,0.37157726,0.6634265,0.8326798,0.92661077,0.7407278,0.54101163,0.20898637,0.15974173,0.0822387,0.04676968,0.0,0.0,0.0,0.0,0.0,0.0,0.024191916,0.0,0.0,0.0,0.02350185,0.0019265115,0.0064426437,0.00792861,0.0,0.0,0.0,0.0,0.0766915,0.29072642,0.612187,0.80403346,0.7881843,0.5558849,0.16265754,0.037615545,0.005180642,0.033251666,0.0,0.0,0.0,0.0,0.0,0.0,0.031953648,0.015417464,0.0,0.0,0.011054277,0.008361764,0.0,0.00027051568,0.0,0.0058315545,0.027316451,0.036429785,0.0,0.05151099,0.33764914,0.6044595,0.76031035,0.6383792,0.265051,0.047205307,0.0,0.026696712,0.0,0.0,0.0,0.0,0.0,0.0,0.032665074,0.025816202,0.007271804,0.0,0.008323774,0.01841367,0.0,0.0,0.0,0.032322727,0.09399353,0.11286079,0.0,0.0,0.14788525,0.4705087,0.795214,0.82679313,0.48048383,0.16241053,0.020330891,0.029692307,0.0,0.009585425,0.00042700768,0.0,0.0,0.0,0.034024365,0.03524535,0.0086748,0.0,0.0017311126,0.040458947,0.010193035,0.0124479905,0.0,0.047110878,0.1310717,0.1661379,0.0,0.0,0.06427086,0.39814192,0.77252203,0.9162873,0.62091196,0.23519564,0.05244542,0.03988693,0.0,0.0358887,0.008457281,0.0,0.0,0.0,0.02471798,0.026026621,0.0,0.0008753985,0.0,0.062684774,0.04991419,0.053449713,0.027869575,0.07175401,0.137127,0.19306168,0.0,0.0,0.035607457,0.35820043,0.7052375,0.91836786,0.6541631,0.20189479,0.032985054,0.03250003,0.035445347,0.064842194,0.016029745,0.0,0.0,0.0,0.027658336,0.0235302,0.0,0.020819739,0.0050626546,0.073549956,0.09383613,0.12042141,0.12340901,0.15767707,0.19553715,0.26460522,0.04506234,0.022387765,0.026284501,0.3220317,0.5931114,0.83569676,0.6075595,0.16455722,0.008138962,0.008197799,0.058934458,0.07706557,0.018247329,0.0,0.0,0.0,0.046910904,0.03355235,0.0,0.04369072,0.014268428,0.09846916,0.18107805,0.24611558,0.25478455,0.2590867,0.25228655,0.3248264,0.12710163,0.12299572,0.12854691,0.40866387,0.56557816,0.75528777,0.50301033,0.078690484,0.0,0.0,0.0758633,0.08043213,0.025742896,0.0,0.0],[0.0,0.011884965,0.0,0.002549976,0.016564086,0.0,0.0,0.012626894,0.026049063,0.08884031,0.11786716,0.104493834,0.15246315,0.2679807,0.29130375,0.35237008,0.47768486,0.4729414,0.47523242,0.37782413,0.24653636,0.15312073,0.012459904,0.0,0.0,0.005601898,0.0,0.0,0.0,0.00567697,0.0,0.0,0.0038119555,0.0,0.0,0.004271552,0.0,0.017934576,0.07668321,0.1169308,0.26787874,0.39559597,0.40113717,0.39121133,0.4407841,0.4589513,0.44052672,0.34299886,0.26198894,0.16095234,0.030906975,0.017469287,0.017102256,0.021290652,0.0,0.0,0.0,0.00035245717,0.0,0.0,0.0,0.0,0.0,0.002394259,0.0,0.0017375201,0.052321643,0.102365084,0.32401633,0.53165513,0.61021733,0.5690577,0.5159043,0.4598595,0.39162445,0.278867,0.25460517,0.17372738,0.07680033,0.030039273,0.03764209,0.044368625,0.0,0.002559647,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008549154,0.0,0.017953135,0.05102343,0.06966336,0.21216789,0.52753663,0.74747556,0.84689033,0.80281436,0.6303796,0.39976346,0.20161834,0.16352691,0.104609534,0.041751154,0.0,0.003048256,0.010745995,0.0,0.0205765,0.0,0.0036004335,0.0,0.0,0.0,0.0011483133,0.0,0.010626137,0.0,0.0,0.0,0.0,0.0,0.15293936,0.38941967,0.69045323,0.771704,0.7044281,0.38428533,0.08466303,0.0,0.01119899,0.035938084,0.0,0.011966407,0.0,0.0,0.0354542,0.0,0.02329322,0.0,0.0,0.0,0.00735683,0.0,0.0,0.0,0.011978842,0.0,0.010703519,0.0,0.0,0.12189791,0.47627163,0.6554713,0.71208817,0.4505217,0.11988913,0.0,0.0,0.025254995,0.0,0.029719375,0.0046440214,0.0,0.04099161,0.0,0.033960186,0.0,0.0,0.0,0.014225312,0.0,0.0,0.0,0.039252453,0.0,0.04743067,0.0,0.0,0.011865921,0.3260417,0.59447014,0.77896494,0.61253715,0.25183606,0.033017933,0.0,0.0,0.0,0.038395546,0.011121452,0.0,0.033507675,0.0061971024,0.046432614,0.0039812177,0.000029414892,0.0,0.028313428,0.0,0.0,0.0038374215,0.07352352,0.010172904,0.0677181,0.00019580126,0.0,0.0,0.2624584,0.56384474,0.769889,0.7075832,0.36731514,0.07711455,0.0,0.0,0.0,0.04248602,0.0067418367,0.0,0.017988645,0.01846458,0.04384893,0.00043807924,0.0,0.0,0.04635611,0.0,0.023826085,0.10238321,0.13497534,0.07542172,0.07680236,0.0,0.0,0.0,0.22582504,0.5294424,0.7193841,0.73624104,0.41138822,0.07266565,0.0,0.003954798,0.016234726,0.05970279,0.0,0.0,0.00025688112,0.03610993,0.043640263,0.00029553473,0.0,0.0,0.074563384,0.0161582,0.08415037,0.21382222,0.21802424,0.17199056,0.1141116,0.021221861,0.0,0.037839435,0.19977395,0.4932925,0.6480405,0.6799831,0.4018845,0.074438736,0.0,0.0,0.016481958,0.058352426,0.0,0.0,0.0058818907,0.05373869,0.052431226,0.014428295,0.0,0.025547698,0.10193978,0.06031481,0.19210346,0.35857856,0.3117091,0.25693437,0.14700314,0.040577874,0.0,0.09237912,0.27678713,0.55059433,0.62112945,0.60520256,0.34063452,0.052322313,0.0,0.0,0.018450014,0.055983327,0.0,0.0,0.009463631],[0.013840273,0.0052654296,0.0,0.0,0.0,0.0,0.0,0.0,0.025211945,0.026757583,0.029698186,0.008182354,0.13065025,0.16703828,0.32938343,0.45610076,0.56561875,0.49666822,0.48383683,0.2793049,0.11343635,0.04037319,0.0,0.0,0.0,0.0,0.0,0.0,0.016344935,0.0005569756,0.0016438067,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015545115,0.04357694,0.20054829,0.27393404,0.4341516,0.47049546,0.48817235,0.46445203,0.4487338,0.28789315,0.13350385,0.06650653,0.0107478425,0.0,0.0,0.0,0.0,0.0,0.014125764,0.0,0.0,0.0,0.0,0.0,0.0069091693,0.012032613,0.0,0.0,0.017581627,0.10181111,0.27469245,0.4348476,0.6215708,0.6057423,0.50459146,0.4323886,0.3837607,0.2742991,0.17786363,0.097439885,0.048382737,0.0,0.0,0.0,0.0,0.0,0.014392994,0.0,0.0,0.0,0.0,0.0,0.018624239,0.03889054,0.007776268,0.0,0.015730001,0.1082045,0.23156318,0.4739678,0.73599017,0.8307586,0.71387625,0.5394595,0.3381968,0.19014436,0.14398657,0.08345314,0.024673887,0.0,0.0,0.0,0.0,0.0,0.009108521,0.0,0.0,0.0,0.0,0.0,0.025642224,0.040340252,0.0,0.0,0.0,0.0,0.0,0.15654543,0.45772249,0.7812269,0.84674585,0.60324085,0.26370743,0.014395185,0.026211932,0.023627311,0.011032537,0.0,0.0,0.0,0.0,0.0045738816,0.012284115,0.0,0.0,0.0,0.0,0.008157119,0.018024795,0.039074622,0.0,0.0,0.0,0.0,0.0,0.024233595,0.26972592,0.69484204,0.9070512,0.6891716,0.2880714,0.0,0.0,0.0,0.0,0.02909533,0.043348476,0.04233384,0.02121228,0.008130185,0.015564166,0.0,0.0,0.0,0.0,0.013453193,0.011591814,0.045653842,0.0,0.0,0.0,0.0,0.0,0.0,0.14529794,0.59616107,0.9196589,0.80100006,0.42227036,0.037379034,0.0,0.0,0.0,0.037022434,0.038792282,0.039463133,0.02778244,0.0069322363,0.017586105,0.011911117,0.0009474009,0.0,0.0,0.025076166,0.010562837,0.058969505,0.03610263,0.007833064,0.020608,0.0022923797,0.0,0.0,0.047387607,0.46458304,0.86034364,0.8437431,0.53954226,0.114430085,0.0,0.0,0.0,0.032636717,0.023817144,0.014875352,0.01048024,0.0,0.01604864,0.023926295,0.0,0.0,0.014116161,0.03611216,0.007969752,0.10881065,0.15419537,0.11649566,0.09426376,0.0345857,0.0,0.0,0.0,0.33096945,0.7861219,0.8446333,0.65124893,0.17634548,0.0,0.0,0.0,0.014572345,0.0,0.0,0.0,0.0,0.016102359,0.037859216,0.009400912,0.03536001,0.05250469,0.054112993,0.028905302,0.14781009,0.25708908,0.21531957,0.1489426,0.08284366,0.0,0.0,0.0,0.2711867,0.72288597,0.80426604,0.6725304,0.18049113,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023989916,0.052297607,0.04536917,0.09065661,0.10620692,0.090739354,0.07566913,0.18881693,0.3548485,0.31665897,0.20017764,0.14397927,0.016473219,0.029594138,0.0,0.30011076,0.73342144,0.8141761,0.6557809,0.13996017,0.0,0.0,0.0,0.00072963536,0.0,0.0,0.0,0.0],[0.0,0.026792333,0.016164258,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07655996,0.19275104,0.27306372,0.40522408,0.58963513,0.6751574,0.6737733,0.55123246,0.42188203,0.17964472,0.08262544,0.028208368,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.024267472,0.021389432,0.0069979057,0.0,0.0,0.0,0.0,0.0,0.0,0.08403065,0.20404443,0.3002088,0.4532761,0.63136095,0.6595967,0.5702192,0.47501916,0.40869182,0.1926368,0.113678545,0.04865773,0.0,0.0,0.0,0.0,0.0,0.0034922957,0.0,0.0069219097,0.0,0.0058331713,0.0,0.0,0.0,0.0,0.0,0.0,0.0722169,0.20922817,0.3120622,0.5141972,0.70203376,0.70973796,0.5077475,0.39115566,0.35522234,0.22425103,0.15020974,0.091437414,0.029259525,0.0,0.0,0.0,0.0,0.011747673,0.0,0.0019687116,0.0,0.008079216,0.0,0.0,0.0,0.0027487874,0.0,0.0,0.054107025,0.16725573,0.23933119,0.48147917,0.7395311,0.8519818,0.5942058,0.42463154,0.26135254,0.16588312,0.09176068,0.08243639,0.020249523,0.0,0.0,0.0,0.0,0.019612752,0.0,0.009275772,0.0038411766,0.022106104,0.011958092,0.0,0.0011400878,0.006985858,0.0,0.0,0.0001579076,0.00013057888,0.025260001,0.2681832,0.6081309,0.910276,0.80443084,0.5124281,0.17994535,0.022114962,0.0,0.034990475,0.033070296,0.0,0.011576176,0.0,0.0,0.020054474,0.0,0.013179198,0.009627923,0.004045263,0.0016387701,0.006546743,0.0,0.024094082,0.0,0.0,0.0,0.0,0.0,0.15149891,0.4933706,0.9324744,0.9731798,0.59256405,0.1665919,0.0,0.0,0.0,0.045890994,0.028324604,0.06510272,0.043363206,0.0,0.011729293,0.0,0.015926115,0.01649142,0.007562235,0.005893849,0.008827254,0.0,0.04419492,0.0,0.0,0.0,0.0,0.0,0.08905903,0.3864869,0.8664715,1.0,0.7034434,0.2719438,0.0,0.0,0.0,0.053448,0.030396365,0.060549602,0.050697356,0.0,0.010534525,0.0,0.020995133,0.031303927,0.028330065,0.027753398,0.029726408,0.0,0.054903448,0.013201565,0.0203956,0.0,0.0,0.0,0.032694563,0.27749097,0.72245777,1.0,0.8058338,0.40869695,0.0018354505,0.0,0.0,0.033611096,0.021005124,0.05303029,0.037265874,0.0,0.013924696,0.0,0.023339957,0.043944605,0.049595654,0.057827055,0.053062007,0.012496069,0.10299337,0.104634285,0.1149872,0.006714992,0.0,0.0,0.0,0.16391313,0.5602545,1.0,0.9102562,0.5806024,0.101247296,0.0,0.0,0.010218613,0.0,0.04429003,0.04162754,0.0,0.021079645,0.0,0.018719837,0.057164162,0.085192785,0.09801869,0.08154318,0.029883184,0.12564231,0.17076036,0.16969363,0.029465921,0.0,0.0,0.0,0.12191889,0.46797955,0.98276615,0.9349105,0.6570039,0.15215434,0.0,0.0,0.0,0.0,0.022954226,0.0144519955,0.0,0.0245957,0.0,0.018137604,0.06329821,0.10349749,0.13279736,0.12720305,0.060260244,0.12999094,0.21831608,0.20046198,0.051660016,0.01163701,0.0,0.0,0.105262004,0.43951982,0.9708009,0.9503418,0.6449778,0.14575014,0.0,0.0,0.014956541,0.0,0.018556774,0.0,0.0,0.01845216],[0.031608887,0.021299161,0.026847705,0.0,0.0,0.0,0.0,0.015732192,0.0,0.0010000318,0.10171118,0.29897386,0.48821324,0.7092337,0.79222476,0.7785184,0.7896913,0.5099674,0.38774842,0.06738629,0.014378071,0.0,0.0,0.0,0.0,0.022333004,0.046031825,0.00052946806,0.032567732,0.03509319,0.037197806,0.0,0.0,0.0,0.0,0.016589582,0.0,0.005376786,0.09459979,0.2665633,0.44313723,0.712218,0.810519,0.78204453,0.6986651,0.43408543,0.33945805,0.08924614,0.040334262,0.0,0.0,0.0,0.0,0.017983288,0.046195082,0.0018846393,0.0085223615,0.01463525,0.028675832,0.0,0.0,0.0014440566,0.0,0.022392593,0.0,0.0,0.06140577,0.21289518,0.37892523,0.6506296,0.7953276,0.75984454,0.6071504,0.3585112,0.3050265,0.12891039,0.08444114,0.030733958,0.006437376,0.0,0.0,0.0027956218,0.035302013,0.0036094189,0.0,0.0,0.010391541,0.0,0.0,0.0075968504,0.0,0.02686508,0.0,0.0,0.011890583,0.11261904,0.23003048,0.5225089,0.75397706,0.77367187,0.6090722,0.34256962,0.24768367,0.12632963,0.09535837,0.046012342,0.0,0.0,0.0,0.0,0.023097716,0.019420922,0.0,0.0,0.036032252,0.011190496,0.0,0.013041437,0.004572928,0.040570997,0.0,0.0,0.0,0.0028891712,0.074166164,0.39156824,0.73064655,0.8947797,0.76268643,0.36320245,0.1178979,0.015227199,0.019223131,0.032331973,0.0028036088,0.022890955,0.016450562,0.0055770427,0.019529581,0.016650103,0.0,0.0,0.03406159,0.0118441805,0.0,0.011398405,0.012227237,0.045330763,0.0,0.009535953,0.0,0.0,0.0,0.30468333,0.7051469,1.0,0.9125266,0.43601656,0.065675355,0.0,0.0,0.019942746,0.03223066,0.08042099,0.08541329,0.05491688,0.02935341,0.00016474724,0.0,0.0,0.028588153,0.01003892,0.0,0.0035385191,0.016336635,0.043908834,0.0,0.029443525,0.0,0.0,0.0,0.21421269,0.5891706,1.0,1.0,0.57179576,0.12406276,0.0,0.0,0.013272993,0.03597129,0.08414504,0.09148279,0.07157947,0.04229399,0.0,0.0,0.0,0.020584412,0.018168695,0.0,0.0036626607,0.022061259,0.04900957,0.0,0.053257406,0.0,0.0,0.0,0.106018156,0.43498552,0.94591624,1.0,0.72276455,0.21797478,0.0,0.0,0.0,0.034193717,0.08082424,0.10096436,0.07004945,0.047971442,0.003708467,0.0,0.0,0.0,0.011119783,0.0,0.0062010735,0.034967758,0.1115263,0.09114967,0.13073425,0.018482238,0.0,0.0,0.0,0.2670043,0.8290641,1.0,0.88844675,0.3569423,0.0,0.0,0.0,0.020314142,0.05974049,0.11315686,0.07527683,0.058568284,0.010648675,0.0,0.0,0.0,0.023359396,0.0,0.024995968,0.04497239,0.14405283,0.13833667,0.17136607,0.06573703,0.011423729,0.0,0.0,0.18972139,0.72843397,1.0,0.9524104,0.42266166,0.048244335,0.0,0.0,0.008991063,0.019544758,0.09320088,0.053188927,0.04922662,0.011423953,0.0,0.005005792,0.00042256713,0.033749424,0.0,0.043865643,0.04334034,0.15465902,0.16264863,0.18009938,0.07647996,0.036740683,0.0,0.0,0.15503614,0.65555745,1.0,0.98126036,0.4287495,0.06939204,0.0,0.007452272,0.022170492,0.013264403,0.07927904,0.0126135275,0.023476198,0.00950817],[0.010026045,0.02968891,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04727689,0.15378866,0.44275242,0.65932214,0.9227848,0.95002687,0.88779944,0.6832739,0.444822,0.23502961,0.012186579,0.0,0.0,0.002765134,0.0,0.0,0.033635966,0.013594277,0.0,0.016224682,0.03517209,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.031823993,0.10300084,0.3636594,0.58500093,0.9091448,0.97286165,0.9064233,0.5988383,0.36525342,0.19475001,0.03347075,0.0,0.0,0.009602025,0.0,0.0,0.03514789,0.01341527,0.0,0.00046280026,0.016916305,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.056272335,0.27311772,0.4710188,0.84586585,0.95114404,0.8737073,0.52164555,0.30328193,0.1681718,0.06195213,0.0,0.0,0.030493163,0.0,0.0,0.02611991,0.0026129484,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0069478974,0.0,0.0,0.0,0.0056709796,0.12357088,0.28801548,0.70135826,0.8783996,0.80843353,0.49499357,0.25316268,0.14680953,0.06216521,0.0,0.0063460916,0.016006872,0.0,0.0,0.0099915415,0.011886001,0.0011955351,0.0,0.0008466691,0.0087439045,0.0,0.0,0.0,0.005157605,0.0034151673,0.0,0.0,0.0,0.0,0.119582124,0.59722525,0.92204005,0.88396966,0.54880124,0.15491202,0.020614512,0.0,0.00962659,0.028874308,0.0054576844,0.0,0.026164643,0.015930519,0.03328196,0.006740235,0.0,0.0043199956,0.009225652,0.0,0.0,0.0,0.0073517635,0.0,0.0,0.0,0.0,0.0,0.028914236,0.5050141,0.9398037,0.9748676,0.6168341,0.11242847,0.0,0.0,0.0036494285,0.050269805,0.008787081,0.0,0.077980414,0.049065627,0.046823762,0.0,0.0,0.0059532598,0.0026984662,0.0,0.0,0.0,0.003732562,0.0,0.0,0.0015401393,0.0,0.0,0.0,0.38749373,0.8755046,1.0,0.76338655,0.21049014,0.0,0.0,0.0,0.04620333,0.003684014,0.0,0.087325126,0.059035018,0.05054669,0.001304239,0.0,0.014434755,0.005505383,0.008385174,0.0,0.0,0.011023253,0.0,0.0,0.005165145,0.0,0.0,0.0,0.2704539,0.7548127,1.0,0.9242909,0.36648613,0.0,0.0,0.0,0.040910758,0.0,0.0,0.080370195,0.046076275,0.047096975,0.011324793,0.0033005178,0.018323027,0.0,0.014378488,0.0,0.0023189783,0.041129284,0.0069535747,0.017063618,0.0347538,0.0,0.0,0.0,0.15824959,0.58805287,0.94022804,1.0,0.54653084,0.121280536,0.0,0.0,0.037215404,0.0,0.0,0.089946866,0.021562122,0.04752001,0.025098607,0.0049564093,0.029693075,0.0,0.032306008,0.0,0.03236556,0.06168381,0.023659326,0.051446415,0.056359902,0.019892707,0.0,0.0,0.10075863,0.4738884,0.84780264,1.0,0.6532964,0.20415269,0.0,0.0,0.049440093,0.0,0.0,0.083588704,0.0,0.038599037,0.024269909,0.0018336326,0.041006625,0.006264612,0.04479921,0.000836879,0.056502573,0.073488235,0.040185027,0.08060976,0.065958135,0.023480527,0.0022217333,0.0,0.07781544,0.38910133,0.7861665,1.0,0.7035489,0.2272436,0.0,0.0,0.05707342,0.0,0.0,0.062308513,0.0,0.008990608,0.016771123],[0.015772633,0.0,0.0,0.0,0.0,0.0,0.024225019,0.048165902,0.032546952,0.094210535,0.20734629,0.42039514,0.71062493,0.86069816,0.910906,0.8436249,0.7251633,0.399298,0.22840653,0.0624206,0.0034659058,0.0,0.0,0.0,0.026000105,0.0069142953,0.0,0.0,0.018130906,0.0019916147,0.0,0.0,0.0,0.0,0.020906761,0.037760533,0.015189566,0.044088848,0.11405127,0.34468287,0.66611505,0.9264003,0.99633336,0.89181125,0.64311814,0.30918095,0.12625158,0.0,0.0,0.0,0.0,0.0028868467,0.036129907,0.015549161,0.0,0.0,0.01358363,0.0,0.0,0.0,0.0,0.0,0.019861117,0.03585214,0.007780798,0.029516466,0.0639729,0.27009806,0.5745687,0.9049066,1.0,0.8984902,0.57082176,0.27199966,0.11569083,0.0,0.0,0.0,0.0,0.0,0.034368515,0.010653004,0.0,0.0,0.016380757,0.0,0.0,0.0,0.0,0.0,0.019282259,0.025953919,0.0007375628,0.02796296,0.013253003,0.122318745,0.32724965,0.71248204,0.9102231,0.8597709,0.5180952,0.2542029,0.11942115,0.018781908,0.007055603,0.010572679,0.0,0.0015995651,0.045580097,0.0,0.006376952,0.0015087724,0.012970351,0.0,0.0,0.0,0.0,0.0,0.021946356,0.012748264,0.0,0.0,0.0,0.0,0.16349486,0.6011103,0.86615777,0.80247134,0.40960127,0.09585859,0.0,0.0,0.0,0.030608103,0.0073451623,0.0,0.05170782,0.0173909,0.018463895,0.002840966,0.013205282,0.0031981617,0.0,0.0,0.0,0.0,0.01585655,0.0044448823,0.0,0.0,0.0,0.0,0.08410473,0.5653401,0.8836801,0.8389718,0.39499277,0.042819902,0.0,0.0,0.0,0.032852024,0.00445424,0.011481725,0.06808129,0.045063585,0.02972851,0.010027856,0.01090233,0.0027005225,0.0,0.0,0.0,0.0,0.013938628,0.0033833832,0.0,0.0,0.0,0.0,0.06813946,0.57651937,0.89917207,0.940953,0.5175492,0.11476213,0.0,0.0,0.0,0.012029946,0.0,0.023226045,0.07497246,0.05153738,0.034875624,0.02040781,0.0059501156,0.010804072,0.023531757,0.016761802,0.0,0.0,0.016134225,0.00089262426,0.0,0.0,0.0,0.0,0.08376072,0.55609584,0.8584386,0.99265057,0.6304933,0.2099151,0.0,0.0,0.0,0.0,0.0,0.02754049,0.065619,0.03967011,0.034900807,0.027591504,0.006722845,0.019059174,0.03864181,0.017064571,0.009251207,0.0,0.033487387,0.0024145544,0.0,0.0,0.0,0.0,0.11179338,0.49461257,0.73324364,0.9402247,0.6802863,0.29474828,0.0,0.0,0.0,0.0,0.0,0.019311085,0.050695896,0.031839915,0.052192733,0.045513637,0.008921228,0.03582125,0.063865945,0.025661893,0.018270373,0.0,0.030327171,0.002014488,0.0,0.003980294,0.0,0.017014861,0.13544758,0.4329607,0.62882763,0.86682975,0.70281714,0.36575592,0.027645953,0.0,0.0,0.0,0.0,0.008611806,0.048156828,0.027132235,0.0685219,0.05462545,0.010372415,0.04356256,0.08046319,0.060617767,0.04695048,0.0045491606,0.027495295,0.0022043884,0.0,0.017978735,0.015054129,0.04565286,0.14451596,0.37195298,0.5418148,0.78797656,0.7262246,0.43388492,0.06471791,0.0,0.0,0.0,0.0,0.0012211204,0.037900142,0.011330679,0.0773205,0.06144666],[0.019042619,0.012275651,0.004254684,0.0037248582,0.0025138855,0.0,0.052656174,0.002677083,0.009502366,0.045664683,0.072006166,0.2626691,0.5928853,0.71991634,0.7313261,0.7386377,0.535191,0.41661882,0.31524348,0.09747422,0.054511726,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016296439,0.0,0.0,0.0,0.0,0.0,0.0435965,0.0,0.0,0.0,0.02339004,0.23721969,0.6292705,0.8405871,0.8795041,0.84512794,0.48056167,0.26081946,0.13055514,0.0,0.010187082,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019161507,0.0,0.0,0.0014727861,0.004743248,0.0,0.03051737,0.0,0.0,0.0,0.03648323,0.2038292,0.60016006,0.8738485,0.97164035,0.90501,0.43482792,0.20582205,0.104210585,0.0,0.024999887,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03231185,0.0,0.004084587,0.0046126395,0.022233367,0.0,0.024777994,0.0017833412,0.0,0.0,0.017398588,0.09855732,0.4146564,0.78141296,0.9399987,0.8564633,0.4087628,0.19951874,0.0911641,0.0102795735,0.058730587,0.0,0.015390918,0.008013867,0.011399671,0.0,0.0,0.0,0.026901208,0.0,0.00443393,0.004156038,0.01912669,0.0,0.02298282,0.0,0.0,0.0,0.0,0.044140987,0.27927864,0.76085204,0.9335623,0.7174335,0.25866812,0.009503022,0.0,0.009356007,0.084140316,0.011006057,0.017412089,0.018182777,0.031107955,0.023656711,0.010677375,0.0,0.015480176,0.0,0.010774411,0.0,0.019425996,0.0,0.013872236,0.0,0.0,0.0,0.0,0.048755668,0.23155406,0.78894997,0.9716773,0.6909689,0.22545415,0.0,0.0,0.0,0.06564697,0.030132301,0.033158727,0.032490984,0.053030394,0.052788876,0.034581706,0.005363673,0.008649386,0.0,0.018825933,0.0,0.020563193,0.0,0.008062974,0.0,0.0,0.0,0.0,0.05267687,0.26957303,0.8237763,0.99088246,0.7674583,0.31626856,0.0,0.0,0.0,0.039957456,0.02385401,0.034503162,0.039386705,0.058446057,0.049405716,0.0407466,0.01469066,0.0006978065,0.010197438,0.03995263,0.0,0.0124552995,0.0059303194,0.0,0.0,0.0,0.0,0.0,0.08676527,0.3131466,0.8163236,0.9624129,0.8172721,0.40544248,0.0,0.0,0.0,0.009926699,0.013999097,0.03863758,0.04563901,0.060661472,0.04748007,0.05421838,0.02954299,0.0,0.012355618,0.058351584,0.0,0.0005463213,0.017463602,0.0,0.0,0.0,0.0,0.0,0.13235138,0.3401431,0.7653972,0.86160433,0.79209805,0.48043823,0.032935195,0.0,0.0,0.0,0.013317004,0.059438936,0.046865866,0.04886657,0.059083797,0.0993141,0.060453452,0.0023111105,0.029644586,0.08268747,0.0,0.0,0.009200186,0.0,0.0,0.0,0.032382026,0.025824144,0.16139063,0.346813,0.6979223,0.7437016,0.7616778,0.5319604,0.08658465,0.0,0.0,0.0,0.0052595437,0.06273089,0.05932074,0.044624485,0.06545981,0.12655826,0.08245108,0.0,0.03327076,0.09532386,0.0025013387,0.0041881204,0.015292212,0.0,0.0035050213,0.0,0.093798205,0.077237114,0.18655545,0.34257054,0.6112816,0.6263357,0.73027414,0.5789785,0.15307325,0.0,0.0,0.0,0.0024436563,0.052663907,0.076311514,0.037385195,0.0629673,0.14108038,0.09769],[0.0,0.030001,0.03305188,0.0,0.0,0.04816377,0.046590105,0.0,0.004181117,0.0,0.05519429,0.16797832,0.40300548,0.5209288,0.5635935,0.49642807,0.4727078,0.43746156,0.36933392,0.16964285,0.049176216,0.0,0.0,0.0007954687,0.021313265,0.017472379,0.004314691,0.0,0.0,0.02044221,0.024646796,0.0,0.0,0.037546664,0.025105134,0.0,0.0,0.0,0.04078436,0.21249199,0.5013529,0.74795556,0.81224406,0.67613804,0.43541974,0.24085753,0.14585084,0.031656943,0.0016161054,0.0,0.0,0.0072669387,0.010960527,0.015902765,0.0,0.0,0.0,0.015654251,0.028059125,0.0,0.0,0.029115312,0.009107232,0.0,0.0,0.0,0.021826752,0.196609,0.50883424,0.8810278,0.99000186,0.84751457,0.4166351,0.15609786,0.07655485,0.02245386,0.01863473,0.0,0.004155591,0.012439422,0.0,0.01811532,0.0,0.0,0.0,0.018727176,0.03463386,0.0,0.0,0.030241236,0.014903136,0.0,0.0,0.0,0.0,0.10144071,0.42801142,0.87019473,1.0,0.8360301,0.39563686,0.12834458,0.065538436,0.025661394,0.051679283,0.018256634,0.05813469,0.01013986,0.0,0.019630305,0.0,0.0,0.0053673834,0.024201073,0.041121103,0.017607696,0.0,0.030707851,0.029131033,0.0,0.0,0.0,0.0,0.098658726,0.4017645,0.84716827,0.9153907,0.57793343,0.15859525,0.0,0.011605315,0.02439601,0.03675002,0.016852476,0.055946626,0.01770474,0.042910494,0.04420533,0.01561252,0.0,0.002179265,0.015251853,0.0363717,0.021574296,0.0058459938,0.027132735,0.034512743,0.0,0.0,0.0,0.0,0.15831056,0.4526953,0.8922167,0.8701879,0.42433995,0.04217376,0.0,0.0,0.02728165,0.033117436,0.025896527,0.054645173,0.019882366,0.07426719,0.07073216,0.036642797,0.0,0.0,0.013285041,0.03167689,0.01576829,0.0026932657,0.0387656,0.041876927,0.0,0.0,0.0,0.018757649,0.21492253,0.5309507,0.94394046,0.88277,0.38204318,0.037211448,0.0,0.0,0.03020291,0.024827555,0.02145838,0.045302853,0.011938944,0.08483894,0.08174546,0.049355313,0.0020215362,0.0,0.011552088,0.022434935,0.012782529,0.0,0.03699483,0.03621164,0.0,0.0,0.0,0.058227926,0.24921355,0.57843125,0.91879493,0.8506729,0.3440082,0.06506718,0.0,0.0,0.033828154,0.01873602,0.026956491,0.04159797,0.011921197,0.09533338,0.09350956,0.06874013,0.010654047,0.0,0.005612001,0.007182926,0.012386166,0.0130158365,0.040842168,0.027561925,0.0,0.0,0.0,0.12493828,0.31978709,0.61655825,0.82661265,0.743189,0.28270274,0.09042689,0.0,0.0,0.037817642,0.023446433,0.045015693,0.046626724,0.02839899,0.11785298,0.13592036,0.11923389,0.038229316,0.0046337396,0.010130808,0.006437376,0.011571348,0.0075190216,0.054508045,0.02260822,0.0,0.019925743,0.031391904,0.20067088,0.38332623,0.6555188,0.7663283,0.6697962,0.24900815,0.103771225,0.0,0.004533574,0.04326146,0.031003222,0.053306885,0.048879273,0.039821975,0.12847976,0.16279958,0.15063757,0.05772937,0.0,0.0026391596,0.0,0.009411089,0.0147431195,0.08056459,0.025512166,0.01223357,0.10625994,0.12859607,0.29316175,0.42009652,0.6588072,0.7132736,0.5996218,0.2334373,0.14266576,0.007147655,0.02895502,0.048197247,0.043037765,0.06741893,0.059914134,0.048215598,0.13222991,0.17207974,0.16387874,0.0700206],[0.0,0.0018694997,0.0044516325,0.0,0.0,0.07761182,0.07707603,0.022756398,0.10054468,0.0,0.057331257,0.09380008,0.32050276,0.41926044,0.35527617,0.3929714,0.3499687,0.45668805,0.4115454,0.1970864,0.044202097,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0036070794,0.003973216,0.0035310239,0.0,0.0,0.04462003,0.032857932,0.0,0.06674852,0.00025439262,0.093850754,0.19821644,0.45795614,0.6873641,0.665371,0.5670958,0.33387372,0.25629002,0.1487078,0.045816876,0.0021352172,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0106790215,0.012264259,0.0031773,0.0,0.0,0.0141733885,0.0102598965,0.0,0.03406202,0.0,0.07599174,0.22749007,0.5481433,0.9013012,0.9369465,0.72955316,0.31449842,0.12092599,0.019849733,0.015431665,0.009533741,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02384498,0.015043899,0.0,0.0,0.0,0.0057979897,0.016923979,0.0,0.013009131,0.0,0.011640362,0.16103633,0.55885345,0.98225623,1.0,0.71658677,0.24484575,0.05359789,0.0,0.0010956973,0.0028519928,0.0006637126,0.0,0.0,0.0,0.0,0.010477312,0.0062082633,0.033104464,0.006067723,0.010686941,0.0,0.0,0.0016303211,0.03453473,0.0,0.0,0.0,0.008932628,0.15886995,0.56930023,0.948144,0.87468195,0.41915905,0.023556456,0.0,0.0,0.00056895614,0.008751906,0.016470186,0.015323728,0.0,0.021736048,0.011279441,0.027539171,0.0000346452,0.034012444,0.0,0.01834409,0.002930805,0.0,0.0031296313,0.069659606,0.0,0.0,0.0,0.035810806,0.21978416,0.6177664,0.9491352,0.7586913,0.2232282,0.0,0.0,0.013361603,0.02815687,0.039280348,0.021334931,0.036088355,0.0020005256,0.029161222,0.030506141,0.032188185,0.0,0.03103967,0.0,0.013938867,0.0,0.0,0.0,0.083493486,0.0,0.0,0.0,0.058424883,0.30378175,0.69718796,0.9874199,0.71499306,0.14384045,0.0,0.0,0.005263865,0.053817898,0.05554553,0.013340585,0.046528794,0.013091989,0.032433353,0.041445404,0.023835257,0.0,0.026178055,0.0,0.013342731,0.0,0.0,0.0,0.08920281,0.0,0.0,0.0350561,0.10514056,0.38817972,0.73019046,0.97905844,0.6742932,0.10943613,0.0,0.0,0.0,0.07275408,0.06548318,0.01423569,0.07136804,0.02993112,0.040221132,0.064719096,0.019905277,0.0,0.029228836,0.0,0.005136892,0.004069999,0.04639022,0.01921215,0.10483823,0.0,0.0,0.071202345,0.20748252,0.5007201,0.7395604,0.89330673,0.6037774,0.08125466,0.0,0.0,0.0,0.08899946,0.070943356,0.0138918385,0.08188319,0.051977046,0.06367327,0.114641264,0.03546817,0.0030081868,0.029371053,0.0,0.0046129823,0.005547717,0.07304121,0.04403188,0.13673851,0.018537536,0.0,0.14792062,0.33575058,0.6153655,0.7843994,0.8304766,0.5714647,0.081675425,0.0,0.0,0.01801379,0.099705026,0.07083231,0.014897138,0.08975874,0.06187077,0.08469868,0.1539877,0.044050477,0.015390441,0.015858077,0.0,0.0,0.0,0.085409835,0.06601157,0.17325497,0.09598063,0.10869058,0.29177526,0.47933167,0.6846026,0.8128601,0.7902844,0.56250626,0.122915015,0.010187641,0.0,0.042857572,0.09957755,0.059393764,0.02086889,0.10894903,0.07210693,0.11016922,0.18424267,0.05737721,0.021307297],[0.008837469,0.0,0.00011470914,0.0028572828,0.0020999014,0.034531236,0.04387691,0.034799032,0.08688438,0.08509673,0.13224699,0.1137065,0.19286124,0.20841268,0.12106077,0.15129891,0.36614165,0.49900973,0.499256,0.244066,0.0979418,0.0,0.0,0.0045209974,0.0,0.0,0.0,0.0,0.010972485,0.0,0.0011774749,0.006546274,0.0,0.0,0.0039836466,0.025685579,0.09092017,0.11446748,0.1835353,0.22390188,0.36596102,0.50411814,0.49818093,0.46356308,0.42114544,0.3291934,0.20499161,0.0019079,0.009865537,0.0,0.0,0.015275143,0.0,0.0,0.0,0.0,0.010416977,0.0,0.007904045,0.008678041,0.0,0.005808547,0.0,0.006773427,0.07259095,0.06890303,0.14901873,0.28332332,0.56472623,0.82628036,0.85335773,0.63795364,0.28104246,0.09994413,0.038308673,0.0,0.0,0.0,0.0,0.014947891,0.0,0.0,0.0,0.0,0.0105835125,0.0,0.019975655,0.010340169,0.0,0.01107242,0.0,0.0,0.037738986,0.0,0.064837925,0.3258549,0.75309473,1.0,0.9634733,0.60788196,0.12803093,0.0,0.0,0.0,0.0,0.0,0.0,0.010833725,0.0,0.0,0.0,0.0,0.011767954,0.0036542267,0.04347892,0.008668549,0.0,0.029085629,0.011853285,0.0019129664,0.014037907,0.0,0.11473799,0.4474107,0.89786595,0.9879801,0.69525605,0.23104839,0.0,0.0,0.0,0.0,0.0,0.0,0.008476883,0.022221386,0.015496738,0.019774258,0.014697388,0.0015634596,0.00945586,0.0,0.045645736,0.012439087,0.0,0.05694431,0.039012223,0.020862408,0.005810261,0.0,0.2467688,0.6120774,0.990333,0.8850121,0.47248363,0.033071227,0.0,0.010333866,0.0,0.0026325583,0.015144408,0.022628844,0.015991576,0.018108606,0.016267873,0.024802886,0.028039917,0.014649384,0.008359648,0.0,0.037161738,0.019794643,0.0,0.060087055,0.04052493,0.016612992,0.0,0.04902421,0.3813238,0.7561089,1.0,0.82850933,0.35582566,0.0,0.0,0.023870364,0.0,0.0,0.011922665,0.019681007,0.026091486,0.025262251,0.02438657,0.024018064,0.024638735,0.0133462325,0.00924772,0.0,0.034169815,0.034634285,0.0,0.06427425,0.04131861,0.008284919,0.030291803,0.12828359,0.5184709,0.8596548,1.0,0.7350778,0.2752276,0.0,0.0,0.022575796,0.0,0.0,0.02252791,0.034345344,0.053787336,0.04750541,0.045879595,0.042491406,0.034648225,0.014723308,0.0142902285,0.0,0.03185881,0.06438763,0.02554351,0.07781618,0.06619598,0.013293251,0.0662775,0.20104992,0.66849005,0.964572,1.0,0.59452707,0.20396242,0.0,0.0,0.043363787,0.0,0.024256371,0.059915528,0.072564445,0.09236099,0.08126184,0.0812009,0.095850214,0.08285616,0.045266047,0.025888115,0.024192072,0.04060489,0.08475125,0.035562143,0.07913988,0.103165075,0.0790097,0.16379985,0.29055,0.778498,1.0,0.9843706,0.5288285,0.18150255,0.0,0.0034849346,0.13259687,0.040701866,0.09920052,0.12768544,0.11265639,0.14049561,0.12055678,0.121844314,0.14682744,0.12205624,0.06544782,0.019788064,0.026203342,0.025526397,0.076277114,0.038820237,0.08927428,0.14312264,0.16768982,0.3140368,0.44125783,0.8509493,1.0,0.9542788,0.52384996,0.20141184,0.0,0.120350614,0.23333615,0.13822326,0.1765176,0.18790357,0.15021273,0.1837527,0.17020632,0.17019439,0.18613137,0.14507379,0.073587514],[0.00027176738,0.001654774,0.0,0.00608287,0.07407352,0.07213194,0.06700615,0.160125,0.1536069,0.17653033,0.20509376,0.15898967,0.1885609,0.113506444,0.11575634,0.25028366,0.4833287,0.6996789,0.51257324,0.2691208,0.010844834,0.0,0.0,0.05166705,0.014044575,0.008325838,0.0,0.0,0.0069699883,0.0,0.0,0.009084351,0.03579203,0.030614555,0.03163632,0.14608584,0.14900938,0.22902404,0.26035658,0.26313752,0.3158468,0.37866366,0.46043414,0.56049186,0.50579154,0.4849012,0.2050502,0.029006414,0.0,0.0,0.0017383844,0.050816245,0.0193481,0.0,0.0,0.0,0.010271184,0.0,0.0034640431,0.019361869,0.019818686,0.021527648,0.020684205,0.088962406,0.11927311,0.18300506,0.23026435,0.35746297,0.5362149,0.76186526,0.7660984,0.6130942,0.25196692,0.1459366,0.025448628,0.0,0.0,0.0,0.0,0.037142284,0.01731623,0.0,0.0,0.0,0.012904339,0.0041261613,0.012957029,0.028905481,0.007964298,0.016793527,0.0052636564,0.043523453,0.0710206,0.07832639,0.18761393,0.45136184,0.8078574,1.0,0.8506767,0.44182837,0.0,0.0,0.0,0.0,0.0,0.0,0.0019655675,0.020484641,0.012600429,0.0,0.0,0.0,0.015121117,0.025658362,0.0024636388,0.00934349,0.0,0.01637163,0.002160266,0.038666345,0.016951784,0.05052983,0.29075104,0.60236305,0.96691626,1.0,0.57418627,0.121478766,0.0,0.0,0.0,0.013362728,0.018545061,0.0,0.0051760525,0.015762359,0.036476046,0.023213886,0.023470484,0.0,0.014260657,0.030181795,0.0,0.0093864575,0.020966709,0.034228668,0.02107624,0.058039322,0.0,0.10126043,0.4422533,0.7683086,0.99711,0.8606129,0.32255474,0.0,0.0,0.007504344,0.0,0.05970504,0.05396583,0.01765652,0.027942851,0.02103357,0.05300644,0.039800562,0.037681416,0.020446263,0.0164994,0.027103782,0.0,0.024068758,0.04869257,0.048897162,0.035076678,0.04714623,0.0025733113,0.20537773,0.6017408,0.924544,1.0,0.7207754,0.22759679,0.0,0.0,0.03187631,0.013871029,0.08317076,0.0707306,0.05481609,0.079412356,0.07016978,0.09380013,0.047491387,0.03746011,0.027756065,0.020418637,0.029719055,0.0,0.04385084,0.07812269,0.06157413,0.05486524,0.060646385,0.06412175,0.3262065,0.7389737,1.0,0.94709665,0.5683954,0.1554894,0.0,0.0,0.033144414,0.031365402,0.11824612,0.10677329,0.11053831,0.14614499,0.13128957,0.14579661,0.07714762,0.04703173,0.035279356,0.023943126,0.029622652,0.0,0.07042941,0.12019509,0.08021158,0.10024474,0.09035832,0.12830141,0.4302538,0.8586022,1.0,0.83425635,0.3840239,0.08004467,0.0,0.0,0.063467965,0.08360869,0.18688062,0.16729878,0.18535922,0.21716252,0.19811083,0.21544495,0.15015617,0.09958398,0.07107036,0.029543951,0.04387805,0.0,0.0902462,0.13361305,0.087328106,0.1391472,0.1801579,0.22636065,0.5143662,0.93313694,1.0,0.7732669,0.30507284,0.066942126,0.0,0.118154675,0.22334038,0.2643268,0.32895142,0.27709752,0.26207694,0.29454413,0.26701647,0.28114063,0.2123928,0.1372444,0.09669657,0.029087111,0.05148743,0.0,0.09207168,0.14093038,0.0931119,0.16664162,0.2740115,0.35731912,0.6074056,0.98057324,1.0,0.74226534,0.318492,0.122160904,0.09007238,0.26843473,0.40063566,0.4475463,0.47155213,0.3843618,0.33123565,0.3627173,0.335077,0.33930093,0.24842405,0.15578291,0.11151056],[0.020157196,0.0,0.0,0.0,0.06860542,0.105594546,0.19170941,0.19306993,0.24170122,0.2583537,0.1425576,0.11510175,0.095312655,0.0925637,0.22984284,0.48897564,0.7593654,0.74262613,0.55433404,0.10707858,0.0,0.0,0.0012245625,0.058480464,0.10048538,0.079137474,0.05292026,0.0,0.021020517,0.0046194345,0.0,0.0,0.036666743,0.047629192,0.10824724,0.118869215,0.19655079,0.25750226,0.22729725,0.20904633,0.2363747,0.37249774,0.5749539,0.7273141,0.711965,0.490943,0.22096366,0.0,0.0,0.0,0.019131847,0.04005138,0.06693622,0.048891626,0.042409994,0.0,0.0073190033,0.00009089708,0.0,0.0,0.031716123,0.016165562,0.026230536,0.027815841,0.10354269,0.17998879,0.25315773,0.3496264,0.5113449,0.7065155,0.7652998,0.5872514,0.29246444,0.10121294,0.02702745,0.0,0.0,0.0,0.016915083,0.025813833,0.039101593,0.027322344,0.02743423,0.0,0.0010132641,0.0031648725,0.0,0.0,0.023310386,0.0038834512,0.0,0.0,0.046338536,0.091630206,0.24704693,0.5745161,0.8944933,0.9978817,0.68154967,0.1877158,0.0,0.0,0.0,0.0,0.0,0.0,0.0023180842,0.0026096702,0.010208644,0.008196726,0.009433247,0.0,0.0005045235,0.0098404065,0.0,0.0,0.0,0.007178478,0.0,0.0,0.019574374,0.081311285,0.35575426,0.7783227,1.0,0.902855,0.3974045,0.0,0.0,0.0,0.009990469,0.02508723,0.0,0.0026384443,0.00090669096,0.0053884834,0.014820002,0.020241454,0.022359066,0.008762628,0.0068383217,0.02299714,0.0020281672,0.0,0.0,0.03268197,0.020591617,0.0007469207,0.01683823,0.16181323,0.5400411,0.9170765,0.97416335,0.6560059,0.16530782,0.0,0.0,0.0,0.02765695,0.057533875,0.014368705,0.0,0.0,0.0,0.018701881,0.029221736,0.03524548,0.024408273,0.014116846,0.028184146,0.004468918,0.0,0.019769214,0.056774862,0.03777223,0.04717438,0.12740807,0.38115495,0.75902325,1.0,0.8731145,0.4852352,0.05671125,0.0,0.0,0.008337572,0.06226261,0.084918246,0.03232225,0.029190034,0.056780323,0.049850576,0.05215107,0.030719541,0.024741404,0.024216518,0.023607321,0.037148096,0.016401492,0.006464362,0.038585648,0.08307536,0.07885299,0.13727249,0.2869045,0.6065661,0.9246468,1.0,0.712823,0.31028566,0.0,0.0,0.010796025,0.041915573,0.105871364,0.13640217,0.068697155,0.07723816,0.1322707,0.11779232,0.10173341,0.05135934,0.029569276,0.024939075,0.03374263,0.044984646,0.0386132,0.028968267,0.058962658,0.123821326,0.13053359,0.21126516,0.40617663,0.81552994,1.0,1.0,0.5110104,0.14060421,0.0,0.0,0.003145948,0.067844905,0.17502397,0.20680112,0.13287774,0.13186575,0.19842184,0.1755292,0.15507442,0.109199286,0.08104795,0.04492087,0.037952855,0.04646427,0.056816757,0.042365752,0.06725726,0.1471389,0.17271,0.29875976,0.5144822,0.94400305,1.0,0.99890566,0.40588003,0.08346044,0.0,0.0011921823,0.18440971,0.30346137,0.3931625,0.3642805,0.28423262,0.23699333,0.28466633,0.24946547,0.22260238,0.17390616,0.1281103,0.06072247,0.04499895,0.059850097,0.08878176,0.062410377,0.07568735,0.1491827,0.20845547,0.3686939,0.59889203,0.9879248,1.0,0.9676992,0.3746274,0.084049836,0.00009216368,0.14148644,0.40315652,0.5586341,0.65418077,0.57058096,0.42789048,0.3146246,0.35837108,0.3187949,0.28185427,0.21769628,0.15411133,0.06873754],[0.0,0.0053193867,0.0,0.010062687,0.101283185,0.26217294,0.34636796,0.40295213,0.4256841,0.3498307,0.27476308,0.1564458,0.19678715,0.34377986,0.5182767,0.7244388,0.9402419,0.7490772,0.35458928,0.0,0.0,0.0009838194,0.033879727,0.04119654,0.047356814,0.0347116,0.05053003,0.0,0.0,0.005363375,0.0,0.0,0.038101368,0.16211629,0.2303274,0.26271695,0.3005907,0.32622385,0.28764093,0.23800224,0.28416628,0.5390294,0.71725535,0.7929748,0.76759595,0.48228598,0.09481695,0.0,0.0,0.0,0.025642559,0.019996703,0.038668342,0.019750752,0.028611474,0.0,0.0,0.0,0.0,0.0,0.01324977,0.078289896,0.10045083,0.09303406,0.16348013,0.25888893,0.32992303,0.4247591,0.5631173,0.7633143,0.7733401,0.523243,0.2578641,0.12716548,0.0,0.0,0.0,0.0,0.022056669,0.006196253,0.02347543,0.0011049211,0.011106186,0.0,0.0,0.0,0.0,0.0,0.0033658594,0.021458842,0.028912649,0.018993042,0.07144733,0.17365095,0.41429508,0.69048893,0.9497779,0.94340706,0.6168228,0.12372336,0.0,0.012364626,0.021964133,0.0,0.0,0.0,0.003985867,0.0,0.015016846,0.0,0.0005630553,0.0023481995,0.0,0.0,0.0,0.0,0.0,0.0,0.008519046,0.0,0.019674003,0.19084917,0.5407092,0.8394574,1.0,0.75616336,0.30003196,0.0,0.0,0.0,0.030725338,0.0,0.0017002225,0.0,0.0,0.018669702,0.045050435,0.0,0.019052863,0.006533973,0.0057601035,0.0,0.0,0.0,0.0,0.0,0.0026115477,0.009878777,0.024256952,0.27966237,0.65452594,0.8344147,0.81162626,0.46490908,0.06559913,0.0,0.0,0.0,0.030238226,0.024222992,0.02544982,0.0,0.0,0.028718643,0.063817285,0.009269215,0.035515986,0.015012428,0.009699807,0.0,0.0025424808,0.0,0.0,0.0,0.020059183,0.119693436,0.18922448,0.5509087,0.84070426,0.8404388,0.6223216,0.27573335,0.0,0.0,0.0,0.0,0.048881777,0.054604344,0.056406453,0.04030654,0.07842107,0.083577946,0.08461928,0.002792731,0.02693864,0.019286871,0.009528413,0.0,0.0036610216,0.0,0.0,0.002821505,0.07630172,0.2734933,0.407403,0.77462864,0.9527199,0.7632277,0.3915739,0.09308916,0.0,0.0,0.047330722,0.0,0.09693016,0.110078745,0.07897203,0.0925996,0.172496,0.14102031,0.1141213,0.0052554756,0.020854458,0.018582597,0.005349189,0.0,0.0,0.0,0.006717503,0.04336559,0.11494683,0.3742854,0.5548377,0.9302083,1.0,0.6827938,0.1464211,0.0,0.0,0.0,0.081213504,0.030712746,0.19554192,0.19787583,0.13159011,0.14730053,0.2615954,0.18035433,0.14626229,0.04389832,0.036257707,0.013068363,0.0,0.0,0.0,0.0,0.0019515753,0.063958794,0.1304303,0.45464283,0.6368228,0.9833645,1.0,0.63267976,0.029824078,0.0,0.0,0.008061171,0.24708083,0.2743017,0.40293306,0.37785766,0.27846792,0.27219647,0.36313176,0.24405119,0.19726828,0.09301128,0.053224884,0.008290626,0.0,0.0075304955,0.0005374849,0.0,0.0,0.05958052,0.1356981,0.48788232,0.66590166,0.9677195,1.0,0.6045508,0.008946016,0.0,0.0,0.09395023,0.4321437,0.5506136,0.66798955,0.5983105,0.43593842,0.38374662,0.43976194,0.30876803,0.25252292,0.12986997,0.057617143,0.0050911456],[0.0,0.0,0.0,0.002185285,0.109743804,0.1871666,0.3485828,0.49365962,0.59830946,0.50362575,0.44991457,0.45695716,0.538039,0.65413845,0.77773,0.8705488,0.82125145,0.4642697,0.207033,0.0,0.0,0.0,0.0007674545,0.05513782,0.07054891,0.044058055,0.00003258884,0.0,0.0,0.0,0.0,0.0,0.03842306,0.08560166,0.19040611,0.31090403,0.43226194,0.41917914,0.4362436,0.44411093,0.5088638,0.7051834,0.84185237,0.83886766,0.65242904,0.27707174,0.064006925,0.0,0.0,0.0,0.00001694262,0.041570954,0.04767829,0.021779336,0.0,0.0,0.0,0.0,0.0,0.0,0.015305497,0.023796715,0.043447092,0.08542696,0.22836667,0.3129645,0.42776555,0.5173281,0.60773295,0.748268,0.7296231,0.52730864,0.25536314,0.060778588,0.012132272,0.010651916,0.005572453,0.01531785,0.005148664,0.023816489,0.007838301,0.0029731542,0.0,0.0,0.0,0.0,0.0,0.0,0.022707492,0.0055564195,0.0,0.013387017,0.09981785,0.27040583,0.4861704,0.72982436,0.8832697,0.7881338,0.47411215,0.14869481,0.01740902,0.0,0.011382192,0.039588317,0.03883157,0.015235759,0.0,0.014234677,0.0,0.009296112,0.0,0.0,0.004148662,0.0,0.0,0.015593417,0.02439928,0.0,0.0,0.0057593435,0.09295716,0.32465094,0.62126046,0.821584,0.8207445,0.52611053,0.16785453,0.00808154,0.0,0.0,0.006977774,0.02836141,0.035673805,0.016801447,0.0020264387,0.017120913,0.0,0.003874451,0.0022211522,0.0,0.00958474,0.0030514896,0.0,0.021482386,0.027423695,0.0,0.0,0.012323886,0.1543287,0.41242844,0.7207041,0.75745565,0.5778964,0.23144864,0.0,0.0,0.0,0.0,0.009011976,0.018151484,0.040827096,0.02747561,0.02254086,0.0149106905,0.0,0.0,0.0006263107,0.0,0.012331761,0.002466783,0.0,0.007864401,0.020439997,0.0,0.0,0.093941435,0.36303568,0.61519045,0.8343821,0.71988904,0.414783,0.054449484,0.0,0.0,0.0021330118,0.0,0.0343752,0.043437794,0.068796635,0.072957344,0.07682606,0.04362102,0.013237938,0.0,0.0,0.0,0.016747601,0.0059289336,0.0,0.0,0.009605244,0.0,0.026724108,0.22545752,0.548332,0.7448303,0.85679615,0.6250271,0.2503215,0.0,0.0,0.0,0.009780593,0.026572458,0.07870994,0.06975374,0.08297456,0.11978141,0.1327003,0.072426304,0.028418563,0.0,0.0,0.0,0.022657014,0.029344872,0.0,0.0062075704,0.021103173,0.0,0.077504486,0.31867427,0.66372633,0.81620777,0.8229874,0.52710325,0.101862416,0.0,0.0,0.007750444,0.020053752,0.062900156,0.16375735,0.10139111,0.10215734,0.16917512,0.18816367,0.09901482,0.053048857,0.007849783,0.0,0.0,0.026071772,0.049747996,0.0,0.010338195,0.027702421,0.0,0.10241738,0.36984694,0.7112162,0.8305033,0.75537145,0.47694612,0.053327836,0.0,0.0,0.09107756,0.15981653,0.22091815,0.3486104,0.24455065,0.22915138,0.27135062,0.24816085,0.1506358,0.09078584,0.039541416,0.0,0.0,0.029605217,0.07813607,0.02538044,0.022576064,0.03215438,0.0,0.104786254,0.38266802,0.7029273,0.79225016,0.6838274,0.44097465,0.054946296,0.0,0.0,0.18976602,0.3404503,0.42114556,0.5684973,0.41845214,0.3336903,0.34633765,0.30169177,0.21244505,0.13512428,0.05873239,0.0015211403,0.0],[0.0,0.0,0.0011886805,0.0077606067,0.06050442,0.15808661,0.33614177,0.4882099,0.6287275,0.7082322,0.7512015,0.773134,0.81872207,0.86056685,0.85667276,0.82518697,0.5572597,0.25699455,0.019686423,0.0028930008,0.0,0.021507993,0.037406176,0.022251531,0.021874465,0.012504131,0.005229488,0.0,0.0,0.0,0.0,0.0,0.024901338,0.07529543,0.20259063,0.34108865,0.49044365,0.62236494,0.68039143,0.7354313,0.75886947,0.85351086,0.8597852,0.74002963,0.39738846,0.10260119,0.0,0.008041218,0.0,0.006512046,0.011074416,0.011939816,0.0,0.0005424619,0.0,0.0,0.0,0.0,0.0,0.0,0.019381404,0.026972093,0.07490363,0.1603619,0.3144659,0.5108665,0.61916625,0.749306,0.8228344,0.7913366,0.6579949,0.42514944,0.128666,0.0,0.019617096,0.0,0.0,0.004014373,0.0,0.0,0.0,0.0,0.0,0.0,0.0010290295,0.0,0.0,0.0,0.024063185,0.0045558214,0.018796228,0.10304439,0.22044179,0.45227337,0.6718311,0.89050484,0.9801228,0.69719565,0.30515823,0.082315,0.0,0.0008405745,0.07974894,0.0,0.0134655535,0.0,0.0,0.0,0.0,0.023046628,0.0,0.0,0.013911262,0.0,0.0,0.0036826283,0.021505468,0.0056990534,0.02456817,0.092794515,0.22882208,0.47295427,0.719078,0.8282152,0.77100134,0.34818676,0.041635744,0.02409181,0.043555923,0.018453188,0.07559542,0.0,0.016045153,0.009748235,0.0,0.0,0.00091329217,0.021174401,0.0017655045,0.00949949,0.025018595,0.0,0.0,0.016229324,0.018340662,0.0014781058,0.03295943,0.11536573,0.31048563,0.5704722,0.75179696,0.65063685,0.45517784,0.043115035,0.0,0.045841992,0.0779237,0.022628158,0.041630268,0.0025476962,0.023989096,0.038525216,0.008787736,0.007111512,0.016118586,0.012467399,0.0,0.016497865,0.032158516,0.0,0.003262192,0.017715469,0.025929958,0.0,0.051236197,0.19430861,0.48461503,0.7233772,0.81063986,0.5597488,0.28127712,0.0,0.0,0.062024802,0.09627934,0.031505898,0.035960227,0.02243428,0.031308673,0.07630953,0.036475554,0.037823364,0.02396375,0.0013784766,0.0,0.017392375,0.04492478,0.0,0.012043081,0.016738333,0.030210458,0.0,0.10527408,0.27706116,0.58073276,0.7652349,0.7644385,0.42420065,0.11860071,0.0,0.0,0.09207306,0.12838869,0.0655559,0.052981816,0.03470234,0.0330256,0.11643064,0.06469458,0.0667112,0.026684612,0.0017381012,0.0,0.010226652,0.055277936,0.0,0.009713508,0.032157622,0.03693603,0.007268667,0.16032715,0.31628585,0.6244521,0.72954637,0.67591304,0.31045982,0.021343626,0.0,0.0,0.13108157,0.16642466,0.13258632,0.09299,0.029374905,0.05412928,0.16373399,0.10223255,0.095830396,0.039843127,0.024185106,0.0,0.00042700768,0.06390965,0.02227813,0.010310039,0.03947171,0.044076078,0.008778036,0.1816701,0.3131249,0.6014174,0.6519142,0.57615566,0.24314845,0.034668103,0.0,0.028395116,0.17260619,0.2508178,0.25727832,0.19249983,0.09835972,0.11904412,0.20295775,0.12332681,0.12931673,0.059854366,0.04592648,0.0,0.0,0.066488236,0.04740441,0.017608956,0.047821946,0.04775224,0.0,0.17562456,0.2939335,0.54694235,0.5472326,0.48594844,0.21786419,0.07453376,0.0,0.053050943,0.23507911,0.35133398,0.38508284,0.32520807,0.17817762,0.1491788,0.22649063,0.1441418,0.16558997,0.07694931,0.050875224,0.0,0.0],[0.0,0.0,0.0,0.0,0.042169496,0.10206209,0.1265706,0.27744362,0.49068052,0.60882026,0.7412182,0.70487666,0.6577908,0.59701145,0.5357446,0.37449038,0.21791339,0.04777667,0.0,0.0,0.0,0.02251558,0.0,0.0014414489,0.009822659,0.02771496,0.018649824,0.0042630434,0.0,0.0,0.0,0.0,0.03510966,0.05596645,0.06592084,0.2081396,0.42491484,0.55174094,0.69126606,0.6847531,0.64802885,0.6202035,0.5505393,0.35108733,0.18207291,0.00077579916,0.0,0.0,0.0,0.033316515,0.0036538094,0.0,0.0053127706,0.007553421,0.008753248,0.011016063,0.0,0.0,0.0,0.0,0.024131611,0.012443721,0.0,0.110674925,0.3299052,0.4657666,0.6061854,0.640929,0.6563497,0.56552655,0.4418792,0.19731036,0.0774381,0.0,0.0,0.0,0.0,0.04832027,0.021569312,0.0,0.0,0.0,0.00027173758,0.0033868104,0.0,0.0,0.0,0.0,0.0015098602,0.0048658103,0.0,0.07902143,0.26090857,0.43263882,0.6178008,0.7446766,0.7269652,0.42417645,0.14684652,0.0,0.0,0.0,0.0,0.0,0.006190732,0.050153024,0.019662216,0.0,0.028762735,0.010099821,0.025529042,0.0,0.0,0.0,0.0,0.000039711595,0.0034588724,0.0,0.00020433962,0.068086915,0.21760759,0.41489714,0.5623175,0.60364515,0.47203702,0.14919887,0.0,0.0,0.0,0.03382603,0.0,0.0,0.0,0.024574451,0.0,0.0,0.021707952,0.013728768,0.026605524,0.0035482347,0.0,0.0,0.0,0.009086095,0.020529144,0.0,0.018039413,0.0975811,0.25499848,0.4430883,0.5173582,0.38978493,0.20944417,0.002141714,0.0,0.0,0.0,0.020994395,0.0,0.0,0.0,0.0106474385,0.0,0.0,0.0018875152,0.0042163283,0.0021243095,0.0,0.0,0.0,0.0,0.0059542283,0.017365023,0.0,0.022632092,0.1378452,0.34328884,0.51375794,0.51007235,0.2931376,0.07055847,0.0,0.0,0.0003464967,0.0,0.009264633,0.0,0.0,0.0,0.011931635,0.0021809638,0.0,0.0,0.0,0.0,0.0,0.003807798,0.0,0.007237278,0.00015068054,0.01377362,0.0,0.0431706,0.14774014,0.366189,0.51765066,0.45177144,0.23959395,0.0,0.0,0.0022932142,0.036988094,0.0155905485,0.0,0.0,0.0,0.0,0.009265378,0.010837838,0.0,0.0,0.0025933534,0.0,0.0,0.016068637,0.0,0.018098913,0.0,0.02778513,0.0,0.08838053,0.16607589,0.37486917,0.48678786,0.38992614,0.22556481,0.0,0.0,0.057191692,0.10550036,0.08118835,0.042791292,0.013672031,0.0,0.0,0.0041356087,0.026564546,0.0,0.0,0.014867015,0.0,0.0,0.030565403,0.006876923,0.027352229,0.0,0.0362243,0.0008484721,0.11267589,0.16724965,0.35745972,0.41464788,0.30980816,0.20585442,0.0,0.0,0.098153174,0.14227799,0.16250576,0.15494017,0.1204471,0.048247144,0.0,0.0,0.0406894,0.0,0.0,0.020449929,0.0,0.0,0.035005942,0.017969564,0.027348153,0.0,0.03204386,0.011111759,0.108118415,0.14474727,0.30669433,0.30462444,0.22029698,0.18379414,0.029494286,0.013954811,0.12831551,0.15881039,0.23509496,0.29116347,0.24483135,0.09357586,0.0,0.0,0.047304757,0.018448383,0.0,0.016791657,0.0,0.0],[0.0,0.0,0.0,0.019406237,0.008034743,0.018532336,0.03415996,0.03155075,0.09670121,0.15515494,0.20323998,0.20335546,0.14049923,0.047872327,0.013413325,0.0,0.0,0.0,0.0,0.0,0.034626074,0.011532277,0.0,0.0,0.009317778,0.018815942,0.006444365,0.007257931,0.0,0.0,0.0,0.0058015063,0.02195616,0.0,0.0,0.008062035,0.092768826,0.16616088,0.23604675,0.23969841,0.18749775,0.13468102,0.0718932,0.0,0.0,0.0,0.013540924,0.0,0.051125996,0.021274418,0.0,0.0,0.0,0.02145549,0.007876411,0.018181294,0.0,0.0,0.0,0.0,0.023187041,0.0,0.0,0.0,0.08035018,0.1783738,0.24756022,0.25279045,0.24764785,0.17085463,0.06638222,0.0,0.0,0.0,0.012570016,0.00064118207,0.055258207,0.0416734,0.0,0.0,0.0,0.02054926,0.0034848154,0.008038789,0.0,0.0,0.0,0.0,0.010387786,0.0,0.0,0.0,0.11111136,0.24617788,0.31729665,0.37936342,0.3601826,0.09750175,0.0,0.0,0.0,0.013606571,0.0,0.0025507212,0.01896511,0.035489075,0.0,0.0,0.0114603415,0.03657811,0.0069952384,0.0025137067,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0155077875,0.114709176,0.28489318,0.28181857,0.27852488,0.1592786,0.0,0.0,0.0,0.00056390464,0.040743835,0.0,0.0,0.0,0.018112823,0.0,0.0,0.019066371,0.037868254,0.0037542582,0.01521904,0.0,0.0,0.0,0.0,0.00061649084,0.0,0.0,0.05692307,0.105231054,0.29978922,0.19998378,0.10810943,0.0,0.0,0.0,0.009118341,0.02595324,0.0,0.0,0.0,0.0,0.015920326,0.0,0.0020979494,0.030205294,0.024485238,0.0015913248,0.0184616,0.0,0.0,0.0,0.0,0.0112307,0.0,0.0,0.08943659,0.17429838,0.338774,0.19945014,0.0055965185,0.0,0.0,0.0,0.035700507,0.020578884,0.0,0.0,0.0020393878,0.0011490583,0.029732503,0.0,0.009742357,0.04148739,0.0053529292,0.0,0.017038085,0.0,0.0,0.0,0.006528452,0.026333682,0.0,0.0019307584,0.09489713,0.2020962,0.35251558,0.21267985,0.0,0.0,0.0,0.04763183,0.060271285,0.014255866,0.0,0.0,0.0,0.0017407537,0.041831873,0.008062892,0.019870482,0.05511255,0.0032708049,0.008492492,0.0043161064,0.0021404326,0.0,0.0,0.029012345,0.053028665,0.00012905896,0.040416084,0.10549929,0.22061053,0.34723294,0.23379791,0.0008505285,0.0,0.033891544,0.12144802,0.11799648,0.06388624,0.02784276,0.015638404,0.021221735,0.0,0.05757328,0.029061802,0.011492781,0.06344282,0.012273401,0.010273725,0.0,0.016589656,0.0,0.0,0.046315268,0.06716769,0.027783483,0.082823955,0.10543956,0.21658218,0.2982153,0.21335286,0.02774167,0.0,0.06201701,0.16427779,0.14762062,0.13188718,0.12934586,0.10176225,0.08610629,0.032789573,0.060699522,0.033208683,0.0,0.061438695,0.009765133,0.0067687184,0.0,0.035043992,0.008421451,0.0,0.052196786,0.07336821,0.049098186,0.10663445,0.08093232,0.18569979,0.20987347,0.17259845,0.054202877,0.0,0.0910559,0.17897943,0.1576818,0.19659065,0.24412574,0.18941295,0.12111163,0.03980396,0.05383131,0.035917133,0.0,0.05389964,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.02259145,0.007305965,0.0,0.0,0.0,0.008805215,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01744347,0.0,0.011762299,0.034453087,0.0,0.0,0.018058546,0.016618617,0.04049313,0.00848902,0.0,0.0,0.0,0.0,0.0,0.02171781,0.0032031387,0.0,0.0,0.0,0.008248158,0.006722264,0.007642582,0.0,0.0,0.0,0.0,0.0,0.025165468,0.0,0.015260801,0.02973999,0.0010727048,0.0,0.01345624,0.005415052,0.024855673,0.0,0.008626662,0.0,0.0,0.0,0.0,0.000078722835,0.0,0.0,0.0,0.011216857,0.024516314,0.00690002,0.024525732,0.0,0.0,0.0,0.0,0.0,0.012607001,0.0,0.015632235,0.034341954,0.02540896,0.0,0.009509072,0.0,0.0,0.0,0.0071940273,0.0040775537,0.0,0.0,0.0,0.0,0.0,0.0,0.0003361404,0.07340723,0.10742917,0.075269386,0.11309229,0.07384092,0.037802987,0.0,0.0,0.0,0.026685141,0.0,0.0006751269,0.006017439,0.0108142495,0.0,0.0017548203,0.0,0.0,0.0,0.0074692294,0.0,0.0007714182,0.0,0.0,0.0,0.00653293,0.0,0.021150567,0.069027126,0.09853487,0.060213566,0.085291795,0.0,0.0,0.0,0.0,0.0,0.054389358,0.0,0.0,0.0,0.0,0.0,0.0,0.011504948,0.0,0.0,0.0047154874,0.0,0.010375269,0.0,0.0,0.0022292733,0.008057736,0.0,0.025489777,0.038604423,0.062464662,0.015323274,0.04423686,0.0,0.0,0.0,0.00022830069,0.0,0.025803559,0.0023959875,0.0,0.0,0.0,0.0,0.0,0.014204875,0.0,0.0,0.0,0.0,0.0025496632,0.0,0.0,0.0,0.0,0.0,0.043912806,0.046486147,0.05106002,0.0,0.016226962,0.0,0.0,0.0043699294,0.0,0.0,0.01693137,0.0066614524,0.0,0.0,0.0,0.0,0.0,0.011015594,0.0,0.0,0.0,0.0,0.0002811253,0.0,0.0,0.0,0.0,0.0,0.051580794,0.04638973,0.03576377,0.0,0.013533466,0.0034011006,0.010156371,0.025002562,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011555918,0.0,0.016122907,0.0,0.0,0.0,0.0,0.015153073,0.0,0.0,0.0,0.0,0.0,0.05950708,0.043656684,0.03091047,0.0,0.029182322,0.06452379,0.033802338,0.07733095,0.04001244,0.0,0.013625935,0.024737619,0.0035998821,0.0,0.0,0.020398296,0.0,0.013914391,0.0,0.0,0.0,0.0,0.029616743,0.007640317,0.0,0.00013566017,0.008762978,0.0025208294,0.079885975,0.04633814,0.033243336,0.021695144,0.059660025,0.10315892,0.041985452,0.12214397,0.09400502,0.0666402,0.058555126,0.09396182,0.061254896,0.033061415,0.0,0.021780774,0.0,0.011727273,0.0,0.0,0.0,0.0,0.039878726,0.026381783,0.0,0.014401428,0.029642321,0.028128974,0.067816906,0.031161025,0.03079544,0.05245442,0.07390316,0.10568738,0.016860425,0.121271186,0.1239852,0.13864401,0.12757075,0.16779448,0.108894765,0.06478493,0.0,0.026516907,0.0,0.008630812,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.04091259,0.0,0.0,0.0,0.0,0.024908721,0.018077046,0.0,0.0,0.0,0.0,0.0,0.0,0.021134764,0.029008403,0.0,0.0353211,0.014734477,0.016909808,0.021279126,0.03247898,0.0,0.0,0.0074631944,0.0,0.0,0.0,0.0,0.042777903,0.0032645315,0.0,0.0,0.0,0.0316839,0.014070928,0.0,0.0,0.0,0.0,0.0,0.00040335953,0.033713102,0.012825705,0.0,0.025698967,0.012755573,0.02180548,0.01981587,0.0411705,0.0,0.0,0.0131201,0.0,0.0,0.0,0.0,0.020838574,0.0,0.0,0.0,0.0,0.03181351,0.010541916,0.0,0.0,0.002715677,0.0,0.0,0.014677145,0.012753271,0.0,0.0041870326,0.041763775,0.03054925,0.028500907,0.021956034,0.042515717,0.0,0.0,0.0131927505,0.0,0.0,0.0,0.0,0.0008778572,0.0,0.0,0.0038952976,0.021734752,0.049694814,0.050773084,0.0,0.0,0.03271067,0.0,0.0,0.04759123,0.0,0.0,0.005259514,0.043818474,0.020874545,0.007312797,0.028680518,0.03520628,0.0,0.0,0.016347617,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02748695,0.012944542,0.02051042,0.032121286,0.0,0.0,0.0,0.0,0.0,0.03737943,0.0,0.0,0.0,0.025461562,0.0,0.0,0.009270199,0.022609763,0.0023471713,0.0033500344,0.008289419,0.0,0.010951519,0.000110551715,0.031486884,0.0,0.0,0.009648919,0.030320317,0.0,0.0,0.0,0.0,0.0,0.0,0.018339515,0.0,0.0,0.0,0.005208373,0.0,0.019542351,0.0032572597,0.0,0.0022148043,0.015891679,0.0069514588,0.0,0.0,0.0,0.014018573,0.002968371,0.027943201,0.0,0.0,0.0064630434,0.03742785,0.0047118813,0.0,0.0,0.0,0.0,0.0,0.021940708,0.0,0.0,0.0,0.00467743,0.0,0.010962136,0.007406175,0.0,0.0,0.011584729,0.007864997,0.0,0.0,0.0,0.029455177,0.013832264,0.031057864,0.0,0.0,0.00006349385,0.0414074,0.035842188,0.013805926,0.0,0.011780582,0.023855835,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0035872757,0.016445749,0.0,0.0014490783,0.021291599,0.020833313,0.0,0.0,0.016357593,0.07287331,0.051175646,0.049574316,0.0,0.0,0.0,0.051971033,0.052182958,0.024138056,0.011790171,0.040731214,0.03086619,0.010528348,0.010149606,0.0,0.0,0.0,0.0,0.0,0.004070163,0.014691509,0.0,0.016774625,0.041528,0.054057598,0.0,0.0,0.027684093,0.10619881,0.088489845,0.067822,0.008962266,0.0,0.0036223233,0.063519776,0.05441744,0.03653565,0.024840474,0.061980926,0.03666395,0.033952184,0.024451524,0.0,0.0,0.0,0.008753262,0.02334635,0.02025292,0.007142544,0.0,0.028218858,0.0563564,0.06938203,0.006729707,0.0,0.0340069,0.12517276,0.109549366,0.08524805,0.036595836,0.0,0.0030677766,0.05569283,0.042734064,0.05331394,0.03717289,0.07234399,0.03382235,0.041679226,0.02502381,0.0,0.0,0.005515799,0.0329277,0.0551643,0.03716232,0.006361611,0.0,0.026703969,0.054455914,0.06818501,0.0018938929,0.0],[0.0,0.0,0.0,0.0000154078,0.037959553,0.013302125,0.0,0.0,0.0,0.0084832385,0.030697942,0.012146398,0.0037981123,0.006060332,0.0,0.0,0.0,0.03409279,0.0057709217,0.0,0.0,0.0,0.009528615,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0008600652,0.029777579,0.00038282573,0.0,0.0,0.0,0.0023046732,0.017725922,0.008731045,0.0024618357,0.015197478,0.0,0.0,0.0,0.025539272,0.0,0.0,0.0,0.0012637377,0.025044441,0.0,0.0,0.0,0.0,0.0,0.00020298362,0.0,0.0,0.0,0.01964657,0.0,0.0,0.0,0.0,0.0,0.005241573,0.0,0.0,0.015179634,0.0,0.0,0.0,0.0075277835,0.0,0.0,0.0,0.023641177,0.05145298,0.010744587,0.0,0.0,0.0,0.0,0.009505518,0.0,0.0,0.0021660775,0.017584682,0.0,0.0,0.0,0.0036181211,0.0,0.0,0.0,0.007641688,0.0093970075,0.009342343,0.0,0.0,0.0,0.0,0.0,0.0,0.029054701,0.059756927,0.026099995,0.0,0.0,0.0,0.0,0.015596919,0.0,0.0,0.004730776,0.009370625,0.0,0.0,0.0017027557,0.0,0.0,0.0007956177,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.005028829,0.0,0.0,0.017182581,0.00063472986,0.0,0.0,0.0,0.0,0.016471282,0.0,0.0014441311,0.0070711747,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011512913,0.008034147,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009936936,0.0031039119,0.010141373,0.0047813803,0.0,0.0,0.0,0.0,0.0,0.00052811205,0.013045654,0.023897037,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018614516,0.011202835,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0064577386,0.01328136,0.01846353,0.0047747195,0.0,0.0,0.0,0.0,0.0,0.0055211633,0.032195494,0.053002223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019331425,0.022314407,0.0,0.0,0.0,0.00652948,0.0,0.0,0.0,0.010165013,0.03924048,0.03579036,0.015409887,0.0,0.0,0.0,0.0,0.0,0.0,0.038628735,0.061500885,0.005512804,0.0016542971,0.0,0.0,0.0,0.0,0.0,0.02137591,0.02990742,0.009342559,0.0,0.0,0.028500773,0.0,0.0,0.0,0.015929319,0.06261294,0.05666388,0.027114742,0.0,0.0,0.0,0.006857179,0.00060883164,0.0,0.03576319,0.06250939,0.013681419,0.02698712,0.0,0.016432889,0.0,0.0013526827,0.0,0.027254783,0.03809741,0.019200616,0.0,0.0,0.04696157,0.0,0.0,0.0,0.018062882,0.0714332,0.07486134,0.03580819,0.0,0.0,0.0,0.024794087,0.0024681836,0.0,0.037260897,0.070240155,0.031929605,0.038107775,0.018230401,0.023628332,0.0,0.007947549,0.0,0.034460843,0.05116444,0.037389226,0.0053542405,0.0,0.059523612,0.0,0.0,0.0],[0.033581987,0.010182545,0.024359912,0.0,0.01669722,0.0,0.010852195,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.029936776,0.0,0.0,0.0,0.0,0.021648452,0.011341192,0.0,0.0,0.008274384,0.0048489273,0.0078100488,0.02578865,0.0,0.014567718,0.00024348497,0.013010927,0.0,0.0122422725,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025359578,0.0,0.0,0.0,0.0,0.010935351,0.0061627105,0.0,0.0016850829,0.016413264,0.009531319,0.0023063868,0.017548725,0.0,0.0017238259,0.0,0.007865645,0.0,0.005806744,0.0012761205,0.0018609762,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009996906,0.0,0.0,0.0,0.0,0.01121857,0.014657423,0.0,0.0,0.0004993528,0.00086568296,0.0,0.01816219,0.0,0.0016929358,0.013697572,0.0072297677,0.0,0.00036627054,0.0,0.007887714,0.0044213384,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013777256,0.01542595,0.0,0.0,0.0,0.0,0.0,0.018066347,0.0,0.0,0.010928541,0.0020051152,0.0,0.0045300573,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018630922,0.0,0.0,0.0025896132,0.0011872202,0.0,0.0,0.0028257668,0.0014238805,0.0,0.017369457,0.0,0.0,0.007430032,0.0,0.0,0.012941591,0.0,0.0,0.012931824,0.0,0.011478446,0.0,0.0,0.00668025,0.0,0.0,0.00589741,0.03269629,0.0,0.0,0.0,0.0,0.0,0.0020538718,0.003147751,0.0,0.0,0.020674586,0.0,0.0,0.0,0.0,0.0,0.027700514,0.0,0.0057607666,0.036978364,0.0,0.020484842,0.014726438,0.0,0.014496781,0.0,0.0,0.011378974,0.03644988,0.0,0.0,0.0,0.0,0.0,0.0088857785,0.009358779,0.0,0.0,0.026303515,0.001796186,0.0,0.0,0.0,0.0,0.026826292,0.0,0.03277523,0.07036306,0.009116434,0.014655128,0.023419999,0.0,0.018765293,0.0,0.0,0.011213727,0.043613136,0.0,0.0,0.0,0.0,0.0,0.013463467,0.0152006,0.0,0.0,0.031708106,0.006954141,0.0,0.0,0.0,0.0,0.025394358,0.0,0.05661813,0.0937165,0.007275112,0.0,0.022029929,0.0,0.02495163,0.0,0.0,0.012266293,0.04336302,0.0,0.0,0.0,0.0,0.000396654,0.018773645,0.027766041,0.0,0.0,0.033053778,0.011905313,0.0,0.0,0.0,0.0,0.023648314,0.00326325,0.0645891,0.10898393,0.0014517158,0.0,0.018559612,0.0,0.02965299,0.0,0.0,0.0125397,0.041022435,0.0,0.0,0.0,0.0,0.008756377,0.027992204,0.04373747,0.0,0.0,0.03389918,0.030977651,0.0,0.0,0.0,0.0,0.008706838,0.0047092885,0.071082704,0.12027484,0.007001497,0.0,0.019871064,0.0,0.035253935,0.0,0.0,0.015741922,0.04227618,0.0,0.0,0.0,0.0,0.020058483,0.03644847,0.05854258,0.0,0.0],[0.022324428,0.0,0.0035194755,0.0,0.032803982,0.009083442,0.022954583,0.0,0.0,0.0,0.038188867,0.0,0.0,0.0011939257,0.0,0.0,0.03132768,0.00023853779,0.0,0.0,0.008324854,0.01100339,0.007235296,0.0,0.0013580918,0.01579132,0.010284863,0.0,0.01723849,0.0,0.0,0.0,0.032631084,0.008810155,0.0200603,0.0,0.0,0.0,0.018771835,0.0,0.007594228,0.0004813373,0.0046899915,0.0,0.011019319,0.0,0.0,0.0028380454,0.017749578,0.024142228,0.012043193,0.0,0.006979026,0.019977003,0.020522304,0.0,0.010867722,0.0,0.0,0.0,0.030336216,0.0016335994,0.013943329,0.0,0.0,0.0,0.0013502836,0.0,0.009476565,0.0,0.0027039498,0.0,0.0,0.0,0.0,0.0,0.021177307,0.03180276,0.025427207,0.0,0.0,0.0,0.020056725,0.0,0.0037447214,0.013020121,0.0,0.027400963,0.033975944,0.0,0.004015833,0.0,0.0,0.0,0.0,0.0,0.012938961,0.002399981,0.011002079,0.0,0.0,0.001141116,0.004744604,0.0,0.009301513,0.017618485,0.031067438,0.0,0.0,0.0,0.015533559,0.0,0.0,0.026627228,0.0072717294,0.035322852,0.028890572,0.0,0.00015926361,0.0,0.0,0.0,0.0,0.0,0.010566995,0.0067402795,0.014065132,0.0,0.0,0.010119006,0.03079424,0.0059813336,0.005456716,0.016490437,0.03599236,0.0075699836,0.0018489659,0.0,0.0154238865,0.0,0.0,0.021140568,0.0012414157,0.030278996,0.017086528,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009491287,0.011188656,0.0126549825,0.0,0.0,0.010979876,0.030543901,0.011072621,0.017537162,0.038335092,0.033960454,0.011662029,0.015105747,0.0,0.0030405372,0.0,0.0,0.013859592,0.0,0.0071736574,0.008972727,0.0,0.02171421,0.0,0.011263996,0.0,0.0,0.01596129,0.01268585,0.0067881867,0.010754488,0.0,0.0,0.013868183,0.02111502,0.0,0.0056363344,0.04272075,0.028460488,0.012905091,0.032821625,0.0,0.0,0.0,0.0,0.015037924,0.0,0.0,0.0020309687,0.0,0.02245678,0.0,0.05020123,0.0144969225,0.0011383146,0.028133385,0.012064308,0.0,0.0065250546,0.0,0.0,0.0066141635,0.010455765,0.0,0.0,0.026119843,0.010316618,0.013127908,0.04507392,0.0,0.0,0.0,0.0,0.007407509,0.0,0.0,0.0024099052,0.0,0.025482453,0.0,0.08582981,0.018916331,0.0042657405,0.026572451,0.01619012,0.0,0.0045985878,0.0,0.0,0.0,0.0,0.0,0.0,0.016819172,0.0,0.017502382,0.05786839,0.009074107,0.0,0.0,0.0,0.00082241,0.0,0.0,0.0,0.0,0.025611207,0.0,0.10970362,0.020398118,0.0,0.028434135,0.028739534,0.0,0.00018003583,0.0,0.0,0.0,0.0,0.0,0.0,0.0044643134,0.0,0.021278597,0.06854303,0.015627183,0.0017499328,0.0,0.0,0.014045641,0.0,0.0,0.0,0.0,0.0028692037,0.0,0.1367325,0.03968945,0.012818836,0.03656877,0.06399109,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025152154,0.07911369,0.020719431,0.0014773309,0.0],[0.01201307,0.0139071345,0.04678891,0.035039537,0.03852377,0.01990094,0.011804558,0.0,0.03326101,0.0,0.044475883,0.008114606,0.049704187,0.0,0.0029246658,0.029706419,0.029301323,0.0,0.0,0.022772469,0.031696476,0.021237917,0.028688043,0.0,0.021838568,0.0046655387,0.0,0.004698932,0.004270807,0.0038478225,0.03043349,0.021954887,0.033265695,0.0300887,0.01878462,0.0,0.052285217,0.0,0.025012612,0.0,0.056086957,0.0,0.014812067,0.00975626,0.032197043,0.0,0.010328747,0.024379842,0.044859722,0.030919045,0.030572027,0.00057539344,0.025438488,0.014766537,0.00871028,0.0025808811,0.0,0.0,0.023463488,0.020638973,0.029902421,0.033204265,0.014868528,0.005414784,0.053567097,0.0,0.015125446,0.003311038,0.06286085,0.0,0.01965867,0.001551345,0.033229806,0.0,0.019302092,0.030622542,0.048656665,0.037679084,0.03831751,0.0,0.0114911795,0.011203267,0.016364008,0.0,0.0,0.01448755,0.042796507,0.04308994,0.030719861,0.042389795,0.012108713,0.0037380308,0.038169958,0.0,0.0,0.0,0.03160187,0.0,0.01944857,0.00975465,0.036550783,0.011553466,0.040895537,0.050141133,0.050697424,0.03960543,0.045684263,0.0,0.0,0.0011833459,0.012902431,0.0,0.0,0.018663839,0.05513463,0.05158837,0.027983636,0.04859811,0.028574027,0.0009589642,0.014604293,0.0,0.0,0.0,0.0076114535,0.0,0.012373358,0.0,0.021237567,0.04913871,0.016770758,0.06547963,0.07279313,0.072028026,0.057450593,0.0029660314,0.013470277,0.004694864,0.0061405897,0.0,0.0,0.0,0.05030361,0.042756937,0.016448997,0.0515391,0.029518574,0.0,0.0,0.0,0.017443337,0.0,0.0091848,0.0,0.009868912,0.0,0.002241686,0.052607886,0.0,0.053910084,0.099208996,0.12385373,0.05236329,0.0025375336,0.025796413,0.0,0.0,0.01708395,0.0,0.0,0.03631772,0.02651374,0.011441998,0.0745161,0.032177158,0.0,0.0057593286,0.0,0.038097218,0.0,0.02891428,0.0,0.012720615,0.0,0.006203592,0.052657172,0.0,0.026743032,0.09362589,0.14482352,0.03970004,0.0077001676,0.04135993,0.0,0.006808609,0.025697224,0.0,0.0,0.026855536,0.025851488,0.0052009076,0.07200496,0.039631628,0.027086996,0.049774036,0.0,0.05212169,0.0,0.04556141,0.0,0.021270387,0.0,0.009852387,0.036524676,0.0,0.010182761,0.06353654,0.12699457,0.03028375,0.008531913,0.057328887,0.008145079,0.025155954,0.023546956,0.0,0.0,0.014521293,0.028768532,0.005708866,0.061823837,0.03922312,0.053593785,0.09217434,0.0,0.051068515,0.0,0.06423295,0.0,0.025276445,0.0,0.009829074,0.01522541,0.0,0.001067087,0.04923585,0.116470784,0.032063663,0.009590045,0.07504423,0.015997626,0.03740464,0.018311918,0.0,0.0,0.0097013265,0.026039436,0.0,0.04420978,0.042177282,0.0738483,0.13015398,0.0037270486,0.040997513,0.006750703,0.079760686,0.0,0.03138289,0.0,0.005199164,0.00084379315,0.0,0.0,0.03385351,0.086867504,0.027433805,0.00566034,0.0903355,0.018979363,0.04500238,0.01370395,0.0,0.0,0.008359753,0.0050228834,0.0,0.0023194402,0.032266818,0.09838829,0.17160268,0.035047792,0.029940672,0.04261192,0.11369684,0.0,0.036343157,0.0,0.0,0.0,0.0,0.0,0.008183055,0.043923035,0.021967687,0.0036077201,0.100568905,0.017704248,0.047035143,0.017042384],[0.0,0.03391546,0.0031956583,0.0,0.008067258,0.0019653141,0.026365854,0.0165736,0.018335223,0.030650847,0.040655643,0.040769972,0.03903029,0.056348294,0.019900195,0.008063465,0.051304974,0.044935137,0.071192645,0.02719117,0.07393566,0.06953475,0.012582801,0.0,0.024037391,0.0,0.0,0.0,0.0,0.021504708,0.0,0.0,0.008769788,0.010969415,0.035800584,0.02202525,0.028693274,0.05464957,0.02736158,0.019817345,0.008189015,0.05304482,0.03371554,0.026585221,0.0532898,0.04146436,0.076655895,0.031346716,0.08093703,0.073149905,0.014653787,0.0,0.023254573,0.0,0.0,0.0,0.0,0.024372697,0.01011125,0.0,0.011883639,0.02666752,0.048529014,0.025005922,0.028974771,0.045747347,0.03316959,0.03677226,0.007983953,0.04607962,0.047151923,0.011862241,0.017227814,0.02103389,0.062020004,0.054582834,0.08730386,0.07778479,0.020787343,0.0,0.013263755,0.0,0.0,0.0,0.0,0.032074474,0.029071957,0.012266055,0.0299085,0.06597844,0.06346604,0.010099746,0.006737016,0.012143083,0.012603261,0.019772321,0.0,0.014745794,0.03709683,0.0,0.0,0.016022377,0.06952141,0.10315327,0.11562414,0.06758902,0.027309783,0.0,0.0016577244,0.0018228143,0.0,0.0,0.0,0.039206296,0.027288072,0.0039858967,0.035417333,0.06766519,0.06420004,0.012687184,0.0026232898,0.0,0.0,0.0,0.0,0.0021631569,0.006546207,0.0,0.0,0.008334838,0.065541424,0.1148609,0.15186289,0.10135185,0.063920945,0.0,0.0,0.0116197765,0.0,0.0,0.0,0.02547878,0.007876851,0.0,0.04533767,0.07186795,0.056283034,0.0,0.0,0.0,0.0,0.0,0.016659506,0.031153224,0.004457921,0.013451137,0.0,0.0,0.035895586,0.15077633,0.21372691,0.13770218,0.05732858,0.0,0.0,0.033636875,0.0016613007,0.01353614,0.0,0.011727855,0.0,0.0,0.074349105,0.101364516,0.073940754,0.0,0.0,0.0,0.008172579,0.0039631277,0.0388792,0.065195665,0.032630935,0.04660856,0.012090661,0.0,0.017732792,0.1787478,0.25180358,0.1677284,0.05801139,0.0,0.0045110136,0.046203732,0.0,0.007910602,0.0,0.0024838597,0.0,0.0,0.085516095,0.10598504,0.09598883,0.013140917,0.002667591,0.01269421,0.027456246,0.009962551,0.050544873,0.084639855,0.059063695,0.071894854,0.03688611,0.0,0.0,0.17273505,0.24247155,0.16322118,0.056519024,0.0,0.012687385,0.049872704,0.0,0.0,0.0,0.0,0.0,0.0,0.09704642,0.10416145,0.11062884,0.030463412,0.030380107,0.03996961,0.050582618,0.017665736,0.0618956,0.09290485,0.07743783,0.09159352,0.04854881,0.0,0.0,0.14701873,0.22044787,0.1565983,0.053418398,0.0,0.022809692,0.047115855,0.0,0.0,0.0,0.0,0.0,0.0,0.08624133,0.09285912,0.12124947,0.050055943,0.06208726,0.07420184,0.07833472,0.021786273,0.07013831,0.09175979,0.08594918,0.11006328,0.068884715,0.0,0.0,0.111980125,0.18236889,0.13087268,0.04317198,0.0,0.027060151,0.043444663,0.0,0.0,0.0,0.009099841,0.0,0.0,0.04101418,0.06299312,0.106835194,0.063930854,0.09215083,0.113043904,0.13803202,0.06893143,0.12455794,0.12926228,0.13409114,0.14085557,0.073380925,0.0,0.0,0.07575297,0.12906887,0.08834745,0.02257441,0.0,0.029414095,0.044762045,0.0,0.0],[0.0,0.0,0.01352372,0.0,0.0,0.0,0.0,0.0,0.015409239,0.031725638,0.08193083,0.10257016,0.19324139,0.28131765,0.34105536,0.33427697,0.39581567,0.35058844,0.318444,0.23064297,0.17969605,0.14152227,0.017297715,0.011873946,0.0,0.0,0.0,0.0,0.0,0.0,0.0066705793,0.0,0.0,0.0,0.0,0.0,0.020324044,0.029052451,0.032941617,0.044488475,0.14963207,0.21259771,0.28006777,0.30372,0.34592894,0.33865947,0.3154965,0.23353472,0.1764369,0.11059286,0.018607855,0.009106688,0.0,0.0,0.0,0.0,0.0,0.0,0.014385022,0.0,0.0,0.0,0.0,0.0,0.020904183,0.03120356,0.032967202,0.038328417,0.121920876,0.15044543,0.19304343,0.20507881,0.22588016,0.26502883,0.2766255,0.23467213,0.17276023,0.07798472,0.024083965,0.0,0.0,0.0,0.0,0.0,0.0,0.021714479,0.017109126,0.003634721,0.0,0.020361066,0.002870351,0.0,0.002124086,0.021126956,0.013556965,0.012528352,0.034156494,0.05339071,0.06775613,0.08573673,0.12558496,0.19830628,0.28749037,0.27635184,0.20287961,0.07211518,0.03693059,0.0,0.0,0.0,0.0,0.0,0.0,0.02401793,0.0064092577,0.0,0.0043954253,0.036086507,0.024558038,0.0,0.00447537,0.003238678,0.0,0.009362251,0.023238398,0.01103314,0.044003233,0.077865735,0.12094146,0.17421752,0.31118494,0.2862702,0.24125262,0.117881976,0.060240224,0.0,0.0,0.0,0.0,0.0,0.0,0.0023614913,0.0,0.00039720535,0.044419035,0.063804485,0.034604706,0.0,0.021247506,0.033602558,0.0012154281,0.022403724,0.037519142,0.0,0.020463407,0.09731458,0.12443527,0.16870621,0.3458996,0.356958,0.33798856,0.14103544,0.07792252,0.0,0.0,0.006063983,0.0,0.0,0.0,0.0,0.0,0.023401462,0.09878458,0.10359251,0.054007597,0.0,0.028865226,0.06588393,0.02483201,0.036638476,0.034660175,0.010664426,0.023276582,0.13608086,0.14260882,0.16852154,0.35342157,0.4161281,0.43556482,0.19312401,0.120274566,0.0,0.0,0.014420122,0.0,0.0,0.0,0.0,0.0,0.028150573,0.12092368,0.120045155,0.060014732,0.0,0.037631817,0.09327562,0.03912227,0.045099072,0.019763961,0.031118415,0.03227959,0.16363771,0.17262827,0.19023272,0.33622208,0.413122,0.46236008,0.22197112,0.14118509,0.00071020424,0.0,0.02358257,0.0,0.0,0.006279461,0.0,0.0,0.034628786,0.12868695,0.12449468,0.06059143,0.0,0.043943092,0.11290762,0.05672834,0.05921817,0.0076448247,0.05259332,0.048364013,0.18333095,0.19588326,0.20698471,0.30101913,0.3845235,0.469845,0.23342752,0.14941344,0.0131357685,0.014976189,0.025216252,0.0,0.0,0.012722313,0.0,0.0,0.03298372,0.13186741,0.12626213,0.0698023,0.0,0.068723,0.13931271,0.0879016,0.08420147,0.0039657354,0.07620327,0.065727726,0.21285695,0.23736605,0.21918441,0.2503075,0.32268247,0.42476922,0.2148984,0.13055517,0.028498255,0.037549198,0.027394168,0.0,0.0,0.019343853,0.006753199,0.0,0.016557418,0.10682557,0.117306836,0.077845894,0.020705223,0.113190696,0.17015879,0.16446179,0.16953194,0.05811982,0.1575854,0.1416124,0.2510113,0.2694965,0.22276832,0.18476367,0.22471532,0.30530044,0.14485267,0.05809124,0.022909917,0.035139143,0.036110707,0.0,0.0],[0.0,0.008374162,0.0,0.0053254366,0.029224157,0.04059653,0.0,0.010731779,0.027199857,0.11625674,0.19169274,0.3068785,0.4501779,0.61586356,0.6939091,0.81006104,0.82831836,0.80395085,0.68542075,0.5593341,0.43374193,0.275612,0.16488746,0.031549886,0.019563548,0.0,0.0,0.0,0.0,0.0,0.0,0.008734144,0.031606816,0.035699643,0.0,0.00835859,0.009920619,0.068917535,0.108423635,0.19608149,0.31012732,0.46691877,0.5901826,0.73541725,0.7760958,0.7629417,0.66370356,0.53497475,0.40946424,0.25599134,0.13718225,0.027792208,0.027790137,0.0027074069,0.0,0.0,0.0,0.0060651153,0.0,0.017460734,0.021125458,0.023452863,0.0007741302,0.005661711,0.0,0.0360497,0.041511938,0.07903311,0.14377752,0.27380693,0.41674656,0.58301705,0.64117587,0.67124104,0.6052223,0.4794953,0.34319258,0.20976,0.092608124,0.019650243,0.028843962,0.03158085,0.0,0.0,0.0,0.02051954,0.00782986,0.013830997,0.02140396,0.017365426,0.009702675,0.0016558617,0.0,0.0,0.014988162,0.006988272,0.0,0.06994783,0.17873582,0.3584795,0.49505436,0.6043395,0.5706018,0.4643858,0.34679383,0.20363784,0.076207735,0.0,0.009210154,0.039117135,0.0,0.0,0.0,0.010876335,0.0058990195,0.002930954,0.017653205,0.005240038,0.00045363605,0.0,0.0,0.0,0.022078782,0.020829745,0.006580122,0.03553137,0.070403785,0.23887816,0.37291193,0.51509243,0.56620497,0.5498419,0.39083678,0.21073876,0.08944966,0.0,0.0,0.0154414475,0.0,0.0,0.0,0.0,0.010726549,0.014578305,0.027031489,0.0,0.015660353,0.0,0.007856071,0.0026641935,0.04025259,0.04780504,0.044715196,0.010107346,0.00844983,0.12274403,0.27810156,0.4633445,0.66015905,0.6923921,0.48569244,0.23547584,0.11569261,0.0,0.0,0.0016668886,0.0,0.009200506,0.0,0.0,0.016535692,0.039676532,0.05578076,0.0007292181,0.03000784,0.0,0.039076746,0.0047841817,0.05359511,0.07214967,0.089317575,0.047645606,0.013225831,0.0961238,0.23807558,0.4447999,0.7193106,0.80657977,0.59103614,0.3011734,0.15994073,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011914238,0.0452794,0.077450275,0.01191932,0.05366741,0.0,0.046452083,0.0062611774,0.06374267,0.10593365,0.1312894,0.0844221,0.029180534,0.10718088,0.23912767,0.44629842,0.74138194,0.8688721,0.6629921,0.33853328,0.2213794,0.0042183846,0.015307054,0.0,0.0,0.0,0.0,0.0,0.0051669925,0.05155626,0.09818735,0.022107564,0.06354687,0.0,0.046473913,0.009548821,0.08189007,0.14406022,0.18491475,0.13436712,0.06169504,0.13624342,0.25755864,0.4540854,0.77222073,0.9282111,0.7085375,0.34554574,0.27049085,0.034859866,0.041972198,0.0,0.0,0.0,0.0,0.0,0.0022509843,0.051490895,0.11191711,0.029103108,0.07227881,0.0,0.05271405,0.021527663,0.105479434,0.17489551,0.24818835,0.19877179,0.12298554,0.17386866,0.26692754,0.41182846,0.7377828,0.9021514,0.68934786,0.30856758,0.27400202,0.045653977,0.053368486,0.0,0.0,0.0,0.0,0.0,0.0032550693,0.041207105,0.10311957,0.026283987,0.06610159,0.0,0.101067275,0.109144285,0.20259348,0.2913285,0.3763103,0.32899523,0.25726196,0.25105444,0.3022799,0.35432667,0.6289372,0.74058276,0.53937197,0.18767197,0.1914202,0.030504383,0.04328365,0.0,0.0,0.0],[0.00009520352,0.0,0.008422121,0.03584812,0.037739977,0.04151737,0.0045027584,0.015368663,0.040425025,0.17176795,0.25268057,0.45119745,0.584218,0.73615223,0.82683784,0.9046109,0.9414208,0.93385756,0.85669225,0.7255208,0.61445034,0.4504453,0.21635178,0.10662379,0.015080646,0.0,0.0,0.0,0.0,0.0,0.00048783422,0.03607183,0.04079128,0.027383037,0.008567646,0.014517367,0.016346022,0.09303083,0.14545107,0.30051696,0.43144858,0.6236119,0.7669069,0.872605,0.9381085,0.9078913,0.82756376,0.69067734,0.5676877,0.41808665,0.1995035,0.1042879,0.05023378,0.008729972,0.0,0.0,0.0,0.0,0.0011139512,0.03438793,0.013319537,0.009050503,0.0,0.007871069,0.0,0.04963386,0.061534077,0.14023413,0.23969962,0.45540428,0.62912583,0.7696396,0.882294,0.8439265,0.75183785,0.6020054,0.48807234,0.33878347,0.1712945,0.08803713,0.08261503,0.03510125,0.012480222,0.0,0.0,0.0071833804,0.007881552,0.022239834,0.0045015216,0.0,0.022803396,0.014796637,0.0022360384,0.01654017,0.025355026,0.046352126,0.06767807,0.24609534,0.37654626,0.5638021,0.7729317,0.8307921,0.7144153,0.5429847,0.44290298,0.32004058,0.17494881,0.047548532,0.080010585,0.024658687,0.0055097193,0.0,0.0,0.0046357512,0.008708008,0.020138174,0.0,0.0,0.02947808,0.007803887,0.022088751,0.023267105,0.012738064,0.06003318,0.049691796,0.10749236,0.20511194,0.37750587,0.578671,0.73608804,0.7257125,0.5905671,0.39574707,0.24012041,0.114140846,0.0,0.033051595,0.0,0.0,0.0,0.0,0.014616102,0.025149047,0.045558803,0.022420533,0.00595849,0.0490932,0.022377767,0.036292054,0.0010396093,0.006675862,0.09557369,0.060699552,0.019265875,0.06618485,0.17755108,0.40927565,0.730352,0.84436756,0.72081923,0.41710508,0.17712525,0.07829006,0.0,0.018291064,0.0,0.0,0.0,0.0,0.0054950863,0.034645304,0.07681669,0.04749678,0.0,0.051209323,0.047668763,0.044358343,0.0,0.0,0.107743226,0.07842444,0.024709351,0.04225184,0.101026446,0.31314632,0.74412537,0.9149166,0.83485466,0.47425318,0.20374157,0.08839535,0.0,0.03545712,0.0,0.0,0.0,0.0,0.0,0.033790797,0.08574493,0.055376478,0.0,0.06382023,0.06358504,0.066834666,0.0,0.0003655851,0.11488661,0.09289868,0.052823566,0.04494106,0.075738356,0.26720786,0.7453078,0.9420845,0.9357848,0.5066813,0.23579916,0.13649757,0.044620298,0.095789924,0.0045555383,0.0,0.0,0.0,0.0,0.031214692,0.09561393,0.060990177,0.0,0.060096473,0.06309098,0.0666011,0.020075135,0.0117281675,0.13302447,0.11114786,0.090426005,0.06216559,0.065611474,0.23295768,0.7521057,0.9688624,1.0,0.5204727,0.24496035,0.16704628,0.10339194,0.13966832,0.012558013,0.0,0.0,0.0,0.0,0.033521578,0.10679353,0.06498998,0.0,0.05983349,0.064091675,0.073889725,0.057205968,0.04064303,0.15220149,0.14053446,0.14475572,0.10336919,0.064406686,0.17625079,0.6966493,0.9115972,1.0,0.49004138,0.20930779,0.15769489,0.13411446,0.14566433,0.009837724,0.0,0.0,0.0,0.0,0.030670367,0.10219027,0.06442773,0.0,0.04489179,0.08246046,0.15721369,0.18593447,0.21218544,0.28067565,0.2607745,0.24936889,0.2083826,0.16421351,0.19817159,0.65323246,0.7856036,0.9290589,0.3900305,0.102204636,0.09647828,0.11263671,0.10070093,0.012097269,0.0,0.0],[0.0,0.0057579353,0.02040235,0.0,0.0,0.0053676367,0.0,0.04540678,0.092876896,0.19160782,0.25288963,0.35048977,0.4837461,0.5322463,0.5906213,0.5340697,0.6432791,0.61573833,0.6924325,0.60253584,0.5520025,0.3873865,0.25200054,0.06764469,0.027833521,0.0,0.0,0.0,0.0,0.0,0.008757986,0.0,0.0,0.01013153,0.0,0.027109228,0.056471236,0.11626831,0.15313774,0.2501787,0.424042,0.5632425,0.64379364,0.5812287,0.65986717,0.6113929,0.66791093,0.57501787,0.54395807,0.4079278,0.25365642,0.08440827,0.05480431,0.01386328,0.0,0.0,0.0,0.014112249,0.0,0.0,0.0,0.008177288,0.0,0.005994715,0.028020665,0.05935239,0.061201997,0.12490633,0.32106936,0.54708284,0.67330974,0.63876116,0.7292439,0.6480333,0.6516613,0.50761735,0.48454636,0.37607837,0.24760707,0.11481957,0.084922075,0.030418493,0.004887581,0.0,0.0,0.025890358,0.0,0.0,0.0,0.012716703,0.0,0.005389005,0.02445165,0.04688803,0.035712793,0.04027734,0.15781614,0.37606335,0.5168727,0.6472598,0.85331833,0.8283896,0.7297172,0.5054528,0.47261542,0.34649545,0.22043392,0.09287374,0.07279904,0.026757881,0.0068898275,0.0,0.0,0.023023173,0.0,0.0,0.0,0.003565535,0.0055929273,0.0,0.009882703,0.008884124,0.026310347,0.035797223,0.08073419,0.15287882,0.2191501,0.41654575,0.6797746,0.84330636,0.78560376,0.5107672,0.3308507,0.18532291,0.09165162,0.0,0.009635679,0.0019170046,0.0,0.0,0.0,0.031098932,0.018640913,0.0,0.0,0.00570897,0.016665004,0.0,0.0016768277,0.0,0.0329272,0.07713096,0.099489875,0.0,0.0,0.17671387,0.4922648,0.81523246,0.8734071,0.55989796,0.24019904,0.06351094,0.034964822,0.0,0.0045485944,0.0021295547,0.0,0.0,0.0,0.03463669,0.035357825,0.009840421,0.0,0.0041383356,0.033110708,0.003742963,0.006684318,0.0,0.04071448,0.13116163,0.16616744,0.0,0.0,0.077211715,0.41829318,0.8071978,0.92533755,0.6123154,0.24091105,0.055573687,0.04634452,0.0,0.035630725,0.008216038,0.0,0.0,0.0,0.034837328,0.045717604,0.013233729,0.0009380579,0.00084994733,0.051973566,0.030148134,0.03953497,0.0,0.050095305,0.14286274,0.21074277,0.002116993,0.0,0.01543121,0.37676802,0.80767924,0.9763241,0.6830604,0.2604518,0.08693613,0.099151574,0.051216282,0.08662678,0.025282763,0.0,0.0,0.0,0.035044566,0.058848858,0.01849538,0.022603557,0.00073841214,0.05171871,0.04100924,0.05775126,0.021400586,0.070163995,0.15431194,0.2506688,0.026899554,0.0,0.0,0.36031377,0.8518596,1.0,0.7645972,0.26113755,0.103474505,0.14275502,0.11015479,0.121113956,0.036765687,0.0,0.0,0.0,0.047231607,0.085431114,0.039817363,0.060696438,0.010651231,0.06271181,0.06559559,0.09173667,0.05980619,0.10351142,0.18265256,0.29442698,0.0654186,0.0,0.0,0.30261284,0.7985641,1.0,0.7929412,0.2388151,0.08273149,0.13938494,0.1432981,0.13897932,0.033292286,0.0,0.0,0.0,0.05654812,0.087730765,0.046990685,0.07991321,0.015334107,0.09347883,0.14827944,0.19789648,0.18329012,0.22039881,0.2609998,0.36092192,0.14481357,0.046036497,0.0407949,0.36560854,0.73786986,0.9809017,0.69224334,0.1755912,0.035993658,0.09211376,0.1426321,0.13322772,0.034255944,0.0,0.0],[0.0,0.018861637,0.0,0.0,0.0,0.0,0.0,0.0,0.029866546,0.13575913,0.20996162,0.27550933,0.33363223,0.40057468,0.34766665,0.3641928,0.44039762,0.4575103,0.53523326,0.5315062,0.4408577,0.3364464,0.1423886,0.08192544,0.0121117905,0.006974064,0.0,0.0,0.0,0.008874543,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0826242,0.16520494,0.2536164,0.3921246,0.49100477,0.4448002,0.3959555,0.4237631,0.47323143,0.51820475,0.51534104,0.46300626,0.3671859,0.15541951,0.09724258,0.035653323,0.025234714,0.0,0.0,0.0,0.009327821,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05813629,0.12211783,0.21441509,0.4214623,0.5759637,0.58136696,0.5111963,0.4808004,0.51616967,0.5110739,0.47266692,0.43342632,0.36093205,0.18475252,0.13144286,0.06942423,0.04572104,0.0,0.0,0.0,0.0031319708,0.0,0.0,0.0,0.0,0.0,0.03354255,0.0,0.0657879,0.10367656,0.13268603,0.3082176,0.50641924,0.59914124,0.6758946,0.7228155,0.7191719,0.61022156,0.49734056,0.4479494,0.34383178,0.20030603,0.13160995,0.057365917,0.03600794,0.0,0.0,0.0,0.005970277,0.0,0.0,0.0,0.004733458,0.0,0.02607537,0.0,0.036356278,0.04505819,0.04226076,0.11430152,0.23058635,0.31297427,0.5147091,0.71619695,0.8081761,0.6318739,0.39976877,0.23522253,0.14633195,0.047654927,0.011713684,0.016900577,0.0120025575,0.0,0.002002135,0.0,0.026125357,0.0013771355,0.0,0.0,0.011233993,0.0,0.0,0.0,0.04172703,0.0,0.041609034,0.0,0.0,0.06370139,0.35417867,0.62204796,0.8086768,0.6828907,0.3446537,0.10257447,0.01043807,0.0,0.0,0.030636564,0.01388263,0.0,0.021571413,0.004165679,0.04548519,0.005002126,0.007854573,0.0,0.026559219,0.0,0.0,0.0,0.05300512,0.0,0.058137566,0.0,0.0,0.0,0.27284017,0.58321404,0.7867581,0.6977813,0.3513887,0.07139374,0.0,0.0031974316,0.0,0.04264544,0.009557165,0.0,0.026056007,0.012553528,0.056308925,0.021235429,0.020279527,0.0,0.043991163,0.0,0.0,0.023808584,0.054626174,0.0,0.049329728,0.0,0.0,0.0,0.21436423,0.56607634,0.7720606,0.7378012,0.40706813,0.07443522,0.026114352,0.051586956,0.016227946,0.059042476,0.01602593,0.0,0.018232822,0.018949881,0.066040285,0.03909546,0.03701049,0.027299382,0.06998457,0.0,0.024953745,0.07805677,0.06707684,0.0019671172,0.035638787,0.0,0.0,0.0,0.1760917,0.5639457,0.79860324,0.8046295,0.4643336,0.06434504,0.049971364,0.0847462,0.03580539,0.06475046,0.015512757,0.0,0.0083417,0.028919145,0.08146192,0.061362207,0.06289586,0.077923864,0.10081742,0.008836113,0.06459872,0.14201668,0.09719406,0.040399663,0.05184836,0.0,0.0,0.0,0.13429809,0.49971175,0.7538717,0.80225617,0.49214178,0.05533222,0.048451133,0.08245658,0.042565987,0.0670845,0.0,0.0,0.0,0.041528597,0.07835368,0.06222692,0.055022374,0.096600965,0.124256216,0.043707967,0.1502412,0.2666312,0.19727099,0.15461549,0.10219975,0.0042913556,0.0,0.0,0.19282955,0.5305624,0.72383136,0.7316849,0.45039886,0.053130865,0.04038941,0.06076607,0.038381904,0.06760926,0.0,0.0,0.0],[0.015063226,0.01072716,0.0,0.0,0.0,0.0,0.0,0.0,0.035716124,0.08183977,0.16781601,0.20726764,0.32109413,0.2340998,0.27241814,0.3099828,0.4460864,0.4328702,0.5213125,0.4224099,0.2830727,0.20192179,0.06514268,0.0,0.0,0.0,0.0,0.0,0.0152899325,0.002330169,0.0,0.0,0.0,0.0,0.0,0.008833975,0.018405885,0.041853234,0.13207617,0.2246122,0.39108145,0.3320405,0.35415167,0.31929147,0.38746232,0.410388,0.48145175,0.43010104,0.30226678,0.23474787,0.09468609,0.0065094903,0.0,0.0,0.0,0.0,0.025068857,0.0,0.0,0.0,0.0,0.0,0.0,0.032772437,0.021273255,0.016769215,0.09715713,0.24384701,0.4351529,0.45941532,0.49167663,0.43049735,0.41483378,0.42350888,0.4672262,0.43426466,0.33414343,0.2723565,0.1583318,0.032082304,0.0051582456,0.0,0.0,0.0,0.02208995,0.008526951,0.0,0.0,0.0,0.0,0.018288687,0.058368303,0.02414547,0.0041930526,0.056451127,0.17359255,0.32589984,0.46129507,0.54037666,0.58728015,0.6468867,0.64158773,0.5970383,0.51361895,0.39229757,0.266606,0.17213616,0.024992801,0.015542284,0.0,0.0,0.0,0.013893649,0.0019322783,0.0,0.0,0.0,0.0,0.019698173,0.05446449,0.0036239177,0.0,0.0114928335,0.012554668,0.059621766,0.21150032,0.3756206,0.60706586,0.83344716,0.79685813,0.5984305,0.340982,0.19528027,0.0887139,0.040986218,0.0,0.0,0.0,0.0,0.0,0.012663901,0.0,0.0,0.0,0.0,0.014233321,0.014674671,0.044853836,0.0,0.0,0.0,0.0,0.0,0.015287943,0.16219836,0.5714888,0.9037393,0.8428373,0.5235967,0.15246342,0.034089036,0.0,0.0,0.01692792,0.018637016,0.01708176,0.011025101,0.0,0.019177638,0.010942571,0.0036920905,0.0,0.0,0.024540462,0.012438737,0.048682533,0.011974223,0.0,0.0,0.0,0.0,0.0,0.0754132,0.5206247,0.8900152,0.84095585,0.49918354,0.09809157,0.0,0.0,0.0,0.0354999,0.030139104,0.022843368,0.018311135,0.0018377304,0.022801407,0.031545788,0.021311209,0.008212805,0.024933375,0.042969428,0.011873484,0.06490154,0.06132111,0.016956493,0.012037396,0.017809488,0.0,0.0,0.0,0.44408834,0.85599935,0.85842115,0.56651723,0.15325926,0.010824248,0.0,0.0,0.04268147,0.036078297,0.023730718,0.013619095,0.0,0.024863519,0.051230036,0.039622582,0.049663253,0.06835466,0.07227905,0.024192296,0.09363119,0.13146965,0.06147407,0.030797608,0.04406938,0.0,0.0,0.0,0.41755146,0.86532795,0.91070414,0.6633089,0.24096254,0.02938705,0.0,0.0,0.052911207,0.04570286,0.02465272,0.008970246,0.0,0.024969846,0.07043888,0.070205346,0.099381894,0.12568672,0.11485475,0.06087193,0.11769636,0.19891448,0.11890118,0.064777255,0.07435316,0.0,0.0,0.0,0.33171403,0.7785337,0.8909972,0.72374016,0.29945314,0.027737536,0.0,0.0,0.044544518,0.027345039,0.0008597225,0.0,0.0,0.02622047,0.076659866,0.08378411,0.13359101,0.16553035,0.14914303,0.09147732,0.14997049,0.27714664,0.21870267,0.12906663,0.13722777,0.0,0.0,0.0,0.32760924,0.7487365,0.8684255,0.7046611,0.255828,0.008742228,0.0,0.0,0.018837042,0.0,0.0,0.0,0.0],[0.0,0.024353229,0.016789302,0.0,0.0,0.0,0.0,0.0,0.0,0.049512655,0.23237589,0.3759647,0.4078921,0.39268857,0.45928568,0.505166,0.59393305,0.5881475,0.47591668,0.3159082,0.28792012,0.13240686,0.027143456,0.0,0.0,0.0,0.0,0.0,0.0,0.015474036,0.007405922,0.0,0.0,0.0,0.0,0.0,0.0,0.042532228,0.21298838,0.38016552,0.43197483,0.42018783,0.47278666,0.4839182,0.5094238,0.4966882,0.46374875,0.3236308,0.31204003,0.15348956,0.048998468,0.002070263,0.010292731,0.0,0.0,0.0021920502,0.0,0.0076276287,0.0029228926,0.0098379925,0.0,0.0,0.0,0.0,0.0,0.040423356,0.19234219,0.36020437,0.43754923,0.47104853,0.5156573,0.5287399,0.4536541,0.42653155,0.44182396,0.3499633,0.33387524,0.20058745,0.107062995,0.017448783,0.01881241,0.0,0.0,0.012964472,0.0,0.02134613,0.013327047,0.022096708,0.003218025,0.0,0.0038653016,0.020896673,0.0,0.028693162,0.11615789,0.25492674,0.34455934,0.44642884,0.5151797,0.6143369,0.5901929,0.5434679,0.54644716,0.43174124,0.3170489,0.19071046,0.09077347,0.0,0.0,0.0,0.0,0.013537936,0.0,0.02244246,0.026406825,0.037379444,0.022271216,0.0,0.00033153594,0.022760898,0.0,0.00006578863,0.018424459,0.041888744,0.13198297,0.29473102,0.4820149,0.7541701,0.82541317,0.7015784,0.5108023,0.26551294,0.09317069,0.07645774,0.03313013,0.0,0.0,0.0,0.0,0.009075314,0.0,0.017196916,0.021774285,0.023304112,0.017152913,0.0095861405,0.0,0.037284754,0.0,0.0,0.0,0.0,0.0,0.11871812,0.37180656,0.81686765,1.0,0.7492727,0.38620704,0.047634535,0.0,0.0,0.048963584,0.003878355,0.0260991,0.015733913,0.0,0.008171819,0.0,0.02355446,0.03268764,0.02830302,0.026394658,0.026076458,0.0,0.0489998,0.0,0.0,0.0,0.0,0.0,0.05313751,0.32529086,0.78124565,1.0,0.764597,0.35317677,0.0,0.0,0.0,0.03784518,0.026128836,0.05674,0.044793077,0.0,0.013630368,0.0,0.038383976,0.060378604,0.05907391,0.057084933,0.051247954,0.0,0.061414473,0.005194247,0.0058812425,0.0,0.0,0.0,0.0,0.24500647,0.69928414,1.0,0.82457256,0.46189475,0.04963381,0.0,0.0,0.026806049,0.026802734,0.07506989,0.062842935,0.0,0.01574602,0.0,0.055867225,0.09276465,0.09564629,0.10107898,0.08105299,0.012365289,0.08591096,0.037209935,0.030816883,0.0,0.0,0.0,0.0,0.1875326,0.66837835,1.0,0.89650023,0.5892422,0.1424867,0.0,0.0,0.037655048,0.036460668,0.097240105,0.086831726,0.0,0.01616469,0.0,0.06678421,0.123402566,0.121976696,0.13672583,0.12476399,0.028614968,0.09179719,0.06491855,0.060127974,0.0,0.0,0.0,0.0,0.11723178,0.5625503,1.0,0.93132824,0.6839828,0.21139136,0.0,0.0,0.023101166,0.020285651,0.088030145,0.07889298,0.0,0.012001947,0.0,0.054656826,0.11498202,0.13034615,0.15256383,0.151319,0.048710078,0.09180756,0.09757626,0.09714714,0.0,0.0,0.0,0.0,0.08607861,0.51379853,1.0,0.9343735,0.6699607,0.20257415,0.0,0.0,0.0,0.0,0.045340285,0.026332632,0.0015985519,0.0057784542],[0.03489192,0.019996539,0.014819406,0.0,0.0016181469,0.0,0.0,0.013408199,0.0,0.07146603,0.23465881,0.40512282,0.56447685,0.66187924,0.66389465,0.65925056,0.8349574,0.6965021,0.57305276,0.2433152,0.1571584,0.023992963,0.002458766,0.0,0.0,0.014200322,0.036511213,0.0,0.03628797,0.028473765,0.015030086,0.0,0.0,0.0,0.0,0.007911384,0.0,0.06261469,0.21346681,0.380666,0.5241637,0.6204438,0.6229524,0.6164197,0.7190966,0.6263901,0.53897244,0.261891,0.16441286,0.035252824,0.003206253,0.0,0.0,0.01023823,0.036616564,0.0017869622,0.026142031,0.031126395,0.022098228,0.0,0.0,0.006849028,0.0,0.0067722276,0.0,0.05426024,0.18040791,0.32426882,0.4734735,0.5804621,0.62313974,0.5936297,0.6201152,0.5604106,0.5171249,0.30312467,0.20324126,0.089411184,0.023063436,0.0,0.0,0.012337163,0.04262525,0.016154237,0.0025669038,0.018129587,0.029614374,0.00700292,0.0,0.008225642,0.0,0.013876341,0.0,0.026747942,0.107025266,0.19042554,0.33012545,0.4223138,0.5370789,0.58600175,0.6741499,0.6291554,0.5710432,0.3606999,0.20677122,0.10038198,0.0051356703,0.0,0.0,0.024330676,0.0502512,0.025324166,0.0,0.0076485276,0.046011344,0.029829621,0.0,0.0005181879,0.0054661334,0.037438735,0.0,0.0040819496,0.009991154,0.039242357,0.13401766,0.354779,0.5981174,0.7958942,0.8744028,0.656742,0.41425872,0.16121668,0.067195565,0.05414608,0.0,0.0,0.0,0.0033899695,0.028803073,0.018830962,0.0,0.0017142296,0.03603684,0.015398227,0.0,0.0,0.00833419,0.04452107,0.0,0.018306606,0.0,0.0,0.0,0.23091018,0.5599973,0.94927347,1.0,0.63762426,0.22571374,0.0,0.0,0.021363303,0.0127014,0.044743374,0.04676655,0.04477877,0.038351454,0.0070623085,0.0,0.0,0.03416571,0.02255208,0.0,0.004305333,0.018130466,0.041760057,0.0,0.03912487,0.0,0.0,0.0,0.15356348,0.50124836,0.9875382,1.0,0.66461897,0.1733594,0.0,0.0,0.0140288845,0.0416769,0.08654262,0.10500494,0.08057362,0.052995756,0.0004414469,0.0,0.0050411075,0.04074525,0.034132943,0.0,0.00857915,0.02244524,0.069015495,0.0059705824,0.0642725,0.0,0.0,0.0,0.07196958,0.41252983,0.96818525,1.0,0.7794586,0.26302004,0.0,0.0,0.027258508,0.059107676,0.10271149,0.14745311,0.11169918,0.076725766,0.0,0.0,0.022079572,0.05812315,0.051424712,0.0,0.012977146,0.024287865,0.103233755,0.050362557,0.10405489,0.0,0.0,0.0,0.040905036,0.3846153,0.98749685,1.0,0.9047662,0.36689636,0.038881965,0.0,0.056064494,0.08650939,0.124782756,0.19260256,0.13976057,0.09536463,0.0,0.0,0.04261923,0.08854142,0.08279354,0.0,0.024654515,0.027255848,0.1151784,0.067019366,0.13049953,0.0,0.0,0.0,0.0,0.31637785,0.9342388,1.0,0.9853986,0.4384657,0.09338829,0.0,0.064569674,0.08485587,0.11130652,0.19656433,0.13188645,0.088867925,0.0,0.0,0.051274978,0.099925436,0.09744465,0.0,0.02091901,0.01790522,0.12252836,0.08888638,0.1280493,0.0,0.0,0.0,0.0,0.26599586,0.8498343,1.0,0.983063,0.42034274,0.11513622,0.0,0.0631041,0.054320373,0.04459686,0.14191712,0.07830708,0.060807943,0.0],[0.0057949126,0.034401573,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11273107,0.2781451,0.517514,0.7078602,0.86730486,0.8761017,0.8414525,0.826764,0.6883662,0.45043826,0.1406071,0.0089572,0.0,0.0,0.0,0.0,0.004319072,0.0073481426,0.0,0.012020104,0.036639675,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0896415,0.22078025,0.45403773,0.6364099,0.8149407,0.838907,0.8175827,0.74807775,0.6283912,0.43076205,0.16003682,0.0,0.0,0.0,0.0,0.0,0.0096774325,0.009591959,0.0,0.009786285,0.033441246,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.059964508,0.16388978,0.3779716,0.5510818,0.76802075,0.8204823,0.79797983,0.68898344,0.58739763,0.428254,0.19982654,0.028297462,0.0094740465,0.016007602,0.0,0.0,0.01947572,0.014696248,0.0,0.000011980534,0.025485195,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022209466,0.10019048,0.25876528,0.38401127,0.61214244,0.7192418,0.7429552,0.7131774,0.5760657,0.41661227,0.2031891,0.034509175,0.03320343,0.020215198,0.0,0.0,0.021634206,0.020084612,0.00840693,0.0,0.01962214,0.02374921,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011689208,0.10525894,0.20696913,0.5730198,0.81525326,0.8842558,0.7776712,0.45570153,0.20470887,0.024462081,0.0,0.025543623,0.0055304915,0.0,0.0129233,0.0034950823,0.019152015,0.010646701,0.0,0.015770562,0.010517053,0.0,0.0,0.0,0.0026468784,0.0,0.0,0.0,0.0,0.0,0.025653206,0.41677654,0.8435218,1.0,0.8283136,0.31854463,0.01688438,0.0,0.0,0.04107587,0.0013802648,0.0,0.05084022,0.036431484,0.03656581,0.0076891333,0.0,0.016632922,0.011521041,0.008007601,0.0,0.0,0.0061218366,0.0,0.0,0.0,0.0,0.0,0.0,0.31736875,0.81550956,1.0,0.882253,0.29554266,0.0,0.0,0.0,0.048901312,0.001931414,0.0,0.0863172,0.06302767,0.0526796,0.0077119023,0.004945129,0.03373743,0.017363727,0.03158006,0.0,0.0,0.015382774,0.0,0.0,0.0014747679,0.0,0.0,0.0,0.2455019,0.7401818,1.0,0.9838869,0.38671637,0.0,0.0,0.0,0.06446171,0.013275333,0.006104395,0.102819875,0.06433004,0.053637862,0.014398895,0.012908459,0.055522017,0.030788325,0.048851155,0.0002862662,0.0,0.030280024,0.0,0.00039453804,0.0152156055,0.0,0.0,0.0,0.22359759,0.7197165,1.0,1.0,0.48588234,0.04338813,0.0,0.0,0.09320529,0.028456926,0.017382093,0.11822756,0.056782156,0.046320364,0.014896832,0.014885873,0.07898727,0.0641008,0.07313565,0.0057161227,0.014197707,0.041037604,0.0,0.018239409,0.02725105,0.0,0.0,0.0,0.16522834,0.6290618,1.0,1.0,0.5791238,0.10745554,0.0,0.0,0.09891679,0.019453965,0.0061275735,0.10964685,0.028798133,0.027047716,0.012840137,0.010681547,0.09578461,0.08041148,0.08855568,0.014406189,0.01971507,0.037494056,0.011292256,0.053766444,0.026798397,0.0,0.0,0.0,0.09648145,0.5297224,1.0,1.0,0.6072669,0.13200022,0.0,0.0,0.084545374,0.0,0.0,0.07466978,0.0,0.0069940537,0.012434185],[0.014652573,0.009957083,0.0,0.0,0.0,0.0,0.025371522,0.03926687,0.054897845,0.15861672,0.3138489,0.52025974,0.7988235,0.85756594,0.8707953,0.8863026,0.86495143,0.605704,0.41527188,0.18116465,0.062093988,0.0,0.0,0.0,0.0151743665,0.0,0.0,0.0,0.015915215,0.011014044,0.0,0.0,0.0,0.0,0.020926744,0.026279718,0.033523776,0.0973382,0.20898822,0.41471875,0.73224205,0.8606754,0.92371374,0.91659784,0.81353414,0.5246156,0.313354,0.09518084,0.0,0.0,0.0,0.009114668,0.03556996,0.004125491,0.0,0.0,0.01910916,0.016709447,0.0,0.0,0.0,0.0,0.020576224,0.01848191,0.016579151,0.08244761,0.16338274,0.35116237,0.67625964,0.8627091,0.9595886,0.93372905,0.75800455,0.50663114,0.2879483,0.07405911,0.0,0.0,0.0,0.007125184,0.044417895,0.015104957,0.005400747,0.0,0.02103395,0.013971001,0.0,0.0013715327,0.0,0.0,0.017954916,0.004205048,0.0046516955,0.06041663,0.10955991,0.22514112,0.49598628,0.7007108,0.8406331,0.88055676,0.7054145,0.51805156,0.30011693,0.1103105,0.0,0.0,0.0,0.0063032955,0.04313287,0.010216467,0.0,0.0,0.018117368,0.0,0.0,0.004193917,0.0,0.0,0.014750093,0.0076073036,0.0,0.0,0.0,0.09139563,0.3315247,0.6597071,0.8583612,0.9289641,0.6300314,0.34689438,0.11975831,0.011261851,0.0,0.0045905113,0.0,0.00615672,0.040613905,0.0038721412,0.0,0.0,0.016232297,0.0,0.0,0.0,0.0,0.0,0.019313172,0.009869069,0.0,0.0,0.0,0.0,0.14877583,0.6075553,0.89477605,0.9578404,0.57787246,0.18232201,0.0,0.0,0.0,0.008144759,0.0,0.011695191,0.055949382,0.029504709,0.019540928,0.0147179365,0.0076373294,0.015208669,0.023252174,0.019941643,0.0,0.0,0.011643842,0.0023483485,0.0,0.0,0.0,0.0,0.08263769,0.59823996,0.91111225,1.0,0.60397685,0.16743527,0.0,0.0,0.0,0.0,0.0,0.031245522,0.07664503,0.050509907,0.039010048,0.027859531,0.007374555,0.039619178,0.064616024,0.049749374,0.0,0.0,0.018257454,0.0074429065,0.0,0.0,0.0,0.0,0.07660303,0.5958585,0.91016304,1.0,0.6677068,0.20283192,0.0,0.0,0.0,0.0,0.0,0.036174074,0.081112,0.052513093,0.04923074,0.03622005,0.008519307,0.06874321,0.10732955,0.08445893,0.011275969,0.0,0.025819346,0.012406856,0.0,0.0,0.0,0.0,0.068178155,0.6159399,0.94386524,1.0,0.739521,0.24701795,0.0,0.0,0.0,0.0,0.0,0.04174173,0.08109477,0.051226676,0.055422246,0.042507075,0.01041051,0.10247354,0.15307474,0.11352052,0.022254467,0.0,0.024977796,0.011476286,0.0,0.0,0.0,0.0,0.054721534,0.5869565,0.907532,1.0,0.785805,0.30056274,0.0,0.0,0.0,0.0,0.0,0.028632484,0.06860654,0.04098875,0.06385447,0.049714275,0.012173891,0.12010139,0.17575823,0.13942227,0.043493986,0.0,0.016065434,0.0023942292,0.0,0.0,0.0,0.0,0.035652854,0.51029134,0.799876,1.0,0.7691264,0.35646102,0.0,0.0,0.0,0.0,0.0,0.002767235,0.057044543,0.029737368,0.08522045,0.06121441],[0.02087462,0.026719622,0.0,0.007193476,0.0061360598,0.0,0.044025622,0.040112466,0.052588873,0.12880127,0.16394304,0.37743694,0.67811,0.7068813,0.643034,0.7453618,0.6828641,0.6196007,0.45674258,0.22649729,0.11541337,0.0,0.0057712123,0.0,0.0,0.0,0.0,0.0,0.013293996,0.009535208,0.0,0.0036118776,0.0,0.0,0.038651377,0.009378135,0.017827682,0.03917653,0.100713,0.3293965,0.6897987,0.7918306,0.8260859,0.8941471,0.66731894,0.46506697,0.2718097,0.055956654,0.01405111,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019498102,0.011108533,0.004026994,0.0077336505,0.0051525384,0.0,0.029795587,0.0,0.013673231,0.022517815,0.10851192,0.31255406,0.6796137,0.8578794,0.93955547,0.9804009,0.63649726,0.40315223,0.17333272,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025674984,0.010597631,0.013473302,0.017907739,0.015561745,0.0,0.022300936,0.0,0.0045636445,0.010839671,0.10773097,0.26420712,0.57128537,0.7775959,0.8948613,0.9521731,0.5999588,0.3954031,0.19405559,0.021918021,0.010703638,0.0,0.0,0.0,0.011956036,0.0,0.0,0.0,0.026931368,0.0016476214,0.008717373,0.008232228,0.023122326,0.0,0.024026543,0.0,0.0,0.0,0.040029176,0.19766912,0.46486843,0.7780499,0.91168183,0.87835,0.4590723,0.18803269,0.0519593,0.015768073,0.05028992,0.006584592,0.017338924,0.0018629283,0.016549066,0.0,0.0,0.0,0.015413351,0.0,0.0028431863,0.0,0.029199272,0.0,0.012460358,0.0,0.0,0.0,0.0,0.10020122,0.33542967,0.82617325,0.97357666,0.81286955,0.3611026,0.0,0.0,0.0,0.049281158,0.017875604,0.02849561,0.024635203,0.040962897,0.024636082,0.024617389,0.008679405,0.003288865,0.014172636,0.04211521,0.0,0.012321681,0.0,0.0021603703,0.0,0.0,0.0,0.0,0.06858583,0.30641574,0.85016906,0.9950675,0.8172237,0.37601936,0.0,0.0,0.0,0.020429306,0.011580266,0.02876801,0.048428617,0.06586447,0.05228541,0.050907947,0.026790187,0.002589941,0.037624322,0.08495358,0.011830412,0.005320534,0.010467753,0.0,0.0,0.0,0.0,0.0,0.09666218,0.34372967,0.8749767,1.0,0.8610412,0.43340194,0.0,0.0,0.0,0.0058064014,0.0,0.026780143,0.060583986,0.06680782,0.06737403,0.07077622,0.042014137,0.005273536,0.05963555,0.12696818,0.037055664,0.004436657,0.014969967,0.0,0.0,0.0,0.0,0.0,0.1258233,0.38459635,0.9299786,1.0,0.9285911,0.49269134,0.0,0.0,0.0,0.0,0.0,0.022995971,0.07322511,0.06382214,0.07865088,0.091290206,0.058325082,0.009527601,0.08564781,0.15935184,0.05424825,0.005629733,0.008006364,0.0,0.0032693744,0.0,0.0,0.0,0.14184809,0.40894473,0.9244332,1.0,0.95002,0.5405984,0.008514293,0.0,0.0,0.0,0.0,0.015591383,0.07840152,0.055108793,0.08282631,0.11335723,0.075568125,0.009577751,0.094818294,0.16942573,0.06836489,0.016289517,0.0026218444,0.0,0.0065083355,0.0,0.0,0.0,0.144185,0.4038288,0.832764,0.96529865,0.888217,0.5528279,0.059654236,0.0,0.0,0.0,0.0,0.0069649518,0.08427718,0.048180044,0.088553,0.1359551,0.09419946],[0.0,0.020255916,0.029404528,0.0,0.0,0.036610067,0.053195007,0.0,0.0681904,0.06837288,0.15118721,0.22580232,0.41841835,0.4448822,0.47345966,0.46502477,0.51995176,0.58194494,0.53752,0.345681,0.13973635,0.0,0.0,0.004388854,0.037335947,0.012812756,0.02258598,0.012487389,0.0,0.012320541,0.022950545,0.0,0.0,0.039169595,0.037205316,0.0,0.02203904,0.024864167,0.12714745,0.26372847,0.51765543,0.6645156,0.73519814,0.6781831,0.55324763,0.40394753,0.2531888,0.09629683,0.0181083,0.0,0.0,0.019004442,0.02473057,0.007826351,0.0,0.0,0.0,0.010568231,0.024843104,0.0,0.0,0.03614565,0.018206641,0.0,0.0,0.030958846,0.14766732,0.31663966,0.59642345,0.8504676,0.9273483,0.83671355,0.5111874,0.25020435,0.10858213,0.020036183,0.013397723,0.0,0.017266348,0.029245645,0.011752285,0.007432036,0.0,0.0,0.0,0.011066519,0.03273037,0.0022238046,0.0011347532,0.032625496,0.01564157,0.0,0.0,0.053731076,0.17094463,0.34100014,0.6133632,0.88281655,0.95134085,0.8437455,0.5078702,0.22972652,0.07888088,0.008367576,0.007479742,0.0,0.032851517,0.024671666,0.014368519,0.007880196,0.0,0.0,0.0051534176,0.0077260435,0.024210311,0.005664319,0.012401246,0.042459704,0.031075709,0.0,0.0,0.022996165,0.11633195,0.29723686,0.5840163,0.8756497,0.923964,0.68009746,0.32747424,0.09047256,0.027208395,0.0047955066,0.014152296,0.0,0.04135821,0.016677938,0.018628702,0.024294086,0.0,0.0,0.00088757277,0.009423502,0.026580825,0.009717293,0.007786818,0.04742325,0.044824526,0.0,0.0,0.0,0.035061672,0.23147115,0.5630442,0.93783045,0.8985534,0.4510029,0.09084965,0.0,0.0,0.021351732,0.01976785,0.015996322,0.04450745,0.013233177,0.056838177,0.067152366,0.03968536,0.0,0.0,0.016400702,0.028916769,0.013100922,0.0006108582,0.04345064,0.042545512,0.0,0.0,0.0,0.027103111,0.23391095,0.57566094,0.9591352,0.87986374,0.35660076,0.048554488,0.0,0.0,0.037059806,0.021166839,0.020970702,0.04166042,0.0064005926,0.09493582,0.0846638,0.06253047,0.009386152,0.0,0.028049491,0.034815952,0.015912637,0.008433968,0.060479186,0.05099158,0.0,0.0,0.0,0.034015797,0.25477,0.60621583,0.95933944,0.8689198,0.33509395,0.06286045,0.0,0.0,0.052486263,0.02238562,0.03323339,0.050743088,0.016266823,0.119026646,0.097864725,0.08147371,0.016131878,0.0,0.04126121,0.05200986,0.03030967,0.02593787,0.08235024,0.066015504,0.0,0.0,0.0,0.035402685,0.28237793,0.64800614,0.9962024,0.89398915,0.34872764,0.07680048,0.0,0.0,0.06258961,0.01791805,0.046118975,0.052363314,0.025667347,0.14160368,0.11504174,0.10449386,0.027175888,0.0025240183,0.046781816,0.063794434,0.040874116,0.02906777,0.09963285,0.06762276,0.0,0.0,0.0,0.06745237,0.32232058,0.6876961,0.9989055,0.88194084,0.34385806,0.08910903,0.0,0.0,0.07122074,0.016680367,0.056409106,0.05448456,0.037458062,0.15439951,0.12831837,0.12534967,0.041824266,0.0014496446,0.0409322,0.05217264,0.044780508,0.030210182,0.11845749,0.05394359,0.0,0.027655303,0.0,0.1330091,0.36993486,0.69772756,0.91901284,0.8013205,0.31143627,0.10108628,0.0,0.0119546205,0.077747874,0.020225443,0.05853577,0.053860158,0.042803653,0.14428739,0.13678576,0.1464524,0.05683168],[0.0,0.0,0.0,0.0,0.0,0.08416991,0.10293849,0.053236216,0.15248227,0.0432095,0.10631344,0.1278196,0.30458933,0.31321883,0.24710535,0.33226675,0.36771697,0.5623986,0.5402276,0.334086,0.07902564,0.0,0.0,0.0,0.0,0.0,0.0,0.00045907497,0.0,0.0,0.0,0.0,0.0,0.061097033,0.064024664,0.015255287,0.12901832,0.05522974,0.14517958,0.23611984,0.4452954,0.58012956,0.5589655,0.5685067,0.44093257,0.3935001,0.24285531,0.08595786,0.0012962222,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012806669,0.009633258,0.0040453672,0.0,0.0,0.028523467,0.038602456,0.0,0.09904468,0.06838492,0.17683953,0.34855807,0.6039234,0.8367947,0.83289635,0.7208496,0.39390498,0.19896318,0.040521026,0.013859071,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023847975,0.011763677,0.009830095,0.0,0.0,0.00352557,0.030981489,0.0,0.06775934,0.08820002,0.19423833,0.41100323,0.6840939,0.96021974,0.9197724,0.72257996,0.35500652,0.10171992,0.0,0.014894798,0.0028099567,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026464507,0.0,0.007223718,0.0,0.0,0.00029963255,0.03909801,0.0,0.013543524,0.061549604,0.13604626,0.3750059,0.6732909,0.9279286,0.8615302,0.51694626,0.13310078,0.02235283,0.0,0.02982039,0.029828295,0.0,0.0,0.0,0.009879053,0.0,0.0,0.0,0.027978584,0.0,0.010698177,0.0,0.0,0.00036990643,0.073608994,0.0,0.0,0.003932297,0.05876483,0.3138538,0.70353925,0.9818772,0.75262827,0.22745678,0.0,0.0,0.0,0.050329126,0.05288142,0.013987131,0.027272396,0.0,0.021838427,0.033196695,0.014996558,0.0,0.025698543,0.0,0.015681908,0.0,0.0,0.0013495982,0.095948905,0.0,0.0,0.017547205,0.07811655,0.35974032,0.74250925,1.0,0.6951168,0.10970581,0.0,0.0,0.0,0.06953676,0.06306763,0.011679083,0.06354578,0.021855779,0.032229595,0.04918786,0.016279861,0.0,0.02836229,0.0,0.018765897,0.0,0.0041852593,0.020270988,0.12453126,0.0,0.0,0.03244701,0.10858985,0.40220147,0.7663847,1.0,0.6887213,0.080087796,0.0,0.0,0.0,0.07949958,0.07052936,0.009125374,0.07159577,0.036089286,0.034012526,0.06026227,0.007144265,0.0,0.034839265,0.0076455697,0.0280516,0.012353294,0.033470213,0.04936611,0.16810355,0.0,0.0,0.03410007,0.13514405,0.4488057,0.8071177,1.0,0.7217735,0.082054265,0.0,0.0,0.0,0.0760891,0.07764254,0.0,0.07295756,0.048580125,0.03526248,0.07434666,0.0014765561,0.0,0.03924103,0.01784993,0.031774558,0.019259721,0.053090297,0.07464938,0.19958386,0.009755276,0.0,0.06552017,0.1962057,0.51551527,0.84936607,1.0,0.736392,0.09126343,0.0,0.0,0.0,0.077073954,0.08023431,0.0,0.07974873,0.06451734,0.0438857,0.09575193,0.0056012273,0.005758621,0.033745714,0.009907924,0.014367484,0.0054492205,0.0656641,0.090203986,0.2151502,0.06229592,0.028764516,0.1345384,0.3017058,0.58868206,0.85858405,0.9983544,0.69729745,0.11093606,0.0,0.0,0.0,0.08202781,0.07657688,0.0,0.089680575,0.065933876,0.056118116,0.132581,0.019215845,0.011233069],[0.008126438,0.0,0.011745349,0.02066455,0.023681484,0.08564484,0.1071238,0.069021195,0.11143679,0.10713607,0.14243197,0.122647144,0.17566073,0.17308313,0.07743199,0.16149005,0.41904014,0.6146413,0.6387383,0.36107427,0.14009108,0.0,0.0,0.0,0.0,0.005576059,0.0015464276,0.0,0.013172187,0.0,0.0070696697,0.010975599,0.0020293295,0.026165359,0.03393574,0.04624205,0.1438488,0.1696406,0.22946167,0.23515683,0.31903717,0.39509547,0.37951297,0.4588669,0.50613195,0.4350509,0.28670502,0.05795198,0.034711562,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016123235,0.0,0.016282305,0.014110103,0.0,0.009929232,0.0025012344,0.04526324,0.16516408,0.2011744,0.28219742,0.35291222,0.54925275,0.72688264,0.728885,0.6214936,0.33283964,0.15058693,0.054463975,0.0,0.0,0.0,0.0,0.009740286,0.0,0.0,0.0,0.0,0.019706398,0.007652506,0.03849306,0.027662925,0.0,0.019366995,0.0,0.04619734,0.12848867,0.17083734,0.3247339,0.5050766,0.7893853,0.9103445,0.81145006,0.55518407,0.17563768,0.014144398,0.0,0.0,0.0,0.0,0.0,0.014105529,0.0,0.0,0.0,0.0,0.018947281,0.0062357634,0.04532183,0.016336404,0.0,0.03438747,0.01299686,0.02465465,0.034751683,0.08928523,0.32556593,0.6256375,0.92755455,0.899197,0.64889354,0.29851598,0.031241134,0.0076193213,0.0,0.0,0.0,0.0,0.0,0.013922684,0.011568189,0.022589527,0.0056676567,0.0,0.013215639,0.0007970035,0.044162966,0.013407871,0.0,0.054766603,0.03838195,0.019781254,0.009143941,0.052277185,0.36941215,0.7442901,1.0,0.8586399,0.42390126,0.007329121,0.0,0.02030468,0.0,0.0,0.005491033,0.0,0.006361924,0.0012634248,0.005859673,0.021402374,0.02116184,0.01156956,0.01000575,0.0,0.035510473,0.0312372,0.0,0.07048863,0.04516179,0.015037432,0.028258584,0.106266156,0.4829709,0.84415096,1.0,0.7911153,0.2977786,0.0,0.0,0.020635337,0.0,0.0,0.0073051676,0.025508113,0.04065124,0.037857123,0.035354435,0.031692468,0.027760625,0.011920184,0.011987068,0.0,0.02986838,0.05875238,0.022783063,0.10098626,0.08957911,0.04750879,0.0724364,0.15462996,0.57127,0.913316,1.0,0.7497923,0.26474857,0.0,0.0,0.023164213,0.0,0.0,0.010333456,0.044292614,0.054808795,0.054476954,0.04848788,0.049723975,0.03968317,0.018276483,0.024725221,0.020570599,0.04177296,0.09718886,0.062706284,0.13535227,0.14242238,0.100275576,0.1472282,0.20641264,0.64639544,0.9792417,1.0,0.75999534,0.2639287,0.0,0.0,0.034097634,0.0,0.0,0.02290453,0.07259559,0.07522081,0.077662036,0.06641974,0.0737295,0.05975526,0.029617794,0.03028217,0.039900362,0.046282746,0.11621651,0.084876955,0.15082979,0.1953029,0.16288072,0.2372432,0.28232217,0.7232061,1.0,1.0,0.74979585,0.25954068,0.0,0.0,0.0921683,0.0,0.042078964,0.0666943,0.10169608,0.10227582,0.10771963,0.09239817,0.10497492,0.08683097,0.043232404,0.024529085,0.0515498,0.038077883,0.11473854,0.08903377,0.14434008,0.23147264,0.22764084,0.33370584,0.36451298,0.77485746,1.0,1.0,0.69512403,0.25683588,0.0,0.011775397,0.17315558,0.057598025,0.113352895,0.13326626,0.12739034,0.13354573,0.1332847,0.1116975,0.13189973,0.11645916,0.058562182],[0.010036334,0.028565228,0.0031350702,0.032295458,0.14308465,0.18541083,0.16015364,0.21062946,0.20416176,0.1673471,0.183575,0.14130303,0.13750672,0.07741818,0.0778046,0.25358096,0.58456737,0.81779754,0.60837185,0.3153962,0.02105628,0.0,0.0,0.048394985,0.026502863,0.00003285706,0.0,0.0,0.01725068,0.011018716,0.01193317,0.0171099,0.090009324,0.09040991,0.09308128,0.209611,0.25301385,0.2971722,0.27990872,0.2337268,0.2397899,0.26112124,0.3586373,0.54009056,0.6163799,0.5661651,0.2448889,0.04408881,0.0,0.0,0.0013403147,0.04451953,0.018223584,0.0,0.0,0.0,0.022541605,0.00800249,0.016342737,0.014581524,0.051330373,0.049027197,0.05899422,0.17400293,0.27639836,0.35989067,0.32213917,0.36948687,0.47593486,0.618008,0.66685516,0.60238296,0.33937615,0.17504936,0.018637694,0.0,0.0,0.0,0.0038057268,0.045843877,0.022773549,0.0,0.0,0.0,0.031826295,0.028307162,0.016927034,0.022966854,0.0258746,0.02596949,0.034231246,0.09941393,0.23501927,0.33503836,0.4277814,0.5855609,0.773627,0.86480355,0.6702059,0.40967244,0.0689477,0.0,0.0,0.0,0.0,0.0,0.0004454106,0.028454438,0.025702342,0.0,0.0020273328,0.0,0.036710627,0.04563345,0.010212988,0.01899074,0.008215293,0.024318822,0.021220043,0.038147934,0.100291945,0.24267663,0.50024444,0.7471828,0.93998075,0.8775878,0.5055276,0.19661687,0.0,0.009659171,0.0,0.0017507374,0.0,0.0,0.0,0.03162288,0.03800022,0.03937947,0.022331454,0.0060458854,0.0293886,0.04497642,0.0,0.014559478,0.02917292,0.041815363,0.032226875,0.03922227,0.032020524,0.21940348,0.5905864,0.92008436,1.0,0.7796348,0.2980222,0.0,0.0,0.035356164,0.007972851,0.06013663,0.04883358,0.015280671,0.028853238,0.027957939,0.05299495,0.04760416,0.03594344,0.0261169,0.023507372,0.032245137,0.0,0.038714565,0.07661854,0.06846534,0.052933462,0.06511523,0.058287524,0.30945837,0.71781564,1.0,1.0,0.63467914,0.18068558,0.0,0.0,0.026252188,0.0166637,0.10239579,0.08852331,0.0932294,0.13221188,0.11873053,0.1345974,0.06972036,0.041258156,0.031197637,0.023997173,0.023458004,0.0,0.061191544,0.12783176,0.1211616,0.139065,0.13930032,0.14968611,0.40064567,0.8087927,1.0,0.9741859,0.53636694,0.13312458,0.0,0.0,0.03042262,0.029426917,0.12902574,0.119510435,0.14300673,0.1895968,0.17429753,0.1875388,0.10732327,0.057652377,0.047140867,0.03292554,0.030999586,0.0,0.08911726,0.18226023,0.17366058,0.22943932,0.23204783,0.26335794,0.50328344,0.89562124,1.0,0.97369176,0.4892944,0.11316418,0.0,0.0,0.04084587,0.053164266,0.15905237,0.15791622,0.1966635,0.24615596,0.23609734,0.24811062,0.15627663,0.081637114,0.06724648,0.03468234,0.035566233,0.0,0.10617473,0.21789938,0.22319673,0.31549424,0.32738566,0.3828491,0.59779423,0.9600672,1.0,0.9504077,0.44933575,0.11738239,0.0,0.032998137,0.13321725,0.16796266,0.26339233,0.23626584,0.25447738,0.31118432,0.2966891,0.30491918,0.20293927,0.10664867,0.087434605,0.025844008,0.03931488,0.0,0.12533002,0.24012397,0.2392503,0.35295185,0.41782695,0.4836411,0.6670688,0.9819976,1.0,0.8725147,0.41751492,0.16351135,0.024856001,0.17299545,0.28888005,0.333499,0.4068563,0.34322417,0.31494257,0.36762047,0.3398654,0.34454513,0.23179035,0.13623753,0.10793804],[0.024115302,0.016831487,0.0033333004,0.04023788,0.18332726,0.2790584,0.35551947,0.30369848,0.31471133,0.26306096,0.1160153,0.083155006,0.05114404,0.04941617,0.22349826,0.54576135,0.8436046,0.84275794,0.653548,0.16513714,0.00033831596,0.0,0.011032455,0.045459248,0.07227486,0.038204335,0.027775817,0.0,0.027834311,0.024298161,0.00047689676,0.0025879294,0.10130678,0.15704124,0.25070477,0.28200543,0.3877868,0.38273013,0.24902152,0.14651614,0.14204612,0.23479117,0.4755299,0.7040685,0.7607793,0.55663145,0.2810682,0.0,0.0,0.0,0.012923911,0.02317866,0.046399295,0.027308144,0.02828946,0.0,0.019345276,0.018731669,0.0,0.0,0.058393426,0.0801251,0.15540491,0.22311264,0.38368386,0.408495,0.36776158,0.31378132,0.4017163,0.52813023,0.6574973,0.5641435,0.3183884,0.13238887,0.049540423,0.0,0.0,0.0,0.017094083,0.008805677,0.029170342,0.008792378,0.010150291,0.0,0.01513043,0.028565563,0.011573933,0.0011747181,0.050980642,0.06273452,0.087014064,0.14923747,0.34645516,0.42063034,0.5222264,0.6095876,0.7685844,0.7195251,0.5248914,0.22281818,0.009909965,0.0,0.000072568655,0.0,0.0,0.0,0.0074921697,0.00034190714,0.02310273,0.010188945,0.007833362,0.0,0.025020137,0.039321646,0.021225706,0.0032699108,0.044668823,0.043978184,0.02950152,0.054523133,0.22190133,0.37183523,0.61674386,0.83910835,0.9457747,0.7227412,0.36269832,0.031730235,0.0,0.0,0.01818268,0.006767109,0.0,0.0,0.0018318146,0.013050251,0.025985762,0.020899676,0.013567336,0.0035371482,0.026062109,0.04263734,0.015405394,0.0,0.028808862,0.053831697,0.03431552,0.05950085,0.18015859,0.42162877,0.75551176,0.9737887,0.89984715,0.5369644,0.12056818,0.0,0.0,0.0,0.050419867,0.0605157,0.0,0.0,0.005687386,0.01099252,0.03172943,0.03178159,0.02901943,0.022488043,0.02238702,0.037678316,0.010517441,0.003737688,0.04420656,0.0859858,0.07994889,0.13252176,0.27753627,0.5755016,0.9024246,1.0,0.7927228,0.38155365,0.0,0.0,0.012846716,0.03967122,0.09384011,0.119817674,0.05349429,0.06628324,0.115741216,0.1085619,0.09713332,0.044179767,0.020212375,0.022388548,0.022799857,0.026869029,0.0034766346,0.017436832,0.09981935,0.18334395,0.20335141,0.2665413,0.4448523,0.76800656,1.0,1.0,0.69441664,0.30370572,0.0,0.0,0.018570907,0.06124337,0.13172735,0.16130356,0.08691699,0.10606146,0.1690349,0.1627371,0.14798109,0.07131795,0.028552853,0.025272697,0.03050159,0.027399167,0.0076167285,0.03785362,0.17129959,0.28509086,0.3264504,0.4324206,0.6328985,0.96593004,1.0,1.0,0.6356608,0.2569609,0.0,0.0,0.03474231,0.09527525,0.17952302,0.20311524,0.12869951,0.14225426,0.21820983,0.21775192,0.20215704,0.11081314,0.045937113,0.032049842,0.03289605,0.0320625,0.0223836,0.07017901,0.2405833,0.37096018,0.42777705,0.5701102,0.7867432,1.0,1.0,1.0,0.562574,0.2134467,0.0,0.0,0.11465956,0.21393922,0.3142969,0.32179862,0.23789015,0.21554883,0.28412387,0.27160972,0.25153214,0.15360323,0.07367343,0.042286716,0.024852417,0.03192427,0.061475456,0.108301416,0.27407712,0.40093136,0.4657024,0.63438916,0.85303426,1.0,1.0,1.0,0.507836,0.19992512,0.013322823,0.10381677,0.30597878,0.4303742,0.5358937,0.502442,0.39184237,0.30364,0.34172744,0.30781952,0.2797501,0.19243993,0.118607365,0.062032707],[0.0,0.039155133,0.011132419,0.06801922,0.23805873,0.4431706,0.53144264,0.57246816,0.54133815,0.38898772,0.30341637,0.14747924,0.18315783,0.35278702,0.566431,0.8105563,1.0,0.8573219,0.43464684,0.0,0.0,0.0105584115,0.03369321,0.02804397,0.0179118,0.009082884,0.034601413,0.0,0.0,0.030066535,0.0,0.024126202,0.13086633,0.29462755,0.410043,0.5209379,0.56264204,0.48991895,0.3483543,0.20189077,0.22632301,0.47689384,0.68443376,0.8053332,0.8339877,0.52630955,0.123288535,0.0,0.0,0.0,0.010197103,0.0015954673,0.015755564,0.009035744,0.022194259,0.0,0.0,0.011458628,0.0,0.0,0.059871115,0.17770153,0.28287008,0.39835268,0.51682293,0.5447473,0.46749306,0.41555905,0.4747432,0.67031455,0.7229161,0.52426004,0.29158682,0.14502749,0.0036932975,0.0,0.0,0.0,0.019568011,0.0,0.0,0.0,0.0,0.0009788424,0.0,0.0028378516,0.0,0.0,0.029330797,0.103935964,0.19101904,0.30522695,0.48060775,0.6058212,0.6977619,0.73382497,0.8462907,0.74863905,0.5519257,0.21447004,0.0,0.0060960203,0.023527324,0.0,0.0,0.0,0.022259519,0.0,0.004838556,0.0,0.0041566193,0.009490155,0.013273947,0.010599822,0.0,0.0,0.017004095,0.016526781,0.07462068,0.15432711,0.3070588,0.57173896,0.80790156,0.883711,0.9025288,0.6325442,0.31981504,0.07873589,0.0,0.0,0.026462696,0.0,0.0,0.0,0.030055687,0.022781484,0.032954156,0.0,0.014313258,0.007476844,0.019865923,0.0027165562,0.0064589307,0.0,0.0,0.0,0.04160414,0.15007755,0.2620681,0.6153824,0.8760998,0.87291783,0.6848906,0.34265018,0.025962673,0.0,0.0,0.0,0.039556183,0.03175865,0.014297597,0.0,0.033099413,0.039293148,0.060598277,0.008819632,0.03006889,0.018690392,0.014191389,0.0,0.005042866,0.0,0.0025885552,0.011331737,0.082743734,0.267436,0.38828075,0.7586658,0.956235,0.8114497,0.48046112,0.15020463,0.0,0.0,0.043631755,0.0,0.083060235,0.09416411,0.07455239,0.08452663,0.15974677,0.13841845,0.11290217,0.0012968183,0.021305077,0.021811053,0.009490125,0.0,0.0,0.0,0.057501577,0.12977071,0.22087818,0.44971782,0.5924423,0.94534516,1.0,0.7775234,0.34824458,0.06167113,0.0,0.0,0.08476679,0.0,0.13378645,0.13806458,0.096839204,0.12795168,0.23844275,0.18742955,0.14373179,0.012513727,0.020942532,0.024616294,0.011750288,0.0,0.0,0.0,0.12821306,0.24796906,0.35581934,0.6553564,0.79636544,1.0,1.0,0.7900794,0.25454056,0.0,0.0,0.0,0.10580717,0.024601594,0.18206128,0.202187,0.13097462,0.16652952,0.3135232,0.2366732,0.17827573,0.034835555,0.023638085,0.025051408,0.014656894,0.0,0.0,0.0074130446,0.2061153,0.34564808,0.44733244,0.8082447,0.9362837,1.0,1.0,0.77246296,0.16933423,0.0,0.0,0.0,0.18188027,0.15710235,0.32065684,0.336631,0.23053597,0.26079595,0.39559895,0.2830336,0.21039721,0.062239267,0.0333815,0.025208265,0.00288105,0.0,0.0,0.034121767,0.2231435,0.35161832,0.4414419,0.84708005,0.9572627,1.0,1.0,0.7110791,0.12139171,0.0,0.0,0.06892334,0.35397947,0.41194063,0.5591082,0.5346191,0.3779502,0.36112195,0.45528632,0.30677944,0.2326802,0.09504901,0.05378522,0.028043814],[0.0,0.0,0.024808541,0.07278954,0.24496393,0.3697879,0.5431401,0.69605696,0.7765998,0.6319348,0.51573384,0.4982834,0.5748585,0.7090358,0.8460347,0.9263356,0.843937,0.4658864,0.23549663,0.0,0.0,0.0,0.0,0.042530008,0.056913175,0.0378107,0.0,0.0,0.0,0.0,0.0,0.0199226,0.124175034,0.23605692,0.40452117,0.60478264,0.7132656,0.6240824,0.51420414,0.46694416,0.5339502,0.7084245,0.8312521,0.80708796,0.6264587,0.26515514,0.089005895,0.0,0.0,0.0,0.0,0.03674511,0.047772408,0.028548233,0.0,0.0,0.0,0.0,0.0,0.0,0.062716335,0.14883189,0.27894688,0.47085845,0.59587896,0.61706126,0.5830261,0.5838346,0.627697,0.7324178,0.6998012,0.49415815,0.23889455,0.07628285,0.035320386,0.026950255,0.019929647,0.0023639798,0.0,0.021489471,0.011826806,0.010146245,0.0,0.0,0.0,0.0,0.0,0.0,0.046501055,0.0823322,0.19708635,0.37317935,0.5306663,0.6447441,0.7163614,0.7906827,0.77967745,0.60998726,0.3914488,0.13993792,0.0055957735,0.010489434,0.03538595,0.051677227,0.05872573,0.0,0.0,0.009537466,0.0,0.008820064,0.0,0.0,0.005117774,0.0,0.0,0.0065399185,0.026957057,0.0,0.020765029,0.161993,0.41414338,0.6404857,0.8182764,0.85411906,0.7078431,0.39508545,0.15735762,0.05432395,0.014869839,0.018124335,0.025282227,0.042073928,0.056511357,0.017823055,0.0026085079,0.012382127,0.0,0.0,0.0,0.0,0.012852609,0.0031553954,0.0,0.014499299,0.026587829,0.0,0.0,0.13174209,0.42856348,0.6730419,0.86160815,0.7600186,0.47359085,0.11416824,0.0,0.0,0.013902433,0.015096307,0.033561707,0.038636096,0.0565397,0.03693278,0.03246413,0.009852715,0.0,0.0,0.0,0.0,0.018019669,0.005263895,0.0,0.00015072525,0.01709991,0.0,0.02247031,0.21856122,0.5451762,0.7423574,0.88105655,0.67809105,0.31295028,0.0,0.0,0.0,0.0033936054,0.01933685,0.06593174,0.06179826,0.08181575,0.10730308,0.121475995,0.07432811,0.031110615,0.0,0.0,0.0,0.018395714,0.007331468,0.0,0.011004545,0.053002737,0.04213725,0.14642435,0.38787842,0.73091024,0.85139436,0.91886944,0.652296,0.22736801,0.0,0.0,0.0,0.0,0.039806485,0.10325812,0.0660868,0.0823334,0.13901146,0.167416,0.106348455,0.05802603,0.0,0.0,0.0,0.024103247,0.025722913,0.0,0.035448074,0.10452144,0.13496667,0.26769933,0.5473837,0.90637857,0.96919715,0.9797079,0.68495816,0.19704863,0.0,0.0,0.0,0.0,0.058166437,0.15516636,0.0908543,0.09864574,0.16176029,0.20911658,0.1431134,0.08975503,0.010478333,0.0,0.0011988282,0.023981094,0.041511133,0.0,0.06589201,0.16360483,0.20218793,0.34476936,0.64345795,1.0,1.0,0.9811637,0.6816971,0.16170442,0.0,0.0,0.0,0.02703815,0.15202956,0.28485876,0.17523527,0.19243848,0.23614193,0.26474193,0.18160167,0.11597884,0.029892392,0.0,0.0024237484,0.016023703,0.06396314,0.014300756,0.08918972,0.18592498,0.19139649,0.32968372,0.6428155,1.0,1.0,0.88726157,0.6304642,0.14403206,0.0,0.0,0.0906986,0.2058908,0.32818535,0.46947503,0.31867498,0.30639476,0.3188883,0.30213034,0.21765396,0.13755324,0.05066946,0.0,0.0010169148],[0.0,0.002108559,0.03140708,0.07206483,0.16541475,0.2968599,0.49066877,0.640633,0.7876642,0.84118605,0.8552471,0.826485,0.8760514,0.9237937,0.8698525,0.8022489,0.5148305,0.23534727,0.038103424,0.017696753,0.0,0.03701917,0.05368164,0.0155368745,0.023041926,0.023553386,0.0,0.0,0.0,0.0,0.008391388,0.02169025,0.08860887,0.19067855,0.38147086,0.5691768,0.72983336,0.79866767,0.79281,0.7811325,0.7965542,0.855167,0.78257555,0.6411689,0.32843912,0.08387372,0.0,0.011318088,0.0,0.0064639226,0.01608137,0.016514264,0.010829911,0.01939299,0.0,0.0,0.0,0.0,0.0,0.008199342,0.05075618,0.12741122,0.29122615,0.4659645,0.6249885,0.7645954,0.8039855,0.8543916,0.86169773,0.7928951,0.5816375,0.341771,0.10108812,0.0086061135,0.053096786,0.0018745512,0.0,0.004244566,0.0,0.0,0.0,0.0063150898,0.0,0.0,0.0,0.0,0.0,0.00022105873,0.043653965,0.08457957,0.23062383,0.39820582,0.56885666,0.7520425,0.8715615,0.93358195,0.84176546,0.52575934,0.20844015,0.01888059,0.009155661,0.029679209,0.122444406,0.0,0.026420899,0.0,0.0,0.0,0.0,0.0143710375,0.0,0.0,0.019375443,0.0,0.0,0.00215438,0.028708689,0.0059350133,0.093912065,0.26245195,0.5141914,0.7637792,0.90403295,0.8018389,0.5934258,0.20847633,0.034483492,0.028929561,0.07449459,0.040468164,0.08598676,0.006241232,0.02438794,0.015579931,0.0,0.0024698377,0.0,0.016627334,0.0,0.004027277,0.03244763,0.0,0.0044867694,0.022117876,0.034912147,0.0,0.060963027,0.22879654,0.5303814,0.76973134,0.8520028,0.60007393,0.32775772,0.0,0.0,0.05637853,0.10310322,0.030996725,0.032789268,0.025117867,0.019466199,0.053155065,0.010812424,0.016316809,0.015612066,0.008310318,0.0,0.014774606,0.042785533,0.0,0.014690243,0.015687652,0.041066512,0.005050108,0.10176252,0.28332165,0.588923,0.78762144,0.79829717,0.47372353,0.16603965,0.0,0.0,0.07517421,0.1171251,0.052831285,0.046583787,0.03427104,0.03549148,0.10619956,0.057681262,0.06583651,0.029740468,0.0,0.0,0.012499072,0.046112843,0.0,0.016905583,0.023861334,0.083252236,0.07342394,0.21907128,0.3953138,0.6813415,0.8216815,0.7793851,0.4079635,0.08006036,0.0,0.0,0.0867486,0.12452324,0.07613983,0.060380593,0.029593661,0.04954268,0.14448597,0.083829455,0.100702375,0.045810714,0.0071274266,0.0,0.0050186813,0.05612161,0.0,0.030428655,0.039969794,0.13380872,0.1486127,0.318516,0.49566424,0.770367,0.85130805,0.80057776,0.40566945,0.08204238,0.0,0.0,0.08694079,0.1221115,0.101724446,0.07049613,0.03309369,0.072581306,0.17475969,0.11013182,0.1342714,0.06452686,0.019970842,0.0,0.0,0.062411547,0.0099221915,0.037537687,0.059046447,0.17090625,0.19646916,0.35990292,0.5305568,0.8094599,0.8289876,0.7683746,0.37995502,0.08500863,0.0,0.0,0.09231451,0.14872676,0.1835934,0.116424,0.05979158,0.112366036,0.21179134,0.13005002,0.15726784,0.07788545,0.035077594,0.0,0.0,0.06145151,0.032184243,0.04014513,0.073888205,0.16159067,0.16642158,0.3084305,0.46624994,0.73992306,0.7153614,0.6698122,0.3552367,0.12179822,0.0,0.0,0.1411891,0.26047963,0.31712228,0.22164533,0.11397039,0.1535816,0.21995947,0.12169611,0.17495099,0.08320704,0.05133874,0.0,0.0],[0.0,0.0,0.015504025,0.027206779,0.07547897,0.15054488,0.18807049,0.34117967,0.5759709,0.68330586,0.80246234,0.7231235,0.6777331,0.5732673,0.49332857,0.30804962,0.14385356,0.0,0.0,0.0,0.0,0.022145204,0.0,0.0,0.014453404,0.02554813,0.020190738,0.0,0.0,0.0,0.0014313459,0.0113636255,0.042753026,0.10290251,0.14494443,0.30693763,0.549027,0.6619248,0.7694094,0.7085584,0.6593695,0.5634617,0.45642775,0.25670552,0.12574475,0.0,0.0,0.0,0.0,0.02538,0.0043668,0.0,0.019770905,0.014916606,0.01145713,0.004899651,0.0,0.0,0.0,0.008539595,0.036395654,0.08805057,0.11693492,0.25892296,0.4968649,0.65099305,0.7531508,0.7200829,0.6805438,0.5225797,0.3372535,0.13048278,0.070259586,0.0,0.0,0.0,0.012312718,0.0420141,0.021755248,0.0,0.0059074387,0.0,0.0,0.0,0.0,0.0,0.0,0.0012738854,0.022360928,0.08318436,0.11911401,0.24632686,0.4408474,0.61929965,0.71679157,0.6872733,0.542055,0.21889372,0.0,0.0,0.0,0.017366387,0.0,0.0,0.00619594,0.026254363,0.017579332,0.0,0.020485356,0.0030868798,0.018657714,0.004139513,0.0,0.0,0.009232543,0.0010642707,0.0044182986,0.0,0.037467018,0.20514977,0.41361475,0.5715879,0.62528116,0.52892125,0.32232982,0.054030962,0.0,0.0,0.024360701,0.059957363,0.013913959,0.0,0.0,0.009216443,0.0,0.0,0.009094179,0.010035507,0.020652838,0.00657434,0.0,0.0,0.004993543,0.00555405,0.015588425,0.0,0.023040704,0.1667904,0.38672358,0.5572438,0.53503376,0.33487487,0.11001806,0.0,0.0,0.010516278,0.015711635,0.025338337,0.0,0.0,0.0,0.010891207,0.00089876354,0.0,0.0,0.004142463,0.0,0.0,0.0031992942,0.0,0.0036127418,0.0,0.0142956,0.0,0.033547558,0.15397717,0.38083506,0.5444036,0.47839457,0.25237954,0.0,0.0,0.0,0.018758148,0.007996023,0.0,0.0,0.0,0.0,0.011425257,0.009758785,0.0,0.0,0.0,0.0,0.0,0.015349224,0.0,0.010692842,0.0,0.021026596,0.0,0.081159055,0.19750023,0.41417348,0.57358485,0.46793282,0.24630068,0.0,0.0,0.00066657364,0.053440295,0.027201712,0.0,0.0,0.0,0.0,0.012141831,0.02867563,0.0,0.0023285002,0.00014474988,0.0,0.0,0.026352309,0.0040532947,0.01870443,0.0,0.039943166,0.020446554,0.12655558,0.2226648,0.43366402,0.6079519,0.49954593,0.2865656,0.0,0.0,0.023344979,0.080050126,0.047736146,0.008191466,0.0,0.0,0.0,0.020591669,0.05033809,0.0016245097,0.0038029552,0.0020685643,0.0,0.0,0.034236223,0.010615721,0.026710711,0.0,0.06809814,0.055174783,0.15104699,0.21353509,0.42876732,0.60092896,0.4942031,0.31111747,0.0,0.0,0.059738867,0.09719463,0.07452156,0.043014303,0.0,0.0,0.0,0.031144723,0.06937067,0.0011892319,0.0,0.002033189,0.0,0.0,0.035954364,0.019567698,0.029839724,0.0,0.06353061,0.042816155,0.13322513,0.18182006,0.3823912,0.495569,0.41699743,0.30268377,0.044235863,0.0,0.098916054,0.110224485,0.15216325,0.15984657,0.104409255,0.028835319,0.0,0.01429835,0.060422286,0.0009983182,0.0,0.00981161,0.0,0.0],[0.0,0.0,0.0055051744,0.038837396,0.015395924,0.036107637,0.05061628,0.034581766,0.111599386,0.16552573,0.20747945,0.19466904,0.12305323,0.0038914233,0.0,0.0,0.0,0.0028196126,0.010222524,0.0,0.04621552,0.0,0.0,0.0,0.007964395,0.017512843,0.015586399,0.01195664,0.0,0.0,0.0,0.023383602,0.012606889,0.016283184,0.029486537,0.02717495,0.12345551,0.19066766,0.2327524,0.2279274,0.18054633,0.09198103,0.04696253,0.0,0.0,0.008831762,0.033319555,0.0,0.0631759,0.0019041896,0.0,0.0,0.0,0.025500998,0.014311455,0.02005934,0.0,0.0,0.0,0.0,0.018928409,0.013264351,0.0084019825,0.020681322,0.12867768,0.25042522,0.2824374,0.27248347,0.25538272,0.14191967,0.043575168,0.0,0.0,0.0077475086,0.021570496,0.017168432,0.06560596,0.020753756,0.0,0.0,0.0,0.024228148,0.0053555667,0.005727008,0.0,0.0,0.0,0.0,0.015785187,0.036480084,0.028142303,0.08724347,0.18115059,0.33346212,0.32816237,0.26917237,0.18986443,0.0,0.0,0.0,0.01379025,0.04557056,0.0,0.011956416,0.018985733,0.022292867,0.0,0.0,0.0,0.023338735,0.0051011443,0.0109601915,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11220246,0.21501939,0.33787492,0.27604583,0.17723587,0.076969214,0.0,0.0,0.012156695,0.045251094,0.05582937,0.0,0.006678544,0.0,0.015040614,0.0,0.0,0.0014199913,0.023938164,0.0090415925,0.013950452,0.0,0.0,0.0,0.0,0.009144686,0.0,0.0,0.10254243,0.20866367,0.34562266,0.20056969,0.034816653,0.0,0.0,0.0,0.052324653,0.03770666,0.0033698976,0.0018600821,0.003834322,0.0,0.02528096,0.0,0.0,0.029650562,0.016947716,0.011281349,0.016988724,0.0,0.0,0.0,0.0,0.022805892,0.0,0.0,0.10199806,0.20430712,0.3681566,0.21393232,0.0,0.0,0.0,0.024450444,0.050406836,0.015169814,0.0,0.0,0.0,0.002588898,0.041956246,0.0061807334,0.020893976,0.05521944,0.0,0.002113521,0.0061236843,0.004483059,0.0,0.0,0.010720678,0.04954125,0.0,0.030312143,0.12849471,0.22928198,0.4093083,0.25059465,0.0,0.0,0.0,0.06752508,0.07521562,0.01628615,0.0,0.0,0.0,0.0,0.051610507,0.024286963,0.020494796,0.07632339,0.0070492327,0.0,0.0,0.017650165,0.0,0.0,0.035475478,0.08705066,0.0038710684,0.06560549,0.14795962,0.24239746,0.4690354,0.33788663,0.032771252,0.0,0.017943293,0.10726774,0.1017773,0.028644867,0.0,0.0,0.0,0.0,0.06935985,0.0428394,0.016766213,0.093271375,0.010913864,0.0,0.0,0.027239278,0.0,0.0,0.07347703,0.12865603,0.037745804,0.09219864,0.13637273,0.23305614,0.48622322,0.39194918,0.07677691,0.0,0.04478678,0.14007923,0.113263294,0.039323993,0.0,0.0,0.014642231,0.017870955,0.08284728,0.050471157,0.0,0.09659017,0.01141756,0.0,0.0,0.037960574,0.0,0.0,0.08050007,0.12415329,0.028063253,0.106633484,0.1087051,0.20582196,0.40830892,0.36566526,0.1051013,0.0,0.088227555,0.17358258,0.1393587,0.12814125,0.094494686,0.085260466,0.056661636,0.019065052,0.06025037,0.028728679,0.0,0.08654886,0.0062609687,0.0,0.0],[0.010755882,0.004579544,0.0022799373,0.0,0.004154235,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0021326244,0.0,0.0,0.020256512,0.0,0.0,0.0,0.024121866,0.044119753,0.012804769,0.0,0.008529879,0.0,0.0,0.0,0.00828588,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011030972,0.0,0.005019173,0.016394302,0.0,0.0,0.0,0.0098664835,0.03191577,0.0037087947,0.0,0.007186115,0.004934266,0.0,0.0,0.0,0.0,0.0,0.0,0.01775562,0.0,0.0,0.008546509,0.0017309487,0.02898062,0.0,0.0,0.0,0.02591692,0.0,0.003373623,0.021487728,0.0,0.0,0.0,0.0,0.0069945827,0.0,0.0,0.0017060041,0.0,0.0,0.0,0.0,0.0,0.0,0.045560442,0.10475589,0.077782914,0.016136236,0.04733379,0.0,0.0,0.0,0.0,0.0022170395,0.04225479,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.045899943,0.084068015,0.08449541,0.039197944,0.06602011,0.0,0.0,0.0,0.0,0.003708765,0.059301473,0.00630036,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0062442124,0.0,0.0,0.0046461076,0.0,0.0,0.048343785,0.056938395,0.06108775,0.0,0.021302633,0.0,0.0,0.009993352,0.004616052,0.0,0.042458326,0.020755507,0.0037834793,0.0,0.0,0.0015766174,0.0,0.016683362,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049362235,0.047654495,0.03654048,0.0,0.00471735,0.0,0.0054287612,0.019367278,0.0,0.0,0.0005477518,0.0,0.0,0.0,0.0,0.008405089,0.0,0.014665335,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.042286694,0.042724445,0.02392131,0.0,0.014007881,0.03559666,0.033807278,0.05057139,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01459495,0.0,0.0024193376,0.0,0.0,0.0,0.0,0.006764129,0.0,0.0,0.0013298392,0.0,0.0,0.049004786,0.04619752,0.04381367,0.012217596,0.061410345,0.092265815,0.045257546,0.08202761,0.008891791,0.0,0.0,0.0,0.0,0.0,0.0,0.019218348,0.0,0.0,0.0,0.0,0.0,0.0,0.003780529,0.0,0.0,0.023668729,0.024014018,0.0,0.05145961,0.040325895,0.06634659,0.05916836,0.097656645,0.12963209,0.04657764,0.10572958,0.03399609,0.0,0.0,0.0066628456,0.0,0.0,0.0,0.021215864,0.0,0.0,0.0,0.0,0.0,0.0,0.010556482,0.0,0.0,0.028661385,0.04393953,0.014597468,0.04240015,0.022905461,0.07808541,0.099733785,0.11782341,0.14167327,0.03385313,0.12774654,0.083005466,0.056671485,0.05367084,0.08040238,0.025351688,0.0,0.0,0.0004130453,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0069879666,0.0,0.039725304,0.01531969,0.0,0.0,0.0,0.02268871,0.017312221,0.0,0.0,0.0,0.0,0.0,0.0,0.014349073,0.01845868,0.0,0.030859038,0.0025131553,0.0,0.0049802363,0.038345613,0.0,0.005015373,0.012471169,0.0,0.0,0.0014588684,0.0,0.03987678,0.016858146,0.0,0.0,0.0,0.027973242,0.018350236,0.0,0.0,0.02370409,0.0,0.0,0.025777698,0.028397165,0.00919088,0.0,0.014406912,0.0,0.0045134276,0.0046040565,0.04968247,0.0,0.00094795227,0.017208092,0.0,0.007808037,0.0,0.0,0.026472993,0.0,0.0,0.0,0.0,0.029024191,0.009185217,0.0,0.0,0.061322086,0.0,0.0,0.05046981,0.020812586,0.0,0.0053911805,0.03429059,0.011296742,0.007256493,0.008176796,0.05214034,0.0,0.0,0.01601582,0.0,0.0,0.0,0.0,0.010164313,0.0,0.009627648,0.030011244,0.056998394,0.0200039,0.020441815,0.0,0.0,0.02822049,0.029140688,0.0,0.05214399,0.0,0.0,0.0,0.037817717,0.004698381,0.0,0.0,0.0146835,0.0,0.0,0.015757442,0.0,0.0,0.0,0.0,0.0,0.0,0.0044077784,0.034502447,0.04479462,0.004707262,0.018344529,0.0,0.0,0.0,0.022083454,0.0,0.0050924867,0.0,0.0,0.0,0.026007228,0.00062039495,0.0,0.0,0.01607731,0.0,0.0,0.012787335,0.0,0.012288749,0.00013159215,0.025737219,0.0,0.0,0.008930847,0.040235057,0.019814037,0.0,0.0,0.0,0.0,0.0,0.024034217,0.0,0.0,0.006857775,0.0013387352,0.0,0.01536791,0.013146505,0.0,0.002490133,0.021346651,0.009190425,0.0,0.0,0.0,0.021128103,0.0077790394,0.0253288,0.0,0.0,0.0,0.03777671,0.027918383,0.007909723,0.0,0.0004130751,0.018175393,0.0,0.009069309,0.0,0.0,0.0,0.0,0.0,0.005097538,0.01413133,0.0,0.0,0.011037283,0.011378214,0.0,0.0,0.0041029155,0.036907874,0.01907444,0.025203086,0.0,0.0,0.0,0.038517244,0.03897196,0.015049659,0.0013209134,0.028204538,0.040416315,0.017747015,0.003533706,0.0,0.0,0.0,0.0,0.0,0.0030079186,0.020600796,0.0,0.0035268664,0.022705972,0.032942273,0.0,0.0,0.012818269,0.061284393,0.043819554,0.034090243,0.006390564,0.0,0.0,0.05604662,0.058621623,0.03976915,0.043967724,0.067705736,0.057825454,0.03760928,0.020671695,0.0,0.0,0.0,0.0,0.0,0.0,0.015866555,0.0028277487,0.011623323,0.032100543,0.053079046,0.0060442686,0.0,0.015208304,0.074080646,0.061030596,0.03975489,0.019427165,0.0,0.0,0.06793292,0.072615616,0.06676081,0.0777417,0.08965652,0.06040691,0.052704267,0.05055365,0.0,0.0,0.0,0.0,0.0,0.0022634566,0.0024665445,0.00044035912,0.020771801,0.044354536,0.06600983,0.021466717,0.0,0.027392745,0.09838548,0.07940225,0.04235904,0.030464679,0.0,0.0,0.04834374,0.06822382,0.09350209,0.096364625,0.09346789,0.056025088,0.06405997,0.06948216,0.0,0.0,0.005870141,0.0,0.0,0.0,0.0,0.0,0.022987336,0.049463257,0.06960581,0.023787826,0.0],[0.0,0.0,0.00393185,0.0,0.04878255,0.017150648,0.0,0.0,0.0,0.0066494048,0.02890125,0.012825824,0.010303423,0.0199821,0.0,0.0,0.0,0.03896752,0.011681065,0.0,0.0,0.0,0.0,0.0,0.0044340193,0.0,0.0,0.0,0.0,0.0,0.003682822,0.0,0.03960231,0.008822955,0.0,0.0,0.0,0.00041124225,0.015038051,0.011928387,0.011412874,0.035619304,0.014347196,0.0,0.0,0.03277073,0.006733708,0.0,0.0,0.0,0.0044624507,0.0,0.0,0.0,0.0,0.0,0.0041100383,0.0,0.00095939636,0.0,0.022798583,0.0,0.0,0.0,0.0,0.0,0.0,0.00092481077,0.012931667,0.038205996,0.0110237375,0.0,0.0,0.018176608,0.005461246,0.0,0.0,0.009677842,0.031705417,0.009821162,0.0,0.0,0.0,0.0,0.007519178,0.0,0.0,0.0,0.018348724,0.0,0.0,0.016131774,0.012757622,0.0,0.0,0.0,0.0,0.001643166,0.0063550323,0.0,0.0,0.0,0.0,0.017861433,0.0072007477,0.015946195,0.031545006,0.004897505,0.0,0.0,0.0,0.0,0.007604204,0.0,0.0,0.0,0.01045388,0.0,0.0,0.0,0.0013799816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022448175,0.0046102405,0.0,0.0001822263,0.0,0.0,0.0,0.0,0.0,0.008493945,0.0,0.009958945,0.0037347227,0.0,0.0,0.0,0.0,0.0,0.0,0.0033501089,0.003203243,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022641852,0.009734556,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0068607107,0.0061551407,0.013132937,0.0019335002,0.0,0.0,0.0,0.0,0.0,0.009373657,0.029786162,0.048126385,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018616267,0.019385338,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0078128725,0.010554172,0.013238497,0.00015161932,0.0,0.0,0.0,0.0,0.0,0.013244338,0.044941634,0.062762834,0.0049467385,0.0,0.0,0.0,0.0,0.0,0.0,0.021657914,0.030305192,0.0022429526,0.0,0.0,0.0010140389,0.0,0.0,0.0,0.012504168,0.023414575,0.01839608,0.0001296103,0.0,0.0,0.0,0.0,0.0,0.019293748,0.057261094,0.074386746,0.021355718,0.0,0.0,0.0,0.0,0.0,0.0,0.022900708,0.02964829,0.009517662,0.0,0.0,0.007525496,0.0,0.0,0.0,0.01674416,0.039040342,0.02971495,0.0022674948,0.0,0.0,0.0,0.0,0.0,0.01912532,0.062052123,0.08116913,0.03409505,0.013860673,0.0,0.0,0.0,0.006397523,0.0,0.020718232,0.02323521,0.014854424,0.0,0.0,0.017298102,0.0,0.0,0.0,0.027755104,0.06067823,0.049161732,0.007432379,0.0,0.0,0.0,0.0055740923,0.0,0.0198896,0.066445835,0.08949511,0.052009486,0.031818353,0.006014958,0.0,0.0,0.013653249,0.0,0.023385696,0.027978495,0.024817102,0.0,0.0,0.03233642,0.0,0.0,0.0],[0.031144157,0.00976488,0.015375756,0.00015936792,0.015826285,0.0,0.014445759,0.0,0.0012430102,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028250366,0.0,0.0,0.0,0.0,0.04308968,0.02434121,0.007608928,0.0,0.008604988,0.0024264902,0.014297135,0.028332978,0.0,0.008614935,0.004514277,0.0083464235,0.0,0.011389859,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025834575,0.0,0.0,0.0,0.0,0.023915559,0.010624096,0.0029762536,0.0,0.010559425,0.0051198304,0.007222317,0.019142434,0.0,0.00075019896,0.007971793,0.0022632629,0.0,0.008152425,0.0,0.0026727915,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.005319461,0.0,0.0,0.0,0.0,0.027205803,0.011179864,0.0,0.0,0.0021437109,0.003263101,0.002196446,0.018567838,0.0,0.0077461973,0.021848254,0.00845205,0.0,0.011007935,0.0,0.0018367767,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006317869,0.0,0.0,0.029692464,0.008119531,0.0,0.0,0.008872926,0.0064995885,0.0,0.020631865,0.0,0.0025283098,0.023678958,0.010087103,0.0,0.018103264,0.0,0.0,0.00043573976,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.024579927,0.0,0.0,0.015893064,0.0,0.0,0.0067372248,0.013145387,0.0050931424,0.0,0.02129732,0.0,0.0,0.019207567,0.00022648275,0.0,0.026571669,0.0,0.0014202744,0.018070348,0.0,0.0,0.0,0.0,0.009191781,0.0,0.0,0.0,0.03671226,0.0,0.0,0.0008702278,0.0,0.0,0.008714311,0.0072209015,0.0,0.0,0.024802111,0.0020072758,0.0,0.0,0.0,0.0,0.02970627,0.0,0.025590196,0.06041851,0.0,0.0018540472,0.01871302,0.0,0.017775573,0.0,0.0,0.0080221,0.04279445,0.0,0.0,0.0,0.0,0.0,0.009609722,0.009736814,0.0,0.0,0.031004958,0.0063417777,0.0,0.0,0.0,0.0,0.025622256,0.0,0.054872945,0.09137257,0.008387096,0.0,0.022497244,0.0,0.024215758,0.0,0.0,0.012274295,0.04381015,0.0,0.0,0.0,0.0,0.0,0.018021882,0.025987104,0.0,0.0,0.034171157,0.008207865,0.0,0.0,0.0,0.0,0.025558643,0.00409925,0.06358586,0.10914528,0.0,0.0,0.019452058,0.0,0.030119337,0.0,0.0,0.011523217,0.038527273,0.0,0.0,0.0,0.0,0.004941061,0.021871023,0.03770203,0.0,0.0,0.040089816,0.017564125,0.0,0.0,0.0,0.0,0.00983315,0.005846508,0.06652202,0.13226013,0.0,0.0,0.016315438,0.0,0.041011535,0.0,0.0,0.015303284,0.0370899,0.0,0.0,0.0,0.0,0.013468146,0.027642012,0.05328002,0.0,0.0,0.0422325,0.031344548,0.0,0.0,0.0,0.0,0.0,0.00016231835,0.06082152,0.13134609,0.0011932999,0.0,0.011659019,0.0,0.049995378,0.003819123,0.0,0.0126471,0.033241086,0.0,0.0,0.0,0.0,0.021534115,0.031576313,0.06881024,0.0,0.0],[0.022549294,0.0,0.0037394315,0.0,0.02524624,0.0,0.014420606,0.0,0.0,0.0,0.050112434,0.0,0.0,0.0,0.0049322993,0.0,0.034249894,0.00683105,0.0,0.0,0.017913021,0.009204119,0.014118426,0.0,0.001537323,0.003025502,0.0,0.0,0.022353247,0.0,0.0,0.0,0.023731627,0.0,0.010827929,0.0,0.0,0.0,0.030080855,0.0,0.015460543,0.007785544,0.01832974,0.0,0.009136595,0.0,0.0,0.0,0.02078446,0.013687685,0.0076605305,0.0,0.0032081902,0.0,0.0013526827,0.0,0.010911405,0.0,0.0,0.0,0.0249684,0.0,0.0045023113,0.0,0.0,0.0,0.0,0.0,0.017591067,0.0030315816,0.013538346,0.0,0.0,0.004972607,0.0,0.0,0.02333127,0.016808331,0.011299752,0.0,0.0,0.0,0.008370839,0.0,0.001921013,0.0,0.0,0.005267963,0.02862478,0.0,0.006530851,0.0,0.0,0.0,0.0,0.0,0.021743722,0.004706517,0.01130496,0.0,0.0,0.022890039,0.0,0.0,0.00500378,0.014213048,0.01787673,0.0,0.0,0.0,0.014839031,0.0,0.0,0.013902381,0.0,0.022120677,0.030551098,0.0,0.008099772,0.0,0.0,0.0,0.0,0.0,0.03378719,0.015999258,0.019459344,0.0,0.0,0.030020848,0.025102295,0.0,0.0,0.005541742,0.01822035,0.01110182,0.01325576,0.0,0.015836447,0.0,0.0,0.027015485,0.00054743886,0.024830267,0.012233973,0.0,0.0104027465,0.0,0.0,0.0,0.0,0.007442467,0.032575928,0.019840367,0.019318476,0.0,0.0,0.01916065,0.030366085,0.02627641,0.021890715,0.036882482,0.020658605,0.017246924,0.022045739,0.0,0.0031162053,0.0,0.0,0.017932668,0.0,0.0,0.0,0.0,0.016829193,0.0,0.035563096,0.01042641,0.0,0.026519306,0.017292209,0.0014279187,0.0108878985,0.0,0.0,0.009225249,0.013294339,0.0,0.0,0.027721569,0.0077258795,0.010870047,0.037435383,0.0,0.0,0.0,0.0,0.009356163,0.0,0.0,0.002294317,0.0,0.025045477,0.0,0.08196008,0.019239374,0.005341634,0.026213355,0.015064098,0.0,0.005299598,0.0,0.0,0.0,0.0,0.0,0.0,0.018408403,0.0,0.016885936,0.056058027,0.007530503,0.0,0.0,0.0,0.0,0.0,0.0,0.0025901347,0.0,0.03142084,0.0,0.109734,0.017378114,0.0,0.027914688,0.023431651,0.0,0.0019008517,0.0,0.0,0.0,0.0,0.0,0.0,0.00869444,0.0,0.017855838,0.063647404,0.013043277,0.004104808,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018487878,0.0,0.1393489,0.027440563,0.0,0.027690746,0.037844434,0.0,0.005358964,0.0,0.0,0.0,0.0,0.0,0.0,0.007865861,0.0,0.025016665,0.07780716,0.020228863,0.013636038,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1424291,0.03199309,0.0016676635,0.029023528,0.048517995,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00654307,0.0,0.031001478,0.09031227,0.024392858,0.014198996,0.0],[0.017889053,0.016139723,0.04720547,0.036286555,0.0333241,0.020240173,0.003744945,0.0,0.043679513,0.010817565,0.030300118,0.016836755,0.036879666,0.0,0.0,0.020962104,0.029006764,0.0,0.007608339,0.030972838,0.06070462,0.026526384,0.038370587,0.0,0.013625532,0.0,0.000039070845,0.0053800344,0.015565835,0.00798557,0.03261759,0.023416057,0.025487855,0.027685225,0.009114608,0.0,0.06232871,0.001222372,0.029703863,0.02361688,0.05351772,0.0,0.0037978739,0.0,0.018258974,0.0,0.012569211,0.018198289,0.054870144,0.026990347,0.034945652,0.0013923794,0.0115316585,0.0,0.0042525083,0.0,0.008373782,0.003124863,0.018338352,0.016493045,0.020761184,0.036538795,0.010516137,0.0,0.06597893,0.0,0.01905176,0.01696083,0.05475641,0.0,0.0045415014,0.0,0.031133302,0.0,0.009889312,0.0193742,0.05117944,0.024990879,0.03333597,0.0,0.010166772,0.0,0.021771424,0.0,0.0,0.00738208,0.021600716,0.02852755,0.020678215,0.052633137,0.019499272,0.0,0.04647492,0.0,0.0,0.0,0.023651496,0.0,0.0040133595,0.0,0.04602506,0.016432948,0.023209535,0.031019203,0.034016922,0.027133927,0.04976622,0.0015310198,0.013095528,0.0,0.02438835,0.0,0.0,0.0,0.029654153,0.04378005,0.020541973,0.060132362,0.030638076,0.0,0.029932626,0.0,0.0,0.0,0.019333132,0.0,0.011393115,0.0,0.031892605,0.04158239,0.015902534,0.05289162,0.045206346,0.04569473,0.05497978,0.007272139,0.02387859,0.0048455596,0.02009844,0.0,0.0,0.0,0.031734847,0.044769354,0.0065663904,0.067491844,0.036131553,0.0,0.023239747,0.0,0.021200255,0.0,0.025145158,0.0,0.015351877,0.0,0.007784739,0.03789264,0.0,0.08308919,0.103873245,0.11407022,0.058126695,0.00447236,0.03321428,0.0,0.012835808,0.0,0.0,0.0,0.023829632,0.02320037,0.0,0.06626271,0.036050647,0.015585877,0.04129632,0.0,0.044509657,0.0,0.041919135,0.0,0.021509185,0.0,0.014525719,0.03659211,0.0,0.025069416,0.07310623,0.12222518,0.031233609,0.007017024,0.05300299,0.0025120527,0.019491859,0.015727043,0.0,0.0,0.016072512,0.028252125,0.005814187,0.063382626,0.03945099,0.050509833,0.08616145,0.0,0.05232469,0.0,0.0626006,0.0,0.02535434,0.0,0.010622628,0.01832053,0.0,0.002410233,0.050828137,0.11871629,0.032321297,0.009444259,0.07253236,0.014882937,0.035666242,0.01905778,0.0,0.0,0.0085821,0.030027486,0.004786521,0.054631002,0.04112915,0.07224074,0.12701514,0.0,0.03979539,0.0019924194,0.07412146,0.0,0.0261698,0.0,0.0070410892,0.00012229383,0.0,0.0,0.04382074,0.10078432,0.028667547,0.0032514632,0.088631615,0.021462984,0.049405463,0.015862577,0.0,0.0,0.007828541,0.023089536,0.0,0.0257435,0.03510829,0.09170177,0.16712184,0.0,0.020414814,0.012663804,0.088877335,0.0058862343,0.02305425,0.0,0.0,0.0,0.0,0.0,0.04046554,0.08561678,0.02714312,0.008130506,0.108199365,0.025616951,0.06537783,0.018581927,0.0,0.0,0.005746089,0.011354029,0.0,0.0,0.036276817,0.09641584,0.16721524,0.022542708,0.026851736,0.035756618,0.092829205,0.0019631833,0.025566049,0.0,0.009121269,0.0,0.0,0.0,0.025736518,0.07695097,0.028996818,0.017142795,0.13044792,0.023227192,0.070188835,0.02583532],[0.0,0.03523922,0.017035335,0.0,0.011511333,0.0054273307,0.026908167,0.017413303,0.028907157,0.057903394,0.03811709,0.037691154,0.011832118,0.043079615,0.0015363395,0.0,0.030428886,0.034177713,0.08076069,0.054623947,0.11425306,0.10288335,0.039599337,0.006262526,0.030969776,0.0,0.0,0.0012969673,0.0,0.02451834,0.007439077,0.0,0.0047626942,0.014207333,0.031995684,0.015415154,0.0238944,0.059011243,0.038568735,0.039864734,0.0036867708,0.036220573,0.0030335486,0.0,0.016983904,0.018274695,0.05347591,0.030050635,0.10426643,0.09399296,0.032815106,0.0,0.027321652,0.0,0.0,0.0,0.0,0.029093683,0.024580255,0.0,0.011991434,0.034191832,0.043002054,0.0070234835,0.016416587,0.04779464,0.041527778,0.048618406,0.007324174,0.033794828,0.022966705,0.0,0.0,0.0,0.042744614,0.04618974,0.11526257,0.09702584,0.028195284,0.0,0.03092482,0.0,0.0,0.0,0.0,0.033900633,0.031197548,0.004183233,0.027104877,0.053463206,0.050619468,0.00028166175,0.0032996237,0.0038521588,0.0035636127,0.018867083,0.010137163,0.019942783,0.033135436,0.0,0.0,0.0,0.026039198,0.06574166,0.13330899,0.10613012,0.052430756,0.0,0.020623624,0.004850313,0.0,0.0,0.0,0.026313946,0.016640313,0.0,0.031718865,0.05871336,0.056730837,0.0,0.0,0.0,0.0,0.011761636,0.019732624,0.005486831,0.018491767,0.0,0.0,0.0,0.035006978,0.08888632,0.14736354,0.09810175,0.06501942,0.0,0.00710205,0.017331049,0.0,0.0,0.0,0.017857768,0.0013256967,0.0,0.037237898,0.06828413,0.06580367,0.0011966228,0.0,0.0,0.008251786,0.011683337,0.026898794,0.03082078,0.02437935,0.019751757,0.0,0.0,0.018602408,0.16649821,0.2400209,0.15132374,0.066498406,0.0,0.0056711584,0.021721587,0.0,0.0,0.0,0.0033584088,0.0,0.0,0.06250975,0.089716025,0.08856165,0.011153959,0.0,0.007549271,0.023504354,0.005866632,0.042398147,0.07272757,0.05352895,0.07101372,0.03152679,0.0,0.0,0.17635426,0.24671263,0.15963383,0.05664047,0.0,0.011588089,0.043510735,0.0,0.0,0.0,0.0,0.0,0.0,0.09539208,0.10439603,0.108725436,0.027849108,0.026225746,0.036318906,0.046808638,0.016795404,0.060803063,0.09360954,0.07689476,0.08909398,0.047439545,0.0,0.0,0.15144671,0.22434813,0.15877452,0.054409675,0.0,0.021083675,0.047340713,0.0,0.0,0.0,0.0,0.0,0.0,0.09984326,0.10153546,0.12349582,0.049601533,0.05760044,0.067906864,0.0758408,0.02271495,0.069066584,0.087760955,0.074577674,0.098681435,0.054665685,0.0,0.0,0.12572077,0.19930169,0.13995539,0.043161377,0.0,0.029132284,0.04419796,0.0,0.0,0.0,0.0,0.0,0.0,0.07997423,0.08440712,0.12654366,0.07514885,0.093110174,0.10866055,0.10890546,0.025092326,0.07594531,0.084102206,0.07017556,0.10105906,0.04304125,0.0,0.0,0.11264828,0.18091482,0.116280496,0.02550327,0.0,0.03804396,0.039590158,0.0,0.0,0.0,0.0,0.0,0.0,0.060551688,0.06916611,0.12497508,0.09698412,0.12285596,0.13873392,0.14809969,0.05524791,0.099687286,0.10762795,0.09724824,0.11574448,0.065605365,0.0,0.0,0.098750666,0.15592526,0.09717693,0.024569884,0.0,0.056080133,0.038918637,0.0,0.0],[0.0,0.0,0.016848989,0.0,0.0,0.0,0.0,0.0096643865,0.022236489,0.04053256,0.046834715,0.04471516,0.112346366,0.20904839,0.22726193,0.2722548,0.36846435,0.4115312,0.38844234,0.334149,0.2762401,0.2310951,0.10337075,0.044391967,0.015976727,0.0,0.0,0.0,0.0,0.0,0.008286044,0.0,0.0,0.0,0.0,0.0,0.020486936,0.029475093,0.036009416,0.022576272,0.09263977,0.13593228,0.14286456,0.21197823,0.28106076,0.35617536,0.33569497,0.29535478,0.2561141,0.18659063,0.10083918,0.044710502,0.017573833,0.0,0.0,0.0,0.0,0.005586013,0.0133515075,0.00066670775,0.0,0.0,0.0,0.0,0.0143980235,0.036427416,0.030348383,0.018599585,0.05583769,0.07204364,0.079789706,0.12482732,0.15516777,0.25969735,0.27579728,0.2759116,0.2641681,0.17623062,0.12112152,0.03656756,0.028047748,0.0,0.0,0.0,0.0,0.01893343,0.009715915,0.00899826,0.0,0.0133607015,0.0,0.0,0.0,0.024491154,0.01795964,0.009338371,0.012050353,0.031858876,0.044654623,0.06406851,0.07622889,0.16341707,0.23929207,0.25416496,0.28336024,0.188595,0.12432174,0.015650034,0.01623895,0.0031997263,0.0,0.0,0.0,0.010904245,0.0,0.0027241707,0.0001489222,0.03056664,0.015105933,0.0,0.0,0.023605742,0.016760573,0.009589963,0.0,0.004540682,0.022584401,0.052667506,0.06807135,0.12936732,0.2722354,0.27508974,0.2959565,0.19005622,0.1208701,0.0,0.0,0.009710118,0.0,0.0,0.0,0.000066265464,0.0,0.00301297,0.031719632,0.054621987,0.039609656,0.0,0.02019205,0.053589433,0.025355674,0.015248261,0.004680708,0.0,0.018811107,0.06963071,0.08196875,0.117698535,0.31584334,0.36341152,0.38702583,0.21359779,0.110424675,0.0,0.0,0.008661784,0.0,0.0,0.0,0.0,0.0,0.01126796,0.09443662,0.09814933,0.05228646,0.0,0.033201583,0.08695215,0.036295563,0.034874506,0.0128899515,0.018777363,0.031875983,0.14378293,0.16157186,0.17118481,0.33188647,0.41348654,0.45304137,0.22087416,0.13921745,0.0,0.0,0.016311467,0.0,0.0,0.0053908825,0.0,0.0,0.033239126,0.12693177,0.12385378,0.060530208,0.0,0.0425497,0.11051918,0.053837635,0.05705192,0.009159036,0.050766915,0.047020137,0.18084604,0.19194523,0.2050379,0.306186,0.38939488,0.47050428,0.23358303,0.14912811,0.011066921,0.011533894,0.025102995,0.0,0.0,0.012215741,0.0,0.0,0.04022269,0.13726638,0.13148546,0.06858797,0.0,0.059264123,0.13418387,0.07876308,0.072524466,0.0,0.06117884,0.052182645,0.2005162,0.21808454,0.20767485,0.26404637,0.35481268,0.45766848,0.22518778,0.14669156,0.030526437,0.041299142,0.02728758,0.0,0.0,0.021964133,0.0,0.0,0.035770625,0.13077486,0.13600913,0.08373378,0.016877957,0.09068522,0.1661392,0.1133259,0.08541834,0.0,0.06884916,0.05727887,0.21782354,0.23176894,0.2032107,0.22863807,0.31776172,0.42812204,0.18540426,0.12129639,0.049305998,0.06451956,0.032949343,0.0,0.0,0.02526147,0.008534655,0.0,0.015401855,0.11571352,0.13868812,0.09432165,0.03922391,0.13586111,0.1886174,0.159045,0.13727771,0.014972873,0.13874505,0.12426456,0.2683354,0.28367043,0.21100429,0.20650358,0.27913052,0.39458877,0.17100385,0.10354758,0.062263362,0.07731986,0.030243188,0.0,0.0],[0.0,0.02418594,0.0,0.011793941,0.023240983,0.02860646,0.001599431,0.0064317286,0.006571509,0.06858756,0.12188765,0.2208299,0.331761,0.48955613,0.62586737,0.76545954,0.8508858,0.9124547,0.84259516,0.7441611,0.6261214,0.46596724,0.3371385,0.13736273,0.047447316,0.0,0.0,0.0,0.0,0.013452105,0.0,0.013162725,0.023653306,0.022627227,0.000041916966,0.0,0.0,0.039997414,0.071375415,0.12041516,0.19212838,0.3258956,0.48968458,0.6581717,0.7638617,0.83205354,0.772278,0.6818802,0.58451843,0.44027662,0.31707627,0.1507526,0.06682296,0.0,0.0,0.0,0.0,0.018511318,0.00088353455,0.020119108,0.0182629,0.01246766,0.0015262961,0.0,0.0,0.0,0.050592266,0.041251987,0.050811082,0.1422862,0.29470897,0.45741546,0.59020996,0.6989504,0.6785897,0.64111423,0.58647627,0.4426862,0.30651945,0.16496061,0.08517418,0.021642,0.0,0.0,0.0,0.017767139,0.006029196,0.012125149,0.024865195,0.008103475,0.0036140233,0.0,0.0,0.003036648,0.04972437,0.039807037,0.020185962,0.070836976,0.12852916,0.2773251,0.43155867,0.57664347,0.58383095,0.5671871,0.572155,0.44168782,0.29464287,0.13276032,0.065111615,0.02591829,0.0,0.0,0.0,0.008536361,0.0020855814,0.0026390404,0.023499638,0.0,0.0,0.0,0.0,0.014134318,0.056479156,0.06484506,0.039364375,0.051340133,0.038864955,0.16944472,0.32131422,0.5185218,0.5855574,0.63645,0.58171946,0.41875583,0.2640698,0.06991391,0.0397949,0.019753441,0.0,0.0,0.0,0.0004221648,0.004198134,0.006607607,0.028264232,0.0,0.0055187047,0.0,0.00024697185,0.02663353,0.06981084,0.08647896,0.0774896,0.035045147,0.0,0.070944786,0.21507919,0.4460891,0.65595967,0.78301454,0.67701864,0.41314453,0.2483185,0.023007408,0.02217663,0.0,0.0,0.0,0.0,0.0,0.005100742,0.028055765,0.058346413,0.0,0.04134693,0.0,0.039969333,0.013442963,0.06855949,0.10527958,0.117575735,0.0676484,0.018105812,0.09465568,0.22843492,0.44408935,0.7355331,0.87378126,0.6914461,0.37349206,0.24518242,0.016909845,0.017145365,0.0,0.0,0.0,0.0,0.0,0.00622233,0.050754428,0.095034316,0.020562097,0.061958052,0.0,0.046466157,0.009063065,0.07894973,0.13936348,0.17805141,0.12753801,0.057424195,0.13192846,0.254064,0.45229745,0.7673387,0.9209388,0.7046062,0.34830475,0.26676646,0.03213132,0.03888373,0.0,0.0,0.0,0.0,0.0,0.005304724,0.06007675,0.12215383,0.037314087,0.07581697,0.0,0.045719616,0.014353752,0.09915047,0.16729502,0.22337836,0.16909905,0.089021996,0.14794521,0.26754892,0.44881368,0.7941897,0.96930957,0.73274726,0.32812575,0.2901973,0.048543856,0.05920186,0.0,0.0,0.0,0.0,0.0,0.010847315,0.06763153,0.1469186,0.05629375,0.09092902,0.0,0.0527052,0.026836336,0.120936036,0.19240972,0.26155084,0.20350167,0.13808437,0.17655565,0.28948477,0.43566692,0.805139,0.9892398,0.72345096,0.28938943,0.28739768,0.060624138,0.08074631,0.0,0.0,0.0,0.0,0.0,0.00037044287,0.05154854,0.14188647,0.064784765,0.10273556,0.0,0.104238726,0.0869247,0.17975017,0.27754802,0.34840748,0.2908007,0.2512799,0.2649221,0.3533036,0.42236888,0.77472067,0.932678,0.6670682,0.24325572,0.28990343,0.08107129,0.08850837,0.0,0.0,0.0],[0.0067974404,0.007389076,0.023176424,0.03205441,0.021464296,0.03432452,0.019663826,0.0,0.006184824,0.09211808,0.16546641,0.3500378,0.47315538,0.68887746,0.79710215,0.8933582,0.98040533,1.0,1.0,0.91775495,0.839634,0.69419354,0.40999913,0.21093738,0.061267816,0.0,0.0,0.0,0.0,0.0,0.007231027,0.024656229,0.022740461,0.018981814,0.021759905,0.0,0.0,0.048347726,0.100091755,0.21010438,0.31550828,0.55456495,0.7177357,0.8447795,0.9722498,0.9738789,0.9584519,0.8709813,0.78718585,0.6450975,0.41531265,0.24201173,0.11727219,0.010040805,0.0,0.0,0.0,0.0,0.006334305,0.024621576,0.0023750067,0.0,0.029543363,0.0,0.0,0.014327958,0.066056244,0.0861903,0.13184215,0.37161154,0.5447062,0.6725618,0.87475646,0.8908538,0.8809358,0.83097124,0.73788345,0.6069049,0.4193675,0.25915912,0.17593512,0.035421044,0.0,0.0,0.0,0.0034562647,0.0073100477,0.021105148,0.0,0.0,0.04131794,0.013240054,0.018384635,0.020120375,0.054339938,0.07029925,0.06436201,0.23347598,0.34457642,0.47199827,0.7179671,0.8212646,0.79908705,0.74433976,0.68320143,0.5979899,0.4218219,0.21632567,0.16309205,0.021980979,0.0,0.0,0.0,0.001061067,0.009723358,0.02330061,0.00095802546,0.0,0.041047283,0.023702957,0.046264105,0.025433823,0.04076109,0.09231821,0.0548862,0.13317405,0.20634466,0.31369352,0.550243,0.75910187,0.79788786,0.7767139,0.6185684,0.51014364,0.3550584,0.16161646,0.13424622,0.012524195,0.0,0.0,0.0,0.0046858042,0.020903543,0.036134176,0.013573185,0.0,0.037678435,0.04133346,0.06810859,0.023396462,0.026982933,0.12541318,0.080864474,0.072931364,0.071146876,0.12893164,0.36538732,0.73580503,0.8992036,0.9125357,0.62688565,0.40546906,0.2504718,0.100551784,0.09590397,0.0,0.0,0.0,0.0,0.0,0.03216041,0.07260669,0.0461149,0.0,0.0592561,0.061540104,0.07103035,0.0014342666,0.0029267669,0.11860958,0.091332436,0.057067834,0.043325797,0.077611685,0.2780861,0.7494454,0.95598656,0.95679295,0.5488677,0.28569877,0.17154872,0.06419229,0.09738041,0.0,0.0,0.0,0.0,0.0,0.031498127,0.09410382,0.06007742,0.0,0.060428277,0.063353606,0.06759595,0.016703963,0.009516403,0.1309771,0.10860247,0.08494644,0.06047979,0.06791267,0.23749483,0.74997485,0.9650238,1.0,0.52158725,0.24815926,0.1655671,0.0965659,0.13450903,0.011991166,0.0,0.0,0.0,0.0,0.037701435,0.11391044,0.074724965,0.0,0.065339565,0.061842144,0.06041669,0.042253755,0.022436827,0.14146918,0.12826803,0.1275235,0.07759701,0.030901954,0.1859752,0.7482022,0.98360336,1.0,0.51019377,0.22853175,0.17155081,0.14390916,0.16544603,0.012136094,0.0,0.0,0.0,0.0,0.04596521,0.13746454,0.09675333,0.0049553514,0.071325384,0.065052904,0.061621666,0.073776,0.03635703,0.15464179,0.14800364,0.17479819,0.11480156,0.026917659,0.156537,0.7518948,0.99590355,1.0,0.47901928,0.21131825,0.1882846,0.1846911,0.19403252,0.02400098,0.0,0.0,0.006416023,0.0,0.043743454,0.1298752,0.09875614,0.022272594,0.07607745,0.095703095,0.11836389,0.15740126,0.14426224,0.2376639,0.22319844,0.25910503,0.18228666,0.08853796,0.17925191,0.7412097,0.94513065,1.0,0.41153795,0.17683266,0.19997823,0.21911658,0.18066461,0.031168401,0.0,0.0],[0.0,0.017323308,0.035632864,0.0,0.0,0.009163082,0.0,0.021300167,0.05902257,0.16838327,0.22505751,0.3442581,0.5112143,0.60682154,0.6798973,0.58605,0.66329455,0.6475045,0.73439103,0.71714467,0.7615053,0.6527833,0.4686197,0.14669648,0.02740381,0.003776595,0.01006081,0.0,0.0,0.0081583485,0.014920801,0.0,0.0,0.01484184,0.0,0.001969248,0.027623408,0.09354204,0.12576328,0.22842713,0.42388487,0.6021686,0.70489556,0.6318006,0.7007297,0.67607355,0.72749865,0.6870979,0.7283795,0.65850085,0.4774269,0.1967304,0.074276805,0.021237262,0.008898817,0.0,0.0,0.019052804,0.0012743771,0.0,0.0,0.008353062,0.0,0.0,0.014946319,0.04942003,0.047135733,0.09880687,0.2970789,0.53363943,0.65511787,0.63933665,0.7619529,0.72293556,0.721581,0.65372235,0.7014262,0.66560465,0.4918267,0.24398693,0.11172183,0.03725849,0.013453066,0.0,0.0,0.026902013,0.0,0.0,0.0,0.0,0.0,0.008728214,0.0365273,0.034519717,0.044524126,0.052271076,0.1760184,0.3501171,0.45110357,0.55803186,0.79619604,0.8197893,0.78905946,0.67579633,0.7194174,0.62794167,0.46900344,0.22752744,0.105152115,0.03490153,0.018390514,0.0,0.0,0.021918416,0.0,0.0,0.0,0.0,0.013631582,0.0037144572,0.022798069,0.011435695,0.044124395,0.058867097,0.120225355,0.17774507,0.22419983,0.39914465,0.6802977,0.85617197,0.8587317,0.6891568,0.58807296,0.45822293,0.32356358,0.14022416,0.08232847,0.038616814,0.010188796,0.0,0.0,0.020140946,0.01427947,0.0,0.0,0.0,0.03372439,0.019603819,0.02709227,0.008776218,0.051538162,0.097723946,0.15108457,0.060035966,0.01338958,0.15284017,0.48829514,0.8362682,0.98922294,0.7815884,0.50729156,0.29988694,0.18112954,0.0595937,0.051302686,0.027210265,0.0,0.0,0.0,0.032396935,0.03787864,0.0052360445,0.0,0.0,0.0508554,0.032846585,0.039316304,0.0,0.04119993,0.1348194,0.20570256,0.020606905,0.0,0.029240094,0.39061737,0.8248093,1.0,0.7362201,0.33215916,0.14133683,0.12222417,0.056604758,0.078214526,0.02556526,0.0,0.0,0.0,0.03469263,0.05645483,0.017285027,0.018254265,0.00004696846,0.05154796,0.039253578,0.055432692,0.018153831,0.0672477,0.15273131,0.24595112,0.024150789,0.0,0.0,0.3616763,0.8437501,1.0,0.75401604,0.26570767,0.10661673,0.14056315,0.103043,0.11646293,0.035555586,0.0,0.0,0.0,0.05002089,0.089284204,0.046249837,0.066977814,0.017263599,0.061796337,0.052217096,0.07200052,0.04212697,0.08801456,0.16920486,0.27778834,0.044582374,0.0,0.0,0.33635867,0.88240325,1.0,0.82545227,0.24000075,0.086022794,0.15115142,0.14753261,0.14535482,0.036167823,0.0,0.0,0.0,0.063924216,0.11721882,0.07994944,0.12461384,0.041435406,0.07853935,0.070041716,0.095152885,0.06902353,0.10851295,0.18918245,0.30562237,0.08270399,0.0,0.0,0.33856782,0.9042397,1.0,0.83303154,0.2067245,0.06992075,0.16505022,0.18625112,0.17667672,0.038515113,0.0,0.0,0.0,0.07078895,0.12526624,0.09937629,0.14643069,0.054440543,0.10240946,0.1317331,0.17840517,0.15017733,0.18361655,0.24577954,0.34932172,0.14205888,0.0,0.011482991,0.36142874,0.8712561,1.0,0.7327502,0.17338932,0.08926063,0.21128277,0.21899018,0.18888696,0.041242488,0.0,0.0],[0.0,0.02619809,0.0,0.0,0.0,0.0,0.0,0.0,0.018562876,0.14526305,0.22871858,0.33868414,0.4382186,0.54132044,0.46772504,0.38949692,0.39352447,0.4227957,0.56218004,0.64903796,0.62366444,0.5516515,0.3066081,0.13350521,0.0,0.0041333884,0.0,0.0,0.0,0.008555129,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09315062,0.17774811,0.30413765,0.47007883,0.6026222,0.5545655,0.4365704,0.42133522,0.46854258,0.55243224,0.6191234,0.60992366,0.5661414,0.32871336,0.18085954,0.023943715,0.021066897,0.0,0.0,0.0,0.016073026,0.0,0.0,0.0,0.0,0.0,0.0010057241,0.0,0.0689052,0.12520935,0.22441316,0.46225184,0.63639706,0.6257844,0.52783585,0.5070165,0.5516223,0.5628672,0.5955285,0.61111414,0.6029064,0.3791237,0.23677489,0.06630931,0.044655956,0.0,0.0,0.005603954,0.015289299,0.0035369396,0.0,0.0,0.0049695224,0.0,0.04215461,0.005423695,0.06513984,0.10844531,0.13707723,0.3497753,0.4946816,0.534668,0.5781543,0.6742104,0.7078428,0.68804705,0.6846054,0.6738827,0.5907378,0.4086541,0.23943964,0.064188555,0.043101102,0.0,0.0,0.006903589,0.014109179,0.011691622,0.0,0.0,0.016278379,0.0,0.032332927,0.0,0.05140525,0.07905339,0.057172753,0.1841868,0.2735961,0.31304115,0.50061524,0.7165624,0.794409,0.7405408,0.62874985,0.5121991,0.40169126,0.25413382,0.13405164,0.045876324,0.037667096,0.0,0.0,0.005783744,0.024381317,0.025906816,0.0007058531,0.0,0.025076441,0.0,0.015502185,0.001283586,0.060178705,0.04023961,0.05632104,0.06769427,0.075507544,0.10725717,0.33961493,0.65865314,0.8275953,0.8412243,0.59926206,0.36719283,0.21850052,0.10274817,0.03582702,0.027871385,0.03305217,0.0,0.0,0.011110537,0.049939938,0.017673723,0.012478024,0.0,0.03734614,0.0,0.00032877922,0.017908499,0.05371449,0.0,0.05544004,0.0074866116,0.0,0.0,0.23018862,0.5827065,0.79438645,0.78562313,0.47108614,0.14940566,0.069894806,0.060333997,0.01856649,0.047775514,0.020999901,0.0,0.0133007765,0.018151432,0.06467861,0.036402114,0.033927888,0.02038674,0.06692947,0.0,0.019943438,0.0699456,0.06500793,0.0006634146,0.037258245,0.0,0.0,0.0,0.18058509,0.5636735,0.7926293,0.7940104,0.45793384,0.069963634,0.051818483,0.08396621,0.033585772,0.064021505,0.01566077,0.0,0.0090757385,0.027179867,0.08367826,0.06754505,0.08127478,0.08964786,0.10387132,0.009286903,0.051752776,0.12385149,0.08156514,0.014353573,0.031238824,0.0,0.0,0.0,0.14366668,0.54869694,0.8145897,0.85564506,0.5001373,0.03817004,0.040485032,0.085211754,0.045304462,0.065814495,0.0063668117,0.0,0.004091233,0.03133603,0.09946374,0.10038079,0.13313086,0.16446409,0.14376798,0.027795203,0.080201715,0.17185085,0.09912301,0.033538714,0.029393315,0.0,0.0,0.0,0.13449633,0.5468464,0.82085276,0.8623241,0.48378962,0.00094236434,0.042189986,0.09440732,0.058298625,0.07703087,0.0,0.0,0.0042737573,0.03147465,0.10043982,0.11043808,0.16165012,0.19428787,0.16623785,0.046695128,0.1321024,0.22516903,0.12784496,0.060340904,0.052297786,0.0,0.0,0.0,0.1477422,0.5391424,0.7877081,0.7666269,0.4023112,0.0,0.09737628,0.14949244,0.060119227,0.08139394,0.0,0.0,0.0],[0.013332963,0.00811667,0.0,0.0,0.0,0.0,0.0,0.0,0.022256598,0.09266195,0.2481622,0.37253278,0.51234245,0.38600934,0.32463712,0.21736267,0.3223651,0.34357405,0.5017672,0.5295288,0.4498865,0.38026476,0.16201921,0.050319858,0.0,0.0,0.0,0.0,0.009709619,0.0,0.0,0.0,0.0,0.0,0.0,0.0013287067,0.008282512,0.05933646,0.218763,0.404101,0.58540565,0.47618175,0.39618087,0.2527092,0.31047893,0.34280047,0.47433412,0.5270128,0.44524437,0.38929904,0.19805452,0.068190046,0.0,0.0,0.0,0.0,0.02466543,0.0036184192,0.0,0.0,0.0,0.0,0.0,0.030199505,0.022130467,0.0049179643,0.11257369,0.32473615,0.5664774,0.56686974,0.48815584,0.36951268,0.37904054,0.39771712,0.51474106,0.5605429,0.48603594,0.41798735,0.26978153,0.11250767,0.025096081,0.0,0.0,0.0,0.030579075,0.024560131,0.0,0.0,0.0,0.0,0.0061035827,0.052418076,0.03998392,0.0,0.061204553,0.16478148,0.3559276,0.45586956,0.48641342,0.4953881,0.6291918,0.6728011,0.71732855,0.6747565,0.54141426,0.39073956,0.2948888,0.1193408,0.042795643,0.0,0.0,0.0,0.022950836,0.022197917,0.0,0.0,0.0,0.0,0.013268374,0.05774129,0.031004563,0.0,0.03778971,0.031898588,0.11604157,0.25619835,0.3777604,0.54739714,0.7943525,0.83778125,0.80214196,0.6187484,0.40464967,0.21809343,0.16866615,0.0431834,0.028131902,0.0,0.0,0.0,0.014073223,0.013778679,0.0,0.0,0.0,0.015021771,0.008240499,0.0564814,0.037847877,0.0,0.039535284,0.03691954,0.0,0.09599541,0.17853981,0.5095498,0.88211226,0.93479496,0.8146535,0.4985224,0.2528136,0.0848299,0.032304972,0.0,0.010180205,0.0,0.0,0.0,0.020620883,0.025079176,0.011255182,0.000688076,0.011288218,0.03441102,0.007997744,0.06592916,0.06330992,0.02184774,0.029205121,0.032823674,0.0,0.0,0.010463826,0.4468968,0.8625848,0.89058226,0.6422247,0.24452767,0.06515739,0.0,0.0,0.030871846,0.027093068,0.01740162,0.006698996,0.0,0.02471894,0.048502244,0.036876507,0.04354056,0.061926536,0.068707496,0.021719329,0.08953364,0.121267624,0.054558128,0.02844359,0.040973797,0.0,0.0,0.0,0.42274678,0.8650693,0.90340906,0.6491123,0.22865015,0.029747538,0.0,0.0,0.051696397,0.044680595,0.02445075,0.00921078,0.0,0.025835007,0.071410835,0.07586917,0.10209437,0.12922841,0.115457684,0.05905976,0.1143648,0.18111542,0.0996453,0.046071954,0.06331468,0.0,0.0,0.0,0.37691057,0.84596145,0.9417747,0.7387141,0.3084882,0.024047494,0.0,0.0,0.054203622,0.042608835,0.015684128,0.0010636151,0.0,0.02849365,0.09359209,0.11913321,0.15979399,0.19997087,0.1712389,0.093191735,0.1294501,0.22030294,0.13435046,0.060753018,0.08666377,0.0,0.0,0.0,0.3423941,0.8207306,0.91844815,0.73415434,0.30455154,0.011453271,0.0,0.0,0.068522975,0.0514568,0.0075697526,0.0,0.0,0.029767111,0.098842844,0.14724015,0.19187711,0.2360008,0.19530095,0.09984937,0.13007143,0.2348042,0.16499422,0.075379744,0.13195068,0.0,0.0,0.0,0.3211459,0.73927796,0.8350322,0.6440385,0.2667231,0.026123412,0.0,0.0,0.10150395,0.07438956,0.005650088,0.0,0.0],[0.0,0.008246534,0.0122540295,0.0,0.0,0.0,0.0,0.0,0.0,0.11888349,0.35211462,0.5638564,0.5625859,0.4771356,0.4298398,0.36013493,0.48068827,0.5363565,0.45257866,0.42242444,0.4458248,0.27581936,0.14166853,0.038477138,0.0026025325,0.0,0.0,0.004423976,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11734254,0.35355902,0.60278845,0.5976035,0.49599725,0.432319,0.34319508,0.418226,0.43732,0.45094568,0.43439388,0.45127636,0.27283937,0.16005284,0.040981673,0.007849552,0.0,0.0,0.00653854,0.0,0.004546866,0.0028223693,0.004907042,0.0,0.0,0.0,0.016682297,0.0049121976,0.08220707,0.2601981,0.50137097,0.580879,0.54411817,0.46643555,0.39779592,0.41279304,0.40472698,0.49760902,0.50666004,0.49328297,0.3111955,0.1970456,0.05583986,0.01866404,0.0,0.0,0.008669034,0.0060278326,0.033291318,0.03583418,0.03914474,0.025178872,0.0,0.017777525,0.041317888,0.00954473,0.04733149,0.15640756,0.29303312,0.41287076,0.50484073,0.4836744,0.5013225,0.5988639,0.59883213,0.6769475,0.595826,0.4694388,0.28550392,0.17561913,0.04773093,0.0100928545,0.0,0.0,0.0005428791,0.0,0.039231695,0.050347283,0.059722155,0.050105803,0.0063521117,0.008895934,0.04740251,0.0034593642,0.025922954,0.047625534,0.07208096,0.22247604,0.37443143,0.47797167,0.61494327,0.7816402,0.76081246,0.76301205,0.51869166,0.2836599,0.15874557,0.099658765,0.000051632524,0.0011447817,0.0,0.0,0.0,0.0,0.026604787,0.04614775,0.051823176,0.04479547,0.014271416,0.0,0.057785265,0.0,0.030690841,0.0,0.0,0.07507918,0.18327972,0.34105328,0.677086,0.9515267,0.88427824,0.73253363,0.3746786,0.089687474,0.05088944,0.065118544,0.0,0.015314907,0.0052211434,0.0,0.0,0.0,0.030940928,0.05076036,0.050522335,0.048199087,0.034779876,0.0,0.060664482,0.006646104,0.02437684,0.0,0.0,0.0,0.009826854,0.24171352,0.6807045,1.0,0.85253733,0.54267436,0.1351096,0.0,0.0,0.03809035,0.013245143,0.061660044,0.05211942,0.0,0.012734339,0.0,0.053306833,0.0880682,0.09049882,0.09527869,0.076478004,0.010504052,0.083084434,0.03276001,0.027825259,0.0,0.0,0.0,0.0,0.19667791,0.6746537,1.0,0.8868724,0.5709623,0.12999701,0.0,0.0,0.035921335,0.035155356,0.09428831,0.083440214,0.0,0.01594536,0.0,0.07564346,0.13850304,0.12770082,0.14336641,0.12382732,0.030063912,0.09451177,0.054481924,0.045317486,0.0,0.0,0.0,0.0,0.13744631,0.6230629,1.0,0.9573881,0.6882047,0.20361736,0.0,0.0,0.040605105,0.038925946,0.105774365,0.09730068,0.0,0.015852943,0.0,0.09911941,0.18535417,0.15421918,0.18786186,0.1617338,0.04965879,0.09728006,0.05867102,0.047173873,0.0,0.0,0.0,0.0,0.09942209,0.58561426,1.0,0.97038406,0.71211106,0.20644008,0.0,0.0,0.041795447,0.057668157,0.11965739,0.10933681,0.0036655217,0.011787713,0.0,0.098682836,0.18990104,0.15894994,0.18969856,0.17429934,0.050310396,0.073740214,0.026304156,0.035943605,0.0,0.0,0.0,0.0,0.09042557,0.5435999,1.0,0.88354474,0.64223915,0.20075127,0.0,0.0,0.03666628,0.093969725,0.13331352,0.08488482,0.0048523843,0.0],[0.037632488,0.025532186,0.0,0.0,0.0,0.0,0.0,0.012908161,0.01628171,0.20061804,0.41544986,0.5609932,0.66746354,0.6852107,0.61233896,0.56272167,0.78653693,0.7371672,0.6493192,0.39334786,0.29230696,0.107122734,0.040884152,0.0,0.0,0.028383248,0.038114876,0.0008917153,0.032141455,0.014841691,0.0,0.0,0.0,0.003658861,0.0,0.002610281,0.004382178,0.1962271,0.41182864,0.55884933,0.6544706,0.62465715,0.53987956,0.50431055,0.68817943,0.6575812,0.61279523,0.4058485,0.28894874,0.1084685,0.038349822,0.0,0.0,0.01014927,0.03309132,0.012646571,0.035782367,0.028350279,0.0,0.0,0.0,0.018157251,0.0,0.008396491,0.029479668,0.13476832,0.31491256,0.46609956,0.64101624,0.6095766,0.54295933,0.48493928,0.63018703,0.6453879,0.63615507,0.4544477,0.3220472,0.14865047,0.048743084,0.0,0.0,0.025970906,0.053436287,0.02907718,0.017966047,0.0326109,0.035056695,0.018900812,0.0,0.016592607,0.0,0.025740087,0.042276204,0.08384993,0.19356695,0.26936328,0.47119737,0.4992454,0.52826905,0.5474805,0.74952596,0.7721496,0.71429026,0.4727943,0.28955328,0.14320327,0.038670182,0.0,0.0,0.029075906,0.05053699,0.02079881,0.0,0.031502195,0.055566028,0.045911625,0.0,0.012437768,0.00861115,0.048083737,0.032403506,0.06826404,0.07089391,0.08918579,0.25061777,0.40524864,0.54862475,0.65502,0.8765394,0.86277264,0.6898449,0.353451,0.14860094,0.087856725,0.027705096,0.0,0.0,0.018516712,0.039988935,0.015188657,0.0,0.008910745,0.03639058,0.022009544,0.0,0.00046256185,0.009168655,0.072809786,0.02956836,0.053978406,0.0,0.0,0.02344893,0.25069243,0.47573775,0.80395323,1.0,0.8702976,0.51931065,0.18432057,0.024554454,0.05217155,0.019126058,0.021932758,0.04368104,0.05157671,0.051520742,0.009962536,0.0,0.00078874826,0.03398083,0.025090605,0.0,0.0,0.013771541,0.071612045,0.01816526,0.07015668,0.0,0.0,0.0,0.0868003,0.40279973,0.92802435,1.0,0.81592786,0.33147654,0.027060531,0.0,0.03227842,0.047360793,0.08305463,0.12556122,0.10124315,0.07406017,0.0018004477,0.0,0.018631034,0.054709077,0.048497096,0.0,0.012051694,0.024285674,0.0996848,0.045919746,0.09964817,0.0,0.0,0.0,0.04660759,0.39046842,0.987279,1.0,0.8876851,0.35255623,0.030043386,0.0,0.05161047,0.08300476,0.12177927,0.18596363,0.13579519,0.09308182,0.0,0.0,0.045627445,0.09396368,0.08768584,0.0,0.021845147,0.026683629,0.113203466,0.059977576,0.121799506,0.0,0.0,0.0,0.012658186,0.35373864,0.99556655,1.0,1.0,0.44264936,0.08289925,0.0,0.07229212,0.10034692,0.13563631,0.21967387,0.14841281,0.09589285,0.0,0.0,0.0666636,0.12948902,0.12723204,0.0,0.023379505,0.025997177,0.11750502,0.06410211,0.124910295,0.0,0.0,0.0,0.0,0.33746994,0.9924172,1.0,1.0,0.45308632,0.09226525,0.0,0.087510765,0.12530889,0.16442937,0.26053908,0.15853158,0.09180732,0.0,0.0,0.0833095,0.17455916,0.15735996,0.0,0.00494346,0.00390628,0.09810763,0.053675994,0.10698894,0.0,0.0,0.0,0.0,0.34176216,0.9481402,1.0,0.97845864,0.40243566,0.10347827,0.0,0.11616688,0.15687495,0.1758889,0.26255676,0.12916261,0.06573644,0.0],[0.007209718,0.04151386,0.0,0.0,0.0,0.0,0.0020646006,0.0,0.013401404,0.27828524,0.45765978,0.634713,0.7838113,0.85361415,0.8016947,0.77204335,0.8697312,0.8044987,0.62911147,0.3118024,0.13568586,0.01709453,0.0,0.0,0.0,0.0,0.003152877,0.0,0.0,0.022240601,0.0,0.0,0.0,0.0,0.0028095394,0.0,0.0,0.24648103,0.42086953,0.59322697,0.7288287,0.7821219,0.73861134,0.7258452,0.7884931,0.74650836,0.6194427,0.31594846,0.11902945,0.002480805,0.0,0.0,0.0,0.0,0.010856807,0.0,0.012474455,0.031102866,0.0,0.0,0.0,0.0,0.0,0.0,0.0054798275,0.17044133,0.3326162,0.54492927,0.7077342,0.77981967,0.75191987,0.7061497,0.75800943,0.73427266,0.62692523,0.33992678,0.13603176,0.039376162,0.008515261,0.0,0.0,0.01377029,0.033107348,0.013035074,0.0095554665,0.041396983,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09150274,0.19291802,0.4050517,0.54854023,0.71871716,0.7789399,0.75879216,0.8554413,0.7675181,0.5822403,0.29040158,0.11890053,0.06091792,0.0266582,0.0,0.0,0.0075313076,0.017694362,0.020440921,0.0028871596,0.034777716,0.019098766,0.0,0.0,0.0009227544,0.0,0.0,0.0,0.038267255,0.080187574,0.24097218,0.35327557,0.67031914,0.81210095,0.86237293,0.92097294,0.7249849,0.43396747,0.14237665,0.028706148,0.045977548,0.029472545,0.0,0.0031825304,0.00068835914,0.018846735,0.023475043,0.000739485,0.026266009,0.005988665,0.0,0.0,0.0,0.00040273368,0.0,0.0,0.008980669,0.004935682,0.057042845,0.12773888,0.47476494,0.77655804,0.96625847,0.97172326,0.5909921,0.2309111,0.0,0.0,0.044443443,0.015706204,0.0,0.038533077,0.030081525,0.036070324,0.025215432,0.0040446073,0.030515589,0.012036681,0.019520737,0.0,0.0,0.01044748,0.0,0.0,0.0024092495,0.0,0.0,0.0,0.27442065,0.7292083,1.0,1.0,0.4452415,0.04110942,0.0,0.0,0.059794687,0.014348738,0.0,0.086986035,0.05956158,0.051463403,0.018242203,0.01183404,0.052118957,0.028208926,0.04650212,0.0,0.0,0.028283574,0.0,0.0,0.013720259,0.0,0.0,0.0,0.22700346,0.72399867,1.0,1.0,0.4720018,0.03390295,0.0,0.0,0.08811222,0.026079774,0.015013672,0.11556364,0.05806107,0.04774583,0.015052803,0.016101666,0.07902855,0.06706318,0.07423039,0.004763603,0.0078954175,0.038167186,0.0,0.012341559,0.025892563,0.0,0.0,0.0,0.20356104,0.6920729,1.0,1.0,0.57355064,0.094825305,0.0,0.0,0.1125428,0.039148398,0.024959661,0.12119056,0.033079177,0.025515161,0.010470875,0.01554931,0.1050703,0.108346716,0.10889945,0.01881288,0.017623305,0.035640642,0.0,0.031269856,0.033783853,0.0,0.0,0.0,0.18771565,0.67205346,1.0,1.0,0.6246397,0.11349416,0.0,0.0,0.11923989,0.06876823,0.03843657,0.12195633,0.0037625134,0.0,0.002294287,0.012943596,0.1293101,0.14936484,0.13784385,0.028641313,0.0006753355,0.012069613,0.0,0.042122424,0.018098883,0.0,0.0,0.0,0.15163696,0.6229899,1.0,1.0,0.57750636,0.071416765,0.0,0.0,0.1220453,0.087418586,0.02417931,0.086449385,0.0,0.0,0.0],[0.021421187,0.025395289,0.0,0.0,0.0,0.0,0.017590955,0.04953952,0.13961837,0.30932105,0.48597062,0.63614446,0.86810964,0.86356544,0.84403867,0.8855532,0.9223564,0.7391712,0.6168313,0.34440494,0.15561184,0.021668136,0.0,0.0,0.005427897,0.0,0.0,0.0,0.011171751,0.016352266,0.0,0.0,0.0,0.0,0.01810027,0.027410604,0.09504243,0.2389182,0.40603703,0.5711766,0.8448196,0.86467266,0.8801137,0.9085252,0.8909245,0.6693251,0.51913863,0.2656822,0.06409086,0.0,0.0,0.004112363,0.02746956,0.0,0.0,0.0,0.02194111,0.03550592,0.0,0.0,0.0,0.0,0.013068117,0.013690241,0.06636253,0.19379148,0.36160207,0.5464084,0.864093,0.8855601,0.91690344,0.93598133,0.854662,0.6425481,0.4511549,0.21914682,0.043444514,0.0,0.0,0.012336209,0.05119822,0.024635732,0.018131271,0.0,0.027247548,0.03319925,0.0,0.0,0.0,0.0,0.0022324175,0.0,0.015239507,0.100026585,0.2279349,0.41130108,0.74096084,0.83991605,0.89279294,0.95697594,0.83999443,0.6536363,0.39457864,0.17491041,0.00846678,0.009526029,0.0,0.010892399,0.04269047,0.014076121,0.0,0.0,0.02148801,0.0051136315,0.0,0.0076143146,0.0,0.010373443,0.0042625368,0.0,0.0,0.030487716,0.1023104,0.28056568,0.5903593,0.8038037,0.88887656,1.0,0.8054867,0.60576415,0.28875935,0.09614335,0.0,0.0039088577,0.0,0.0072052255,0.03749845,0.008244678,0.0,0.00255315,0.022738494,0.0,0.0,0.0065544844,0.004548967,0.01532799,0.01646714,0.0,0.0,0.0,0.0,0.08238211,0.35160667,0.731636,0.9099439,1.0,0.73715186,0.38161403,0.08098364,0.0,0.0,0.0,0.0,0.023616359,0.05855196,0.026106432,0.006765306,0.015604794,0.01142586,0.03043285,0.045798473,0.033537284,0.0,0.0,0.020665735,0.007887706,0.0,0.0,0.0,0.0,0.12008717,0.6140115,0.9028144,1.0,0.6899328,0.23531684,0.0,0.0,0.0,0.0,0.0,0.034994647,0.07723287,0.04723852,0.03979858,0.0327043,0.008216284,0.06453978,0.101270676,0.07925051,0.007946946,0.0,0.025231093,0.012302086,0.0,0.0,0.0,0.0,0.06897225,0.61300623,0.93944025,1.0,0.7297387,0.24132478,0.0,0.0,0.0,0.0,0.0,0.04098423,0.080778256,0.051143765,0.054713845,0.041880496,0.009951398,0.10136377,0.14970192,0.11015443,0.01801271,0.0,0.025831975,0.015239313,0.0,0.0,0.0,0.0,0.064891644,0.63022745,0.9670754,1.0,0.80897987,0.29026583,0.0,0.0,0.0,0.0,0.0,0.043216586,0.07439515,0.040968224,0.054146923,0.044550613,0.011212669,0.13256402,0.19346908,0.15154621,0.04459405,0.0,0.020298205,0.018228836,0.0,0.0,0.0,0.0,0.06076576,0.6457814,0.98069066,1.0,0.8618469,0.32785589,0.0,0.0,0.0,0.0,0.0,0.043693125,0.06860115,0.026470944,0.048318,0.04422678,0.015210465,0.16649663,0.22930005,0.18039022,0.047301665,0.0,0.0008600354,0.007799387,0.0,0.0,0.0,0.0,0.008138776,0.61872596,0.9709876,1.0,0.8430768,0.3329255,0.0,0.0,0.0,0.0,0.0,0.0208043,0.05857966,0.020298101,0.04855477,0.035981096],[0.033126183,0.04300841,0.0,0.011936851,0.003275305,0.0,0.040902607,0.06640147,0.15025707,0.27220273,0.31759048,0.5008526,0.71693283,0.70211196,0.5706859,0.70410484,0.7549754,0.7913868,0.60711855,0.40717733,0.22010866,0.014904797,0.024380334,0.0,0.0,0.0,0.0,0.0034863204,0.015121385,0.021390095,0.0,0.015009619,0.0029194504,0.0,0.039548226,0.028692164,0.11104103,0.20038646,0.28371346,0.47850585,0.7649074,0.7810977,0.7302692,0.85520315,0.7734384,0.6510933,0.44014853,0.22937198,0.086959586,0.0,0.010800503,0.0,0.0,0.0,0.0,0.0,0.017789342,0.031177327,0.017304376,0.019950606,0.0,0.0,0.031480163,0.0,0.089291334,0.17936975,0.3186772,0.517418,0.83184916,0.8310661,0.853096,0.95435905,0.7538913,0.55328095,0.30415902,0.11021556,0.04394587,0.0,0.01900144,0.0,0.0,0.0,0.0,0.0,0.022936918,0.034053735,0.022708893,0.014037617,0.0,0.0,0.0211664,0.0,0.033022672,0.10097578,0.2510225,0.4615621,0.7983741,0.82740116,0.87561077,0.99548155,0.7174882,0.49488187,0.24752448,0.044116654,0.022904754,0.0,0.012511186,0.0,0.002654761,0.0,0.0,0.0,0.021390311,0.01291582,0.011523731,0.012046367,0.0055082142,0.0,0.018080689,0.0,0.0,0.035580635,0.1727771,0.40007883,0.71522295,0.83447546,0.9042621,0.98702276,0.6367951,0.37753636,0.1830675,0.021335617,0.026341327,0.0031265914,0.015450448,0.0,0.016927883,0.0,0.0,0.0,0.023164593,0.0018152297,0.008370616,0.008196168,0.038042307,0.016787544,0.009493925,0.0,0.0,0.0,0.041681677,0.22946562,0.53889114,0.86368257,0.9461533,0.9004851,0.51195925,0.13369304,0.0079427585,0.0,0.044879355,0.000996396,0.017920591,0.019398198,0.044773646,0.013454333,0.025370397,0.019707322,0.00767494,0.030996017,0.062476337,0.0072294697,0.010997415,0.013371222,0.0,0.0,0.0,0.0,0.0,0.11730193,0.3757154,0.86926836,1.0,0.8685897,0.4490512,0.0,0.0,0.0,0.01900357,0.0,0.023950644,0.05418948,0.06509049,0.056757517,0.062652156,0.039528415,0.004503548,0.056365505,0.12118548,0.032763228,0.0034758747,0.014509372,0.0,0.0,0.0,0.0,0.0,0.12159504,0.3790635,0.9219138,1.0,0.91921103,0.48450142,0.0,0.0,0.0,0.0,0.0,0.024386957,0.071923465,0.0644227,0.07750337,0.08855946,0.05589944,0.008914158,0.081835404,0.15780759,0.052191958,0.0018045455,0.009895094,0.0,0.006837696,0.0,0.0,0.0,0.143884,0.4172631,0.9695796,1.0,0.98795545,0.5460066,0.0,0.0,0.0,0.0,0.0,0.011490814,0.08093096,0.055619366,0.078805104,0.10404194,0.07080266,0.0083242655,0.09912416,0.18752016,0.0833095,0.014969379,0.0018422902,0.0,0.01866655,0.0,0.0,0.0,0.16316657,0.45587504,1.0,1.0,1.0,0.59408695,0.0015007257,0.0,0.0,0.0,0.0,0.0070543215,0.0953151,0.056793503,0.075346336,0.11242918,0.08068583,0.014247023,0.13627693,0.19935858,0.09428131,0.027782708,0.0,0.0,0.010382131,0.0,0.0,0.0,0.14611533,0.45631534,0.99186623,1.0,1.0,0.6007413,0.005546659,0.0,0.0,0.0,0.0,0.008309215,0.10641785,0.050965466,0.07782887,0.10814821,0.071540594],[0.0,0.018439896,0.029251814,0.0,0.0,0.018797435,0.060445964,0.0,0.15921032,0.17015636,0.28067687,0.3101738,0.44574797,0.40858454,0.38062042,0.4062965,0.52040577,0.68119824,0.6804134,0.52457637,0.23889706,0.03312458,0.00082170963,0.0134991035,0.055736832,0.0043799877,0.037535258,0.03549397,0.0,0.008154668,0.025294513,0.0,0.0,0.0256024,0.04451607,0.0,0.12279308,0.15243056,0.27518392,0.36909562,0.5564567,0.61927164,0.64247745,0.62750167,0.5852396,0.5690811,0.42129308,0.21949464,0.053669572,0.0,0.017564885,0.024344333,0.040084325,0.000015631318,0.00054717064,0.0,0.0,0.013084769,0.030162148,0.0028588027,0.0,0.02841106,0.03332825,0.02290976,0.105207786,0.21144341,0.3881637,0.536816,0.6965264,0.7615275,0.77310157,0.7095189,0.5386358,0.37836424,0.20908703,0.073138095,0.0075192526,0.0,0.03467544,0.036496267,0.034107745,0.0022693723,0.0,0.0,0.0049974173,0.023678511,0.033261165,0.0018654466,0.0,0.03177563,0.036269113,0.034764774,0.06140244,0.1832684,0.37653697,0.5795443,0.7686399,0.84950995,0.83963025,0.7426047,0.53035545,0.30047762,0.110679604,0.008548848,0.0,0.0,0.02728147,0.031467654,0.030013092,0.01151827,0.0,0.0,0.0069626346,0.0060252994,0.017226204,0.0,0.0106160715,0.04613976,0.040983364,0.030957974,0.010522626,0.13770264,0.3298713,0.55390745,0.7610245,0.90733707,0.8926726,0.74191654,0.49088627,0.23752344,0.07153531,0.002996534,0.0,0.0,0.029326886,0.020233877,0.024085656,0.022703879,0.007985078,0.0,0.007676244,0.0,0.011744976,0.0025453717,0.031072497,0.07256607,0.065011546,0.03623715,0.0,0.03355761,0.16789022,0.40757972,0.70243716,0.9168973,0.8526256,0.49700898,0.2199504,0.027377822,0.0,0.016674802,0.005778469,0.00876487,0.03894858,0.016267337,0.044535175,0.04890418,0.037611276,0.0021244586,0.0,0.020495407,0.030113444,0.009638011,0.0134421885,0.064188585,0.048327975,0.0,0.0,0.0,0.05510927,0.27660495,0.62043685,0.9421062,0.8543567,0.35230327,0.0850977,0.0,0.0,0.044755496,0.018964998,0.029319309,0.05015058,0.018302217,0.1038494,0.0871025,0.073549636,0.013948545,0.0,0.039309144,0.048359826,0.026873842,0.022348478,0.07952187,0.06525898,0.0,0.0,0.0,0.03476063,0.27779308,0.64052683,0.98973995,0.89011765,0.34674495,0.0747505,0.0,0.0,0.061418533,0.01857122,0.04433415,0.052614003,0.024520002,0.13915348,0.11297463,0.101600856,0.025459938,0.0020118505,0.044524416,0.06266856,0.03992074,0.035952523,0.10232622,0.072292686,0.0,0.0,0.0,0.051584154,0.31153402,0.69018024,1.0,0.9148076,0.35996544,0.08975826,0.0,0.0,0.07087313,0.0133322105,0.056456618,0.050717734,0.033680595,0.15496281,0.12563695,0.121006146,0.040392354,0.0036667436,0.039901994,0.067609295,0.052475177,0.050682917,0.13728108,0.079883054,0.0015775561,0.018949717,0.0,0.07628898,0.34466416,0.72925806,1.0,0.9185705,0.36623687,0.108353764,0.0,0.0,0.07624754,0.0,0.056846127,0.04710634,0.03203301,0.15954234,0.11846709,0.12810557,0.051568374,0.013517305,0.05450938,0.07294726,0.047695465,0.04045,0.15294707,0.0817333,0.0,0.028350554,0.0,0.09319456,0.3621502,0.72784,1.0,0.95276916,0.40382248,0.12888624,0.0,0.0,0.09124074,0.0,0.058607027,0.050931014,0.032603845,0.14849263,0.09258565,0.110769995,0.047000043],[0.0,0.0,0.0,0.0,0.0,0.098806515,0.13429618,0.09872374,0.21873765,0.13552597,0.18037221,0.17527735,0.28859895,0.23549208,0.15577236,0.26625082,0.38005197,0.6293924,0.6564378,0.4759956,0.13406038,0.02476897,0.0,0.0,0.0,0.0,0.0,0.011590295,0.0,0.0,0.00046861172,0.0,0.0,0.07007476,0.099105254,0.06811387,0.20991406,0.16353567,0.23027208,0.29997253,0.4400888,0.48681277,0.44624978,0.49978477,0.48306322,0.5293481,0.37695223,0.16064245,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.005506739,0.0,0.007421151,0.0,0.0,0.03675902,0.085693195,0.06506352,0.19721532,0.23650281,0.35937637,0.52518016,0.64008695,0.716687,0.6367124,0.60432637,0.46325618,0.32191944,0.13852997,0.042924255,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02015438,0.0,0.00941439,0.0,0.0,0.016614825,0.06902251,0.043669358,0.14951096,0.21722026,0.3729688,0.61566377,0.74716556,0.8646398,0.765422,0.63951117,0.44107527,0.21088105,0.0,0.025654763,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0044500977,0.020442896,0.0,0.008824982,0.0,0.0,0.007881075,0.065518424,0.013676025,0.073388815,0.17815399,0.32568938,0.60089195,0.75771075,0.92876685,0.8343492,0.62024,0.34833986,0.1349303,0.0,0.049550146,0.04394997,0.0,0.0,0.0,0.0,0.0,0.0,0.00077447295,0.022230946,0.0,0.005956158,0.0,0.013623223,0.011460803,0.09309544,0.006482914,0.0,0.09692104,0.17708585,0.49883282,0.76871836,0.9484229,0.7168743,0.3050477,0.0032334626,0.0,0.0,0.060289487,0.060404338,0.014319174,0.007923275,0.0,0.00424543,0.022370182,0.0,0.0,0.027344868,0.0,0.014143884,0.0,0.007873103,0.019274399,0.11900277,0.0,0.0,0.04707647,0.11701141,0.41300988,0.7644847,1.0,0.67875683,0.10327879,0.0,0.0,0.0,0.076438025,0.0686139,0.01238995,0.06071773,0.026672162,0.02418413,0.051859215,0.0008639544,0.0,0.033667214,0.0051940233,0.025814049,0.008662544,0.028937995,0.045573026,0.16343401,0.0,0.0,0.034005404,0.1308212,0.44038814,0.79956704,1.0,0.7159322,0.081376016,0.0,0.0,0.0,0.07617518,0.076526344,0.00014416873,0.0723835,0.047281347,0.035736747,0.07258986,0.0024537146,0.0,0.039906695,0.019126058,0.03672602,0.022748955,0.056178585,0.07629813,0.19855681,0.0,0.0,0.04735753,0.16706029,0.49526876,0.8498018,1.0,0.7522664,0.08814502,0.0,0.0,0.0,0.075803705,0.084382266,0.0,0.076466545,0.058696195,0.036084972,0.08533722,0.0,0.007180594,0.042094693,0.032636352,0.04770889,0.026598081,0.08182463,0.107150294,0.22106072,0.023613751,0.0,0.07294448,0.19545268,0.53485584,0.88379836,1.0,0.76685774,0.10434843,0.0,0.0,0.0,0.075811416,0.0972607,0.0,0.07532251,0.055331275,0.025408998,0.08502063,0.0,0.018309332,0.044511393,0.040285632,0.026605688,0.004260361,0.071743175,0.123979636,0.231388,0.06441616,0.008987978,0.08641642,0.22935382,0.5485324,0.8964563,1.0,0.80067,0.14889784,0.0,0.0,0.0,0.06553051,0.09495538,0.0,0.08430204,0.051685877,0.020366952,0.07791302,0.0,0.015643165],[0.008128621,0.005544767,0.018856518,0.031111866,0.057616003,0.16270491,0.22345959,0.16301516,0.16010824,0.14988783,0.1517707,0.13372152,0.16056585,0.13947967,0.029093765,0.15430433,0.43553317,0.68570966,0.75183845,0.49139488,0.2117244,0.0,0.0,0.0,0.0057872385,0.01700455,0.010684058,0.00020417571,0.008489147,0.0,0.010022223,0.015910774,0.0216152,0.07487959,0.12242655,0.13597968,0.22725645,0.23578265,0.25340348,0.2478765,0.30201155,0.3337571,0.28731284,0.42851192,0.5488693,0.5364286,0.4097342,0.15580155,0.069284946,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017201804,0.00031214952,0.028167106,0.0239373,0.0064189658,0.043571003,0.07311478,0.1531785,0.29344904,0.36318898,0.41966504,0.4500156,0.5147854,0.5367916,0.503252,0.5162008,0.3917908,0.25449207,0.1085729,0.0,0.0,0.0,0.0067153126,0.017027289,0.009108223,0.0028817058,0.0,0.0,0.026573218,0.016777717,0.051604845,0.038661033,0.0026261061,0.04810413,0.06945911,0.15589952,0.27223366,0.3670295,0.5080602,0.6293025,0.7576112,0.7174677,0.6238143,0.49481094,0.28161526,0.12637231,0.0058738813,0.0,0.0,0.0,0.0,0.012190767,0.0037319213,0.015621379,0.0025120676,0.00023496151,0.02539774,0.014268033,0.057106808,0.034069367,0.0,0.04343442,0.055802315,0.09005987,0.15317644,0.2937736,0.5462187,0.7540118,0.8939494,0.8061123,0.64249015,0.4294994,0.19694337,0.06853994,0.0,0.0,0.0,0.0,0.0,0.008460596,0.0,0.029686786,0.015998743,0.0044971257,0.022785068,0.0076736435,0.051004156,0.024965279,0.0,0.055131517,0.06866482,0.057971038,0.095122926,0.21224812,0.55250996,0.8375134,0.99051815,0.74624574,0.39493018,0.078257635,0.0,0.027593255,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.033975728,0.024555564,0.011215106,0.014820583,0.0027786642,0.03836508,0.05629029,0.021927841,0.0938926,0.08655211,0.04776275,0.081015065,0.16207044,0.56724805,0.89895713,1.0,0.7385306,0.26983517,0.0,0.0,0.022956677,0.0,0.0,0.003120333,0.026230253,0.040760905,0.036856547,0.027909622,0.044518627,0.036400817,0.017579205,0.022629179,0.016826741,0.039210536,0.09116937,0.057361454,0.13201597,0.13565087,0.092545226,0.13557382,0.19783312,0.6340778,0.9667405,1.0,0.7573283,0.26358342,0.0,0.0,0.029429704,0.0,0.0,0.020171292,0.06876806,0.07264301,0.07464666,0.06421067,0.070421785,0.05694247,0.027999409,0.034250848,0.04118187,0.05160366,0.121196106,0.09033584,0.15655205,0.19146067,0.15506324,0.22838296,0.26578104,0.7117194,1.0,1.0,0.7700586,0.26253742,0.0,0.0,0.065828204,0.0,0.02289749,0.04821278,0.0942619,0.091328785,0.09943704,0.08334429,0.09610036,0.07926953,0.040968128,0.041458644,0.061830126,0.05646444,0.13371219,0.11508737,0.17302015,0.24105668,0.21784915,0.31789806,0.32657522,0.7516391,1.0,1.0,0.7595691,0.2445896,0.0,0.0,0.107386604,0.0,0.055965573,0.0703427,0.09448723,0.086418256,0.105704635,0.067263566,0.08719733,0.08648291,0.05291214,0.04286349,0.070108116,0.04676374,0.14417496,0.13658127,0.18685351,0.29942286,0.2752819,0.3853382,0.3532709,0.7447243,1.0,1.0,0.78127927,0.28556195,0.0,0.0,0.15921448,0.02028153,0.09278688,0.10211565,0.105025664,0.090226166,0.11728455,0.059860833,0.06955829,0.08546074,0.056655273],[0.01630561,0.048928097,0.01373826,0.04925058,0.21827507,0.33581778,0.30173206,0.30228752,0.25117502,0.1497922,0.15026265,0.12055723,0.08205357,0.040964358,0.03649494,0.23414806,0.64432144,0.89690787,0.687069,0.38245714,0.067872226,0.0,0.00044374168,0.036486328,0.029029407,0.0,0.0,0.0,0.015548773,0.025987595,0.02220156,0.02744107,0.16043916,0.20836273,0.2238155,0.3090222,0.3459409,0.3044242,0.25112242,0.20776874,0.1836093,0.18925108,0.27788937,0.50344104,0.6896674,0.65483665,0.32150477,0.09125298,0.0,0.0,0.026576236,0.033050664,0.01879742,0.0,0.0,0.0,0.032387905,0.035895877,0.030656472,0.026510537,0.11417544,0.13853307,0.17879562,0.31398124,0.44047552,0.48932362,0.41967535,0.3809424,0.38543868,0.4047547,0.46100444,0.5368137,0.45402396,0.2740595,0.05489833,0.0,0.0,0.0,0.024150208,0.035557978,0.03190565,0.0036884248,0.009122454,0.007879078,0.05462233,0.057448864,0.020783916,0.034206204,0.078727394,0.09961583,0.16875952,0.27643305,0.44152635,0.53503704,0.5995425,0.6419766,0.69005656,0.6238449,0.5125981,0.43556094,0.24613972,0.08458992,0.0,0.0,0.0,0.0,0.004629791,0.020334527,0.033103324,0.037265338,0.028700903,0.013647854,0.057801194,0.07192604,0.0065663382,0.029030599,0.05253222,0.06383736,0.11844695,0.15319113,0.3078711,0.49608332,0.7140792,0.83267117,0.872536,0.7044426,0.4925887,0.35969228,0.13163874,0.008903205,0.0,0.0,0.0,0.0,0.0,0.01671172,0.028032474,0.07099672,0.042902313,0.022340521,0.05560167,0.0741788,0.0,0.019876704,0.0536587,0.07120331,0.1176322,0.12455254,0.22047806,0.43490195,0.7650149,0.93455875,0.92507166,0.59140754,0.26686394,0.06989612,0.0019169301,0.027638659,0.0,0.04437433,0.025602832,0.0013599545,0.0030272454,0.018126331,0.036199503,0.08963758,0.052646577,0.03507822,0.031991072,0.035089,0.0,0.055275843,0.11779367,0.11638975,0.13852468,0.13564183,0.17299779,0.40266997,0.80662185,1.0,0.96418107,0.5366467,0.1436699,0.0,0.0,0.03458698,0.028435707,0.112637274,0.099676825,0.115594044,0.14948627,0.13617672,0.14774485,0.10432388,0.05618894,0.045322597,0.03137304,0.029693179,0.0,0.08639074,0.1768189,0.16808559,0.217554,0.21917772,0.24705161,0.48834378,0.88175565,1.0,0.9723083,0.49531746,0.11573365,0.0,0.0,0.034435235,0.045987464,0.15305008,0.15160012,0.18943614,0.23810716,0.22767848,0.23978133,0.14937983,0.07829294,0.06439529,0.043502055,0.04336883,0.0,0.10582236,0.22285157,0.2316519,0.32312572,0.32400444,0.3766349,0.59039915,0.9650404,1.0,0.9765232,0.4550082,0.10740778,0.0,0.0,0.088220626,0.12319529,0.22942558,0.21095079,0.238857,0.29522723,0.28853554,0.29849148,0.19903767,0.101522215,0.0839916,0.050304845,0.057429694,0.0,0.12078707,0.2688853,0.3061104,0.42869824,0.44342917,0.5035376,0.65641546,1.0,1.0,0.96533024,0.4088679,0.11045496,0.0,0.044518523,0.1588764,0.20533778,0.30055457,0.26001674,0.25597912,0.33188522,0.32741094,0.31824657,0.2036953,0.10577311,0.098240204,0.046219938,0.048593186,0.0,0.14935906,0.3158366,0.3664292,0.52539337,0.5464725,0.5876703,0.6804023,1.0,1.0,0.9493842,0.4501384,0.17866167,0.0,0.11993549,0.24525687,0.29833016,0.39603794,0.33142748,0.28398746,0.36687633,0.3509192,0.32562575,0.18539853,0.103343144,0.10453425],[0.022830151,0.036147475,0.023323491,0.123298585,0.32802325,0.5132158,0.5571349,0.4072706,0.32628265,0.22603433,0.066821896,0.05743964,0.022293009,0.013970293,0.21433213,0.5620304,0.86490947,0.90091336,0.73348534,0.23539001,0.042173713,0.0,0.022101954,0.037483282,0.064475,0.006709017,0.004149869,0.0,0.020809315,0.024459578,0.0034313798,0.06726526,0.22808532,0.35120583,0.44563675,0.41810364,0.46956933,0.3807804,0.21360831,0.1138694,0.09965576,0.14589033,0.41798425,0.7083047,0.81119025,0.6303674,0.3673261,0.013415426,0.0,0.0,0.011749104,0.011785686,0.044386014,0.008273959,0.013365909,0.0,0.028518125,0.045548692,0.01609081,0.038014486,0.15468144,0.24644531,0.36628628,0.43765122,0.6053462,0.5264775,0.41486442,0.27847892,0.2926291,0.3030504,0.51416016,0.57518107,0.4244504,0.21793357,0.09690462,0.0,0.0,0.0022761524,0.017410986,0.002669081,0.051240645,0.019977272,0.025906213,0.0043679625,0.044894107,0.07008645,0.033693805,0.02653718,0.12200725,0.20689121,0.32167703,0.4321851,0.6833097,0.65996486,0.6549895,0.58314997,0.6341996,0.506773,0.47868073,0.35083622,0.16452932,0.033519015,0.012691341,0.0,0.0,0.0041353554,0.011532076,0.0042198002,0.04012344,0.029301584,0.02869697,0.013896465,0.054780103,0.076932296,0.04307238,0.021248735,0.11533839,0.15620999,0.20193347,0.2758324,0.5667136,0.7091834,0.81817544,0.8127781,0.7865299,0.5792159,0.4103762,0.20853236,0.067737676,0.0,0.0009767562,0.0,0.0,0.0,0.0011443198,0.006955825,0.03272167,0.028551392,0.025683813,0.014409095,0.053254977,0.07280104,0.038489655,0.0137121305,0.107219525,0.15370521,0.1910219,0.25202516,0.49542654,0.72991544,0.90315264,0.90046924,0.70779777,0.40369606,0.14835781,0.0035652667,0.036192268,0.0050725937,0.053403147,0.051662266,0.0,0.0,0.0,0.011667818,0.033813357,0.04122363,0.030831382,0.022273824,0.03079167,0.038246766,0.010778941,0.016300373,0.10643956,0.18457446,0.20542581,0.26486003,0.46546257,0.77169895,1.0,1.0,0.68612087,0.30484253,0.0,0.0,0.020727515,0.053973205,0.12209585,0.14371943,0.064847074,0.080117315,0.13023034,0.12864602,0.11619668,0.062093668,0.028095804,0.025723055,0.029092163,0.026915327,0.007746123,0.0361562,0.16322333,0.27379957,0.31205446,0.4096272,0.60630363,0.93754965,1.0,1.0,0.64367384,0.2638818,0.0,0.0,0.029546484,0.08603561,0.17041853,0.19593424,0.12141965,0.13721323,0.21122502,0.2098144,0.19429286,0.10503743,0.043462977,0.031096883,0.040402092,0.039660938,0.017308012,0.068549454,0.25317147,0.3881601,0.44287175,0.58123136,0.7991343,1.0,1.0,1.0,0.58424395,0.21924765,0.0,0.0,0.06658338,0.16461994,0.2627194,0.28258383,0.19475572,0.18506633,0.26645285,0.2643403,0.24759799,0.14414246,0.060219266,0.03758867,0.046647474,0.0560771,0.039743386,0.11257821,0.36340034,0.52286345,0.5906357,0.7426447,0.9612325,1.0,1.0,1.0,0.5471127,0.1920172,0.0,0.0,0.12825483,0.26770413,0.37396824,0.37078,0.2619096,0.22099775,0.30240077,0.2864108,0.24739066,0.13159819,0.056881644,0.043632627,0.032403752,0.06051276,0.06873569,0.16853528,0.47641557,0.64480704,0.72122955,0.8333371,1.0,1.0,1.0,1.0,0.55958766,0.23756666,0.008761123,0.07600938,0.2394133,0.37537265,0.5087571,0.50880975,0.37928978,0.29669034,0.34446913,0.30310023,0.25021172,0.12538537,0.059179343,0.053560153],[0.0,0.06419898,0.03038042,0.13523336,0.39768338,0.66819257,0.7302564,0.6970062,0.58693373,0.3808332,0.31430185,0.1432561,0.17353338,0.36201674,0.590286,0.8290319,1.0,0.90384895,0.48768526,0.05024422,0.0,0.009370044,0.008440688,0.020382188,0.0,0.0,0.014201604,0.0,0.0,0.04061742,0.0015020072,0.0819426,0.27850062,0.48574162,0.6024888,0.69963473,0.67574084,0.51790553,0.37358713,0.19514179,0.2214195,0.44703048,0.69859076,0.8495526,0.8981612,0.57961476,0.17266172,0.0,0.0,0.0,0.0,0.0,0.0026794523,0.0,0.01198753,0.0,0.0,0.04722497,0.0031983703,0.02991061,0.17407486,0.35709238,0.51348376,0.69180876,0.76588327,0.6912936,0.54653233,0.4025364,0.39161384,0.5395678,0.6606179,0.592927,0.4193468,0.1947218,0.017069504,0.0,0.0,0.0,0.0061750114,0.0,0.0,0.0,0.006700903,0.012045808,0.01961726,0.053913847,0.0059093237,0.0,0.11778483,0.29584748,0.45837432,0.6850465,0.84692043,0.87892616,0.80694705,0.6925227,0.7022493,0.614884,0.56195086,0.3809784,0.18696082,0.024853058,0.0,0.0,0.0,0.0,0.029254332,0.0,0.005153388,0.01248619,0.022524111,0.013161823,0.03872001,0.04445941,0.0027190596,0.0,0.09934381,0.22528666,0.33902252,0.5102141,0.742273,0.9475669,0.98354656,0.8322833,0.7496893,0.5327632,0.3853609,0.22856422,0.091001645,0.0,0.012867376,0.0,0.0,0.0027792752,0.052812785,0.008964889,0.020496316,0.009236179,0.026959814,0.0060678497,0.039122663,0.018710487,0.0,0.0,0.08654527,0.170492,0.2750232,0.45894963,0.6560502,0.96109813,1.0,0.7976116,0.52497286,0.26115316,0.08097168,0.08853817,0.08585997,0.0,0.05158399,0.04714281,0.0,0.006310202,0.07217477,0.024590664,0.037044555,0.010582484,0.030043587,0.020321012,0.018226728,0.0,0.0,0.0,0.07184391,0.14554982,0.23706442,0.45861816,0.6165695,0.9637829,1.0,0.7800076,0.37068778,0.08144673,0.0,0.0,0.09318485,0.0,0.12553644,0.122522965,0.07055344,0.09851342,0.20291832,0.14699376,0.114134096,0.009168498,0.023458615,0.024685591,0.011359133,0.0,0.0,0.0,0.118566394,0.23337246,0.33937514,0.6272242,0.76884973,1.0,1.0,0.7876999,0.26770997,0.0,0.0,0.0,0.10178062,0.018711448,0.17414244,0.18996964,0.1236932,0.16054988,0.30272597,0.22951901,0.17318362,0.03146784,0.023165248,0.025015488,0.024401687,0.0,0.0,0.010735385,0.22452936,0.3736971,0.4792871,0.83627,0.9671967,1.0,1.0,0.7988819,0.18318437,0.0,0.0,0.0,0.13239136,0.092629984,0.26623625,0.2953737,0.1928242,0.23185095,0.3838455,0.2775488,0.20652565,0.052504204,0.025216997,0.024886556,0.039100036,0.021497145,0.00021314621,0.07569681,0.34423637,0.5231577,0.6240522,1.0,1.0,1.0,1.0,0.7976892,0.13622537,0.0,0.0,0.0,0.20429999,0.2101233,0.38450092,0.39941454,0.2607828,0.2953814,0.44219577,0.2928728,0.19422305,0.03718006,0.0118430555,0.025869794,0.036212742,0.032069266,0.031314306,0.14743693,0.45197046,0.64831185,0.71278375,1.0,1.0,1.0,1.0,0.76494265,0.15303642,0.0,0.0,0.0487919,0.28788018,0.33569193,0.5170257,0.5289887,0.36583474,0.3733623,0.48414248,0.3044302,0.18609186,0.034275077,0.008011453,0.037091196],[0.0011927038,0.009729981,0.056899123,0.16868871,0.42021447,0.587235,0.72243947,0.86962205,0.9257942,0.74573916,0.5808518,0.53732157,0.6031227,0.7448436,0.8703831,0.91701615,0.81920666,0.45837128,0.2707768,0.014881946,0.0,0.0,0.0,0.036371864,0.0468714,0.031162515,0.0,0.0,0.0,0.0,0.011030801,0.098933935,0.286512,0.43959457,0.603424,0.8092455,0.88550526,0.7486187,0.57256687,0.5128122,0.582545,0.74161047,0.8328507,0.7830231,0.5968807,0.2598113,0.10922712,0.0,0.0,0.0,0.0,0.037373118,0.046970658,0.03128697,0.0,0.0,0.0,0.0,0.0,0.06046904,0.18554659,0.33305907,0.51458985,0.7792393,0.88647157,0.8201275,0.68885714,0.63098454,0.6214239,0.6396194,0.600039,0.44133294,0.23216693,0.10462835,0.05536087,0.03390999,0.03330987,0.0,0.0,0.023075938,0.026692353,0.023024142,0.0,0.0,0.0057237595,0.0,0.0,0.03734597,0.13316344,0.26703495,0.46203446,0.7558179,0.9182427,0.9009454,0.79826325,0.7575062,0.6696874,0.48972076,0.38559216,0.22629863,0.07516244,0.034427226,0.033019006,0.03902155,0.055638403,0.0,0.0,0.013463259,0.0215654,0.022695735,0.0,0.0,0.016195685,0.0066185817,0.0,0.03535854,0.10959864,0.1661176,0.31029367,0.57343596,0.8321346,0.92627126,0.8772418,0.80647355,0.6033996,0.3079577,0.176354,0.10184698,0.030014627,0.01734978,0.031361677,0.04014516,0.071019925,0.007946894,0.0,0.012631625,0.013321906,0.013668887,0.0,0.0,0.015656665,0.0037650317,0.0,0.027057327,0.081532,0.104720056,0.23138885,0.48070735,0.78649616,0.90886605,0.90039724,0.70672035,0.40539676,0.07863799,0.0,0.017181635,0.01810003,0.028414562,0.06510092,0.04278232,0.067016445,0.030098267,0.028384037,0.008415766,0.00039687753,0.0009329915,0.0,0.0,0.018505849,0.00807295,0.0,0.015157692,0.062809475,0.06294011,0.17431314,0.42490333,0.76380134,0.8779449,0.9308216,0.67127085,0.25833958,0.0,0.0,0.0,0.0,0.043980874,0.1019294,0.063203245,0.07622218,0.113757536,0.13428508,0.07850675,0.038953967,0.0,0.0,0.0,0.02315145,0.02309008,0.0,0.03236851,0.09741506,0.12390307,0.25286186,0.5265688,0.8823015,0.9524018,0.9717092,0.6801004,0.20129623,0.0,0.0,0.0,0.0,0.05396092,0.14381085,0.08417022,0.093172096,0.15853406,0.20312227,0.13765357,0.085272506,0.007980131,0.0,0.0008594841,0.027725935,0.038658097,0.0,0.06840889,0.17278863,0.23149714,0.37566584,0.68292093,1.0,1.0,1.0,0.70855176,0.17020574,0.0,0.0,0.0,0.0,0.11128524,0.24342313,0.14373606,0.1637811,0.2125262,0.256263,0.17440504,0.114642136,0.02323214,0.0,0.0025006086,0.027561754,0.055994794,0.0,0.12729162,0.2638892,0.34204763,0.47578436,0.81005794,1.0,1.0,1.0,0.7299408,0.16027996,0.0,0.0,0.008773811,0.04507277,0.20988429,0.369351,0.22075668,0.23926958,0.26046437,0.28908783,0.1892302,0.118547745,0.021697678,0.0,0.0,0.013569623,0.04352805,0.009829335,0.1665776,0.32636037,0.4066996,0.5243092,0.8394669,1.0,1.0,0.9967981,0.7115516,0.16145581,0.0,0.0,0.028192699,0.11527358,0.2966469,0.4634409,0.3131074,0.3160278,0.31621107,0.31737506,0.21493118,0.12940235,0.02360405,0.0,0.0],[0.0,0.034724616,0.061974436,0.15805686,0.29237872,0.4463926,0.6239471,0.7705377,0.9328656,0.97482574,0.94909596,0.8748017,0.9414071,0.9622714,0.83615464,0.71603763,0.4376639,0.22219083,0.06869514,0.025444344,0.0,0.044715308,0.06021872,0.0111710355,0.017549455,0.022821277,0.0,0.0,0.0,0.0,0.03603273,0.105805695,0.21161997,0.33200154,0.53704363,0.72947043,0.8931567,0.93663603,0.88486564,0.83694524,0.8689374,0.8864221,0.72521955,0.53152895,0.25228918,0.076351106,0.018403277,0.011798084,0.0,0.013132259,0.027746543,0.024288774,0.021053873,0.03122396,0.0,0.0,0.0,0.0,0.01964935,0.07027571,0.14806251,0.2609914,0.4851542,0.71110904,0.865198,0.9384214,0.9014493,0.8813988,0.8028295,0.6676106,0.41030216,0.19800057,0.058765985,0.03358087,0.08008925,0.009920053,0.008579373,0.009408914,0.010345504,0.015000246,0.0073271394,0.020092227,0.0,0.0,0.0085437745,0.0,0.0038526207,0.031513512,0.111512974,0.22077312,0.468778,0.6973138,0.840886,0.90383756,0.85122126,0.82908285,0.6564428,0.4080063,0.20499563,0.0771382,0.044782005,0.046054907,0.10867098,0.007049307,0.035427816,0.009071946,0.0,0.023109019,0.017396122,0.018374793,0.0,0.0,0.027539939,0.0,0.0066408217,0.024668664,0.099041075,0.15067355,0.35686415,0.57805574,0.7803224,0.8961403,0.84315974,0.69142246,0.438318,0.14797957,0.06765589,0.052665785,0.086410314,0.05799242,0.086736605,0.023006529,0.053159826,0.043860175,0.0027523637,0.03355585,0.024106443,0.020790689,0.0,0.0,0.041539036,0.0,0.014730714,0.02399598,0.1007079,0.11140683,0.2964928,0.5041563,0.74600863,0.8761975,0.82233566,0.50199956,0.21425858,0.0,0.0,0.058187112,0.1142088,0.065722205,0.06391136,0.03226313,0.031475738,0.07510025,0.018388338,0.04011134,0.024724185,0.0094347745,0.0,0.000054359436,0.046655536,0.0,0.019359425,0.02350416,0.09309533,0.088216394,0.24810794,0.44062757,0.7122434,0.8458156,0.8019699,0.42881882,0.10421222,0.0,0.0,0.08535526,0.13441183,0.07396959,0.06517034,0.0334263,0.038740993,0.13118504,0.06741875,0.08739011,0.04016442,0.0061625615,0.0,0.004035488,0.054500334,0.0,0.028763935,0.038302176,0.12715727,0.13798049,0.3062113,0.48221064,0.7566922,0.84764165,0.79767174,0.4057756,0.08124258,0.0,0.0,0.08754096,0.12264083,0.09537682,0.06880133,0.030762784,0.067924134,0.17056486,0.10609828,0.12994866,0.06215477,0.018340439,0.0,0.00013890862,0.06575078,0.0076915473,0.041806623,0.060002267,0.18645346,0.22770001,0.4017591,0.58327967,0.8551219,0.88033533,0.81595504,0.40540612,0.085584536,0.0,0.0,0.0812638,0.12789132,0.15917493,0.091797605,0.049332373,0.105134435,0.20976482,0.13345851,0.1594295,0.07835238,0.028993249,0.0,0.0,0.069979504,0.018789679,0.05595196,0.09669615,0.25371912,0.30696058,0.47535294,0.648003,0.9225341,0.88472384,0.8170088,0.41691136,0.10413018,0.0,0.0,0.089023694,0.17971368,0.26323706,0.14847095,0.07833251,0.14379321,0.22011289,0.1367269,0.17347687,0.07941278,0.037125677,0.0,0.0,0.056071915,0.00457336,0.038555562,0.11487381,0.28264982,0.32441595,0.45310622,0.6071278,0.8756431,0.8069388,0.7709059,0.4057464,0.11422761,0.0,0.0,0.078635424,0.21353142,0.3132683,0.20345058,0.11284559,0.16836873,0.22468436,0.1139375,0.17662024,0.071642876,0.035353355,0.0,0.0],[0.0,0.03553226,0.051912427,0.08508071,0.13763586,0.19750807,0.22771493,0.3999917,0.66877544,0.7762619,0.8645897,0.74294597,0.70933074,0.5468726,0.42445725,0.2239871,0.08931698,0.0,0.0,0.0,0.0,0.017049164,0.0,0.0,0.018876195,0.016481906,0.017288096,0.0,0.0,0.01538717,0.03558758,0.057555646,0.088675715,0.16046555,0.21139193,0.39342022,0.6533187,0.7534122,0.8199107,0.72347605,0.688857,0.5050061,0.34683686,0.14500657,0.061532624,0.0,0.0,0.0,0.008641832,0.025580376,0.011069283,0.0,0.036125004,0.011825398,0.0062694177,0.0,0.0,0.014186449,0.03503295,0.04703167,0.07166691,0.15048538,0.21624377,0.37570834,0.60843986,0.7556131,0.7889887,0.6742737,0.5769733,0.330099,0.1169481,0.005075142,0.04090949,0.0,0.0,0.0,0.020932026,0.022084318,0.027707696,0.0,0.01348827,0.0,0.0,0.0,0.0,0.0,0.024684824,0.020202123,0.053642616,0.16224274,0.24233785,0.36215612,0.5204615,0.64545697,0.6402418,0.5136915,0.36470658,0.13326684,0.0,0.0,0.046699725,0.03231649,0.0,0.0,0.011250019,0.008865938,0.037410446,0.0,0.025148593,0.0,0.0,0.0,0.0,0.0,0.01885198,0.0,0.039809935,0.12448925,0.209138,0.35231978,0.49500352,0.60942715,0.53237253,0.37592244,0.19676632,0.019495904,0.0,0.01839406,0.08547928,0.06090278,0.015386045,0.0,0.004925117,0.013176113,0.026772216,0.0,0.01389838,0.0,0.0,0.0,0.0,0.0,0.019410856,0.0,0.028188676,0.06459228,0.16074304,0.31592748,0.47944272,0.60534996,0.47460216,0.29637462,0.07942092,0.0,0.0,0.057597682,0.087094545,0.035429142,0.0,0.0,0.005699083,0.0255057,0.030398272,0.0,0.008506633,0.0,0.0,0.0,0.012423128,0.0,0.013650671,0.0,0.023580916,0.00417307,0.11509923,0.24222773,0.44367397,0.60120636,0.4860534,0.2619873,0.0,0.0,0.0020586252,0.057637252,0.039085835,0.0009808838,0.0,0.0,0.0,0.014924899,0.0320618,0.0,0.001685679,0.0,0.0,0.0,0.025022537,0.0033548027,0.017937183,0.0,0.03625235,0.013278514,0.11997266,0.21948856,0.43086326,0.60227066,0.4944384,0.28032818,0.0,0.0,0.020487212,0.07812373,0.044643812,0.005175367,0.0,0.0,0.0,0.017935127,0.04662305,0.0011386424,0.0045383573,0.0022871196,0.0,0.0,0.033744954,0.009692289,0.027468786,0.0,0.074253336,0.07000254,0.17420357,0.24238563,0.4576462,0.6472188,0.533427,0.328244,0.0,0.0,0.044768058,0.09262127,0.070301026,0.03264694,0.0,0.0,0.0,0.035873823,0.07216795,0.0034175962,0.0,0.000845924,0.0,0.0,0.032913722,0.013230212,0.030840307,0.0021499395,0.10489955,0.09324375,0.20411286,0.2509385,0.47625005,0.6732517,0.5637298,0.37396413,0.010177977,0.0,0.07526718,0.10836559,0.11999442,0.10219543,0.030259877,0.0,0.0,0.035608776,0.077597894,0.0,0.0,0.0,0.0,0.0,0.025640331,0.014424123,0.025198177,0.0,0.08803654,0.06220624,0.17052683,0.21517847,0.43727732,0.60980624,0.5224838,0.37098712,0.0673683,0.0,0.07472616,0.074425474,0.122990794,0.131973,0.06555468,0.012323752,0.006654978,0.03765256,0.07070899,0.0,0.0,0.0,0.0,0.0],[0.0038063824,0.0,0.023962617,0.08191085,0.041667476,0.039577357,0.047530554,0.048038952,0.14427106,0.18815058,0.20997787,0.19849628,0.116257,0.0,0.0,0.0,0.0,0.006832987,0.014369637,0.0,0.055262,0.0,0.0,0.0,0.012800686,0.010671914,0.021639012,0.015663117,0.0030436963,0.0,0.011720419,0.05489307,0.024476402,0.031568244,0.049512163,0.052548476,0.16014926,0.21228716,0.21777588,0.22576463,0.17643075,0.036891334,0.0,0.0,0.0,0.0033381432,0.033199713,0.010210976,0.07267263,0.0,0.0,0.0,0.0063134134,0.01865948,0.016992487,0.017681494,0.0015047044,0.0,0.0,0.031636402,0.018324777,0.048023567,0.057520345,0.06757571,0.18304598,0.28375846,0.26085418,0.20108795,0.15905091,0.0,0.0,0.0,0.024326973,0.031850986,0.024163924,0.028794162,0.0632724,0.0,0.0,0.0,0.0,0.00618919,0.00265114,0.01023268,0.00072972476,0.0,0.0,0.00827603,0.025780633,0.08595526,0.08203243,0.10693873,0.1895189,0.2818278,0.22714017,0.11354062,0.04755556,0.0,0.0,0.021917053,0.06944093,0.04443741,0.0,0.018878505,0.030355595,0.014129974,0.0,0.0,0.0,0.0,0.0,0.013824455,0.0,0.0,0.0,0.006023161,0.03126496,0.08532578,0.07532969,0.14428909,0.23530263,0.30332968,0.18488362,0.050601177,0.0,0.0,0.020351313,0.074708,0.07946605,0.05168596,0.0,0.004588276,0.0030083507,0.019263782,0.0,0.0,0.0,0.0,0.0,0.0102638155,0.0058189034,0.0,0.0,0.007251218,0.037243314,0.044292644,0.07411854,0.16214065,0.26591033,0.34721047,0.17378397,0.019968107,0.0,0.0,0.041321307,0.10927332,0.061488554,0.022047475,0.0,0.0,0.0,0.0354596,0.0,0.0,0.010041468,0.0,0.00013279915,0.00469321,0.006849818,0.0,0.0,0.013679542,0.051054746,0.0011749268,0.05760636,0.15322046,0.25028116,0.4175614,0.24968375,0.0,0.0,0.0,0.06992978,0.0828882,0.025260158,0.0,0.0,0.0,0.0,0.05131585,0.018694893,0.016544782,0.058258086,0.0,0.0,0.0,0.016454123,0.0,0.0,0.030754693,0.080786005,0.0,0.061014295,0.14555645,0.2400748,0.46025074,0.32439542,0.024457395,0.0,0.015560932,0.101587035,0.09973418,0.027758114,0.0,0.0,0.0,0.0,0.065576054,0.039745905,0.017865308,0.09144046,0.010206535,0.0,0.0,0.024715379,0.0,0.0,0.07712616,0.14024608,0.052774765,0.10455277,0.16058667,0.25600147,0.5240203,0.4200912,0.081160605,0.0,0.034813836,0.13497402,0.11555524,0.037679978,0.0,0.0,0.0049363375,0.015032552,0.09141321,0.060381234,0.009027787,0.10399894,0.01551199,0.0,0.0,0.035638936,0.0,0.0,0.112869635,0.17450607,0.06494407,0.12039981,0.1646994,0.264421,0.57181066,0.49923444,0.13007352,0.0,0.069199234,0.17431098,0.14940393,0.08652088,0.01943808,0.027368829,0.028522901,0.014322996,0.097000524,0.06102752,0.0,0.12755671,0.012546271,0.0,0.0,0.04273902,0.0,0.0,0.10156047,0.15352887,0.024038285,0.10100457,0.124727815,0.23105133,0.5290255,0.47923756,0.14105313,0.0,0.090350054,0.17116773,0.14083154,0.11400243,0.055599347,0.059712112,0.04204446,0.024971984,0.08424087,0.041614175,0.0,0.12633689,0.005222082,0.0,0.0],[0.021221906,0.026515923,0.010786347,0.0,0.0,0.0001899451,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0036210567,0.0,0.0,0.0,0.036552384,0.04594537,0.017127857,0.0,0.022393502,0.027528122,0.006746471,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0041100085,0.0,0.0,0.0,0.02034992,0.031574577,0.003046155,0.0,0.0153123215,0.023356497,0.001986593,0.0,0.0,0.0,0.0,0.012808517,0.047996044,0.0,0.0,0.0,0.0,0.0048550814,0.0,0.0,0.019278899,0.03448256,0.0,0.0,0.0018953085,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006801918,0.010196365,0.0022898614,0.0,0.0,0.0,0.0,0.04577683,0.07942564,0.015025437,0.0,0.0,0.0,0.0,0.0,0.0,0.008281067,0.030948281,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0035953373,0.0108672455,0.0047820807,0.0,0.026029855,0.011696875,0.0,0.06090434,0.074046925,0.03403005,0.0,0.0,0.0,0.0,0.02282735,0.01409667,0.013204709,0.0480311,0.0075865164,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0012501031,0.019181646,0.0,0.0,0.023577884,0.0021516085,0.0,0.080162235,0.06527955,0.036296166,0.0,0.0,0.0,0.023086682,0.05255059,0.01431223,0.0,0.030264638,0.0136856735,0.0,0.0,0.007035166,0.011046797,0.0,0.009684272,0.0,0.0,0.0,0.0,0.0034688115,0.0,0.0,0.0024522692,0.0,0.0,0.07009441,0.059303947,0.035882197,0.0,0.01445698,0.034097537,0.03757848,0.058594808,0.0,0.0,0.0,0.0,0.0,0.0,0.00080120564,0.01772385,0.0,0.0035300702,0.0,0.0,0.0,0.0,0.007656552,0.0,0.0,0.000023066998,0.0,0.0,0.0468216,0.045241416,0.03997305,0.0045765787,0.053253435,0.08429444,0.044003256,0.078678995,0.0067844093,0.0,0.0,0.0,0.0,0.0,0.0,0.018172875,0.0,0.0,0.0,0.0,0.0,0.0,0.0008147061,0.0,0.0,0.030035779,0.031588368,0.0,0.064068094,0.0528163,0.068561435,0.056018643,0.1017222,0.13407081,0.050509624,0.10257355,0.024886332,0.0,0.0,0.0,0.0,0.0,0.0014041662,0.025512062,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.042904064,0.07235569,0.03145188,0.08282629,0.054923728,0.098499954,0.1024048,0.15242533,0.18409494,0.06539215,0.1393517,0.06685665,0.0029778332,0.0,0.026657045,0.0011738539,0.0,0.0,0.016609415,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035673402,0.07910678,0.027453087,0.050560333,0.026843876,0.10919416,0.11959452,0.15436377,0.18964675,0.06790974,0.14203337,0.07173566,0.025498375,0.029916808,0.06096118,0.019140087,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.007966392,0.022788249,0.0,0.038984314,0.04080315,0.0,0.0,0.0,0.021002583,0.016984195,0.0,0.0,0.02237799,0.0,0.0,0.019604683,0.013752967,0.019909032,0.0,0.02140195,0.0,0.0,0.0,0.048870258,0.0034343302,0.020565026,0.01747913,0.0,0.014268786,0.018708557,0.0,0.035794146,0.036354028,0.0,0.0,0.0,0.021102816,0.01777614,0.0,0.0,0.055952266,0.016527116,0.0,0.044132434,0.024802878,0.0045316666,0.0036232471,0.013018891,0.0,0.0,0.0,0.058639772,0.0017053187,0.013557531,0.019075371,0.001555413,0.0256292,0.0159958,0.0,0.021665528,0.022108182,0.0017116964,0.008359514,0.021878555,0.016976304,0.0,0.0,0.0,0.06392616,0.030173257,0.0,0.057173938,0.027383685,0.0,0.0029056668,0.02372583,0.0,0.0,0.0,0.049362138,0.0,0.0012918264,0.015667446,0.0029869229,0.021683969,0.01535517,0.0,0.023611084,0.011153519,0.027481355,0.033913694,0.04983207,0.0,0.0,0.0,0.0,0.025364503,0.031787597,0.0,0.032255962,0.00086413324,0.0,0.0,0.03594798,0.0071790516,0.0,0.0,0.015348233,0.0,0.0,0.012274981,0.0021494627,0.017708883,0.020446606,0.00451003,0.025182106,0.004492387,0.032792702,0.04455676,0.045255072,0.0,0.0,0.0,0.0,0.0,0.02100689,0.0,0.0,0.0052141547,0.0,0.0,0.029205665,0.014610782,0.0,0.0,0.0033659637,0.0,0.0,0.0060281977,0.004706949,0.034391195,0.021290652,0.021731712,0.015192777,0.0,0.007060528,0.05498387,0.048198543,0.0,0.0,0.0,0.0,0.0130061135,0.018491484,0.0,0.0,0.0,0.0,0.0,0.016669743,0.029734,0.0057372674,0.0,0.02346094,0.0,0.0,0.0,0.005121872,0.039699994,0.018792488,0.02574534,0.0,0.0,0.0,0.05254188,0.051953383,0.015509285,0.0036182255,0.021330953,0.03749746,0.023783617,0.0060219243,0.0,0.0,0.0,0.0,0.0,0.0060834587,0.027851261,0.0037474185,0.0033801645,0.020796828,0.020760179,0.0,0.0,0.0134482235,0.060853206,0.042292997,0.03286188,0.0038513541,0.0,0.0,0.052048087,0.055299602,0.036010496,0.03789883,0.0620424,0.05523382,0.03517078,0.017993465,0.0,0.0,0.0,0.0,0.0,0.0,0.017040275,0.0027251244,0.010573596,0.031018592,0.05130642,0.0034029186,0.0,0.0131081715,0.070463106,0.05642139,0.038941823,0.024306253,0.0,0.0,0.08015448,0.078301445,0.06408211,0.07800123,0.095191,0.0661236,0.051321328,0.044550195,0.0,0.0,0.0,0.0,0.0,0.004137397,0.0073454827,0.002983451,0.018372335,0.039090008,0.06328917,0.021968514,0.0,0.015495293,0.08191311,0.072715454,0.031533748,0.036513038,0.0,0.0,0.09969885,0.104207166,0.10533229,0.122007415,0.12874013,0.08498904,0.073936924,0.08077508,0.0,0.0,0.0,0.0,0.0,0.004168242,0.0,0.0,0.029745758,0.049130835,0.07395904,0.038161896,0.0,0.010895647,0.05808299,0.048406124,0.0011142045,0.03344381,0.0,0.0,0.07511993,0.10717912,0.14738314,0.13999356,0.12789191,0.08790028,0.087076865,0.09366219,0.0,0.0,0.00078848004,0.0,0.0,0.0,0.0,0.0,0.020584092,0.046802804,0.06390645,0.04381454,0.0],[0.0,0.0,0.015819915,0.0,0.059954464,0.020009115,0.0037177652,0.0,0.0,0.0,0.022233948,0.007112071,0.0153578,0.02372013,0.0043255836,0.0,0.0,0.052811258,0.028412089,0.0,0.0,0.0,0.0,0.006979391,0.01588089,0.0,0.0,0.0,0.0,0.00021886826,0.014504395,0.0,0.050328694,0.0130749345,0.0,0.0,0.0,0.0,0.012738712,0.011532143,0.017698102,0.03476283,0.013924286,0.0,0.0,0.047220305,0.023565315,0.0,0.0,0.0,0.0,0.00576178,0.008459941,0.0,0.0,0.0,0.005310312,0.007766746,0.017018303,0.0,0.032766365,0.0018197149,0.0,0.0,0.0,0.0,0.0,0.0,0.011087276,0.021536909,0.0,0.0,0.0,0.036887184,0.025755309,0.019262426,0.0,0.0,0.0036322773,0.0014369339,0.0,0.0,0.0,0.0,0.005892813,0.008284345,0.020377591,0.0,0.02130796,0.0,0.0042579174,0.011711545,0.0074647963,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0031051785,0.000837028,0.03388167,0.012029506,0.004768789,0.0048255622,0.0,0.0,0.0,0.0,0.0,0.0069112256,0.007474713,0.026394218,0.0,0.023197137,0.0,0.0,0.0,0.0004950315,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.038496725,0.020752065,0.00283283,0.0,0.0,0.0,0.0,0.0,0.0,0.0099103525,0.012734197,0.024937585,0.0018237531,0.002956897,0.0,0.0,0.0,0.0,0.00070366263,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02935052,0.026109688,0.006061457,0.0,0.0,0.0,0.0,0.0,0.0,0.008624531,0.011501096,0.015456557,0.00013537705,0.0,0.0,0.0,0.0,0.0,0.013091177,0.03816746,0.050031908,0.000999406,0.0,0.0,0.0,0.0,0.0,0.0,0.023454882,0.03195344,0.006028801,0.0,0.0,0.0013884902,0.0,0.0,0.0,0.012836754,0.023167484,0.018512353,0.0,0.0,0.0,0.0,0.0,0.0,0.018382363,0.05553092,0.07250688,0.019119225,0.0,0.0,0.0,0.0,0.0,0.0,0.023246087,0.030807987,0.008587569,0.0,0.0,0.0070993304,0.0,0.0,0.0,0.016073912,0.036191188,0.028323181,0.005404502,0.0,0.0,0.0,0.0,0.0,0.022135012,0.064120755,0.08171506,0.031917542,0.0056696534,0.0,0.0,0.0,0.000044971704,0.0,0.020535395,0.02255202,0.015124135,0.0,0.0,0.010109954,0.0,0.0,0.0,0.021840245,0.048427254,0.040918626,0.013016544,0.0,0.0,0.0,0.0,0.004549101,0.040297434,0.0903876,0.092958644,0.044982746,0.01582592,0.0,0.0,0.0,0.015530117,0.0,0.017867982,0.014827035,0.020860866,0.0,0.0,0.013645969,0.0,0.0,0.0,0.024165511,0.040516205,0.029503383,0.00022518635,0.0,0.0,0.0,0.0,0.01080022,0.071533225,0.110515416,0.09519634,0.05353784,0.025411077,0.0,0.0,0.0,0.028752856,0.0,0.016148046,0.013200112,0.02302906,0.0,0.0,0.017344855,0.0,0.0,0.0],[0.024913646,0.0060605854,0.0065659583,0.0,0.010892361,0.0,0.017852299,0.0,0.0024122596,0.004783675,0.0,0.0,0.0027369857,0.0,0.0,0.0,0.03269256,0.0,0.0,0.0,0.0,0.053093098,0.027183354,0.0163479,0.0,0.010585025,0.0019073337,0.018949777,0.02781754,0.0025714338,0.004701808,0.003486216,0.0,0.0,0.011677489,0.0,0.0025080591,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028902404,0.0,0.0,0.0,0.0,0.045621775,0.017385647,0.015968814,0.0,0.0018274486,0.0,0.013695389,0.0210284,0.0,0.0003554374,0.0066417307,0.0,0.0,0.00519605,0.0,0.010091722,0.0,0.0,0.0,0.0,0.0,0.0,0.0040432364,0.0071691796,0.0,0.0,0.0,0.0,0.04508371,0.011255302,0.0066201687,0.0,0.0,0.0,0.0008236319,0.019388497,0.0,0.005933866,0.018533885,0.0011045933,0.0,0.018977888,0.0,0.011210807,0.0035138428,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011248134,0.0,0.0,0.041986726,0.0016957521,0.0,0.0,0.0070578456,0.0,0.0,0.020333953,0.0,0.00922057,0.03150356,0.013889357,0.004104346,0.028457716,0.0,0.005440742,0.009522639,0.0,0.0,0.0031974167,0.0020041764,0.0,0.0,0.0,0.0,0.021589316,0.0,0.0,0.031570166,0.0,0.0,0.0026660264,0.010356188,0.0,0.0,0.022602975,0.0,0.0,0.034023546,0.009351648,0.0,0.040949047,0.0,0.005585134,0.026084594,0.0,0.0,0.010809615,0.006933242,0.01141081,0.0,0.0,0.0,0.03359881,0.0,0.0,0.017835267,0.0,0.0,0.005834222,0.00529404,0.0,0.0,0.028865606,0.00740432,0.0,0.007322952,0.0,0.0,0.037629128,0.0,0.03655552,0.06314432,0.0,0.0,0.010393515,0.001618728,0.020882264,0.0,0.0,0.0,0.03611912,0.0,0.0,0.0,0.0,0.0,0.0046425015,0.0056650043,0.0,0.0,0.03333895,0.00834918,0.0,0.0,0.0,0.0,0.026619114,0.0023296028,0.06120705,0.10327338,0.0,0.0,0.017370597,0.0,0.027503848,0.0,0.0,0.0106147155,0.03947003,0.0,0.0,0.0,0.0,0.0018540323,0.019505918,0.03332161,0.0,0.0,0.039664976,0.015861705,0.0,0.0,0.0,0.0,0.012636796,0.0063232407,0.06699951,0.130992,0.0,0.0,0.016603075,0.0,0.04005461,0.0,0.0,0.014990605,0.03743173,0.0,0.0,0.0,0.0,0.011589751,0.025584482,0.04965198,0.0,0.0,0.045817405,0.026908696,0.0,0.0,0.0,0.0,0.0,0.0000397861,0.050427362,0.1324703,0.0,0.0,0.014294513,0.0,0.053509727,0.0,0.0,0.019970812,0.034502126,0.0,0.0,0.0,0.0,0.02013933,0.030024752,0.064446524,0.00040329993,0.0,0.04824765,0.042372234,0.0,0.0,0.0,0.0,0.0,0.0,0.03631264,0.12019059,0.0,0.0,0.012959905,0.0,0.06422517,0.0032131523,0.0,0.016914457,0.03105829,0.0,0.0,0.0,0.0,0.025637306,0.028034799,0.07402613,0.007573627,0.0],[0.014704749,0.0,0.0,0.0,0.018542372,0.0,0.008777849,0.0,0.0,0.0,0.047227822,0.0028144121,0.0021079183,0.0,0.011299074,0.0,0.03832023,0.018143795,0.0,0.0,0.015393473,0.0016404688,0.01917778,0.0,0.018686034,0.003939733,0.0,0.0,0.02095098,0.0,0.0,0.0,0.013197675,0.0,0.0,0.0,0.0,0.0,0.02720312,0.010629378,0.027685411,0.009361498,0.021976031,0.0,0.013314821,0.015810318,0.0,0.0,0.030475512,0.01638522,0.022195756,0.0,0.004901737,0.0,0.0,0.0,0.010628857,0.0,0.0,0.0,0.014212422,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.038624495,0.022935025,0.02769962,0.0,0.005488962,0.024290614,0.0,0.0,0.0368054,0.030299962,0.029389001,0.0,0.0014107525,0.0,0.0,0.0,0.00014011562,0.0,0.0,0.0,0.022890009,0.0,0.013755158,0.0,0.0,0.0,0.0,0.007750526,0.056982517,0.027628802,0.016967744,0.0,0.005217448,0.032871224,0.0,0.0,0.013296671,0.024633825,0.02024746,0.0,0.007807955,0.0,0.0041623116,0.0,0.0,0.0,0.0,0.0003017187,0.03342493,0.0,0.024125889,0.0,0.0,0.0,0.0,0.018391505,0.06655813,0.03535816,0.023105726,0.0,0.0,0.030664995,0.0,0.0,0.0,0.011483401,0.01601088,0.0034570992,0.017871626,0.0,0.009409949,0.0,0.0,0.010812186,0.0,0.009199798,0.02202247,0.0,0.029287785,0.0,0.0060834885,0.0,0.0,0.026903376,0.057466052,0.030787498,0.022589669,0.0,0.0,0.023436189,0.0034730583,0.012998506,0.01162903,0.02742175,0.0093823,0.010061048,0.024657756,0.0,0.0033875704,0.0,0.0,0.020965733,0.0,0.0,0.0,0.0,0.015339784,0.0,0.045777142,0.0072751865,0.0,0.024964571,0.03477715,0.011568733,0.016595028,0.0,0.0,0.0040019155,0.0,0.0035105795,0.0045726597,0.027971454,0.0,0.008236773,0.032874554,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.027156405,0.0,0.10063578,0.015058294,0.0,0.02427692,0.022481635,0.0,0.0025365204,0.0,0.0,0.0,0.0,0.0,0.0,0.0101145655,0.0,0.017287873,0.060197882,0.008195743,0.0007145256,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021225661,0.0,0.13840345,0.02649153,0.0,0.027404167,0.03637989,0.0,0.0054525584,0.0,0.0,0.0,0.0,0.0,0.0,0.008148983,0.0,0.023147374,0.07425888,0.018154196,0.012563765,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0022128671,0.0,0.1331414,0.0051101,0.0,0.03473921,0.054278933,0.0,0.009467714,0.0,0.0,0.0,0.0,0.0,0.0,0.009375781,0.0,0.031901695,0.09147212,0.025468387,0.022540458,0.0,0.0,0.0042234957,0.0,0.0,0.0,0.0,0.0,0.0,0.12784325,0.0,0.0,0.04138968,0.06426985,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014429867,0.0,0.03395167,0.095790744,0.02451735,0.024294116,0.0],[0.015774429,0.016714923,0.04118423,0.036706477,0.030328333,0.028896183,0.0,0.0,0.049896553,0.009324692,0.010412097,0.025313638,0.02137386,0.0,0.0,0.013181277,0.04001628,0.0,0.003584832,0.032205768,0.07778254,0.036259808,0.046606682,0.006033115,0.021635696,0.0,0.00072300434,0.0051205456,0.020833515,0.005309731,0.019598573,0.018127427,0.0137842,0.029874183,0.0,0.0,0.06970948,0.0069853514,0.010892995,0.03826435,0.043268792,0.0,0.0,0.0,0.029864974,0.0,0.009199038,0.027313136,0.07131682,0.036847703,0.029664896,0.006798893,0.013989672,0.0,0.010921612,0.0,0.015123941,0.0,0.0014443398,0.0061471984,0.00384593,0.044365287,0.0070963725,0.0,0.08724106,0.0108053535,0.0,0.019383155,0.0438803,0.0,0.0,0.0,0.050743736,0.0,0.002375424,0.031394802,0.07300339,0.051731408,0.029727362,0.010873757,0.020460986,0.0,0.026377872,0.0,0.0,0.0,0.0040314496,0.01723639,0.01174017,0.06679403,0.038940758,0.00426732,0.08234702,0.008237876,0.0062625036,0.020674422,0.048716784,0.0,0.0,0.0,0.059348002,0.013528869,0.0015186667,0.028580971,0.052336626,0.047881603,0.041347735,0.004674986,0.027643166,0.0,0.030717283,0.0,0.0,0.0,0.0,0.030654535,0.018229619,0.080506206,0.052108876,0.0059788898,0.073460534,0.0053268224,0.014816105,0.0146088675,0.047874443,0.0,0.009794436,0.0,0.04429102,0.030416124,0.0037620217,0.037956715,0.03935729,0.06265064,0.059689157,0.009259425,0.0336354,0.0,0.030345358,0.0,0.0,0.0,0.0015290976,0.040871166,0.009501778,0.08853078,0.05013694,0.007814094,0.06233345,0.000051751733,0.02864571,0.0094276,0.050060496,0.0,0.017719321,0.0,0.025157884,0.024158098,0.0,0.07654958,0.0817951,0.10052836,0.05793746,0.003989607,0.04125692,0.0,0.027284823,0.0,0.0,0.0,0.0,0.019693814,0.0,0.06343514,0.027339973,0.023352236,0.077307165,0.0,0.030811816,0.00039969385,0.06334198,0.0069782063,0.024445668,0.0,0.027035996,0.017299518,0.0,0.053697146,0.08227211,0.10390741,0.044695236,0.007154964,0.061317973,0.0,0.026471533,0.0,0.0,0.0,0.0053242743,0.025968105,0.0,0.051712364,0.037695795,0.06506358,0.119793855,0.0,0.038436852,0.0,0.07492527,0.0,0.025619067,0.0,0.012078598,0.00469546,0.0,0.0012190491,0.046177544,0.10274924,0.03170412,0.00549601,0.08539525,0.01788842,0.045942806,0.012129977,0.0,0.0,0.007510148,0.024206728,0.0,0.029911064,0.03512761,0.09055185,0.1662167,0.0,0.019725032,0.010524027,0.087916456,0.0055807084,0.023065396,0.0,0.0,0.0,0.0,0.0,0.042477503,0.08662025,0.027171671,0.0064323246,0.10433081,0.025672384,0.06399193,0.017638288,0.0,0.0,0.0009403229,0.015133619,0.0,0.0,0.023497686,0.095790416,0.17458522,0.0,0.019027159,0.029928222,0.116497874,0.013146095,0.013966672,0.0,0.0,0.0,0.0,0.0,0.042699628,0.07607123,0.02295243,0.012956686,0.12669972,0.035083234,0.081473306,0.024099484,0.0,0.0,0.0,0.00017647445,0.0,0.0,0.0269515,0.1012941,0.1753593,0.0,0.029261664,0.049707413,0.11442042,0.0043825507,0.016916402,0.0,0.0,0.0,0.0,0.0,0.033484943,0.07279792,0.028219476,0.017642587,0.14517264,0.03704582,0.08929607,0.0314319],[0.0,0.03547173,0.030230828,0.0,0.020568438,0.012092628,0.027161002,0.0068924204,0.020565003,0.0647648,0.035467267,0.03751263,0.0,0.00661318,0.0,0.0,0.025981702,0.02294334,0.05849842,0.040255845,0.13372755,0.13086715,0.054723747,0.0,0.02881883,0.0,0.0,0.003797844,0.0,0.028348073,0.022493541,0.0,0.008768506,0.015418984,0.024573937,0.0,0.0066643804,0.050779082,0.03475889,0.050909586,0.004968971,0.027308084,0.003371492,0.0,0.0067701787,0.013791077,0.04582198,0.027285911,0.13522522,0.118660256,0.035796992,0.0,0.034431323,0.0,0.0,0.0,0.0,0.03177744,0.03291408,0.0,0.008475453,0.032455787,0.043676488,0.0036960095,0.013661243,0.034218237,0.022864208,0.052769363,0.030737504,0.04745225,0.019943923,0.0,0.0,0.0,0.01805465,0.037925288,0.1668958,0.13266177,0.044555247,0.0,0.046575412,0.0,0.0,0.0,0.0,0.034018643,0.033999823,0.0,0.023489252,0.055123627,0.06365221,0.018758863,0.01960501,0.030576907,0.024758086,0.050155878,0.039735228,0.037222773,0.02744577,0.0,0.0,0.0,0.0,0.04339522,0.17352575,0.14551161,0.071781054,0.0,0.044477046,0.0,0.0,0.0,0.0,0.020561434,0.013164774,0.0,0.030790128,0.058148414,0.07198628,0.015654624,0.010866694,0.022782601,0.017196849,0.04567849,0.042710133,0.022758856,0.030544527,0.0,0.0,0.0,0.0,0.05895794,0.18252042,0.1428992,0.09671657,0.0,0.027294867,0.0038490444,0.0,0.0,0.0,0.0069843754,0.0,0.0,0.03499347,0.06848514,0.08819397,0.019085295,0.0073595494,0.024476446,0.025027208,0.028402552,0.03303244,0.028053492,0.03696204,0.019936144,0.0,0.0,0.0,0.1358479,0.24285266,0.15531935,0.079955585,0.0,0.018903501,0.017691582,0.0,0.0,0.0,0.0,0.0,0.0,0.041306317,0.07069987,0.094626695,0.023046568,0.017781503,0.0327501,0.042719595,0.014228649,0.04024937,0.049682803,0.05700302,0.071478,0.0209928,0.0,0.0,0.1542384,0.23582353,0.13846438,0.04782352,0.0,0.024972975,0.029359289,0.0,0.0,0.0,0.0,0.0,0.0,0.08746271,0.09362271,0.11928268,0.046395406,0.052237272,0.062553436,0.070765644,0.02175562,0.06699937,0.08465451,0.07595709,0.09795727,0.053594977,0.0,0.0,0.12633358,0.20230001,0.14178751,0.0457031,0.0,0.028747976,0.04278411,0.0,0.0,0.0,0.0,0.0,0.0,0.082318306,0.086195,0.12633316,0.07196128,0.088342875,0.103481926,0.10512607,0.025319472,0.07623267,0.0844737,0.06937247,0.10126447,0.042414106,0.0,0.0,0.11560841,0.18511489,0.11856183,0.02641312,0.0,0.03679517,0.03977886,0.0,0.0,0.0,0.0,0.0,0.0,0.051632695,0.05532086,0.11964468,0.0941124,0.11767841,0.1402661,0.14239255,0.033481777,0.08508703,0.07791251,0.062408686,0.09818825,0.019033268,0.0,0.0,0.10355626,0.17043325,0.09756583,0.008960873,0.0,0.04639283,0.03806694,0.0,0.0,0.0,0.0,0.0,0.0,0.030476347,0.03799864,0.117264725,0.1170578,0.14567177,0.15859866,0.16468778,0.04089547,0.084138766,0.082701,0.06764508,0.10404271,0.04059384,0.0,0.0,0.09585069,0.1549046,0.078628406,0.00835038,0.0,0.06809355,0.03688565,0.0,0.0],[0.0,0.004615426,0.02105593,0.0,0.0,0.0,0.0,0.00063689053,0.012238599,0.043820128,0.03634412,0.0044678897,0.028910369,0.12553456,0.13962221,0.23023894,0.3269351,0.4300382,0.3809666,0.3503465,0.32135004,0.30172122,0.17424113,0.057475984,0.021818042,0.0021591485,0.0,0.0,0.0,0.0,0.006715037,0.0,0.0,0.0,0.0,0.0,0.008045763,0.026114807,0.029279523,0.0,0.032183357,0.070679724,0.06592263,0.15452154,0.21122834,0.35318995,0.336924,0.33435005,0.33897662,0.27732116,0.18287101,0.052438736,0.037589706,0.0,0.0,0.0,0.0,0.004995838,0.0047590435,0.0052834004,0.0,0.0,0.0,0.0,0.0,0.03425265,0.023718156,0.0,0.018331565,0.023071952,0.003569156,0.05259107,0.07463331,0.23227301,0.25902998,0.3121032,0.37970752,0.2983276,0.2183871,0.063555054,0.04763233,0.0009973198,0.0021479875,0.0,0.0,0.01292479,0.0005020797,0.005723886,0.0,0.010136977,0.0,0.0011209995,0.0,0.045510188,0.035895772,0.008321501,0.0,0.013021544,0.015231311,0.0498539,0.050255917,0.16810133,0.22215354,0.26469123,0.37441325,0.2903036,0.2079263,0.06659441,0.03479828,0.00078625977,0.0,0.0,0.0,0.003909543,0.0,0.0035945028,0.00019805133,0.028543249,0.012721442,0.0,0.0,0.050240725,0.04436846,0.014714614,0.0,0.008552797,0.01641906,0.037876524,0.032069333,0.106875956,0.2224229,0.26555046,0.3684998,0.28219688,0.19413412,0.038803227,0.012702137,0.015493542,0.0,0.0,0.0034382045,0.0,0.0,0.0048350096,0.026841842,0.056396358,0.0462965,0.0,0.015106462,0.07408807,0.044171467,0.0152839795,0.0,0.0034187734,0.02661211,0.056092218,0.05135516,0.08811485,0.26845026,0.3418327,0.41430092,0.26506698,0.16447581,0.0043604523,0.0,0.019594945,0.0,0.0,0.005777918,0.0,0.0,0.0,0.06653629,0.0768994,0.0442079,0.0,0.026434459,0.10041117,0.05163479,0.0241305,0.0,0.0035369843,0.039022654,0.10947505,0.13019533,0.1312418,0.2855667,0.37901634,0.4435938,0.22918537,0.15368511,0.0067483783,0.0,0.0055071265,0.0,0.0,0.011300534,0.0,0.0,0.030282758,0.12669045,0.12129354,0.06197585,0.0,0.052787766,0.12826997,0.07342324,0.06633006,0.0,0.055455044,0.052487753,0.18919109,0.20998254,0.19859442,0.26102567,0.3560712,0.45858836,0.2298764,0.15141614,0.025651075,0.03425297,0.022853106,0.0,0.0,0.021239854,0.0,0.0,0.037928663,0.13209769,0.13536268,0.08199419,0.013237655,0.08441211,0.16207887,0.10800344,0.08340805,0.0,0.06570157,0.05406571,0.213471,0.22767025,0.2026002,0.23347771,0.3252905,0.43354785,0.1879906,0.12380524,0.04752206,0.062578134,0.03261888,0.0,0.0,0.030905195,0.011088721,0.0,0.03224393,0.11475472,0.12935634,0.09102546,0.03081625,0.113135494,0.18858384,0.13724203,0.092119664,0.0,0.06927352,0.05722154,0.229521,0.22574887,0.17946705,0.186858,0.2905506,0.4052931,0.1527272,0.10824015,0.06648478,0.08306928,0.041269615,0.0,0.0,0.032201827,0.025720343,0.0,0.013840422,0.09836641,0.1320863,0.10224636,0.05162531,0.15805301,0.21100044,0.16390935,0.11429899,0.0,0.10886474,0.094021186,0.2642801,0.27393425,0.17839548,0.16455533,0.26341024,0.3787071,0.13808124,0.09319462,0.085663214,0.11017757,0.041745663,0.0,0.0],[0.0,0.035119615,0.0036249459,0.020340256,0.023503669,0.024074271,0.005486205,0.0,0.0,0.025885664,0.07304084,0.14388064,0.2101413,0.35596448,0.5681294,0.748371,0.8737666,0.97574735,0.91234183,0.8580688,0.7672761,0.62386554,0.46122056,0.2045387,0.06776107,0.0,0.0,0.0,0.0,0.029591002,0.0,0.011338703,0.011408083,0.0046373755,0.0,0.0,0.0,0.0016341954,0.061244346,0.07196141,0.08540191,0.1962885,0.39389133,0.58849233,0.7436563,0.8857765,0.84369296,0.8038021,0.76030105,0.6216287,0.45078272,0.22300747,0.09851755,0.003551647,0.0,0.0,0.0,0.0307782,0.0031801164,0.011849366,0.015625566,0.0,0.0,0.0,0.0,0.0,0.07577114,0.04193317,0.020924307,0.08120756,0.18495658,0.33737212,0.52950186,0.7149748,0.72258204,0.7672992,0.80697167,0.67174816,0.46385878,0.2525068,0.11537736,0.007383719,0.0,0.0,0.0,0.016464032,0.0043803602,0.00885658,0.026384756,0.0,0.0,0.0,0.0,0.019173324,0.08118823,0.07868482,0.050332353,0.07554585,0.091428995,0.23555301,0.431894,0.59947056,0.6098195,0.67125076,0.7533225,0.62903625,0.4311278,0.21415383,0.08645972,0.0,0.0,0.0,0.0,0.007489033,0.0011594743,0.004115686,0.036087774,0.0,0.0,0.0,0.0,0.02772285,0.07843112,0.10544087,0.0771393,0.06829877,0.011135481,0.119804494,0.307867,0.52775145,0.61532336,0.7155948,0.75072724,0.6006031,0.4028002,0.15557641,0.06507143,0.0,0.0,0.0,0.0,0.0014507324,0.0,0.0014593899,0.04297784,0.0,0.005476296,0.0,0.009081751,0.035523735,0.088398024,0.13001104,0.11295963,0.06631753,0.0,0.0506424,0.20894462,0.45033622,0.65901506,0.8292772,0.80942035,0.5678129,0.37295935,0.10284015,0.036885887,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.055954427,0.0,0.02310443,0.0,0.03497491,0.03334243,0.1021964,0.15456632,0.15359402,0.098517396,0.016706787,0.088474765,0.2197519,0.44973415,0.7507251,0.93271315,0.8157237,0.48285908,0.35682827,0.078753166,0.04447905,0.0,0.0,0.0,0.0,0.0,0.0,0.04722126,0.10728559,0.022762112,0.068761565,0.0,0.04281561,0.016080514,0.09948848,0.16783936,0.21511087,0.16007419,0.077375785,0.14069256,0.26164544,0.45154715,0.79058677,0.96644354,0.7442882,0.35111976,0.30224437,0.054011703,0.057938002,0.0,0.0,0.0,0.0,0.0,0.012218207,0.06927294,0.14605564,0.054803282,0.08966613,0.0,0.04883779,0.023504816,0.11858623,0.18754694,0.25452825,0.19543053,0.12528689,0.16680382,0.28390634,0.44097573,0.8114038,0.9966005,0.7313948,0.29567438,0.2874859,0.05796338,0.0791324,0.0,0.0,0.0,0.0,0.005779773,0.014827035,0.07812718,0.17075278,0.070806324,0.099886045,0.0,0.07476485,0.059120156,0.14880742,0.2144887,0.2850919,0.22077787,0.17080736,0.18846372,0.30320948,0.42662245,0.8216566,1.0,0.7096817,0.25064352,0.27594674,0.06636534,0.100989565,0.0,0.0,0.0,0.0055496097,0.0084885135,0.010383777,0.07107243,0.17137901,0.08547715,0.115859196,0.0,0.11615102,0.09289181,0.18117201,0.27025092,0.34425694,0.2737151,0.25352818,0.2527396,0.3606513,0.4231956,0.8041516,0.9548661,0.6598764,0.20819387,0.28226322,0.085568085,0.11106073,0.0,0.0,0.0],[0.008221425,0.019368686,0.038370892,0.031036764,0.007298596,0.03779371,0.035824455,0.0,0.0,0.03792087,0.11932923,0.2613419,0.35657665,0.6301072,0.78404784,0.904194,1.0,1.0,1.0,1.0,1.0,0.9067407,0.5622355,0.2811352,0.10398239,0.0,0.0,0.0,0.002733022,0.0037580729,0.0126094,0.009874381,0.0,0.005960986,0.04303278,0.0,0.0,0.01449018,0.0820245,0.14047916,0.19358164,0.4628296,0.6705824,0.79647475,1.0,1.0,1.0,1.0,0.9967176,0.853441,0.5673358,0.31824958,0.17064378,0.010647394,0.0,0.0,0.0,0.0,0.0069844797,0.013681844,0.0,0.0,0.07195768,0.0,0.0,0.015769504,0.08218214,0.0667702,0.0792033,0.31818396,0.46208662,0.5631747,0.86096466,0.96652174,0.97656995,0.99491554,0.97444785,0.85317177,0.61081636,0.3575776,0.2247892,0.015940763,0.0,0.020030975,0.0,0.0,0.006220624,0.017964743,0.0,0.0,0.06715394,0.010215238,0.044276476,0.026171617,0.06954238,0.093935415,0.07192057,0.22347805,0.31982645,0.42861056,0.7114798,0.8558787,0.8579182,0.8884687,0.8598124,0.79030365,0.5721145,0.30417138,0.19290867,0.0,0.0,0.012333065,0.0,0.0,0.009919316,0.029709391,0.0049947053,0.0,0.062023513,0.032767683,0.07061188,0.03207968,0.047601685,0.12756048,0.07600883,0.13077256,0.18111247,0.26256454,0.5347645,0.79201555,0.85582924,0.90981823,0.78667873,0.7189305,0.51872593,0.2568558,0.1847653,0.0043662935,0.0,0.012831755,0.0,0.0,0.011864305,0.03893604,0.014532208,0.0,0.048829786,0.061819866,0.09289889,0.027220525,0.04076864,0.15990618,0.10059777,0.09832846,0.08083982,0.11875148,0.35680574,0.7355063,0.8977166,1.0,0.7382323,0.59454626,0.41798943,0.21519063,0.15839344,0.0,0.0,0.004590377,0.0,0.0,0.010968067,0.058391742,0.03275405,0.0,0.04663308,0.07284891,0.097260885,0.031569295,0.032188177,0.17179956,0.123209246,0.112518385,0.07231869,0.08848739,0.272736,0.7657967,0.9918578,1.0,0.6612274,0.44179314,0.3190658,0.19277404,0.16278945,0.0,0.0,0.0,0.0,0.0,0.03287241,0.102269486,0.061022855,0.0,0.061116107,0.061161548,0.064397946,0.039984763,0.022693798,0.14781897,0.12758271,0.12191825,0.07238428,0.03839449,0.19908796,0.7546025,0.9896464,1.0,0.5307411,0.25773197,0.19329095,0.15152206,0.16634256,0.00758934,0.0,0.0,0.0,0.0,0.04574868,0.13698733,0.09506706,0.0027880073,0.071333684,0.06307402,0.058803603,0.06892344,0.030590214,0.15089045,0.1437994,0.16605026,0.10732792,0.02033279,0.15575549,0.7561243,1.0,1.0,0.4896143,0.21609952,0.18663983,0.17936665,0.19405824,0.022549488,0.0,0.0,0.00024175644,0.0,0.053052425,0.16101581,0.1196301,0.012454182,0.07397937,0.074790776,0.09634729,0.13223985,0.063740976,0.16979986,0.16372769,0.20458141,0.13605759,0.013189666,0.13735068,0.7782295,1.0,1.0,0.44469625,0.18697932,0.19688591,0.2104525,0.22942427,0.04547125,0.0,0.0,0.017064176,0.0,0.05812513,0.16227883,0.12623864,0.031324126,0.0834633,0.10378708,0.13551651,0.18285713,0.14557333,0.24191011,0.21454829,0.27494323,0.18534622,0.06209769,0.1559081,0.77730954,0.9770965,1.0,0.39135873,0.15972641,0.2169433,0.24507907,0.21340029,0.047268085,0.0,0.0],[0.0,0.02510009,0.048837334,0.004922092,0.0,0.019647375,0.0,0.0,0.02495566,0.1310298,0.20554292,0.3322336,0.5277462,0.67974263,0.780429,0.6803679,0.7316051,0.7037953,0.7853327,0.8026118,0.9232061,0.86611223,0.6468572,0.19981623,0.009334326,0.001167059,0.031706937,0.0,0.0,0.015559591,0.02008517,0.0,0.0,0.017055973,0.0,0.0,0.0152401775,0.07972759,0.108713254,0.18300621,0.37607902,0.5998103,0.73561794,0.69791114,0.78368294,0.7579641,0.78406197,0.75663906,0.8666627,0.82558537,0.6291039,0.25392258,0.06330961,0.017518818,0.029920012,0.0,0.0,0.02340965,0.0016893744,0.0,0.0,0.015671402,0.0,0.0050688386,0.044237614,0.048583306,0.050515965,0.10963796,0.28695852,0.49949014,0.58782727,0.65378726,0.83697057,0.8419125,0.8155244,0.7620288,0.8685683,0.83583754,0.64541423,0.31179374,0.09661411,0.02483245,0.033827722,0.0,0.0,0.026628196,0.0062679127,0.0,0.0,0.0034594089,0.010119043,0.022989899,0.057728924,0.03137993,0.048668176,0.06922055,0.1938369,0.33509263,0.4106329,0.537607,0.79429513,0.83183575,0.8206478,0.7725917,0.8467956,0.7736367,0.59215003,0.2896556,0.09547554,0.02659817,0.035541542,0.0,0.0,0.024970591,0.008666091,0.0,0.0,0.0,0.029940978,0.036179453,0.058742054,0.034169286,0.07052824,0.07458459,0.15285264,0.1828574,0.20517673,0.37586364,0.6892882,0.88738775,0.91495365,0.8125975,0.7524676,0.6393505,0.46618932,0.23916444,0.10490608,0.050539017,0.040416308,0.0,0.0,0.013261922,0.007463768,0.0,0.0013527274,0.015621498,0.06477219,0.06682324,0.072974086,0.039115295,0.08502726,0.11269202,0.18993147,0.0899712,0.021202356,0.15505819,0.51017827,0.85203266,1.0,0.8853692,0.6615701,0.47538394,0.3141551,0.15564832,0.08037949,0.043662526,0.016437463,0.0,0.0,0.010952048,0.019907333,0.0,0.014750451,0.01541926,0.08095968,0.08879499,0.08426167,0.03841196,0.07865588,0.14714876,0.24643953,0.06114281,0.0,0.027403861,0.43099993,0.89695543,1.0,0.93476087,0.5059031,0.29116482,0.21779272,0.1330485,0.08867456,0.03434556,0.0,0.0,0.0,0.041418307,0.07552379,0.032876626,0.052160755,0.009016618,0.059203736,0.05368437,0.07123711,0.042135447,0.08530639,0.1665856,0.2753523,0.04461869,0.0,0.0,0.34976357,0.88873374,1.0,0.8471565,0.2711714,0.105561376,0.15660483,0.14710587,0.1382706,0.036336623,0.0,0.0,0.0,0.06256323,0.1146086,0.075973004,0.11882843,0.039266624,0.076328084,0.065083906,0.08739954,0.06403927,0.104285136,0.18633561,0.3015145,0.07458508,0.0,0.0,0.34280387,0.9151218,1.0,0.8446041,0.21330449,0.070210144,0.16006827,0.18187769,0.17378686,0.038215794,0.0,0.0,0.0,0.076231204,0.13297497,0.1135646,0.17819928,0.057479195,0.09582891,0.10542517,0.13579254,0.11888708,0.13554081,0.20154813,0.3170941,0.09874828,0.0,0.0,0.37074232,0.95538074,1.0,0.80898434,0.15546483,0.054105163,0.17318442,0.21538565,0.20812184,0.04425654,0.0,0.0,0.0,0.09225725,0.1541138,0.14738068,0.20598646,0.07055175,0.112054534,0.14515397,0.19688147,0.1795086,0.19582026,0.24995632,0.35635567,0.15494762,0.004992053,0.017862745,0.4021135,0.9344825,1.0,0.71360266,0.121974014,0.08648686,0.225176,0.2552258,0.22654325,0.05427508,0.0,0.0],[0.0,0.028373323,0.0,0.0,0.0,0.0,0.0,0.0,0.0011736453,0.149037,0.25087756,0.4010523,0.5404524,0.6923042,0.60941726,0.45733124,0.4028893,0.4207657,0.59777737,0.7394885,0.7851997,0.7323866,0.4499424,0.17185766,0.0,0.0,0.0,0.0,0.0,0.011268258,0.0,0.0,0.0,0.0042862,0.002013594,0.0,0.0,0.0961238,0.18513831,0.30426592,0.50675607,0.6906366,0.64831495,0.51053137,0.47592086,0.49297315,0.5845675,0.6830644,0.7256104,0.69535804,0.44344723,0.2216614,0.0,0.014688209,0.0,0.0,0.0,0.019391917,0.006394349,0.0,0.0,0.020248987,0.00073859096,0.027037956,0.0088309795,0.06622888,0.13886742,0.2517434,0.50803506,0.6604812,0.6475236,0.5840208,0.6213021,0.6431508,0.65312207,0.72287184,0.75201386,0.7263675,0.48806912,0.28419,0.026243612,0.029414922,0.0,0.0,0.00568752,0.02767925,0.029831976,0.0,0.0,0.023660228,0.0,0.041807503,0.0192933,0.051065467,0.10736801,0.1359069,0.34874773,0.47442472,0.49088246,0.5523957,0.6768204,0.694297,0.70554537,0.7657265,0.76466197,0.69801337,0.49072582,0.2799005,0.04385589,0.042700946,0.0,0.0,0.017033577,0.027807422,0.039445847,0.0,0.0,0.03193652,0.0,0.044964507,0.034548424,0.07318966,0.11000737,0.05681756,0.21599081,0.28720993,0.29925108,0.4767912,0.7170442,0.7937369,0.8108803,0.76442534,0.6616801,0.5431567,0.37033436,0.21569197,0.044715725,0.052784935,0.0,0.0,0.019408807,0.025283791,0.0407563,0.0033204257,0.0,0.053233914,0.022834688,0.050545998,0.054978266,0.101093635,0.0876915,0.060771853,0.12265902,0.1174704,0.1156258,0.3288225,0.6758422,0.8164464,0.9030279,0.7501778,0.53524834,0.36466873,0.19745733,0.08899847,0.01172176,0.048275225,0.0,0.0,0.01993569,0.037676387,0.040698618,0.02227705,0.01032304,0.07249351,0.03441643,0.06468189,0.08918457,0.09837319,0.06073708,0.06660509,0.046612397,0.0,0.0,0.23011267,0.6314833,0.8475585,0.94936126,0.68887234,0.3252728,0.18948181,0.10429576,0.03597696,0.012133487,0.03152387,0.0,0.0,0.023935735,0.074602686,0.057079494,0.06574414,0.06986986,0.09243421,0.0072636157,0.051148616,0.11686328,0.08376981,0.020456724,0.036442958,0.0,0.0,0.0,0.152324,0.562016,0.82765204,0.8759899,0.52914387,0.06333498,0.04646939,0.08143004,0.04365305,0.057948314,0.010361657,0.0,0.0022363216,0.030542642,0.098152354,0.097134046,0.12782562,0.15721384,0.13964708,0.025266603,0.07468264,0.1664158,0.09775932,0.031863853,0.027820319,0.0,0.0,0.0,0.13598175,0.5574417,0.8325548,0.8783396,0.494879,0.006260708,0.03703676,0.089399695,0.058023296,0.076472,0.0,0.0,0.005487576,0.03430745,0.110279046,0.12619574,0.18922989,0.22797763,0.17308576,0.04247181,0.12142567,0.24288942,0.12848896,0.05326525,0.020310782,0.0,0.0,0.0,0.13424528,0.57998586,0.8497492,0.8623674,0.43102413,0.0,0.0469354,0.107510045,0.06783761,0.09104982,0.0,0.0,0.012218088,0.03584612,0.11900785,0.14801745,0.23103952,0.2620045,0.1874063,0.043765217,0.1521378,0.27422327,0.1560577,0.07989306,0.042178974,0.0,0.0,0.0,0.14928538,0.58048767,0.82369107,0.78006923,0.35146624,0.0,0.10714834,0.16937256,0.07064521,0.09616436,0.0,0.0,0.0045086145],[0.008319914,0.004134983,0.0,0.0,0.0,0.0,0.0,0.0,0.03878843,0.12643589,0.32980466,0.52951074,0.6946087,0.56412137,0.4517913,0.23680422,0.2892024,0.29316103,0.48036182,0.5896015,0.57240456,0.5475908,0.2945959,0.10990203,0.0,0.0,0.0,0.0,0.006654106,0.0,0.0,0.0,0.0,0.0,0.0,0.013565645,0.027867936,0.073184125,0.25594896,0.49405944,0.71041524,0.619297,0.5091072,0.3044575,0.3171286,0.3216085,0.4806373,0.56666225,0.53131413,0.50027853,0.28219655,0.084910825,0.0,0.0,0.0,0.0,0.026507378,0.021008074,0.0,0.0,0.0,0.0,0.0,0.03758829,0.045361854,0.03238289,0.16527101,0.39288998,0.6378128,0.6516245,0.54758006,0.43756992,0.47012228,0.47021192,0.6218303,0.65901583,0.57468027,0.49233687,0.32439917,0.1113654,0.0,0.0,0.0,0.0,0.03806951,0.049660422,0.0,0.0,0.0,0.0,0.0,0.043393508,0.047829725,0.0,0.085457325,0.15637808,0.3464389,0.44367254,0.4769017,0.4836058,0.6246569,0.6595986,0.7725209,0.731505,0.5764256,0.43939036,0.32355422,0.12705837,0.0033590049,0.0,0.0,0.0,0.03745234,0.05531597,0.009027973,0.020837225,0.0,0.0,0.0,0.061206385,0.07222731,0.02510123,0.07272671,0.054904826,0.14921553,0.26502234,0.37109545,0.5102654,0.76394725,0.83402485,0.89672166,0.74246407,0.4923827,0.2961779,0.2349231,0.07596633,0.016249418,0.0,0.0,0.0,0.023393959,0.037160702,0.0014805049,0.02347041,0.008166231,0.035138473,0.01702556,0.08532275,0.11250733,0.050997347,0.08507579,0.055851743,0.045599453,0.12644985,0.17623281,0.47960997,0.84760785,0.9540899,0.9727805,0.704264,0.3883443,0.1536072,0.071640775,0.0,0.0,0.0,0.0,0.0,0.019704834,0.03956276,0.012250543,0.044119276,0.043134794,0.07370564,0.043891758,0.12787803,0.16060984,0.09168273,0.09783411,0.07072961,0.0,0.0027923286,0.0,0.42803,0.87952775,0.9904239,0.9184938,0.54167944,0.19922586,0.0077644438,0.0,0.0,0.0,0.0,0.0,0.0,0.024609707,0.06414111,0.06239056,0.089551486,0.11272777,0.10662653,0.053839065,0.11681396,0.18012482,0.10033941,0.053678967,0.06550936,0.0,0.0,0.0,0.3839906,0.8578365,0.9591069,0.76935935,0.34043366,0.040307745,0.0,0.0,0.042839035,0.03480676,0.014418863,0.0,0.0,0.027813658,0.09175562,0.113434665,0.1531255,0.19200805,0.1656464,0.091410115,0.13098682,0.21818355,0.13119185,0.059993282,0.082451075,0.0,0.0,0.0,0.3519113,0.8396601,0.9389533,0.74803776,0.31144896,0.011389591,0.0,0.0,0.065971486,0.049882196,0.009045988,0.0,0.0,0.03448212,0.11127536,0.16449551,0.21683326,0.26932657,0.21776572,0.12625793,0.15252556,0.25733066,0.16952655,0.0737781,0.112214535,0.0,0.0,0.0,0.31912813,0.82439464,0.90029943,0.6966462,0.2754857,0.0,0.0,0.0,0.083388045,0.06510743,0.008309692,0.0,0.0,0.036560506,0.12365145,0.205594,0.26056302,0.30597788,0.22802562,0.11642286,0.14256524,0.2670697,0.19863537,0.09051395,0.16033052,0.0,0.0,0.0,0.3051328,0.7618878,0.84471816,0.6272887,0.2508489,0.0,0.0,0.0,0.1161015,0.08780843,0.0069430694,0.0,0.0],[0.0,0.0,0.01328516,0.0,0.0,0.0,0.0,0.0028806776,0.04854081,0.21587142,0.46724367,0.7357653,0.7142776,0.61103004,0.49835265,0.31777096,0.42729485,0.47144485,0.413018,0.48333317,0.55061066,0.4539991,0.30166835,0.09299746,0.010034636,0.0,0.0,0.0177631,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0068181828,0.031878747,0.18419065,0.4226401,0.72416395,0.72926736,0.62046784,0.4915501,0.30835757,0.37740904,0.40252703,0.4416517,0.5117243,0.54830927,0.3989117,0.26045352,0.042269982,0.0,0.0,0.0,0.011227906,0.015500791,0.012751609,0.0024660379,0.0,0.006840363,0.0,0.014300063,0.034105174,0.03815479,0.14531036,0.3224828,0.58561987,0.7060631,0.64495474,0.52151245,0.39645612,0.47246474,0.44833976,0.5718803,0.62371826,0.58079535,0.40729785,0.25557435,0.027381375,0.0,0.0,0.0,0.0,0.027977154,0.056474924,0.05489167,0.04195977,0.042650282,0.0,0.019299172,0.049624607,0.013543904,0.07362312,0.18130006,0.29089317,0.46783996,0.5578601,0.52312,0.46826404,0.60347944,0.62415797,0.7382381,0.6746212,0.53679246,0.35894766,0.2151838,0.028900579,0.0,0.0,0.0,0.0,0.025121108,0.067039594,0.077798545,0.07741383,0.07346132,0.0137088,0.01149407,0.07057294,0.024049588,0.07112862,0.077755034,0.10551301,0.28881204,0.44216865,0.5067934,0.54468614,0.758413,0.79495794,0.8843956,0.67233974,0.39880574,0.23862073,0.15824145,0.0,0.0,0.0,0.0,0.0,0.0058868155,0.047397003,0.07157645,0.08036451,0.081192434,0.033682764,0.0062711686,0.09148274,0.036789477,0.08848345,0.0077112615,0.0,0.12588441,0.22405094,0.34568417,0.6019856,0.9155315,0.9382454,0.94378686,0.5768195,0.24316522,0.11381435,0.08801536,0.0,0.0,0.003962159,0.0,0.0,0.0,0.041086964,0.075034186,0.08860782,0.08875394,0.056887828,0.019689038,0.109455116,0.052430436,0.11426504,0.0,0.0,0.0,0.017772064,0.20244974,0.60621053,1.0,0.97851664,0.8608955,0.39389306,0.032865122,0.0,0.046196803,0.0,0.036933333,0.04877252,0.0,0.0042024553,0.0,0.069425,0.12481136,0.119062535,0.13263048,0.111947626,0.027451105,0.097442135,0.055517346,0.056066945,0.0,0.0,0.0,0.0,0.13916375,0.62090325,1.0,0.9657859,0.71719396,0.22791064,0.0,0.0,0.031095617,0.02448237,0.09434408,0.09214022,0.0,0.014227986,0.0,0.097893864,0.18302485,0.15288347,0.1845976,0.15945226,0.050194792,0.101254255,0.06295183,0.051021658,0.0,0.0,0.0,0.0,0.10204817,0.5962461,1.0,0.98498595,0.722427,0.2089119,0.0,0.0,0.04342126,0.054732665,0.11856006,0.112300396,0.0033732355,0.015571564,0.0,0.10831766,0.22115391,0.18256587,0.22428328,0.19994009,0.08081113,0.10612908,0.0651677,0.052846394,0.0,0.0,0.0,0.0,0.06640622,0.56647635,1.0,0.9829433,0.70046407,0.16642658,0.0,0.0,0.027652532,0.07278752,0.1347328,0.12248404,0.011976041,0.015722848,0.0,0.110307515,0.2404571,0.19836414,0.22624265,0.20457923,0.07106049,0.08074528,0.04154238,0.045812346,0.0,0.0,0.0,0.0,0.05401408,0.53412145,1.0,0.9209151,0.6542092,0.16370234,0.0,0.0,0.01863005,0.0992869,0.14256364,0.10231927,0.015076853,0.0],[0.03973095,0.035105772,0.0,0.0,0.0,0.0,0.0,0.016947135,0.097691506,0.3568933,0.5913874,0.7157727,0.76712483,0.75780976,0.64352894,0.53737855,0.74939466,0.7268993,0.6674806,0.4881965,0.45552987,0.2985489,0.16429849,0.019927248,0.0,0.045900546,0.04892485,0.012501478,0.032377847,0.021091945,0.0,0.0,0.0,0.0033970326,0.0,0.009637766,0.08376148,0.31624943,0.55254066,0.6935266,0.7794489,0.709905,0.5747626,0.48422056,0.6761992,0.69247746,0.6783101,0.52426004,0.43554455,0.23921129,0.11536671,0.0003888458,0.0,0.028353415,0.046797678,0.030556664,0.03276729,0.027227089,0.0,0.0,0.0,0.014578596,0.0,0.019105583,0.11677719,0.23432776,0.43739754,0.57627213,0.78233933,0.6947562,0.56716806,0.46642882,0.6766116,0.7272273,0.7476981,0.5919406,0.4498443,0.23239245,0.10617255,0.0,0.0,0.038806684,0.052808084,0.0362551,0.02455359,0.047859997,0.027981035,0.016815394,0.0,0.014238939,0.0,0.034928754,0.10018174,0.1458421,0.2601909,0.33184633,0.57796025,0.59659714,0.5678163,0.51412225,0.7841449,0.83951366,0.8167512,0.5655449,0.35746622,0.17213982,0.066458024,0.0,0.0015590936,0.03633164,0.0516909,0.023929402,0.008764289,0.0626217,0.06078925,0.05044631,0.0,0.014218897,0.0077492744,0.07972507,0.102955624,0.12678182,0.12784012,0.1449434,0.35173905,0.49278903,0.56715393,0.5906592,0.89565164,0.96485335,0.86561334,0.5026431,0.23385605,0.13046707,0.063123934,0.0,0.023707248,0.039952114,0.045307763,0.010043442,0.0,0.041685417,0.046896763,0.03205283,0.0,0.00867518,0.016243055,0.119292386,0.11000051,0.118985325,0.026367724,0.0038586408,0.08364326,0.29722413,0.46270722,0.7056984,1.0,1.0,0.7666215,0.3728667,0.11391963,0.103907004,0.04008215,0.0021529496,0.05493833,0.06469591,0.06428592,0.011262581,0.0,0.027581967,0.042902924,0.022748202,0.0,0.0060914084,0.0245834,0.1320502,0.106091306,0.13263018,0.0030137002,0.0,0.0,0.07044289,0.33862182,0.82663876,1.0,1.0,0.5825927,0.20338298,0.0,0.066960566,0.033127114,0.042035073,0.11654546,0.10534157,0.0844616,0.005504623,0.0,0.043046325,0.085709706,0.076563165,0.0,0.018953927,0.025944673,0.11843842,0.06978687,0.12719625,0.0,0.0,0.0,0.017196953,0.34884804,0.9739926,1.0,1.0,0.464615,0.094317764,0.0,0.064808935,0.089140646,0.12068367,0.20508268,0.14395495,0.09463526,0.0,0.0,0.06476376,0.12353998,0.122283295,0.0,0.026088983,0.029033557,0.119578436,0.06647626,0.12906952,0.0,0.0,0.0,0.0,0.33855283,0.9988122,1.0,1.0,0.45845366,0.08976285,0.0,0.08395562,0.12254125,0.16406137,0.2612647,0.16280097,0.0962396,0.0,0.0,0.083231345,0.15407364,0.15874948,0.0,0.025633298,0.025836535,0.120402776,0.068282135,0.12346494,0.0,0.0,0.0,0.0,0.32651222,1.0,1.0,1.0,0.44858474,0.069386125,0.0,0.082352504,0.14271392,0.18903504,0.30409926,0.17464966,0.09326357,0.0,0.0,0.10302851,0.20385024,0.19576225,0.0,0.0014554858,0.0,0.10202207,0.065299645,0.11053113,0.0,0.0,0.0,0.0,0.3308528,0.96825135,1.0,1.0,0.41850412,0.0798244,0.0,0.115198135,0.17351092,0.20198394,0.311517,0.15240489,0.07125263,0.0],[0.01203578,0.055273376,0.0,0.0,0.0,0.0,0.0,0.0130786,0.119431406,0.4554931,0.6327988,0.73913366,0.85940605,0.87607086,0.7811844,0.722601,0.85215455,0.840319,0.72793216,0.43370873,0.3347563,0.22039548,0.08839241,0.0,0.0,0.0,0.0066497475,0.0,0.0053661317,0.032298863,0.0,0.0,0.0,0.0,0.0,0.016918242,0.09828077,0.40919757,0.6044077,0.7302593,0.8389472,0.82107925,0.7394177,0.67654544,0.8179587,0.8446961,0.76764446,0.46357602,0.31185317,0.16586985,0.05029212,0.0,0.0,0.0,0.025984995,0.0022874177,0.015032157,0.034725204,0.0,0.0,0.0,0.0,0.0,0.035188444,0.10654594,0.32412916,0.5025306,0.6935818,0.84427565,0.83416015,0.7823851,0.6648782,0.8379435,0.8742363,0.83007073,0.50892305,0.3131252,0.16235927,0.047534987,0.0,0.0,0.00035347044,0.04535611,0.02857615,0.01709979,0.056581132,0.0,0.0,0.0,0.0,0.0,0.013833791,0.027319938,0.16902621,0.29007393,0.52222425,0.698384,0.82724655,0.84441817,0.73795164,0.9484247,0.9047749,0.7554728,0.4138894,0.19923753,0.0937036,0.030407637,0.0,0.0,0.0017330348,0.030620769,0.030284755,0.015071921,0.06290036,0.01081381,0.004229158,0.0,0.000059127808,0.0,0.010752186,0.0,0.08417635,0.14463156,0.3464656,0.5093089,0.784818,0.8431751,0.82339257,1.0,0.91274214,0.6522052,0.2850204,0.11652179,0.097735904,0.053270534,0.0,0.015993655,0.01097846,0.026563317,0.035327516,0.0056403577,0.03962262,0.0,0.008890845,0.0,0.0009898394,0.0,0.017061315,0.0026971698,0.043541946,0.042671554,0.11582047,0.26014736,0.5886713,0.78756547,0.931638,1.0,0.8393905,0.46092176,0.13527489,0.030208245,0.08678305,0.041260377,0.0,0.044445023,0.03534735,0.043181293,0.040118985,0.009398431,0.05335734,0.010481939,0.01578287,0.0,0.0074166805,0.020843051,0.0047603995,0.0,0.029159687,0.010552168,0.0,0.022294134,0.32645822,0.6885906,1.0,1.0,0.7004785,0.27271268,0.0,0.0,0.0761273,0.028811045,0.0,0.069117025,0.035434,0.037102662,0.033195063,0.016223557,0.07521628,0.05696799,0.06519928,0.0,0.008451551,0.036050536,0.0,0.012370855,0.027104586,0.0,0.0,0.0,0.21734029,0.69035006,1.0,1.0,0.5932006,0.11724119,0.0,0.0,0.10514672,0.03455951,0.017025232,0.1146048,0.034456648,0.02765479,0.013579264,0.015860878,0.101602755,0.101760216,0.10371453,0.01661019,0.019585438,0.0383955,0.0,0.028780237,0.036439925,0.0,0.0,0.0,0.193353,0.68025184,1.0,1.0,0.62768245,0.11747023,0.0,0.0,0.119749136,0.06654641,0.042015262,0.12792231,0.00970798,0.0,0.0052206367,0.016388372,0.11887564,0.13615857,0.1371458,0.029845893,0.024980232,0.035766788,0.0,0.0407172,0.0273308,0.0,0.0,0.0,0.18296449,0.6742897,1.0,1.0,0.66517854,0.11563553,0.0,0.0,0.11580683,0.0981507,0.04837367,0.12090023,0.0,0.0,0.0,0.014345102,0.14386743,0.18057568,0.17091899,0.035244226,0.0034641027,0.013426177,0.0,0.0569529,0.013185114,0.0,0.0,0.0,0.15111752,0.633668,1.0,1.0,0.6422724,0.08914948,0.0,0.0,0.11997644,0.12321477,0.049497,0.09832446,0.0,0.0,0.0],[0.027868785,0.0452862,0.0,0.0,0.0,0.0,0.008781381,0.06931074,0.24915081,0.492114,0.65963894,0.7201066,0.89969856,0.8603914,0.8229354,0.85062236,0.89479965,0.740579,0.6965572,0.49956495,0.373276,0.18911259,0.05364316,0.0,0.008013517,0.0,0.0,0.0,0.017995872,0.036334127,0.0,0.0,0.0,0.0,0.010130577,0.053909652,0.2139158,0.44580483,0.63364244,0.72770286,0.9503057,0.8945057,0.83998644,0.8829205,0.8958611,0.7704418,0.6831126,0.464073,0.24451062,0.09980399,0.026518397,0.0004647076,0.027874716,0.0,0.003554657,0.0,0.027244553,0.05372516,0.0,0.0,0.0,0.0,0.018363453,0.055274516,0.1921179,0.39026278,0.5960176,0.74667454,1.0,0.9501474,0.88199854,0.9393717,0.8971008,0.784846,0.65565634,0.44007552,0.17821667,0.09270258,0.0355549,0.01931429,0.051147602,0.015468001,0.020757034,0.00046892464,0.035962418,0.0585071,0.0019834489,0.0,0.0,0.0,0.01616235,0.027731165,0.084943235,0.21765876,0.40212905,0.621457,0.95198166,0.9431069,0.90886533,0.9799881,0.9202565,0.7729995,0.54963446,0.29879996,0.056664072,0.033371203,0.013847232,0.020170555,0.052773006,0.01356338,0.0048032254,0.0029722005,0.039697833,0.03730572,0.0,0.0,0.0,0.020702198,0.019776054,0.017772615,0.019113801,0.09306581,0.2233023,0.46925867,0.7924543,0.8970316,0.892606,1.0,0.9007294,0.78016627,0.48801875,0.23037916,0.024978854,0.026710577,0.015923232,0.02036973,0.057101235,0.025058903,0.0020101666,0.010830961,0.027373835,0.0070028603,0.0,0.0,0.0039609075,0.030386388,0.029108979,0.017767139,0.0,0.0057481453,0.019938268,0.23698227,0.53171015,0.82982206,0.91909325,1.0,0.89164805,0.6284753,0.27270317,0.06923122,0.0,0.014841914,0.0109224245,0.035430044,0.07273373,0.038658172,0.011856377,0.026559085,0.02833499,0.036173016,0.036578633,0.020629942,0.019288056,0.014108375,0.029999867,0.01206664,0.0,0.0,0.0,0.0509941,0.23810515,0.7051446,0.9290222,1.0,0.8545583,0.41379607,0.057780765,0.0,0.0,0.0,0.0,0.03181865,0.06654363,0.03773064,0.025584556,0.034584112,0.012565412,0.0931903,0.13426754,0.09679063,0.018029556,0.0,0.02766744,0.015971527,0.0,0.0,0.0,0.0,0.08495771,0.63994825,0.96353513,1.0,0.81493825,0.3054443,0.0,0.0,0.0,0.0,0.0,0.038743526,0.06999052,0.039480083,0.04934793,0.04299672,0.010939971,0.1276532,0.1870181,0.1463391,0.042600825,0.0,0.022556536,0.018827803,0.0,0.0,0.0,0.0,0.06718859,0.6484512,0.9818459,1.0,0.86248404,0.32714579,0.0,0.0,0.0,0.0,0.0,0.047848053,0.07179147,0.02923093,0.049415804,0.045206785,0.011261456,0.14490595,0.21215717,0.1698841,0.06558095,0.0,0.013474889,0.023033738,0.0,0.0,0.0,0.012953192,0.07110672,0.66759723,0.99902225,1.0,0.91349554,0.36451808,0.0,0.0,0.0,0.0,0.0,0.039879926,0.068624094,0.019751027,0.047315463,0.043867275,0.014945962,0.18368235,0.24692412,0.2012007,0.066307895,0.0,0.0,0.013530135,0.0,0.0,0.0,0.0,0.024918847,0.6429965,0.9866589,1.0,0.89620554,0.3607282,0.0,0.0,0.0,0.0,0.0,0.032826237,0.06977995,0.013944618,0.047696628,0.036747687],[0.043510698,0.056979835,0.008491375,0.016189419,0.0,0.0,0.061462164,0.11357042,0.28456473,0.44935572,0.49394715,0.5787887,0.72778547,0.6923518,0.50194216,0.64228415,0.74826807,0.82343906,0.69061744,0.60737544,0.446509,0.16557916,0.08538302,0.0,0.0,0.0,0.0028925538,0.004810557,0.021784484,0.04041443,0.006969452,0.023825407,0.0030591637,0.0,0.049118765,0.072522074,0.24909347,0.4188432,0.52191556,0.64203626,0.83534724,0.7765475,0.6313021,0.7682999,0.8158325,0.8118678,0.621735,0.46441758,0.25780794,0.047405772,0.05516029,0.0,0.0,0.0,0.0,0.0,0.01780603,0.047707364,0.016526565,0.01623746,0.0,0.0,0.06600568,0.06423097,0.23895353,0.4027316,0.57701236,0.7362107,0.9663462,0.8445722,0.7507463,0.89306325,0.853227,0.7276524,0.5200846,0.30589366,0.16110213,0.045250356,0.060024336,0.0,0.00047884881,0.0,0.0,0.0,0.030849531,0.07325811,0.03606061,0.0066084564,0.0,0.0,0.058179803,0.04951568,0.12710841,0.25493863,0.43902522,0.6630967,0.96108425,0.85309726,0.82500434,0.9515522,0.8058491,0.6153827,0.3736956,0.1280348,0.07128593,0.015779369,0.033632994,0.0,0.0,0.0,0.004173845,0.0,0.038700618,0.06243304,0.027349219,0.004440412,0.0,0.0,0.05233913,0.048352465,0.048881628,0.13386098,0.3112868,0.57000947,0.8992072,0.85858727,0.8653759,0.9691866,0.77331305,0.54961306,0.331056,0.075817175,0.04556898,0.015924253,0.026287466,0.0,0.021535777,0.0,0.02369617,0.015864484,0.03620425,0.030753158,0.011635557,0.0010954738,0.02540525,0.024899393,0.038115583,0.04444591,0.003943667,0.026122555,0.14121196,0.39600158,0.7430606,0.89617586,0.943554,0.9726761,0.6893313,0.33699906,0.14306802,0.004587874,0.04023087,0.009715475,0.017542072,0.016444996,0.055007495,0.01933799,0.043475322,0.03862264,0.033317626,0.047689073,0.044491544,0.016494595,0.036393024,0.026672207,0.0011758059,0.0068169236,0.0,0.0,0.0084916875,0.2215752,0.5301162,0.92582655,1.0,0.9745693,0.607245,0.11166885,0.0,0.0,0.03666623,0.0,0.011201791,0.043689825,0.058141887,0.04549136,0.068037294,0.051306456,0.012701057,0.07853368,0.14049958,0.046243556,0.0053248107,0.013065964,0.0,0.0065324977,0.0,0.0,0.0,0.15286714,0.4301386,0.96500075,1.0,0.987177,0.5540864,0.0062098503,0.0,0.0,0.0,0.0,0.014641888,0.07488522,0.055876218,0.074179016,0.099173024,0.06817863,0.007663749,0.094022855,0.18388382,0.080360435,0.0127471015,0.0042712837,0.0,0.018530034,0.0,0.0,0.0,0.1666393,0.45586658,1.0,1.0,1.0,0.5930662,0.0021607429,0.0,0.0,0.0,0.0,0.0076577812,0.09408985,0.057880715,0.07609768,0.113045216,0.08153738,0.0052096695,0.10221787,0.19506034,0.095981225,0.03063754,0.0,0.0,0.026235223,0.0,0.0,0.0,0.19370198,0.5041838,1.0,1.0,1.0,0.6377905,0.007971041,0.0,0.0,0.0,0.0,0.010033153,0.10890892,0.058000274,0.07988633,0.12732682,0.09371768,0.010368258,0.13829193,0.19957426,0.10281325,0.03361804,0.0,0.0,0.01390481,0.0,0.0,0.0,0.1885218,0.51277,1.0,1.0,1.0,0.6407821,0.0,0.0,0.0,0.0,0.0,0.013410218,0.12549378,0.052796245,0.08194228,0.12509345,0.087586656],[0.0,0.017160282,0.031702936,0.008243397,0.0,0.01769925,0.10320996,0.047595225,0.27656835,0.28181052,0.40322357,0.37237018,0.45425045,0.38122702,0.2899313,0.29781336,0.42976356,0.6817167,0.7783369,0.7357191,0.46493554,0.19967413,0.06371695,0.028874502,0.07400645,0.0,0.054006457,0.055450834,0.0,0.006135024,0.029922247,0.024664827,0.0,0.015337631,0.07239744,0.06309663,0.26311946,0.33373016,0.47616196,0.5198297,0.6103863,0.54782265,0.4796428,0.4860199,0.54570234,0.706397,0.64484084,0.43595076,0.14822553,0.00094908476,0.04028283,0.03200017,0.06515213,0.0,0.02499704,0.023538098,0.0,0.01389385,0.02777619,0.027727842,0.0,0.02035752,0.07719876,0.13148254,0.281703,0.4300692,0.63851845,0.7431301,0.7819264,0.67628765,0.619464,0.58119947,0.54412496,0.56804264,0.39190054,0.17308886,0.0,0.0,0.055064686,0.04063697,0.0592848,0.0011510998,0.014269754,0.008201398,0.021340162,0.039999567,0.03818232,0.0144085735,0.0,0.050938524,0.0929683,0.1293982,0.19691858,0.35501564,0.5814405,0.75969005,0.8293615,0.7596547,0.69237214,0.6138481,0.5298494,0.42374313,0.21375129,0.05557152,0.0,0.0,0.04255057,0.030720249,0.049011588,0.010092609,0.014566593,0.006160423,0.031008974,0.033065155,0.03091415,0.0019888282,0.016559973,0.09086965,0.1112773,0.117399454,0.1197503,0.2553646,0.47406244,0.7033426,0.8270201,0.82328635,0.7516965,0.6546894,0.5464788,0.36245003,0.13608354,0.013366073,0.0,0.0,0.03497693,0.022202387,0.038939364,0.022054307,0.030068949,0.013531551,0.032154575,0.015629567,0.015023515,0.0,0.04601212,0.12026387,0.123105854,0.111274235,0.07254559,0.12642114,0.30059057,0.5594808,0.79239184,0.88507175,0.803847,0.54505813,0.3898769,0.15655036,0.047862396,0.017239042,0.00097844,0.009821266,0.041733235,0.032335132,0.058873102,0.055860475,0.060252324,0.022265747,0.02605012,0.023186468,0.033102505,0.0121001825,0.057664767,0.120141394,0.09443462,0.054191858,0.025977544,0.031238146,0.15433393,0.40854162,0.72279304,0.93342954,0.82925093,0.40141988,0.17830673,0.0,0.0,0.04095006,0.010634638,0.03403446,0.05162903,0.03562472,0.09200847,0.08903538,0.088545494,0.026691176,0.005658865,0.04313252,0.060142316,0.03541241,0.03884621,0.103860535,0.0747096,0.0,0.0,0.0,0.05640158,0.31814763,0.6918411,1.0,0.9045595,0.36341453,0.09753608,0.0,0.0,0.0673018,0.013284974,0.05384361,0.050980017,0.03282629,0.14506628,0.11941078,0.11603708,0.03827583,0.002324298,0.038756855,0.06649837,0.052482486,0.0516947,0.13418444,0.07882236,0.0010793507,0.01689066,0.0,0.076812595,0.3463322,0.7309014,1.0,0.915684,0.36238655,0.10589597,0.0,0.0,0.074362874,0.0,0.05662273,0.045954965,0.031553343,0.15939409,0.121163994,0.12951724,0.051792406,0.0054161847,0.024191342,0.05849746,0.056984745,0.06599573,0.1644229,0.08010385,0.0042959005,0.047758825,0.0,0.10771852,0.38114625,0.76707065,1.0,0.9112129,0.36510473,0.12742,0.0,0.0,0.07486501,0.0,0.049950823,0.035672225,0.025035948,0.16831365,0.1230146,0.13865557,0.0629452,0.013411172,0.03817606,0.057137623,0.04937105,0.061870664,0.1837381,0.08684754,0.0,0.057306536,0.0,0.13388783,0.41027266,0.7776689,1.0,0.9324585,0.38396114,0.14183843,0.0,0.0,0.09271653,0.0,0.048050977,0.036992304,0.019137219,0.15666936,0.09927365,0.1230204,0.06122101],[0.0,0.0,0.0035838485,0.0,0.0,0.14715832,0.18678063,0.17117012,0.30430993,0.23008975,0.23717886,0.213575,0.27369434,0.18526238,0.08827756,0.1538954,0.32682383,0.65249383,0.7732628,0.679796,0.32202464,0.1323563,0.010473475,0.021306783,0.006479226,0.0,0.011645623,0.031498455,0.0,0.0,0.00625775,0.0,0.0,0.10958849,0.16608156,0.15886924,0.303675,0.30542123,0.34723258,0.39671922,0.43978894,0.39416677,0.29270557,0.3757631,0.49697405,0.68888724,0.6096483,0.34942007,0.054474756,0.0,0.0,0.0073666945,0.0,0.0,0.00060904026,0.019753605,0.00008766353,0.0,0.0053859353,0.0,0.0,0.07423513,0.16084987,0.18366554,0.31065655,0.4059924,0.52532274,0.6694527,0.6494497,0.5994548,0.4577347,0.48239386,0.52084255,0.5434084,0.33329946,0.09725647,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021950148,0.019560434,0.0,0.00830324,0.0,0.0,0.07131993,0.154686,0.14969444,0.23475915,0.33859736,0.49862462,0.7079591,0.71325874,0.72151166,0.56374323,0.53858715,0.5125479,0.40800816,0.15065926,0.04353614,0.0,0.0016416311,0.0,0.0,0.0,0.0,0.0,0.015135288,0.03213492,0.0,0.00873521,0.0,0.02647905,0.08058466,0.1559148,0.10907732,0.1487659,0.25604594,0.4192161,0.67221117,0.724668,0.81867427,0.6769627,0.5828625,0.48393774,0.3009042,0.057603203,0.056656674,0.03350745,0.004707575,0.0,0.0,0.0,0.0,0.0,0.015627295,0.0353221,0.0,0.00655926,0.0008639395,0.07551487,0.07864849,0.1749238,0.07148595,0.06391035,0.17885698,0.28296477,0.5971409,0.75740016,0.90097725,0.69626063,0.4202469,0.1951024,0.08514043,0.0,0.064175345,0.06385184,0.013514593,0.0,0.0,0.0,0.029647917,0.0,0.014989302,0.038030006,0.0,0.013941698,0.011088096,0.07076533,0.06978816,0.17055918,0.025721572,0.0,0.11401196,0.1963946,0.5222613,0.7924179,0.9843409,0.6738735,0.17896906,0.0,0.0,0.0,0.07274051,0.071636945,0.0075241476,0.0253921,0.011640593,0.0050983876,0.0577353,0.0,0.009731211,0.040278934,0.015987583,0.033481836,0.022003248,0.05854159,0.07701559,0.19526438,0.0,0.0,0.049385577,0.16439128,0.49504328,0.84275126,1.0,0.74333215,0.09496698,0.0,0.0,0.0,0.074739546,0.08112334,0.0,0.07070877,0.051559344,0.029363431,0.079254046,0.0,0.007522315,0.041399986,0.030878209,0.049268715,0.028753318,0.081519485,0.10412334,0.2184073,0.018540882,0.0,0.07033406,0.19322157,0.5363009,0.8834847,1.0,0.76342905,0.09919919,0.0,0.0,0.0,0.07631248,0.09747453,0.0,0.07438572,0.05461262,0.024743624,0.08515083,0.0,0.018342145,0.04156796,0.031966098,0.04790791,0.03038603,0.116227746,0.13729426,0.23124172,0.04683467,0.0,0.09753491,0.2248089,0.57556236,0.90721476,1.0,0.7639221,0.1080169,0.0,0.0,0.0,0.074514546,0.105201595,0.0,0.066823944,0.042241417,0.022185631,0.094743796,0.0,0.034715965,0.04370091,0.038321167,0.029372528,0.012402542,0.110727936,0.15959325,0.23821427,0.08190862,0.025414012,0.115550175,0.26005685,0.5991786,0.92303187,1.0,0.78591555,0.13231598,0.0,0.0,0.0,0.06415323,0.09804301,0.0,0.063061796,0.037802085,0.021864526,0.08725569,0.0,0.037179157],[0.0063502192,0.01632528,0.029441796,0.032814108,0.110874824,0.26929635,0.36419213,0.27238417,0.20560566,0.19411114,0.16056517,0.14804071,0.15710175,0.119807884,0.0,0.13918053,0.42359263,0.7487815,0.89816153,0.69026554,0.3616488,0.075495824,0.0,0.0,0.023865089,0.033248574,0.03271909,0.016008697,0.0073202625,0.0059704334,0.016668908,0.024444811,0.08618311,0.21304882,0.29745942,0.28499448,0.29680133,0.3121825,0.2914486,0.28969654,0.2922757,0.27581787,0.20816404,0.4031157,0.58168614,0.70603913,0.63564444,0.35457093,0.13907748,0.0,0.015264504,0.0057401285,0.017804965,0.019726105,0.028965898,0.016522825,0.013490327,0.012822896,0.030222744,0.0336435,0.068225384,0.1789849,0.26830786,0.34310493,0.41429645,0.4907925,0.5043539,0.52411795,0.48396093,0.40337425,0.3611747,0.4894315,0.5080056,0.4743752,0.2765727,0.066873014,0.005679205,0.0,0.02317924,0.030563466,0.033887036,0.04050561,0.033535168,0.02195245,0.030662328,0.032476254,0.054526746,0.05966434,0.057879366,0.15753196,0.24473746,0.33212417,0.39874566,0.46717286,0.5612043,0.6486724,0.6590547,0.50068736,0.4340878,0.47161466,0.4592204,0.36625177,0.15124588,0.0,0.0,0.0,0.0,0.005783029,0.0015968531,0.03314133,0.016723476,0.012879327,0.03534195,0.038592294,0.06730317,0.08120246,0.060840093,0.14638142,0.21445033,0.26394787,0.31035295,0.39765882,0.5817341,0.7479818,0.7857561,0.6240455,0.51872444,0.46822906,0.4052205,0.26375353,0.06122894,0.0,0.0,0.0,0.0,0.0,0.0,0.045126796,0.02843304,0.018366896,0.039276473,0.030892715,0.067005515,0.0802917,0.06001456,0.1258407,0.18286268,0.19579798,0.23377514,0.33270532,0.62244374,0.8486922,0.8936842,0.66365063,0.42499006,0.25422117,0.16948327,0.12683742,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05677461,0.041254297,0.02408874,0.04027891,0.031263627,0.061268426,0.09292139,0.06844252,0.13208668,0.18120879,0.17976485,0.2378281,0.29255188,0.65060514,0.92951024,1.0,0.6894661,0.29620117,0.0,0.0,0.093555436,0.0,0.0,0.0,0.0000038146973,0.021290623,0.015435606,0.0,0.06850931,0.056148805,0.033068992,0.035686,0.04091028,0.05546079,0.11951148,0.09204243,0.1580238,0.19248968,0.1578663,0.22731575,0.26341438,0.70166814,1.0,1.0,0.7607608,0.26497692,0.0,0.0,0.069299296,0.0,0.014576271,0.038049042,0.08248699,0.0820961,0.08930379,0.07216884,0.091250524,0.07596997,0.040130906,0.040313467,0.059642218,0.057875834,0.13379131,0.11312031,0.17173953,0.23376401,0.21070746,0.30957592,0.32375532,0.75356627,1.0,1.0,0.7577586,0.24294904,0.0,0.0,0.09978905,0.0,0.050084442,0.06597586,0.093578845,0.086270064,0.10451352,0.068936,0.08952445,0.08641352,0.05233401,0.0456948,0.07534698,0.064540915,0.16091572,0.15014082,0.19894671,0.28670478,0.2694412,0.4044912,0.37961733,0.79753613,1.0,1.0,0.72395223,0.21250021,0.0,0.0,0.13751666,0.0,0.089000836,0.086939305,0.08995978,0.068471834,0.11240247,0.061990008,0.09517756,0.0991704,0.06700355,0.047276773,0.08109701,0.0675631,0.18742679,0.18574004,0.23415348,0.35821232,0.33654243,0.464163,0.41331452,0.80460435,1.0,1.0,0.7230307,0.23375094,0.0,0.0,0.18698776,0.032804333,0.12009913,0.11388188,0.09627664,0.065197244,0.117923744,0.052058674,0.07492563,0.09757418,0.07366133],[0.01741457,0.06678159,0.024556793,0.040396534,0.2740693,0.49562865,0.45310724,0.4227267,0.2978085,0.15611461,0.12758535,0.105998285,0.043179214,0.012792043,0.0018936992,0.2296156,0.6910118,0.9980813,0.81442493,0.52015215,0.16852452,0.0074975938,0.008195564,0.030286886,0.043240897,0.005678013,0.0,0.0035469532,0.026403643,0.053859554,0.039911836,0.033858664,0.23503104,0.40003413,0.43163007,0.44662893,0.4267769,0.3130841,0.24475777,0.20520444,0.14248921,0.1455508,0.21263771,0.4886225,0.76822084,0.81731665,0.50238115,0.19864002,0.0,0.000069484115,0.01651746,0.02665753,0.042730704,0.023307547,0.029557869,0.019687548,0.043685198,0.06276609,0.044341303,0.034135528,0.19457944,0.33580232,0.45734394,0.52280164,0.596021,0.5383727,0.46493614,0.38533932,0.32619485,0.28620374,0.34370232,0.5345009,0.60462046,0.48263514,0.1724791,0.0,0.0,0.0,0.02152399,0.026413426,0.059705652,0.06996796,0.0656162,0.037375882,0.063115925,0.08080823,0.033146307,0.045909785,0.15866883,0.2741859,0.42127293,0.4804529,0.57239413,0.5805701,0.62722063,0.6029007,0.55298334,0.3827296,0.36462802,0.50379187,0.50063,0.35853115,0.100251615,0.0,0.0,0.0,0.0055081844,0.0033174306,0.032407038,0.07451082,0.05601985,0.03163907,0.068824835,0.09283185,0.015804008,0.05523804,0.14149106,0.22839034,0.36185062,0.38212425,0.4857905,0.5540527,0.72259164,0.7865496,0.7341746,0.49479914,0.39270616,0.4773662,0.38833517,0.21016091,0.04011383,0.0,0.0,0.0,0.0,0.0,0.021017566,0.10652587,0.07008125,0.042576097,0.06742154,0.08926809,0.0,0.056898437,0.15790394,0.20648503,0.33064336,0.30453372,0.42500454,0.5532496,0.8215183,0.9088029,0.79552513,0.4560899,0.28514892,0.28824624,0.20513278,0.11472451,0.0251154,0.038923204,0.006579183,0.0,0.0,0.0008581728,0.023392938,0.13386089,0.07834099,0.053586468,0.054291755,0.06430176,0.0,0.066936634,0.18233204,0.21283966,0.338623,0.32584596,0.41921425,0.55880255,0.89002275,1.0,0.8833089,0.45093745,0.16223583,0.052959867,0.090767264,0.124739826,0.070449114,0.10314983,0.08979104,0.09553213,0.098543264,0.10196591,0.110416144,0.15711218,0.08520125,0.067891195,0.04539153,0.04676663,0.0,0.102883,0.2222285,0.23389181,0.33126813,0.32623518,0.38090074,0.5825797,0.9564636,1.0,0.9695467,0.45297104,0.10762999,0.0,0.0015390217,0.09046401,0.11605249,0.21089706,0.19515714,0.22100386,0.27027458,0.26526016,0.27370843,0.19338715,0.09958245,0.08189605,0.05035525,0.057637,0.0,0.11898915,0.26343638,0.298076,0.41649562,0.43025905,0.49279326,0.65391225,1.0,1.0,0.967587,0.4070683,0.10483363,0.0,0.034317404,0.14516136,0.19094053,0.287819,0.2513923,0.252546,0.32618892,0.32336414,0.31693113,0.20579267,0.10675825,0.09761007,0.060021475,0.07383828,0.00025440753,0.15663853,0.3269369,0.38280523,0.5342745,0.5482927,0.61764234,0.71430486,1.0,1.0,0.9442968,0.3415591,0.091025226,0.0,0.07769197,0.21165347,0.28108615,0.37973377,0.30349427,0.26080483,0.3510753,0.35264254,0.34934503,0.2237453,0.1215913,0.11594742,0.05736263,0.06425914,0.031423323,0.1948986,0.38198662,0.4580497,0.644116,0.6550683,0.6947056,0.7433023,1.0,1.0,0.9158237,0.35353908,0.12172557,0.0,0.14217521,0.28785592,0.37034637,0.473135,0.37036443,0.28482807,0.3823939,0.37095055,0.35389772,0.20443502,0.124265835,0.12638187],[0.016466059,0.050359406,0.03306599,0.18684816,0.43665677,0.7109119,0.734355,0.47636294,0.2978407,0.18003112,0.023147516,0.036082357,0.007288836,0.0,0.22062844,0.58609784,0.88017416,0.97056156,0.837256,0.3343535,0.10315795,0.0,0.02451682,0.023120195,0.06641114,0.0038843155,0.010063134,0.0,0.018684,0.054514997,0.033016488,0.15079337,0.37050092,0.6003284,0.6804444,0.53703725,0.4832254,0.35827702,0.18274541,0.100869924,0.092251375,0.123497404,0.41642183,0.7450183,0.8713051,0.74737936,0.48990434,0.098734275,0.0,0.0,0.0049747527,0.0011757612,0.05514758,0.031930193,0.04937175,0.0077253953,0.03414285,0.07292938,0.035962164,0.11302412,0.3172353,0.5313258,0.6756909,0.657074,0.72694117,0.5613807,0.390862,0.2572487,0.2581516,0.210805,0.45575184,0.63014364,0.5701912,0.36747113,0.17896482,0.0,0.0,0.012893967,0.0,0.0028314441,0.06855622,0.056081556,0.07079002,0.031803593,0.058182165,0.08975375,0.051663823,0.08910159,0.279885,0.46089596,0.61957186,0.6747173,0.83716273,0.7247808,0.6338989,0.51022047,0.4744491,0.33378685,0.43933064,0.50834846,0.4476956,0.25130796,0.10052389,0.0,0.0,0.010199226,0.0031287968,0.0,0.049064554,0.041864887,0.045931272,0.025896467,0.06466037,0.08907452,0.056615055,0.06590546,0.24718982,0.3817513,0.51814264,0.57598454,0.80985856,0.8415278,0.83103937,0.7368555,0.6287422,0.45844388,0.41021913,0.38408142,0.32177237,0.19185586,0.09093921,0.0,0.0,0.0,0.0,0.0039791763,0.042564467,0.04359749,0.04193361,0.026386492,0.06350725,0.084781654,0.052479133,0.065406166,0.24813583,0.35920802,0.4613555,0.5071856,0.7679161,0.93880224,0.98383135,0.86859155,0.5726596,0.33807328,0.21945694,0.19708881,0.18645123,0.11642191,0.10792121,0.026559137,0.0,0.0,0.0,0.0077402964,0.040553793,0.0570812,0.044568613,0.031433776,0.0488031,0.057165578,0.025427066,0.0504409,0.2324015,0.36568475,0.46781743,0.563876,0.8073416,1.0,1.0,0.9874245,0.5621552,0.2712216,0.062156767,0.06607022,0.168618,0.1601571,0.18841335,0.12890552,0.04543549,0.0479606,0.07311337,0.09030134,0.08788903,0.085338384,0.054809503,0.043138094,0.04204659,0.043420896,0.019330457,0.06920281,0.25628638,0.39409298,0.45516372,0.5871764,0.80269736,1.0,1.0,1.0,0.5799438,0.22101516,0.0,0.0,0.07653731,0.16215947,0.25104856,0.25903463,0.17238384,0.16509826,0.24003918,0.24191236,0.22622906,0.1352873,0.058634125,0.0376257,0.047933266,0.0553829,0.03733342,0.10747604,0.34990543,0.5074008,0.5737426,0.7296992,0.95306236,1.0,1.0,1.0,0.5479449,0.18938899,0.0,0.0,0.113676846,0.25055787,0.35148388,0.3502578,0.24598697,0.21194956,0.29671866,0.2840274,0.2474782,0.132911,0.056566194,0.042659648,0.058773175,0.08987087,0.081207156,0.17164491,0.48455185,0.65360975,0.72568643,0.88152564,1.0,1.0,1.0,1.0,0.5090326,0.16099225,0.0,0.0118865445,0.16678151,0.35555702,0.4842221,0.47146636,0.31619382,0.22946212,0.30862355,0.29530144,0.24692893,0.121767096,0.053146303,0.04855603,0.047126636,0.09961723,0.11507131,0.2338081,0.60168487,0.7921261,0.86509895,0.97059757,1.0,1.0,1.0,1.0,0.50848687,0.18320598,0.0,0.082145646,0.26209107,0.45209074,0.6050202,0.60393065,0.42781794,0.2988431,0.34403884,0.30894995,0.24815673,0.1191117,0.0574539,0.059858546],[0.0,0.07599596,0.033845805,0.17973603,0.50830734,0.8387559,0.8637326,0.75068825,0.56164527,0.33849138,0.2971919,0.14055263,0.1825765,0.3842221,0.641639,0.86735404,1.0,0.96310604,0.55740696,0.12383595,0.0,0.0,0.0,0.007863857,0.0,0.0,0.010545425,0.0,0.0,0.076434776,0.032970756,0.1373248,0.4237886,0.7203662,0.81282365,0.8195207,0.71584225,0.5211977,0.40318036,0.21505882,0.2525174,0.47469616,0.7377415,0.8955791,0.9585276,0.6522154,0.24711257,0.0,0.0,0.0,0.0,0.0,0.0,0.017631054,0.04129272,0.010426424,0.0015273094,0.08836636,0.026553601,0.078474835,0.34636223,0.6494881,0.80331135,0.94383836,0.92348164,0.7395909,0.57478464,0.3975677,0.38645446,0.507313,0.66398317,0.67525774,0.5519444,0.27032787,0.031570204,0.0,0.0,0.0,0.012746312,0.0,0.0,0.035156347,0.050209448,0.030573592,0.023704141,0.08755467,0.01677753,0.03933513,0.28723314,0.5826166,0.7495158,0.963852,1.0,0.93693846,0.80245364,0.6149278,0.551134,0.5035121,0.5465439,0.5448263,0.42198503,0.15477723,0.018162653,0.0,0.0,0.0,0.043078803,0.0,0.0,0.029672168,0.03654085,0.011311635,0.0440486,0.068512455,0.003822863,0.010120884,0.23581171,0.4978857,0.6518505,0.86631066,1.0,1.0,0.98090494,0.75213194,0.6165599,0.4575655,0.39793056,0.39188123,0.32156664,0.11055067,0.06338167,0.0,0.0,0.009283565,0.072742894,0.0,0.0116683915,0.023109227,0.0371833,0.004225686,0.042366795,0.03978294,0.0,0.016318284,0.23493475,0.46145582,0.5893665,0.79202825,0.96641564,1.0,1.0,0.7622921,0.41582698,0.21569932,0.13648152,0.20097896,0.20450862,0.04203797,0.10270433,0.04937882,0.0,0.01360973,0.09942822,0.006832339,0.025989115,0.022983454,0.037497804,0.015850365,0.026308015,0.006142594,0.0,0.0018256456,0.21490018,0.42491055,0.5611536,0.83906555,0.9980599,1.0,1.0,0.75873077,0.3009305,0.068956345,0.0,0.09796925,0.23122361,0.09496103,0.1970727,0.13821316,0.03743218,0.059513964,0.18939792,0.08327074,0.07095008,0.027473979,0.038179986,0.025485821,0.024440251,0.0,0.0,0.012884773,0.23095056,0.39033753,0.5000913,0.8438683,0.97200805,1.0,1.0,0.7964911,0.19418117,0.0,0.0,0.0,0.14741428,0.08765276,0.25129002,0.2698325,0.16692959,0.20314,0.35713017,0.25284803,0.1880809,0.0488038,0.025971033,0.025358744,0.039037988,0.01967071,0.0,0.06691928,0.33088592,0.50727737,0.6115211,1.0,1.0,1.0,1.0,0.8008029,0.13580191,0.0,0.0,0.0,0.19193858,0.18951517,0.36076403,0.37689286,0.24560785,0.28473338,0.43550617,0.2904719,0.19523397,0.037816085,0.012090899,0.024707817,0.058259964,0.05994249,0.03574848,0.15055786,0.46418422,0.6681028,0.7558979,1.0,1.0,1.0,1.0,0.7989324,0.078778744,0.0,0.0,0.0,0.23904043,0.30335128,0.5015854,0.511215,0.3223421,0.33078766,0.47403568,0.28871572,0.18713424,0.029077247,0.0,0.025261283,0.0571462,0.06902519,0.06537151,0.22437641,0.5761324,0.81023043,0.8470082,1.0,1.0,1.0,1.0,0.77011514,0.07943776,0.0,0.0,0.04391828,0.31408155,0.41134447,0.6181369,0.6301722,0.42243767,0.40314943,0.51047915,0.29457936,0.17993137,0.030176386,0.0,0.036846973],[0.0,0.0206986,0.062974356,0.22769457,0.5253974,0.73015654,0.8399895,0.96414584,1.0,0.81864274,0.6385906,0.5807151,0.639655,0.7864466,0.9076171,0.9331542,0.81081545,0.46879286,0.31093186,0.033586964,0.0,0.0,0.0,0.04264816,0.04925078,0.040802248,0.0,0.0,0.0,0.0051086694,0.04322017,0.18284598,0.4414304,0.64724195,0.7871465,0.9805918,1.0,0.86756223,0.65071404,0.58154625,0.6256391,0.7491125,0.82334363,0.7851514,0.5820573,0.27598226,0.1338369,0.00227049,0.015058219,0.0,0.0,0.04195019,0.056457974,0.054530293,0.0039961636,0.0,0.0053382665,0.0,0.01810605,0.15018593,0.37620682,0.59095895,0.7740521,1.0,1.0,0.96623105,0.74471486,0.65202767,0.6267716,0.58157635,0.5801849,0.48280036,0.27017716,0.13553332,0.06457469,0.022036478,0.044825256,0.0,0.0,0.027697489,0.049939618,0.05065144,0.0,0.0,0.010619216,0.009466462,0.0,0.12756106,0.31065047,0.5342429,0.72816694,1.0,1.0,1.0,0.8257847,0.7254004,0.6055578,0.42306656,0.4011525,0.34621543,0.18904212,0.10026836,0.04982563,0.023553714,0.06557921,0.0,0.0,0.013192497,0.047914572,0.055403635,0.0,0.0,0.016912803,0.023624398,0.0,0.11068228,0.26086318,0.44744176,0.62391645,0.9122985,1.0,1.0,0.85053307,0.7488794,0.5420441,0.2661742,0.21168633,0.21979329,0.15512335,0.10510697,0.07058114,0.030857429,0.07460524,0.002091363,0.0,0.010003939,0.034504414,0.041735165,0.0,0.0,0.0157867,0.01766961,0.0,0.09874977,0.22671771,0.3810609,0.5383158,0.80576915,1.0,1.0,0.922742,0.71297574,0.3750295,0.06514725,0.0,0.053039737,0.059046037,0.08619995,0.12442166,0.0416821,0.07336186,0.019886777,0.023026489,0.00849244,0.018884689,0.026381351,0.0,0.0,0.018570758,0.017637596,0.0,0.07414567,0.18907972,0.33295026,0.5064656,0.79707944,1.0,1.0,1.0,0.7147959,0.26378357,0.0,0.0,0.019673795,0.056911297,0.1290549,0.18621665,0.05185982,0.06786515,0.06723455,0.08378382,0.035573587,0.021244824,0.0174248,0.0,0.0,0.027134664,0.03498636,0.0,0.07005425,0.18016651,0.2561646,0.4049983,0.70376974,1.0,1.0,1.0,0.7097301,0.17893775,0.0,0.0,0.0,0.0,0.10796559,0.23129022,0.12657636,0.14323403,0.18769446,0.2320642,0.15572779,0.10221092,0.023246326,0.0,0.002784267,0.02915889,0.057240374,0.0,0.121450625,0.25540304,0.3341897,0.47029793,0.8069484,1.0,1.0,1.0,0.7291916,0.15866835,0.0,0.0,0.0060799345,0.03473661,0.19377446,0.34895587,0.20517576,0.2271877,0.25346205,0.2847269,0.18583955,0.11749601,0.020856306,0.0,0.0,0.030302115,0.066547625,0.019480467,0.18581818,0.35102096,0.43803155,0.5635674,0.92858434,1.0,1.0,1.0,0.7507624,0.1487911,0.0,0.0,0.024385542,0.087935336,0.2968288,0.48210496,0.29818186,0.29432926,0.28799385,0.29841542,0.1875495,0.12016026,0.022617243,0.0,0.0,0.012995429,0.046892107,0.028689593,0.2238259,0.41932106,0.5135193,0.62576157,0.9755794,1.0,1.0,1.0,0.7324108,0.14434804,0.0,0.0,0.041664556,0.14681888,0.3760778,0.5629144,0.38249832,0.36355424,0.3427084,0.32437253,0.20874298,0.13070577,0.023338065,0.0,0.0],[0.0,0.038010366,0.07923081,0.2216725,0.3674359,0.54001796,0.6999125,0.8420872,1.0,1.0,1.0,0.93112516,1.0,1.0,0.8392552,0.6643751,0.37598032,0.21686578,0.09278166,0.023779534,0.0,0.0413303,0.058725514,0.02113399,0.026845753,0.030373827,0.0,0.0,0.0,0.014239259,0.062196597,0.17832963,0.32658845,0.47991318,0.67625755,0.8667604,1.0,1.0,0.96374184,0.86984706,0.90414256,0.8778867,0.6402839,0.45390987,0.19461128,0.07375367,0.043332756,0.025176488,0.0,0.029401794,0.04235995,0.037492678,0.039309934,0.050138585,0.0,0.0,0.0,0.00065506995,0.03885994,0.1482011,0.30657384,0.45738727,0.70218617,0.9388746,1.0,1.0,0.8999189,0.8304772,0.75674635,0.59705305,0.34495142,0.19914168,0.05468844,0.04782415,0.08462348,0.007623352,0.029349804,0.0,0.0064252466,0.03467506,0.033279903,0.040433012,0.0,0.0,0.01707808,0.0,0.03498377,0.104203746,0.25914797,0.4153769,0.70507294,0.9392487,1.0,0.9942801,0.8116659,0.7392509,0.5674308,0.37230447,0.21452844,0.16883554,0.083791524,0.054681636,0.08166,0.019345477,0.0648694,0.027776398,0.0012795776,0.04568015,0.058193,0.045496084,0.0,0.0,0.034949742,0.0,0.03084153,0.07711466,0.2263133,0.36390442,0.6287458,0.8260533,0.9277645,0.9180359,0.74383175,0.6025543,0.36933357,0.122591,0.0755423,0.15427709,0.15438095,0.08778331,0.09077448,0.028313287,0.07681689,0.06556725,0.008222289,0.055270195,0.059768654,0.04264961,0.0,0.0,0.046383075,0.0,0.03250546,0.067173935,0.21361595,0.32374823,0.563069,0.7473402,0.8892777,0.9266482,0.775915,0.46454,0.17293411,0.0,0.0,0.09908058,0.1591816,0.113212585,0.1095274,0.03698512,0.05519212,0.097410336,0.025044337,0.06482571,0.052926823,0.02399443,0.0,0.0,0.049600914,0.0,0.029931158,0.05386597,0.19828746,0.3021369,0.53590316,0.7226662,0.89234525,0.92982703,0.8307213,0.42504472,0.09898627,0.0,0.0,0.10651969,0.19252461,0.1517652,0.12119925,0.022154145,0.03521569,0.12415222,0.040202543,0.081770465,0.045672275,0.016354516,0.0,0.0,0.06376824,0.004230529,0.0403917,0.060611755,0.19229536,0.24572542,0.42694432,0.6058005,0.85902387,0.88102716,0.8147202,0.40483588,0.08204059,0.0,0.0,0.083703056,0.1303557,0.15086357,0.089864425,0.04277952,0.09284298,0.1966826,0.12183668,0.14944842,0.073488966,0.028716609,0.0,0.0,0.0714179,0.02065967,0.05789066,0.09329881,0.24874502,0.30382422,0.47826105,0.6546477,0.9272812,0.8936916,0.8221422,0.4177395,0.10215244,0.0,0.0,0.08930739,0.17321618,0.25114495,0.13694622,0.07269769,0.13906099,0.2196844,0.1387286,0.17337056,0.07964942,0.03560751,0.0,0.0,0.07190973,0.019043237,0.054545358,0.136551,0.3116394,0.36949024,0.547188,0.7219133,1.0,0.914214,0.8465024,0.4270261,0.11796172,0.0,0.0,0.10150692,0.23805098,0.36080915,0.2089594,0.10604646,0.16973275,0.22295308,0.13102525,0.17656493,0.074815944,0.04171925,0.0,0.0,0.052035928,0.004217699,0.038577132,0.15719499,0.3501262,0.40044278,0.5481667,0.70777434,0.97813493,0.85177636,0.81183434,0.41641372,0.12486921,0.0,0.0,0.09169674,0.26864773,0.40970874,0.25195315,0.13661397,0.1924278,0.23276152,0.109529585,0.18215804,0.06776874,0.03899418,0.0,0.0],[0.0,0.051590815,0.07481306,0.14181592,0.20034188,0.23076227,0.25694698,0.44697857,0.7653831,0.8780654,0.9268285,0.76208794,0.7418839,0.5464465,0.37860107,0.15257221,0.04079593,0.0,0.0,0.0,0.0007150769,0.015152432,0.0,0.0,0.028626017,0.006627716,0.018310152,0.0,0.0,0.039537556,0.063321814,0.11989612,0.16590793,0.22638494,0.268977,0.44602603,0.7226908,0.8232331,0.84160054,0.6780611,0.6542341,0.4438594,0.25429735,0.06675836,0.00853356,0.0,0.0,0.0,0.016341366,0.020612046,0.018540993,0.0,0.03637249,0.0,0.0,0.0,0.0,0.050785884,0.06664231,0.10111018,0.15450361,0.26817113,0.3344452,0.46301758,0.6744428,0.7675098,0.7311196,0.55074024,0.48080963,0.24810506,0.0626603,0.0,0.020870417,0.0,0.0,0.0,0.0033566356,0.0,0.026717536,0.0,0.025390506,0.0,0.0,0.0,0.0,0.030090876,0.049785107,0.05586975,0.115271315,0.2734664,0.36734405,0.46354854,0.5889992,0.6564229,0.57235324,0.41671723,0.30105042,0.14652295,0.04278847,0.03141827,0.0749762,0.029143743,0.0,0.0,0.016128168,0.015913129,0.053355962,0.012674585,0.057950728,0.0,0.0,0.0,0.0,0.014537007,0.038249455,0.022012785,0.087435275,0.25030032,0.33882296,0.4303158,0.5227542,0.59721124,0.4552936,0.30397856,0.1516407,0.047259666,0.04100035,0.09439477,0.14543943,0.06398007,0.015362859,0.0,0.014799945,0.02847007,0.049552307,0.0,0.040208735,0.0,0.0,0.0,0.0,0.014503531,0.035610028,0.018523656,0.08768248,0.21373548,0.3154732,0.43329525,0.5347944,0.64497787,0.4482668,0.28170958,0.071875036,0.0,0.04286486,0.12248702,0.15277098,0.05908221,0.0069162026,0.0,0.012904666,0.03563451,0.052154936,0.0,0.02308523,0.0,0.0,0.0,0.014761239,0.010487139,0.02722311,0.003805384,0.0775554,0.16657409,0.29087132,0.39022207,0.52262056,0.67228675,0.5104692,0.30427253,0.0066478252,0.0,0.034160204,0.12144376,0.12654625,0.062137157,0.003738612,0.0,0.0,0.019341879,0.05344581,0.0,0.0064113736,0.0,0.0,0.0,0.032053754,0.00965184,0.02699352,0.0,0.075999424,0.086987495,0.19488229,0.26580924,0.46045786,0.6429087,0.5239509,0.31846058,0.0,0.0,0.041484788,0.09521127,0.072501615,0.03304307,0.0,0.0,0.0,0.030863635,0.068328574,0.0026109964,0.0008752048,0.0014155507,0.0,0.0,0.033952363,0.013403133,0.03165231,0.002849251,0.10571747,0.09707548,0.20838496,0.2569533,0.48112947,0.6788033,0.56620574,0.37182632,0.0033174157,0.0,0.07148463,0.10937766,0.11723493,0.09560569,0.022941962,0.0,0.0,0.03571873,0.07844936,0.0,0.0,0.0,0.0,0.0,0.026308276,0.012774177,0.03025648,0.0012676418,0.12058424,0.096167326,0.22910231,0.27508223,0.5141419,0.71562517,0.60995126,0.42931038,0.060580313,0.0,0.090940684,0.121079065,0.17848533,0.17261916,0.088717125,0.021348454,0.0,0.043804422,0.08013211,0.0,0.0,0.0,0.0,0.0,0.019523919,0.010086834,0.02268342,0.0,0.10884005,0.0803065,0.21574637,0.2556064,0.48716187,0.66131085,0.579469,0.43240654,0.12043947,0.0,0.08729449,0.0863372,0.18182921,0.20586494,0.12409541,0.037343055,0.010142431,0.0499968,0.07909493,0.0,0.0,0.0,0.0,0.0],[0.0106378645,0.0,0.03187935,0.12310661,0.07509747,0.06502877,0.040699266,0.07933247,0.21121225,0.23506433,0.2200036,0.19774558,0.12669964,0.0,0.0,0.0,0.0,0.004557535,0.01038985,0.0,0.064063214,0.0,0.0,0.0,0.01991789,0.00067582726,0.03407737,0.023748353,0.0063800067,0.0,0.017545901,0.10305907,0.05999066,0.072641656,0.05263547,0.07428248,0.20248553,0.2329889,0.2009271,0.18560019,0.14188652,0.0,0.0,0.0,0.0,0.0,0.012126602,0.015342742,0.07218615,0.0,0.0,0.0,0.0,0.00056792796,0.01630319,0.017550372,0.004042074,0.0,0.0072896257,0.081876755,0.057117455,0.123770766,0.101937644,0.10009658,0.21642576,0.26177585,0.19935045,0.1320669,0.09904926,0.0,0.0,0.00034628808,0.0409545,0.018727109,0.0,0.011046678,0.04475414,0.0,0.0,0.0,0.0,0.0,0.0,0.01980979,0.010271788,0.006436743,0.0,0.0464764,0.05785062,0.15496074,0.10873886,0.12346898,0.20024225,0.24294937,0.16188222,0.06982613,0.021365039,0.0,0.032237515,0.07713014,0.08139733,0.03707742,0.0,0.0,0.03630294,0.01299312,0.0,0.0,0.0,0.0,0.0,0.022513837,0.013096236,0.008912995,0.0,0.036487475,0.060581744,0.15312685,0.092627004,0.14145933,0.2114136,0.25940257,0.14870864,0.028877035,0.0,0.0,0.0896316,0.13944083,0.10707605,0.047170505,0.0,0.0,0.009552576,0.025990076,0.0,0.0,0.0,0.0,0.0,0.017153561,0.019522399,0.001070857,0.0,0.044343434,0.083778456,0.12780581,0.1214952,0.19515646,0.2887507,0.36242235,0.18736732,0.04415507,0.0,0.0,0.098059535,0.16500477,0.07913834,0.036068738,0.0,0.0,0.0,0.035180658,0.0,0.0,0.00084230304,0.0,0.0,0.003586918,0.02101811,0.0,0.0,0.05556631,0.1030651,0.11328012,0.16009092,0.2248498,0.3020263,0.46984714,0.3007783,0.08227007,0.0,0.007313177,0.10659453,0.14498982,0.06452711,0.03834623,0.0,0.0,0.0,0.05114995,0.020839743,0.0019574612,0.03879831,0.0,0.0,0.0,0.024173342,0.0,0.0,0.07491841,0.13664232,0.065722175,0.119758494,0.17464545,0.25930935,0.51276016,0.4004163,0.07732756,0.0,0.02873756,0.1311459,0.11450747,0.03412883,0.0,0.0,0.0,0.006733164,0.08281512,0.053951584,0.010173492,0.09730275,0.00957267,0.0,0.0,0.034522288,0.0,0.0,0.11226561,0.17593491,0.070760936,0.122922815,0.16992703,0.26941073,0.57362807,0.49734908,0.12725088,0.0,0.06305665,0.17116031,0.14777346,0.082206205,0.014528513,0.021280743,0.025171235,0.013988502,0.09913069,0.06384446,0.0,0.12606755,0.013988234,0.0,0.0,0.045530036,0.0,0.0,0.13316807,0.18623108,0.058152758,0.12356733,0.17714117,0.29290855,0.630352,0.5728586,0.18630004,0.0,0.10417708,0.21068858,0.18997139,0.15513013,0.08536828,0.08955732,0.057761572,0.027772024,0.11611353,0.079430625,0.0,0.14849132,0.008652814,0.0,0.0,0.048462316,0.0,0.0,0.12074245,0.17359413,0.035086073,0.11475231,0.14745697,0.26462704,0.5946008,0.5643046,0.20588171,0.0,0.12655336,0.2077808,0.18346617,0.18594828,0.12270191,0.12595849,0.07161467,0.032833785,0.10936257,0.06437184,0.0,0.14632116,0.0,0.0,0.0],[0.025316529,0.040282913,0.026186824,0.0,0.0,0.030591093,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049280055,0.052178085,0.028437272,0.0,0.017227307,0.03293071,0.012927502,0.0,0.0,0.013651706,0.0,0.010796048,0.011231646,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020376347,0.01726707,0.0,0.0,0.003975734,0.020972833,0.0015697777,0.0,0.0,0.013153486,0.0,0.06462303,0.07372112,0.014927484,0.0,0.0,0.0,0.016047336,0.0,0.0,0.0024499148,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0003719777,0.010527991,0.0052080452,0.0,0.0008741766,0.018813647,0.0,0.06197638,0.059382245,0.0050667375,0.0,0.0,0.0,0.028938174,0.03794182,0.0010082573,0.0117261335,0.009018324,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0024896264,0.011417925,0.0,0.021949358,0.02143643,0.0,0.058124274,0.045948274,0.00784108,0.0,0.0,0.013570175,0.03323719,0.06870886,0.02428753,0.03255721,0.028111875,0.010135241,0.0,0.0024826527,0.0057795346,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0072593167,0.0025656372,0.0,0.031915426,0.036383472,0.019702673,0.10829468,0.07439804,0.03471195,0.0,0.0,0.048017904,0.051838167,0.09356199,0.031430706,0.020300291,0.00604409,0.0058333725,0.0,0.0,0.012342222,0.01587402,0.0,0.0002348721,0.0,0.0,0.0,0.0,0.0047697723,0.0,0.0,0.02700714,0.036863,0.02786225,0.12790112,0.08984077,0.06526891,0.020162411,0.059980877,0.10861134,0.063136235,0.1015386,0.012959011,0.0,0.0,0.0009505451,0.0,0.0,0.012305893,0.024028413,0.0,0.0,0.0,0.0,0.0,0.0,0.000030130148,0.0,0.0,0.028200999,0.031466983,0.0016293526,0.07194157,0.055587545,0.06436444,0.04899679,0.094341144,0.12984508,0.04959763,0.099674836,0.016571686,0.0,0.0,0.0,0.0,0.0,0.001434207,0.02425512,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.044672273,0.07100223,0.031049542,0.0857846,0.05851698,0.09556481,0.096965745,0.14836322,0.18020284,0.06374775,0.13646986,0.06293365,0.0,0.0,0.022237778,0.0,0.0,0.0,0.019261785,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.043407224,0.09490497,0.055287875,0.11488606,0.06937753,0.13491264,0.15896377,0.22068053,0.24731351,0.07829864,0.1681489,0.10007814,0.047811046,0.05091144,0.07261954,0.028681695,0.000082463026,0.0,0.013704866,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03784672,0.10552035,0.054104254,0.0903653,0.04807706,0.14790642,0.17953967,0.23035626,0.25888503,0.08358224,0.16855416,0.10992556,0.073973805,0.08440027,0.1062454,0.045729056,0.0027132183,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.021591432,0.04854802,0.0,0.04704304,0.08375983,0.024943314,0.03089092,0.02156809,0.030908376,0.020312302,0.0,0.0,0.047949836,0.01838857,0.0,0.05218736,0.014464468,0.02632989,0.0082557425,0.013037585,0.0,0.0,0.0,0.059814617,0.018104523,0.038422585,0.018508963,0.0,0.020691313,0.042418882,0.0,0.042509623,0.06831014,0.019113101,0.03338792,0.029448837,0.027718477,0.022313163,0.0,0.0,0.062550195,0.030716948,0.0,0.049282327,0.009457216,0.0,0.0,0.010502763,0.0,0.0,0.002115056,0.06735163,0.0058466718,0.024145745,0.014530398,0.0,0.021923058,0.03933292,0.0,0.042904906,0.05984419,0.039456077,0.074154295,0.070047095,0.021011688,0.0,0.0,0.00026474893,0.07019141,0.044135466,0.0,0.038913183,0.0,0.0,0.0,0.02014865,0.0,0.0,0.002757609,0.051440492,0.0,0.00383012,0.008990243,0.0,0.020199753,0.03328377,0.0,0.035731196,0.04172568,0.052550167,0.060149632,0.058280766,0.0,0.0,0.0,0.0,0.023087561,0.025963552,0.0,0.011087909,0.0,0.0,0.0,0.02954369,0.008245088,0.0,0.0037038475,0.03537497,0.0,0.0,0.0003245473,0.0,0.018335566,0.029479489,0.009203896,0.028874174,0.01429081,0.04048696,0.056045644,0.03835766,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025842242,0.024439678,0.0,0.0,0.0073043182,0.0,0.0,0.0,0.0025538504,0.02719725,0.028767847,0.009195805,0.021399274,0.0,0.028100908,0.08084422,0.05891569,0.02047079,0.0,0.011709586,0.017719343,0.004423678,0.0035559237,0.0,0.0,0.0,0.0,0.0,0.016330965,0.036779985,0.008518599,0.0,0.019866236,0.0,0.0,0.0,0.0072480068,0.04811667,0.03309975,0.02051597,0.020378344,0.0,0.01685875,0.09540514,0.08250189,0.04424084,0.045426175,0.060051173,0.05765807,0.03677904,0.0055993646,0.0,0.0,0.0,0.0,0.0,0.00451687,0.037299022,0.020323955,0.0076597184,0.028809428,0.0091967285,0.0,0.0,0.011112206,0.065743454,0.05089453,0.035332315,0.024199419,0.0,0.0,0.07889603,0.07808621,0.06031067,0.07251267,0.09116317,0.069687106,0.04969345,0.03431996,0.0,0.0,0.0,0.0,0.0,0.002496764,0.011486322,0.0066802427,0.01654765,0.036459535,0.058187537,0.016843371,0.0,0.015925594,0.08476511,0.07613075,0.038110636,0.039526634,0.0,0.0,0.102194324,0.10301916,0.09746686,0.11595419,0.12581375,0.08300482,0.070249766,0.07530026,0.0,0.0,0.0,0.0,0.0,0.0046432614,0.0,0.0,0.029039524,0.047625378,0.073814325,0.036926202,0.0,0.017923765,0.09415276,0.084857374,0.019070506,0.042187437,0.0,0.0,0.12843928,0.13564599,0.16197684,0.18219626,0.18318802,0.11330531,0.08363286,0.092728615,0.0,0.0,0.0060102865,0.0008339286,0.0,0.011311591,0.0,0.0,0.03242059,0.059675053,0.08680867,0.055746123,0.0,0.005915217,0.05776131,0.048657067,0.0,0.04327704,0.0011063516,0.0,0.109721735,0.13701475,0.19817334,0.1983386,0.18771559,0.11577787,0.0845905,0.09887232,0.0,0.0,0.033794582,0.01394745,0.0,0.007700883,0.0,0.0,0.01978816,0.055477187,0.07658015,0.06299249,0.0],[0.0,0.008507587,0.036696084,0.0,0.07365666,0.022632167,0.011941738,0.0,0.0019154847,0.0,0.008594297,0.0,0.016289152,0.026463576,0.01774463,0.0,0.01428774,0.07139899,0.049835667,0.0,0.0,0.0,0.0,0.015730157,0.027433008,0.0011170357,0.0,0.0,0.0,0.010743715,0.033375815,0.0,0.063766554,0.01809676,0.00886555,0.0,0.0,0.0,0.004725918,0.006315306,0.023853935,0.029436328,0.0072529614,0.0,0.0006290674,0.04882592,0.030678682,0.006311089,0.0,0.0,0.0,0.013253517,0.01803694,0.0,0.0,0.0,0.0,0.011104763,0.040487126,0.0,0.05841656,0.01604607,0.023816377,0.016050726,0.009655848,0.0,0.0,0.0,0.019666694,0.01633051,0.0,0.0,0.0,0.027932733,0.020155773,0.028141037,0.0031781197,0.0,0.0,0.0060573816,0.0054388493,0.0,0.0,0.0019160658,0.0,0.00920327,0.04375022,0.0021840185,0.04578249,0.0072041973,0.016276337,0.0069826096,0.0022441,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.033678867,0.0086622685,0.0,0.0,0.0,0.0,0.0,0.0,0.0035334378,0.0,0.0046678334,0.041586995,0.008124232,0.040141843,0.0,0.0020019412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.038388126,0.025647022,0.0028755665,0.0,0.0,0.0,0.0,0.0,0.0051507354,0.0,0.0035184622,0.0301454,0.0076122433,0.019107156,0.0,0.0,0.0,0.0,0.0069957525,0.0,0.0,0.0,0.0034562647,0.0,0.0,0.0,0.0,0.0,0.03278494,0.033486173,0.007918641,0.0,0.0,0.0,0.0,0.0,0.00443013,0.006608896,0.011531934,0.02170486,0.0058444142,0.0,0.0,0.0,0.0,0.0,0.021647848,0.03648646,0.041608877,0.01927185,0.008234873,0.0,0.0,0.0,0.0,0.0,0.028310284,0.037857935,0.015864864,0.0,0.0,0.0,0.0,0.0,0.0014409125,0.013601422,0.030761994,0.025378041,0.0044005513,0.0,0.0,0.0,0.0,0.0,0.02356401,0.06250813,0.07834282,0.033077084,0.0051469654,0.0,0.0,0.0,0.0,0.0,0.021060579,0.024865031,0.014988244,0.0,0.0,0.009257726,0.0,0.0,0.0,0.021385334,0.049405716,0.043161824,0.016211674,0.0,0.0,0.0,0.0,0.0021540672,0.034288816,0.08513274,0.09212124,0.043186247,0.013313606,0.0,0.0,0.0,0.01231768,0.0,0.018170096,0.015455797,0.020730607,0.0,0.0,0.012694411,0.0,0.0,0.0,0.026750527,0.05743338,0.05298283,0.02016475,0.0,0.0,0.0,0.0064444095,0.027055807,0.08250056,0.13807781,0.112733416,0.05653573,0.019909576,0.0,0.0,0.0,0.024810381,0.0,0.017131522,0.011513948,0.030578703,0.0,0.0,0.02262228,0.0,0.0,0.004780248,0.019829966,0.036208995,0.030804627,0.005816132,0.0,0.0,0.0,0.0032264143,0.028384723,0.10697092,0.15555876,0.11832414,0.061146393,0.019844554,0.0,0.0,0.0,0.045911066,0.0,0.013046488,0.006944485,0.03193944,0.0,0.0,0.026607782,0.0,0.0,0.008141592],[0.021079183,0.0057993755,0.0,0.0,0.0061695203,0.0,0.01891663,0.0,0.0,0.0,0.0,0.0,0.01308088,0.002145782,0.0,0.0,0.03569559,0.0,0.0,0.0,0.0,0.06286601,0.026600778,0.018078655,0.0,0.0,0.0,0.019038357,0.025212295,0.002766192,0.0,0.0,0.0,0.0,0.013475783,0.0,0.0,0.0,0.0,0.0,0.011240929,0.017494224,0.0,0.0,0.025122054,0.0,0.0,0.0,0.0,0.06559758,0.022857942,0.012948513,0.0,0.0,0.0,0.0011536926,0.021313623,0.0,0.0,0.005793564,0.0,0.0,0.021028668,0.0066147894,0.00675223,0.0,0.0,0.0,0.009807155,0.01526168,0.002496481,0.0031940192,0.0072079822,0.0,0.0009797364,0.0,0.0,0.062720016,0.013473928,0.0,0.0,0.0,0.0,0.0,0.020489082,0.0,0.0,0.011901483,0.0,0.0,0.022984333,0.0021139085,0.010902122,0.0035700053,0.0,0.0,0.015379526,0.014694385,0.0026303083,0.0,0.0,0.0,0.0023105145,0.0,0.0,0.057018273,0.00090162456,0.0,0.0,0.0,0.0,0.0,0.021737866,0.0,0.0049711466,0.026936725,0.0,0.0,0.027941033,0.0,0.006865002,0.018753655,0.0,0.0,0.021807134,0.014555573,0.0028089583,0.0,0.0,0.0,0.008977473,0.0,0.0,0.050680205,0.0,0.0,0.0,0.0,0.0,0.0,0.025576368,0.000934422,0.0070122853,0.036159284,0.0006774217,0.0,0.040313885,0.0014082342,0.009847142,0.047326773,0.0,0.0,0.025269695,0.011297606,0.013227753,0.004140392,0.0,0.0,0.017593049,0.0,0.0,0.03931842,0.0,0.0,0.0,0.0,0.0,0.0,0.032941133,0.009453714,0.0,0.021395907,0.0,0.0,0.041869156,0.004338324,0.03706161,0.087756716,0.0,0.0,0.024932638,0.0050960034,0.02228766,0.0047238916,0.0,0.0,0.026353672,0.0,0.0,0.019025147,0.0,0.0,0.0,0.0,0.0,0.0,0.039244577,0.016333833,0.0,0.0053775758,0.0,0.0,0.031248637,0.011413351,0.063083604,0.12602745,0.0,0.0,0.01625295,0.0,0.02985403,0.0012881011,0.0,0.0077031553,0.033763804,0.0,0.0,0.0,0.0,0.0,0.00846421,0.027463049,0.0,0.0,0.045003287,0.024947815,0.0,0.0,0.0,0.0,0.0,0.0027011484,0.053965084,0.13419229,0.0,0.0,0.014581449,0.0,0.05106432,0.0,0.0,0.019467227,0.035166524,0.0,0.0,0.0,0.0,0.018753342,0.029284813,0.062193736,0.0,0.0,0.050944418,0.038444214,0.0,0.0,0.0,0.0,0.0,0.0,0.029835865,0.118578754,0.0,0.0,0.012371562,0.0,0.06611259,0.0,0.0,0.023071826,0.032849662,0.0,0.0,0.0,0.0,0.02457159,0.027042687,0.07046306,0.008155361,0.0,0.054262787,0.053399876,0.0,0.0,0.0,0.0,0.0,0.0,0.014430247,0.103727,0.0,0.0,0.012752481,0.0,0.07671401,0.0021031648,0.0,0.022300988,0.030364253,0.0,0.0,0.0,0.0,0.030104928,0.025238521,0.079122856,0.015587032,0.0],[0.0090345815,0.0,0.0,0.0,0.015077256,0.0,0.0036364049,0.0,0.0,0.0,0.005964257,0.0,0.021692514,0.0061453283,0.02332671,0.0067751184,0.04054769,0.029509604,0.0,0.0,0.025746278,0.007262364,0.03619702,0.00835716,0.02886451,0.0,0.0,0.0,0.01244206,0.0,0.0,0.0,0.003997043,0.0,0.0,0.0,0.0,0.0,0.0,0.009075537,0.051786408,0.025301434,0.023739986,0.009868711,0.019415565,0.034996867,0.0,0.0,0.04940232,0.03795688,0.051696382,0.0,0.012089111,0.0,0.0,0.0,0.00645227,0.0,0.0,0.0,0.0064101517,0.0,0.012278967,0.0,0.0,0.0,0.0,0.012858786,0.06435543,0.040154688,0.030797176,0.018420465,0.015512764,0.045436524,0.0,0.0,0.062164493,0.060652472,0.057538964,0.0,0.0013986379,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0093913525,0.0,0.024423681,0.0,0.0034033656,0.0,0.0,0.026119262,0.08068696,0.046676017,0.02543316,0.014531307,0.0054475665,0.043127388,0.0,0.0,0.039709188,0.049541265,0.044882476,0.0,0.0015535206,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012431957,0.0,0.030530326,0.0,0.012030408,0.0,0.0,0.038148895,0.09188305,0.04898891,0.02117315,0.0,0.0,0.036716893,0.0,0.0,0.0042315423,0.035927698,0.035746537,0.0,0.008114658,0.0,0.00023518503,0.0,0.0,0.0008109957,0.0,0.0,0.0052609146,0.0,0.04164374,0.0,0.02997972,0.002981469,0.0,0.046444267,0.08393332,0.03815919,0.020936266,0.0,0.0,0.025377445,0.0,0.0,0.011268333,0.036294997,0.022789896,0.0024614483,0.017283514,0.0,0.0,0.0,0.0,0.014402576,0.0,0.0,0.0,0.0,0.032047816,0.0,0.067629255,0.020758383,0.0,0.046224356,0.06380637,0.021547064,0.016625613,0.0,0.0,0.008056566,0.0,0.0,0.019341558,0.039067306,0.0040824413,0.009476133,0.031213395,0.0,0.0,0.0,0.0,0.0096426755,0.0,0.0,0.0,0.0,0.025406174,0.0,0.114281975,0.02609273,0.0,0.02986405,0.041191943,0.0,0.006558761,0.0,0.0,0.0,0.0,0.0,0.0,0.023185119,0.0,0.022391431,0.06087265,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0047448575,0.0,0.13530007,0.010051288,0.0,0.033033818,0.051646106,0.0,0.009330034,0.0,0.0,0.0,0.0,0.0,0.0,0.009174801,0.0,0.030698158,0.08906248,0.024213366,0.020956427,0.0,0.0,0.004141137,0.0,0.0,0.0,0.0,0.0,0.0,0.120472535,0.0,0.0,0.041214928,0.065392226,0.0,0.0050017685,0.0,0.0,0.0,0.0,0.0,0.0,0.016475677,0.0,0.035100974,0.097623006,0.025651082,0.030652076,0.0,0.0,0.0075781792,0.0,0.0,0.0,0.0,0.0,0.0,0.11252723,0.0,0.0,0.04584632,0.0748359,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0217067,0.0,0.03641376,0.100637145,0.024472423,0.03425871,0.0],[0.012398168,0.009929426,0.025608562,0.036685638,0.028179958,0.045107096,0.0,0.0,0.054231085,0.0,0.0,0.013263553,0.015057258,0.0,0.0,0.0,0.065533265,0.0,0.0068095773,0.040369354,0.1148502,0.076021865,0.061734483,0.02185911,0.020992704,0.0,0.0,0.0032132566,0.021319851,0.0032262206,0.00639534,0.018239133,0.007159598,0.046295583,0.002625689,0.0,0.08793754,0.0,0.0,0.048005342,0.04747375,0.0,0.0,0.0,0.06583838,0.0,0.0043027997,0.052014172,0.10921303,0.08476423,0.036210828,0.017930314,0.018391334,0.0,0.005791746,0.0,0.017742537,0.0,0.0,0.009881966,0.0018778145,0.058780387,0.03829381,0.013105288,0.11916327,0.007963069,0.0,0.05467067,0.0564942,0.0,0.0,0.0,0.0735652,0.006851703,0.0049728155,0.06369554,0.11799166,0.10774536,0.040341616,0.01319503,0.027473994,0.0,0.03347282,0.0,0.004081741,0.0,0.0,0.01756262,0.007985741,0.07554352,0.066322096,0.030463196,0.12460462,0.025208585,0.022563688,0.047625534,0.069650196,0.0,0.0,0.0,0.06780747,0.027004346,0.006713353,0.059571914,0.099029735,0.09984116,0.04170523,0.0016780049,0.02405686,0.0,0.044887207,0.0,0.0,0.0,0.0,0.019571908,0.006224498,0.08695735,0.06604942,0.035862386,0.12123604,0.02942574,0.030963667,0.041141234,0.07492193,0.0,0.0,0.0,0.05770404,0.03894963,0.009063408,0.058253802,0.07371675,0.104855336,0.059058733,0.00092485547,0.032597013,0.0,0.042210184,0.0,0.0,0.0,0.0,0.021474428,0.0,0.09254427,0.071260184,0.054739967,0.1176945,0.015102804,0.031906478,0.029619217,0.077356145,0.0047738105,0.010726236,0.0,0.04137119,0.0082514435,0.0,0.07044147,0.07126086,0.115066774,0.05770096,0.0013598651,0.044246815,0.0,0.039084114,0.0,0.0,0.0,0.0,0.012057535,0.0,0.06519603,0.044082157,0.06471124,0.13025142,0.0101686865,0.025470927,0.020975888,0.09267133,0.017144099,0.02041915,0.0,0.04025709,0.0041323304,0.0,0.059680007,0.09489602,0.116388135,0.05615522,0.010326661,0.066502355,0.0,0.041903347,0.0,0.0,0.0,0.0,0.0062713027,0.0,0.03261015,0.02634222,0.07710795,0.15585357,0.0,0.018424936,0.013715148,0.10954416,0.016666114,0.02223906,0.0,0.026542835,0.0,0.0,0.024601303,0.06572779,0.10983342,0.042631924,0.01887519,0.09791695,0.008194737,0.058681235,0.0019919127,0.0,0.0,0.0025468916,0.0166682,0.0,0.0009496957,0.02491659,0.09520395,0.17328078,0.0,0.017242856,0.027312271,0.11256415,0.012677178,0.01564762,0.0,0.0,0.0,0.0,0.0,0.043035954,0.077711284,0.023364954,0.011990815,0.12341575,0.033238567,0.07884677,0.02298645,0.0,0.0,0.0,0.002586782,0.0,0.0,0.016187549,0.097449884,0.18303126,0.0,0.028703928,0.042443812,0.13664125,0.014503777,0.006707959,0.0,0.0,0.0,0.0,0.0,0.046093218,0.07253976,0.025012724,0.017597161,0.14335962,0.046274014,0.09807481,0.029834837,0.0,0.0,0.0,0.0,0.0,0.0,0.019329488,0.09957472,0.18565796,0.0,0.03726217,0.058120884,0.13548787,0.011421531,0.0060150325,0.0,0.0,0.0,0.0,0.0,0.042434156,0.07443717,0.027548298,0.016825713,0.15985925,0.050937973,0.10803031,0.037028417],[0.0,0.03169012,0.037669174,0.0048728436,0.030644886,0.022941783,0.030904941,0.0,0.008394986,0.04872951,0.015510634,0.03298814,0.0,0.0060909763,0.0,0.0,0.013026483,0.015178315,0.047409095,0.042115986,0.2011683,0.20061366,0.09779222,0.0,0.02066619,0.0,0.0,0.0067961365,0.0,0.04024049,0.04086685,0.0,0.012196079,0.026354365,0.045081005,0.013298206,0.016172558,0.047416046,0.023174442,0.06786693,0.026143149,0.035927333,0.002660513,0.0,0.004267752,0.0005570799,0.020096935,0.02395995,0.20583388,0.18225619,0.079015866,0.0,0.050204515,0.0,0.0,0.0,0.0,0.047107644,0.04598867,0.003705874,0.013178095,0.046212375,0.07880622,0.04628806,0.037517674,0.053555265,0.030483976,0.08335805,0.0502538,0.054331444,0.00994584,0.0,0.0,0.0,0.013500974,0.045273557,0.23856683,0.20555976,0.09739801,0.00075513124,0.06652636,0.0,0.0,0.0,0.0,0.041642837,0.042157717,0.0074496195,0.030190095,0.06574227,0.0922361,0.0486572,0.037817806,0.054024383,0.03637415,0.0806026,0.05488637,0.04913518,0.019704051,0.0,0.0,0.0,0.0,0.04842695,0.23886609,0.20888905,0.109211065,0.0,0.05977664,0.0,0.0,0.0,0.0,0.022919573,0.022808678,0.0,0.033210658,0.06701019,0.0966926,0.048399992,0.03151957,0.051749073,0.034168787,0.07059306,0.051028132,0.036485888,0.028299317,0.0,0.0,0.0,0.0,0.058412135,0.23882678,0.19829665,0.121124536,0.0,0.04381776,0.0,0.0,0.0,0.0,0.007540904,0.0,0.0,0.03354594,0.07505656,0.11924864,0.06357899,0.03972847,0.055386312,0.04284084,0.04553874,0.038782626,0.024751902,0.044156343,0.018470876,0.0,0.0,0.0,0.094866574,0.24741796,0.17239313,0.09313381,0.0,0.022298008,0.010913447,0.0,0.0,0.0,0.0,0.0,0.0,0.031987086,0.07027856,0.11621936,0.06504537,0.05137541,0.06152889,0.060368627,0.026946224,0.04723844,0.04493721,0.06967282,0.064691514,0.0069474876,0.0,0.0,0.12576585,0.24309456,0.1491605,0.047791995,0.0,0.022934586,0.013394631,0.0,0.0,0.0,0.0,0.0,0.0,0.030109823,0.06180931,0.11367954,0.06936365,0.07592675,0.09418602,0.089191236,0.023846187,0.07141159,0.06616324,0.081940174,0.092548095,0.043293953,0.0,0.0,0.11122264,0.19941132,0.12596624,0.02626761,0.0,0.034959346,0.025271684,0.0,0.0,0.0,0.0,0.0,0.0,0.055354998,0.059568398,0.12090826,0.09087199,0.11362009,0.13593586,0.13727532,0.03271182,0.08446511,0.07990891,0.064272806,0.09896734,0.022012495,0.0,0.0,0.10498673,0.17215441,0.10034759,0.010931864,0.0,0.044410147,0.03818316,0.0,0.0,0.0,0.0,0.0,0.0,0.026612386,0.027166598,0.10904887,0.11186143,0.13975482,0.16365139,0.16817725,0.037684225,0.090429574,0.06880124,0.055336803,0.09344827,0.0060529634,0.0,0.0,0.099224195,0.16600779,0.07940461,0.0,0.0,0.06300427,0.036650084,0.0,0.0,0.0,0.0,0.0,0.0,0.005371079,0.014693573,0.10936983,0.13279462,0.16571867,0.18175086,0.18886675,0.039572045,0.088211685,0.07264837,0.054255657,0.09289855,0.016786262,0.0,0.0,0.09463821,0.16077593,0.06653614,0.0,0.0,0.08071403,0.03538204,0.0,0.0],[0.0,0.0023264587,0.015437447,0.0,0.0,0.0,0.0,0.0,0.0,0.037604913,0.019790828,0.0,0.0,0.081106976,0.08343515,0.16348715,0.25256687,0.42649668,0.35381436,0.3763494,0.40119654,0.41049176,0.26989472,0.06622615,0.024287239,0.0119157955,0.020661883,0.0,0.0,0.0041413903,0.0058612004,0.0,0.0,0.0,0.0,0.0,0.0,0.035779476,0.029612213,0.0,0.0,0.01598952,0.009161882,0.09174676,0.117547765,0.32352418,0.28584504,0.36017495,0.44427192,0.3954805,0.29586202,0.09374341,0.050437696,0.01641956,0.023670137,0.0,0.0,0.014275193,0.004925266,0.0,0.0,0.0,0.0,0.01703769,0.0,0.04872351,0.037007503,0.0,0.0,0.0,0.0,0.046827942,0.03676548,0.23567456,0.24017337,0.34206247,0.47315812,0.40913373,0.30216765,0.10536851,0.05122207,0.012958214,0.014791168,0.0,0.0024720877,0.016860448,0.0005528033,0.00037020445,0.0,0.01651305,0.0,0.020901151,0.0,0.061062977,0.046643756,0.007257417,0.0,0.0010136515,0.0,0.036599748,0.019419156,0.17273147,0.20650667,0.29530722,0.46468627,0.39676768,0.2893033,0.098429814,0.03847774,0.009477824,0.0012834817,0.0,0.009838045,0.009101309,0.0,0.0031356812,0.0047201365,0.034915842,0.011241697,0.015984975,0.000009059906,0.067809805,0.053182885,0.013851307,0.0,0.0036756545,0.0127947405,0.028887227,0.005887538,0.11630828,0.20077512,0.2806573,0.44857734,0.36795798,0.2545969,0.06770204,0.01579795,0.022110708,0.0,0.0,0.016245924,0.0,0.0,0.0058540776,0.026061244,0.063640386,0.04429023,0.013435982,0.024058394,0.08245743,0.05482856,0.012948863,0.0,0.019399866,0.02653484,0.036725946,0.026452772,0.06708785,0.19621044,0.3134559,0.43492275,0.30853754,0.20898198,0.02037464,0.0,0.038927585,0.0,0.0,0.021227323,0.0,0.0,0.0,0.053396665,0.07286501,0.041932352,0.0,0.035260983,0.10290603,0.064950205,0.025473423,0.0,0.02582363,0.043961085,0.08438186,0.09427585,0.07709851,0.19880626,0.33612627,0.43848127,0.25722718,0.17213541,0.0012366772,0.0,0.014866568,0.0,0.0,0.026860796,0.0,0.0,0.0,0.08871345,0.088884994,0.039889812,0.0033050776,0.05934844,0.13737263,0.09178823,0.05934286,0.0,0.042118147,0.06667584,0.16454715,0.18352637,0.14270914,0.18844272,0.3171341,0.4336418,0.21526471,0.16117871,0.02550117,0.025591895,0.008176342,0.0,0.0,0.030219145,0.008190475,0.0,0.031962827,0.11686814,0.12983508,0.08921042,0.028324999,0.10859001,0.1847135,0.13331401,0.09067443,0.0,0.06875929,0.05665618,0.22767185,0.22523907,0.18215805,0.19247372,0.29479656,0.40848368,0.15736173,0.1103717,0.06303518,0.079104215,0.039725125,0.0,0.0,0.03281291,0.022991657,0.0,0.026949346,0.097528495,0.12277734,0.095216736,0.043710947,0.1414553,0.20817757,0.1583405,0.10124744,0.0,0.078319915,0.06727317,0.23839802,0.22944674,0.15457517,0.15143284,0.27321547,0.38809794,0.12561584,0.09781213,0.08833911,0.10891544,0.048964202,0.0,0.0,0.031635165,0.032273576,0.0,0.004463136,0.07796922,0.1285291,0.10472482,0.062089704,0.18293884,0.23219636,0.18178186,0.11667555,0.0,0.10474701,0.08880584,0.25735486,0.25961322,0.14361414,0.12378373,0.24967757,0.36818412,0.11319232,0.08792984,0.10833333,0.13811491,0.053246856,0.0,0.0],[0.0,0.037645303,0.0037657022,0.01791861,0.026988648,0.018955752,0.011214949,0.0,0.0,0.0,0.041775063,0.104921184,0.12503296,0.23490629,0.45547867,0.6548436,0.82409495,0.99464524,0.96107733,0.9763145,0.9319874,0.79901654,0.57131666,0.2687599,0.10849609,0.0155091435,0.0,0.003151819,0.0,0.045754902,0.0034255087,0.007264994,0.008083262,0.0,0.0,0.0,0.0,0.0,0.0727244,0.058990896,0.052488923,0.12196249,0.27206296,0.45746052,0.683211,0.88663507,0.8818831,0.9336392,0.96177506,0.83588076,0.58748215,0.3032078,0.12897405,0.007202007,0.0,0.00037176907,0.0,0.04111184,0.0057400316,0.0039262176,0.01605396,0.0,0.0,0.0,0.0,0.0,0.08672989,0.07265797,0.043886147,0.07216983,0.14183956,0.2978402,0.53905946,0.74925625,0.75912493,0.86886793,0.96118456,0.84731543,0.58158726,0.3001458,0.12098367,0.0,0.0,0.00059747696,0.0,0.02720911,0.005367264,0.0011810809,0.024029203,0.0,0.0,0.0,0.0,0.016618147,0.09351951,0.105932295,0.071353704,0.074196145,0.05986899,0.20210141,0.4425956,0.63386935,0.6382746,0.77695936,0.9119288,0.80754477,0.54920596,0.27505285,0.103516325,0.0,0.0,0.0,0.0,0.012608007,0.003269136,0.0,0.03519261,0.0,0.0,0.0,0.0,0.03167613,0.095676646,0.13629381,0.102288336,0.07298901,0.0,0.10132817,0.33893138,0.5551009,0.62546045,0.78547734,0.87536466,0.7439563,0.49679732,0.2150206,0.080721974,0.0,0.0,0.0001424104,0.0,0.004819393,0.0,0.0,0.04492247,0.0,0.0,0.0,0.011284225,0.039718173,0.10982118,0.16706383,0.14138564,0.09110095,0.0,0.03752148,0.23241803,0.47234857,0.66635406,0.87977886,0.8927882,0.67415595,0.44476748,0.14606506,0.044332214,0.0,0.0,0.0024224818,0.0,0.0,0.0,0.0,0.058156393,0.0,0.007412255,0.0,0.02871298,0.037966356,0.12493002,0.19812977,0.19339421,0.13582624,0.025748916,0.07816443,0.22310074,0.43980247,0.75711966,0.9831666,0.90503407,0.57914895,0.40282553,0.10067441,0.04463756,0.0,0.0,0.0,0.0,0.0,0.0,0.0105646625,0.09286974,0.0,0.039459668,0.0,0.0317159,0.035147764,0.12714122,0.20941816,0.23949763,0.17424455,0.10107328,0.1525451,0.28231394,0.45653063,0.8230464,1.0,0.8389357,0.44472098,0.35293168,0.08247629,0.07412866,0.0,0.0,0.0,0.0,0.003862664,0.0133989155,0.07522477,0.16617538,0.067843415,0.09844364,0.0,0.07007411,0.053522676,0.14372167,0.2098244,0.2803219,0.21689174,0.16442217,0.1855123,0.3005075,0.4280222,0.819451,1.0,0.7137302,0.25821242,0.27788,0.06547371,0.09775646,0.0,0.0,0.0,0.0022617131,0.01410903,0.027435139,0.09661961,0.19115584,0.079222634,0.10341361,0.0,0.09770961,0.08648175,0.17148136,0.24332997,0.31680912,0.24524996,0.20927884,0.20403062,0.3171948,0.41813022,0.8352621,1.0,0.69042945,0.21346264,0.26838177,0.07103884,0.11599504,0.0,0.0,0.0,0.0083442405,0.01595892,0.029690422,0.099523544,0.19564374,0.094133355,0.11439426,0.0,0.12836431,0.11199033,0.19658582,0.2788428,0.3600001,0.27319008,0.25722256,0.22607717,0.34754577,0.41230005,0.82271314,0.97390133,0.6575954,0.18657157,0.27412033,0.08936852,0.13034195,0.0,0.0,0.0],[0.0030885488,0.022305302,0.038375646,0.023359522,0.0,0.03179528,0.053905874,0.0,0.0,0.0,0.099285915,0.19721588,0.25159904,0.5258848,0.7339041,0.85459447,1.0,1.0,1.0,1.0,1.0,1.0,0.689726,0.35245976,0.17584243,0.012136772,0.0,0.0,0.005736433,0.008920968,0.0152459815,0.0034555048,0.0,0.0,0.084634505,0.0,0.0,0.008588932,0.090520106,0.10743537,0.1406513,0.4104569,0.58756614,0.69587445,1.0,1.0,1.0,1.0,1.0,1.0,0.72530574,0.39268708,0.22528642,0.01034002,0.0,0.023494475,0.002876386,0.0,0.0062460005,0.008969173,0.0,0.0,0.11417786,0.0,0.027285323,0.01365611,0.09595099,0.09223975,0.08737815,0.2881208,0.4123307,0.5175396,0.86471534,1.0,1.0,1.0,1.0,1.0,0.7268287,0.3903538,0.23162615,0.013160147,0.0,0.04156307,0.0,0.0,0.0023553222,0.014642969,0.0,0.0,0.096966125,0.0,0.05848103,0.02849137,0.0871245,0.121674836,0.08166863,0.20358449,0.28538537,0.3909555,0.72262627,0.92475736,0.9161697,0.99737996,1.0,0.98372716,0.6965577,0.3608424,0.2163668,0.0057622343,0.0,0.033131838,0.0,0.0,0.003881082,0.029519103,0.0,0.0,0.07962221,0.028957784,0.09076287,0.039468795,0.06954179,0.16082321,0.09017445,0.12532325,0.16465876,0.25135696,0.56819034,0.8530323,0.9003186,1.0,0.9370392,0.8969293,0.6396489,0.3167637,0.21171243,0.0128475055,0.0,0.03581559,0.0,0.0,0.00660865,0.04354149,0.0014991909,0.0,0.057565935,0.06427131,0.10240164,0.036262535,0.058230832,0.19133864,0.11515677,0.10103211,0.08262192,0.117622994,0.3768819,0.7639827,0.92149407,1.0,0.84313655,0.75460845,0.54110104,0.27301928,0.194247,0.0,0.0,0.025901482,0.0,0.0,0.0023527443,0.05499226,0.009761795,0.0,0.035294443,0.07081571,0.09563128,0.049044646,0.05915062,0.21403831,0.1518777,0.13478561,0.09006725,0.098330155,0.28415948,0.773851,1.0,1.0,0.765731,0.5857183,0.4121322,0.24028337,0.19063088,0.0,0.0,0.010208733,0.0,0.0,0.010748304,0.09838188,0.039926544,0.0,0.042427942,0.055845454,0.07765091,0.073228285,0.04512725,0.20435432,0.16775188,0.17051801,0.119178765,0.08620629,0.23057692,0.79339325,1.0,1.0,0.643969,0.39481986,0.29751384,0.22669521,0.2090885,0.005742885,0.0,0.0,0.0,0.0,0.05089376,0.15658507,0.1150296,0.010978088,0.07352707,0.07262057,0.09000658,0.12233764,0.057806186,0.16657563,0.16044162,0.19906996,0.13199052,0.014510587,0.13999365,0.7749975,1.0,1.0,0.45157647,0.19269632,0.19653457,0.20705503,0.22508907,0.042346865,0.0,0.0,0.009431563,0.0,0.07550403,0.1955357,0.14155608,0.016133517,0.07917009,0.08697787,0.12895764,0.1798181,0.096945405,0.20003197,0.18662214,0.24011976,0.16147448,0.008147851,0.12128369,0.7988516,1.0,1.0,0.41527355,0.16552061,0.2128725,0.23354423,0.2503289,0.054987006,0.0,0.0,0.023104325,0.0,0.097306564,0.21143556,0.15462542,0.030111536,0.08865829,0.107934244,0.15608779,0.21757233,0.15448552,0.25619423,0.22804675,0.28600395,0.17983417,0.01692298,0.11831951,0.8026795,1.0,1.0,0.37018633,0.15006605,0.23604171,0.270505,0.24604991,0.06545255,0.0,0.0],[0.0,0.025144279,0.04389725,0.012832008,0.0,0.033380635,0.0,0.0,0.0,0.09569977,0.18458906,0.30656815,0.49673784,0.6915675,0.8114857,0.7389287,0.79609865,0.77576584,0.8371042,0.8651174,1.0,0.98851526,0.757462,0.2644878,0.020581134,0.0021415353,0.045015775,0.0,0.0,0.02015312,0.020328633,0.0,0.0,0.027878366,0.0025274605,0.0,0.036570914,0.077825285,0.09830117,0.17735252,0.35899937,0.5966612,0.7024955,0.72551477,0.8817615,0.86313426,0.8484413,0.8078239,0.97590274,0.94462043,0.7438752,0.3131085,0.055739693,0.009879842,0.054249518,0.0,0.0,0.027091525,0.009451374,0.0,0.0068477243,0.025858939,0.020959206,0.021481082,0.06646317,0.062683344,0.075898856,0.13726658,0.28987506,0.46811342,0.5269499,0.646414,0.8891265,0.9155718,0.8616685,0.8153394,0.9705808,0.93623066,0.7324271,0.338116,0.07860096,0.028619707,0.07545805,0.0068891495,0.0,0.023726784,0.0041302145,0.0,0.010476805,0.015044607,0.02828855,0.037030257,0.07683314,0.04914108,0.0767409,0.102594405,0.21229285,0.31753972,0.35755122,0.524462,0.82934636,0.88324124,0.85375124,0.84270847,0.96287453,0.9113277,0.7038983,0.3416605,0.08792883,0.03182459,0.073345736,0.00044104457,0.0,0.013522111,0.0,0.0,0.015868999,0.013366714,0.050664723,0.07112041,0.096711285,0.07043889,0.106071204,0.09788045,0.18261483,0.18821168,0.18498017,0.37641367,0.7379732,0.9162108,0.93853027,0.895993,0.87490827,0.7720516,0.5758768,0.30732054,0.10952395,0.06443475,0.08601138,0.0031117797,0.0,0.0061329603,0.0,0.0,0.021920718,0.03039179,0.09988235,0.1268871,0.11980222,0.076134086,0.12030409,0.12541367,0.21227793,0.10839836,0.015439168,0.17565237,0.5644434,0.9046174,1.0,0.96141547,0.7534294,0.5961311,0.4210341,0.23954758,0.09983605,0.062270448,0.058685385,0.0,0.0,0.0,0.0023337305,0.0,0.03425345,0.029023342,0.1097935,0.14714196,0.12303505,0.0726089,0.11714495,0.15992136,0.27784106,0.09721801,0.0,0.03971518,0.4868555,0.97566026,1.0,1.0,0.61019325,0.38180178,0.26127443,0.17061254,0.09632661,0.047299884,0.0122752935,0.0,0.0,0.0060765445,0.03042584,0.021967053,0.08104657,0.019594856,0.08722437,0.10620399,0.10375889,0.07655746,0.11120608,0.19719645,0.31741208,0.106755905,0.0,0.0,0.4266438,1.0,1.0,1.0,0.39606225,0.16398063,0.16946706,0.17510569,0.14265396,0.04155281,0.0,0.0,0.0,0.073455736,0.1292079,0.10691235,0.16945486,0.054806925,0.09317742,0.099413104,0.12821843,0.11028702,0.13024142,0.19904314,0.31532043,0.09562452,0.0,0.0,0.36532658,0.94824845,1.0,0.8170926,0.16488893,0.055939823,0.17110354,0.2105296,0.20347813,0.043453284,0.0,0.0,0.0,0.09850192,0.16659755,0.16296029,0.22810829,0.067962214,0.10715917,0.1366083,0.17710394,0.16607851,0.1606221,0.21690619,0.3308496,0.12261039,0.0,0.0,0.4044869,0.99038476,1.0,0.7646106,0.10600289,0.052408762,0.19067568,0.24843636,0.23308694,0.046556443,0.0,0.0,0.0074263588,0.12506643,0.20972902,0.21977139,0.27058744,0.081319004,0.11459325,0.15780668,0.22077064,0.20984203,0.2105693,0.25831193,0.36922356,0.16262712,0.003702268,0.005279824,0.4318931,0.9840573,1.0,0.69954747,0.07544776,0.08236441,0.2313647,0.290734,0.26196498,0.06329406,0.0,0.0],[0.0,0.013328336,0.0,0.0,0.0,0.008237839,0.0,0.0,0.0,0.14023398,0.2651581,0.43101752,0.62058645,0.80009,0.70197695,0.50833595,0.4376675,0.43719876,0.6272954,0.7980601,0.87383366,0.7943181,0.5203497,0.21333404,0.0,0.0,0.0,0.0,0.0,0.012774639,0.0,0.0,0.0,0.037330903,0.010105558,0.0,0.012736492,0.10001324,0.19106412,0.30879974,0.58184975,0.7583085,0.7041397,0.5786997,0.5690558,0.5485823,0.626966,0.7390083,0.8069393,0.7539029,0.5210251,0.26363862,0.0,0.01585859,0.0,0.0,0.0,0.02363731,0.014635369,0.0,0.0,0.044056542,0.013746001,0.03305447,0.031672798,0.086815566,0.16580448,0.2442306,0.51408213,0.6364495,0.6067706,0.59367275,0.69401425,0.681639,0.70369774,0.78812873,0.8293517,0.7849657,0.5538834,0.29658836,0.0,0.04085666,0.0,0.0,0.0043426007,0.027610846,0.03264884,0.0,0.0,0.039821222,0.006092638,0.049012855,0.047858886,0.07942088,0.14507562,0.14106517,0.3603087,0.45583695,0.44531488,0.5580233,0.73198944,0.71181923,0.73574877,0.8227173,0.8390194,0.7886724,0.5665686,0.30715343,0.019224785,0.052326933,0.0,0.0,0.016440935,0.027661197,0.04495631,0.0,0.0,0.04583499,0.016439356,0.06997049,0.08092953,0.11751873,0.16610496,0.07857248,0.24793065,0.30007082,0.28593355,0.48946136,0.7404421,0.78031397,0.83533,0.84286344,0.7531969,0.645648,0.46046662,0.26075324,0.029168531,0.07074311,0.0041906834,0.0,0.024068482,0.027994901,0.04632584,0.0,0.00594984,0.07634415,0.07690813,0.11389857,0.11762993,0.14660995,0.14863099,0.06175971,0.16602428,0.15412916,0.1281002,0.35630715,0.71249795,0.8298385,0.94774985,0.83484846,0.60052884,0.45462638,0.28748488,0.14985645,0.002511695,0.06309173,0.0,0.0,0.025808088,0.039393537,0.061893642,0.039024793,0.046403192,0.106670365,0.0871764,0.13523991,0.16356733,0.14403555,0.124333106,0.06848144,0.0903569,0.0464165,0.024652392,0.24870047,0.7003822,0.9060546,1.0,0.808976,0.40302712,0.23479319,0.12131874,0.052861303,0.0,0.03824617,0.0,0.0,0.019238159,0.051830366,0.062007435,0.07713252,0.102656044,0.10512485,0.048023432,0.11103374,0.17771237,0.12922224,0.09510228,0.061392568,0.017707102,0.0,0.0,0.19251396,0.6408457,0.92397726,1.0,0.6906141,0.14271154,0.055112265,0.059949413,0.051039673,0.033600822,0.013369247,0.0,0.0,0.03347551,0.107845485,0.12119712,0.17953356,0.21780148,0.16820197,0.04054296,0.1147272,0.23138905,0.12408864,0.05102341,0.021788165,0.0,0.0,0.0,0.13393529,0.5745907,0.8459116,0.86548924,0.4423021,0.0,0.04503779,0.1035711,0.06638396,0.088275045,0.0,0.0,0.011185132,0.03857647,0.13000128,0.16672282,0.25023794,0.284711,0.19263984,0.046491876,0.15746734,0.30203593,0.155945,0.07275232,0.02026803,0.0,0.0,0.0,0.1408323,0.61311716,0.8679552,0.8476794,0.374331,0.0,0.061367594,0.13133806,0.077471495,0.101762876,0.0,0.0,0.017995715,0.043790832,0.15120383,0.20655166,0.30983266,0.33018166,0.20299311,0.03514123,0.17370558,0.32896328,0.18218663,0.10564174,0.042102985,0.0,0.0,0.0,0.1414875,0.62209886,0.8619387,0.79207337,0.31183153,0.0,0.108145714,0.17790753,0.08061971,0.10891199,0.0,0.0,0.012365766],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011860445,0.07373392,0.17790015,0.4219324,0.66978246,0.8546644,0.71555895,0.576375,0.2868774,0.2961071,0.2712765,0.4666506,0.5812895,0.6096189,0.6315286,0.38675553,0.16026208,0.0,0.0,0.0,0.0,0.0006854534,0.0,0.0,0.0,0.0,0.0,0.0,0.0297091,0.08216935,0.11415616,0.3025751,0.5599395,0.80354726,0.73955977,0.62001354,0.40620595,0.38175648,0.33589405,0.5094696,0.5647198,0.57137746,0.578974,0.36707616,0.116935365,0.0,0.0,0.0,0.0,0.01815366,0.017760694,0.0,0.0,0.0,0.0,0.0,0.03904604,0.087102935,0.079859145,0.22206597,0.39365596,0.62160975,0.6357888,0.5668338,0.49609268,0.54472303,0.5016798,0.65200794,0.6542356,0.5988377,0.54328614,0.36723742,0.11109842,0.0,0.0,0.0,0.0,0.026984945,0.03731417,0.0,0.0,0.0,0.0,0.0,0.053059183,0.100428715,0.0521304,0.1367019,0.15972498,0.34223184,0.42802674,0.48210537,0.51496613,0.67094654,0.6596412,0.79694384,0.74083513,0.6036314,0.4872902,0.35952514,0.12483302,0.0,0.0,0.0,0.0,0.03361232,0.053431593,0.0,0.026626892,0.0048427433,0.027607605,0.008939676,0.08879663,0.14395143,0.083656326,0.12676273,0.08183909,0.18124148,0.25628895,0.36095643,0.5135293,0.7671467,0.8077733,0.92785215,0.79719865,0.5406337,0.3630846,0.27325144,0.08945872,0.0,0.0,0.0,0.0,0.03168086,0.049917966,0.0,0.03896881,0.036634468,0.09087534,0.073074475,0.15010156,0.1891251,0.11239526,0.13704024,0.08214064,0.08569766,0.1264991,0.17993343,0.47371477,0.8304644,0.9202399,1.0,0.789001,0.43518853,0.20455652,0.111886814,0.0,0.0,0.0,0.0,0.0,0.026768975,0.06335404,0.022675082,0.090900004,0.08917369,0.13660201,0.11017191,0.19384241,0.23554043,0.15166771,0.1521226,0.097945094,0.01586721,0.033631593,0.010043904,0.4286344,0.889034,1.0,1.0,0.7061539,0.27605814,0.024294972,0.0,0.0,0.0,0.0,0.0,0.0,0.02327662,0.070154965,0.06396074,0.12715971,0.14769898,0.1543844,0.10792871,0.16937903,0.2438699,0.16661565,0.13022617,0.112633325,0.0,0.0,0.0,0.39899182,0.9016969,1.0,0.98946375,0.55920076,0.10999437,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.033487946,0.108567946,0.1563559,0.20698795,0.25791484,0.21068178,0.12155917,0.14974217,0.2521342,0.16410294,0.072484836,0.10761343,0.0,0.0,0.0,0.32171804,0.82448196,0.90443087,0.7077633,0.28274816,0.0,0.0,0.0,0.07898456,0.061466716,0.007578045,0.0,0.0,0.039838,0.13180056,0.21782497,0.27981192,0.33185083,0.25111526,0.14793578,0.16734475,0.28832746,0.20251866,0.08484289,0.14159752,0.0,0.0,0.0,0.3144093,0.8306604,0.8837455,0.6569606,0.26170927,0.0,0.0,0.0,0.095167026,0.07139893,0.0040481836,0.0,0.0,0.042408288,0.15646079,0.27964166,0.34516293,0.38211352,0.2563838,0.13239145,0.15547115,0.29471278,0.2273547,0.10597986,0.18276414,0.0,0.0,0.0,0.31024358,0.80369866,0.8694117,0.61447215,0.23910132,0.0,0.0,0.0,0.122713275,0.088043116,0.0,0.0,0.0],[0.0,0.0,0.0015417337,0.0,0.0,0.0,0.0,0.027954206,0.11546043,0.34521508,0.5974433,0.9029984,0.859275,0.74044317,0.570466,0.3014162,0.39444315,0.431933,0.38334858,0.49165833,0.60537034,0.5841139,0.43788815,0.14747474,0.015186682,0.0,0.0,0.009165384,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03596487,0.104313925,0.28292137,0.49328017,0.8073794,0.8634484,0.7659983,0.582846,0.33122692,0.38651705,0.38501364,0.44150007,0.55685014,0.6210309,0.53402716,0.37684947,0.06856933,0.0,0.0,0.0,0.0,0.017268918,0.0052214265,0.0,0.0,0.016975306,0.0060546547,0.031126097,0.059772365,0.10082054,0.22966608,0.37485743,0.58195764,0.7423206,0.69218904,0.57097465,0.41447353,0.5113914,0.4881583,0.5917676,0.6442191,0.63469213,0.50333446,0.31692615,0.0140989125,0.0,0.0,0.0,0.0,0.02461379,0.036889598,0.032494552,0.022236079,0.05359979,0.010793284,0.04137139,0.0835142,0.08299803,0.1614716,0.2264655,0.28834563,0.51267487,0.60689396,0.5653039,0.4715172,0.6392924,0.65192944,0.76794195,0.70999146,0.5955182,0.438491,0.26044086,0.012420602,0.0,0.0,0.0,0.0,0.031137511,0.06517347,0.07936701,0.068560645,0.086662486,0.034687243,0.038647845,0.10640411,0.065970235,0.13951999,0.11120938,0.12054801,0.33517262,0.45978135,0.50162697,0.5329775,0.76932555,0.8014586,0.9248957,0.75085,0.500328,0.3274979,0.20362179,0.0,0.0,0.0,0.0,0.0,0.022831067,0.058689833,0.07875463,0.08501476,0.108294725,0.076829426,0.064748764,0.1439767,0.07635422,0.13991459,0.030512407,0.0,0.16805229,0.25049773,0.3588274,0.5755528,0.8991318,0.9363678,1.0,0.68688816,0.35212004,0.18507932,0.10405131,0.0,0.0,0.0,0.0,0.0,0.010664366,0.05834855,0.1021872,0.122157976,0.12896769,0.10399912,0.07378307,0.14611588,0.083608724,0.17441452,0.0,0.0,0.039277464,0.054449223,0.21848507,0.5945838,1.0,1.0,1.0,0.53918934,0.14733748,0.04372313,0.024576582,0.0,0.0,0.032168783,0.0,0.0,0.0036962032,0.07867366,0.14627793,0.13675286,0.15031007,0.1335723,0.057105787,0.10979304,0.07184939,0.12947804,0.0,0.0,0.0,0.0,0.12253012,0.5986901,1.0,1.0,0.95384747,0.38618118,0.0,0.0,0.0,0.0,0.048147187,0.06573266,0.0,0.0022265613,0.0,0.10731247,0.21569714,0.17742053,0.21865836,0.19384256,0.0763441,0.105415195,0.06501615,0.053281777,0.0,0.0,0.0,0.0,0.07002841,0.5683547,1.0,0.984862,0.70574564,0.17337954,0.0,0.0,0.029291973,0.06907418,0.1314731,0.12006596,0.01049564,0.015534662,0.0,0.116022356,0.25869036,0.21666051,0.2520545,0.2294682,0.10183926,0.10782179,0.068428,0.055292517,0.0,0.0,0.0,0.0,0.04788755,0.56271136,1.0,0.9855604,0.7062649,0.15139426,0.0,0.0,0.016170397,0.07376898,0.13590553,0.12524424,0.018758953,0.016465515,0.0,0.12510887,0.3003593,0.26075634,0.2670859,0.233971,0.08848363,0.08392987,0.050429873,0.053039372,0.0,0.0,0.0,0.0,0.026456498,0.5514558,1.0,0.9707997,0.68811595,0.13898613,0.0057374984,0.0,0.011281706,0.09078482,0.132306,0.10541897,0.023034096,0.00094914436],[0.034671195,0.033011384,0.0,0.0,0.0,0.0,0.0,0.05302556,0.23749334,0.56721306,0.7751411,0.86485434,0.8718843,0.83068055,0.6598915,0.5030463,0.7110722,0.7083887,0.6610732,0.5384612,0.5745199,0.48455453,0.31454575,0.0645535,0.0,0.036485456,0.022972219,0.0042405874,0.021757312,0.013800442,0.0,0.0,0.0,0.0,0.0,0.05509682,0.23971406,0.47499037,0.66529346,0.78106064,0.901925,0.8186108,0.6316509,0.46222162,0.6593906,0.71158606,0.72693187,0.6368016,0.589605,0.4063818,0.23934013,0.015390873,0.0,0.03826917,0.036249563,0.025227197,0.019187778,0.009302959,0.0,0.0,0.0,0.011251502,0.0,0.056351908,0.22818577,0.35320088,0.50258774,0.5923419,0.8074151,0.75162846,0.60271597,0.4525594,0.6877931,0.75706536,0.7867198,0.64932275,0.54568523,0.32498664,0.17495042,0.0,0.0,0.05724871,0.055499174,0.02861026,0.008962132,0.026208423,0.0,0.00022429228,0.0,0.012839377,0.0,0.08020576,0.21878213,0.25587368,0.32811436,0.3770925,0.6465394,0.6842285,0.6148187,0.5039089,0.8123132,0.89727783,0.8961611,0.63844526,0.4435894,0.23373878,0.1155576,0.0,0.011809319,0.0432304,0.049219407,0.01994408,0.00268057,0.063024364,0.04439962,0.04045353,0.0,0.019564502,0.013800137,0.118245244,0.1994895,0.21000853,0.18311876,0.19047101,0.41285723,0.5672683,0.5769635,0.5424189,0.9096883,1.0,0.9925892,0.6424529,0.33287686,0.17860016,0.091880456,0.0,0.041062295,0.04785361,0.04654295,0.010569118,0.0,0.06312142,0.055375136,0.039247826,0.0,0.03469979,0.038690574,0.1620237,0.17803077,0.18405277,0.07200077,0.04165134,0.143867,0.3668366,0.4786836,0.64155453,1.0,1.0,0.9486925,0.54272914,0.20061557,0.13720043,0.055618346,0.0,0.057615913,0.057075344,0.05594006,0.006728351,0.0,0.061287604,0.056280613,0.024334088,0.0,0.024295524,0.04308653,0.17253718,0.16723906,0.17669548,0.032890096,0.0,0.0,0.14941569,0.37431544,0.7744176,1.0,1.0,0.7865344,0.3535276,0.050675407,0.09442556,0.02657123,0.0035450757,0.09615367,0.08526191,0.072446555,0.0016445369,0.0,0.07318619,0.10587415,0.07992458,0.0,0.01234027,0.027984306,0.14486122,0.12038674,0.16099235,0.0,0.0,0.0,0.03470032,0.33585715,0.8960492,1.0,1.0,0.65021694,0.20605762,0.0,0.053249143,0.0371978,0.050127655,0.15400791,0.10557391,0.072298,0.0,0.0,0.08039458,0.14905061,0.1526799,0.0,0.02522277,0.026083954,0.12066622,0.06876356,0.12501468,0.0,0.0,0.0,0.0,0.32680556,1.0,1.0,1.0,0.45271963,0.0736719,0.0,0.081758365,0.13826224,0.1829618,0.29570413,0.17131753,0.09297781,0.0,0.0,0.10290472,0.18711382,0.19580391,0.0,0.023074888,0.021751367,0.12187465,0.071461186,0.11802934,0.0,0.0,0.0,0.0,0.329554,1.0,1.0,1.0,0.4599657,0.064331464,0.0,0.09352624,0.15537393,0.20066026,0.32697484,0.17665228,0.08809917,0.0,0.0,0.12569578,0.24755989,0.2534186,0.015206717,0.0,0.0,0.10292741,0.07360186,0.11337145,0.0,0.0,0.0,0.0,0.32013446,0.9963138,1.0,1.0,0.44485676,0.07295156,0.0,0.12651952,0.18310463,0.21639955,0.33771664,0.16116199,0.06943709,0.0],[0.015700206,0.065422595,0.0,0.0,0.0,0.0,0.0,0.06819639,0.2760601,0.6579982,0.82127404,0.85284525,0.9399649,0.8878725,0.7323583,0.64015955,0.80613184,0.8554809,0.7780871,0.51144415,0.5263558,0.4669128,0.23174134,0.02613175,0.0,0.0,0.0,0.0,0.0070770234,0.031203248,0.0,0.0,0.0,0.0,0.0,0.088261,0.2679806,0.58127755,0.75249684,0.8432175,0.95022625,0.8777411,0.7471913,0.6010017,0.790091,0.889226,0.87720937,0.6244355,0.53995544,0.40084952,0.1558143,0.00516662,0.0,0.0,0.032197483,0.009616338,0.009271875,0.025054023,0.0,0.0,0.0,0.0,0.0,0.07965906,0.21546683,0.4506232,0.58980125,0.7442102,0.9002905,0.8864123,0.8124043,0.61721635,0.8367729,0.91372204,0.9013776,0.61155325,0.45581758,0.29988182,0.112821855,0.0,0.0,0.0,0.051857047,0.027447842,0.01133208,0.044121794,0.0,0.0,0.0,0.0,0.0,0.06758635,0.14822595,0.30414408,0.38844365,0.61051154,0.80066097,0.92052126,0.89661735,0.7194028,0.9921542,1.0,0.87461364,0.53288555,0.3282748,0.19422519,0.07527028,0.0,0.0,0.0,0.03533662,0.03445798,0.01462248,0.06444606,0.0,0.018467948,0.0,0.00050000846,0.0,0.050747238,0.08327688,0.17600389,0.21993718,0.4118042,0.64922845,0.89257365,0.90854347,0.78693926,1.0,1.0,0.83454704,0.45153892,0.22477214,0.14949335,0.08137195,0.0047908723,0.0069668144,0.0,0.022844978,0.03870111,0.008230902,0.056540303,0.0,0.020724364,0.0,0.018193603,0.004618287,0.03476324,0.037781447,0.10054445,0.092968896,0.17912301,0.40399998,0.7140796,0.8557459,0.8974808,1.0,0.99328035,0.69771457,0.3173784,0.1231427,0.12740667,0.07591978,0.0,0.028140761,0.0042335093,0.01978518,0.048070133,0.008533575,0.06914809,0.0,0.014251605,0.0,0.02229049,0.02243682,0.019356497,0.019366115,0.063915215,0.040986344,0.0050264746,0.1533162,0.4799533,0.7520501,1.0,1.0,0.92182153,0.4763497,0.11273137,0.02482061,0.10519316,0.052547522,0.0,0.0427642,0.0,0.008161873,0.04167545,0.015482172,0.09757689,0.06649517,0.061543204,0.0,0.019125141,0.026510395,0.0,0.020458117,0.050900146,0.0,0.0,0.0,0.29657426,0.6947981,1.0,1.0,0.82406557,0.30768877,0.0,0.0,0.089124456,0.035630457,0.0,0.053243972,0.0,0.0,0.022192396,0.016367406,0.11644841,0.13075373,0.13162105,0.027472503,0.024359897,0.036127955,0.0,0.039589345,0.029657677,0.0,0.0,0.0,0.18518144,0.67425525,1.0,1.0,0.6635765,0.119160354,0.0,0.0,0.115873694,0.09177935,0.044770584,0.11905508,0.0,0.0,0.0,0.015946455,0.13495271,0.16953593,0.17059678,0.036956415,0.024802424,0.03322964,0.0,0.04978036,0.017208174,0.0,0.0,0.0,0.18074071,0.67943037,1.0,1.0,0.7120846,0.12669279,0.0,0.0,0.11438908,0.1270066,0.05363775,0.110127985,0.0,0.0,0.0,0.014741391,0.15671113,0.21123761,0.21320249,0.040134616,0.001860112,0.012150206,0.0,0.062939085,0.012206122,0.0,0.0,0.0,0.14631371,0.64526904,1.0,1.0,0.7061715,0.106829494,0.0,0.0,0.120372035,0.15686563,0.063332446,0.096912876,0.0,0.0,0.0],[0.03201162,0.067947656,0.0,0.011197299,0.0042442977,0.0,0.038578704,0.16251825,0.42706406,0.7193408,0.8518829,0.817318,0.9302139,0.83607554,0.7454388,0.7592178,0.8105957,0.72336876,0.73329395,0.620375,0.5791203,0.40843332,0.20781358,0.020496741,0.0,0.0,0.0,0.0,0.017527856,0.0558196,0.0,0.00760293,0.0,0.0,0.055258118,0.17583779,0.42144346,0.6871399,0.8404446,0.8577746,1.0,0.8870675,0.7377554,0.770523,0.8168618,0.83047414,0.8288157,0.6891826,0.48853755,0.29185018,0.11781576,0.001955524,0.02391889,0.0,0.0,0.0,0.019232549,0.06217275,0.0,0.0,0.0,0.0,0.04675775,0.13595521,0.3361576,0.5708093,0.7543366,0.8554277,1.0,0.95448786,0.7916505,0.83562016,0.83428234,0.8470326,0.8073871,0.61668235,0.33920884,0.1804122,0.090032235,0.0279674,0.05718994,0.0027982444,0.017029129,0.0013040006,0.0274048,0.065717995,0.006405212,0.0,0.0,0.013654277,0.05494882,0.10645213,0.2165999,0.39789355,0.5870409,0.79390115,1.0,1.0,0.8759134,0.94535947,0.92180455,0.8743898,0.7322352,0.48832595,0.18888113,0.11119645,0.06333074,0.026812151,0.059591196,0.008371353,0.0052289814,0.0045157075,0.038404517,0.05261478,0.008484863,0.0,0.0023335963,0.041389897,0.061283402,0.092220366,0.12068162,0.23151553,0.39067727,0.672947,0.9753418,0.9876268,0.88201773,1.0,0.95836514,0.9133314,0.6797437,0.39031088,0.098089606,0.07083263,0.048940293,0.023333617,0.060922295,0.019876547,0.00039951503,0.017332628,0.03332624,0.027641393,0.0,0.0,0.022264019,0.056565583,0.058534168,0.08055778,0.05548983,0.10080715,0.14982902,0.43532068,0.7421361,0.9418009,0.92474765,1.0,0.99799097,0.85038495,0.5295161,0.25802127,0.02821993,0.041597508,0.027358927,0.024319798,0.060341693,0.023705564,0.0011903644,0.031159945,0.035429478,0.03532161,0.023230933,0.0023073554,0.044181265,0.035800353,0.054754943,0.05060845,0.00787656,0.011458747,0.0,0.19958998,0.42853755,0.8301232,0.9695546,1.0,0.9999465,0.6333632,0.21474038,0.028506689,0.0,0.015987746,0.00084109604,0.02081494,0.052640922,0.017545946,0.008976437,0.036831543,0.026760712,0.09189584,0.11150978,0.06297821,0.042834222,0.008837327,0.033690207,0.027577199,0.0,0.0,0.0,0.07636222,0.20397922,0.7218803,0.977594,1.0,0.9545612,0.47494268,0.048118614,0.0,0.0,0.0,0.0,0.0049913377,0.027850904,0.0,0.016366534,0.039138183,0.011441417,0.14246228,0.20810077,0.16560915,0.062304527,0.0,0.015579745,0.022891171,0.0,0.0,0.0,0.011025131,0.07209835,0.665368,0.9959645,1.0,0.9071689,0.36094362,0.0,0.0,0.0,0.0,0.0,0.039116174,0.06704783,0.019626848,0.04654511,0.043898597,0.011567995,0.1651333,0.23305222,0.19186807,0.08333601,0.0021891892,0.003415212,0.02822996,0.0,0.0,0.0,0.031432062,0.07446381,0.6862839,1.0,1.0,0.9543614,0.38909674,0.0,0.0,0.0,0.0,0.0,0.030992389,0.059176877,0.002523467,0.04205309,0.042883277,0.013433762,0.19342121,0.25087744,0.20327505,0.071048655,0.0,0.0,0.020460725,0.0,0.0,0.0,0.021997295,0.039829172,0.66883117,1.0,1.0,0.9414965,0.37614852,0.0,0.0,0.0,0.0,0.0,0.034952886,0.06464409,0.0,0.04111678,0.037080005],[0.04766976,0.0655913,0.017649688,0.021721698,0.01459346,0.03348892,0.14528914,0.25736654,0.48920643,0.6594593,0.6929959,0.6739436,0.7489147,0.64980054,0.38930386,0.51144385,0.68619883,0.8109021,0.755824,0.78782463,0.6546612,0.36934352,0.19450575,0.012298822,0.0,0.0,0.0,0.010844305,0.022686407,0.06042193,0.0059012324,0.010329574,0.0004553795,0.02894254,0.16532034,0.2510956,0.48415762,0.6786291,0.761861,0.7826916,0.88754416,0.7239408,0.46538252,0.5720842,0.7652439,0.9027849,0.7967598,0.7180182,0.47779453,0.18773253,0.1257802,0.0036570877,0.0,0.0,0.0051738024,0.005717568,0.021214977,0.08495647,0.018606149,0.0,0.0,0.0,0.13225576,0.19831878,0.39336634,0.60432607,0.7549811,0.8532431,1.0,0.7982755,0.58972335,0.6850278,0.80360633,0.8484785,0.6881238,0.5171359,0.30695704,0.108429156,0.095894486,0.004298687,0.0050821006,0.0,0.01001849,0.0,0.032135874,0.105783775,0.040018573,0.00028416514,0.0,0.0029642582,0.11761409,0.16733138,0.26374653,0.450548,0.6410788,0.8373743,1.0,0.8634001,0.7144065,0.7984085,0.82040954,0.7563839,0.54823405,0.29426602,0.17766297,0.06390199,0.05455496,0.0,0.0058569387,0.0,0.014735453,0.00862205,0.045533337,0.105531804,0.03906411,0.006103955,0.0,0.017632425,0.110455364,0.16776423,0.17455247,0.3113583,0.49872285,0.7711414,1.0,0.89661074,0.8059515,0.88145334,0.82969993,0.68132603,0.4601817,0.1575007,0.08068994,0.04065278,0.025339752,0.0,0.022398353,0.002679184,0.03584116,0.031550884,0.048460074,0.07398082,0.019512251,0.004720077,0.022807091,0.032331064,0.08125721,0.14976421,0.09860054,0.16846769,0.3111873,0.59247386,0.95622593,0.9531182,0.9266895,0.9720193,0.82921875,0.566573,0.34456006,0.09298594,0.04532715,0.017381154,0.0077831745,0.015903614,0.055013217,0.015079081,0.058689483,0.052364185,0.04955017,0.07035054,0.027594998,0.026901685,0.053115457,0.03305693,0.050358437,0.101029634,0.036950096,0.051438153,0.1177226,0.36775926,0.7262416,0.98073757,1.0,1.0,0.7454891,0.28784162,0.07996391,0.0,0.022645317,0.0,0.0,0.03947387,0.059342675,0.030733675,0.076003194,0.066589385,0.034261346,0.091911234,0.093351945,0.041540228,0.031017013,0.014126934,0.012387887,0.057750367,0.0,0.0,0.0,0.23813924,0.5619884,0.99810475,1.0,1.0,0.6785277,0.12388404,0.0,0.0,0.0,0.0,0.0,0.05852738,0.045758255,0.044847116,0.09589574,0.07679395,0.005917318,0.10116962,0.19255248,0.09322842,0.02794791,0.0,0.0,0.025980674,0.0,0.0,0.0,0.19063452,0.4984538,1.0,1.0,1.0,0.63229984,0.008762471,0.0,0.0,0.0,0.0,0.008748405,0.10582177,0.05735316,0.07837637,0.12477808,0.091784224,0.004082456,0.11308806,0.1983804,0.10721532,0.039055184,0.0,0.0,0.034051076,0.0,0.0,0.0,0.21867162,0.5462218,1.0,1.0,1.0,0.6720255,0.0052082986,0.0,0.0,0.0,0.0,0.005484551,0.11873935,0.04823775,0.07826134,0.1388525,0.10518879,0.0055337846,0.1353526,0.18255316,0.08806693,0.023787491,0.0,0.0,0.0278951,0.0,0.0,0.0,0.22478661,0.56011164,1.0,1.0,1.0,0.6735817,0.0,0.0,0.0,0.0,0.0,0.015160821,0.13626063,0.043226294,0.07683733,0.1416147,0.10018711],[0.0,0.009441547,0.02545081,0.026440524,0.021843307,0.06719268,0.20870863,0.19100925,0.45889676,0.46022034,0.5753,0.45388985,0.44468772,0.310817,0.17106989,0.15911621,0.31186736,0.6593444,0.8575266,0.9336974,0.69635427,0.40489447,0.17554173,0.051171117,0.072450414,0.0,0.08025943,0.08577649,0.0,0.0018830597,0.021455988,0.044848576,0.024766274,0.091073506,0.23547962,0.29776162,0.51637846,0.5728128,0.7213985,0.6641793,0.6121866,0.39283794,0.24043411,0.2583664,0.4361893,0.78448516,0.8415774,0.69258213,0.33079952,0.099561185,0.07495131,0.03958551,0.09361477,0.0,0.05682067,0.05804289,0.01205074,0.023255877,0.030865327,0.039466113,0.004268214,0.092804566,0.20860101,0.30682316,0.47506988,0.60375184,0.80879796,0.8334075,0.75059426,0.5202186,0.39746147,0.39332527,0.48698628,0.71329516,0.641744,0.40406042,0.09303316,0.0,0.071711406,0.0353169,0.07654069,0.0043463707,0.041694403,0.033429734,0.034592554,0.050503775,0.04437221,0.040769763,0.015370049,0.121651396,0.1771133,0.23515145,0.3469792,0.5259619,0.77606773,0.8899423,0.8322406,0.6432287,0.52638096,0.46177638,0.48740274,0.5701487,0.38396996,0.1533629,0.0,0.0,0.053528927,0.023505524,0.06295173,0.011387885,0.038022183,0.02483087,0.054945886,0.054946266,0.052908346,0.027020127,0.044094853,0.15842421,0.18917145,0.20825008,0.25750798,0.4274088,0.661894,0.8404897,0.85990924,0.7446237,0.6255158,0.51700795,0.51371133,0.46172303,0.23163295,0.051231787,0.0,0.0,0.04743088,0.025697261,0.061911985,0.031193003,0.058557697,0.034964398,0.058285408,0.04087791,0.037459284,0.017945439,0.06608926,0.17467375,0.18345462,0.18462864,0.19927165,0.28673255,0.47333544,0.6950165,0.85205406,0.84201014,0.7322925,0.54003066,0.50143987,0.33937892,0.14064565,0.034833387,0.0,0.006530516,0.047174186,0.03680861,0.07251763,0.05927798,0.08145313,0.043723926,0.05705043,0.041633263,0.04872556,0.022489473,0.085194156,0.1791637,0.15369704,0.14238943,0.14141403,0.14323848,0.27314478,0.521947,0.79307634,0.8955206,0.7874625,0.4457445,0.29907298,0.06856772,0.02055715,0.046158686,0.0027637035,0.029739298,0.050730623,0.048215657,0.095898345,0.09430747,0.106132746,0.048582807,0.035336696,0.03634803,0.05466359,0.028021783,0.074517876,0.173273,0.119857706,0.060201436,0.07117808,0.017897323,0.13054526,0.4012742,0.7570053,0.9555611,0.8272646,0.36905807,0.16628717,0.0,0.0062101334,0.0719078,0.004417971,0.052631408,0.055236667,0.041036353,0.13104132,0.117807984,0.12566619,0.052538596,0.005426109,0.026292674,0.05953002,0.05596085,0.06428683,0.16117324,0.081071705,0.0051555634,0.04400023,0.0,0.10408427,0.3769952,0.76229936,1.0,0.9088607,0.3629893,0.1240009,0.0,0.0,0.075030714,0.0,0.05117145,0.036618114,0.026362292,0.16702324,0.12273296,0.13753134,0.06120547,0.009316914,0.017383724,0.050017774,0.061320513,0.085540086,0.20169523,0.096063286,0.013260424,0.074375466,0.0,0.13771942,0.4134069,0.8025466,1.0,0.9087926,0.36283147,0.14573659,0.0,0.0,0.07831771,0.0,0.0388624,0.022491515,0.009347923,0.1664498,0.12275283,0.1448706,0.07337126,0.014181599,0.015395187,0.027464576,0.035655826,0.07541697,0.21268967,0.099122375,0.004295692,0.09615979,0.011298768,0.17276472,0.44874334,0.8230225,1.0,0.92198545,0.37218964,0.15947126,0.0,0.0,0.0931754,0.0,0.034126036,0.020814568,0.0042349994,0.16184533,0.10617092,0.13448979,0.07471551],[0.0,0.0,0.0016750097,0.0,0.0,0.21193698,0.29182556,0.2996435,0.39903104,0.3531408,0.30775517,0.26273388,0.22764845,0.11325741,0.0040554255,0.041499957,0.27222314,0.6539721,0.88445526,0.8834914,0.5344086,0.30071855,0.06604088,0.018389113,0.0,0.0,0.036221206,0.06882535,0.0,0.0,0.0012402683,0.0,0.018435359,0.21222243,0.3413155,0.37797105,0.45004117,0.46812862,0.4787354,0.48691314,0.37828255,0.24072762,0.07960039,0.18261832,0.46227914,0.80410606,0.83662766,0.59023476,0.20400995,0.056815505,0.0,0.0084026605,0.0,0.0,0.020493083,0.056090802,0.012437582,0.0,0.0065419152,0.0,0.028480351,0.18378988,0.31868115,0.35675758,0.4228459,0.5097622,0.59830695,0.6593907,0.51504767,0.40834576,0.23434377,0.33448803,0.52892584,0.74042225,0.63314843,0.30469263,0.031593792,0.0072826594,0.0,0.0,0.0,0.0,0.008610427,0.044254005,0.030841932,0.0,0.011287764,0.0,0.056687906,0.17339665,0.2562391,0.2518482,0.3025478,0.44989294,0.5957085,0.712154,0.5925422,0.5418999,0.33981645,0.40220004,0.5083685,0.59523207,0.36622906,0.10489618,0.0,0.011873521,0.0,0.0,0.0,0.0,0.0,0.03221388,0.04724627,0.0,0.019057356,0.0,0.08694997,0.17814872,0.2513586,0.20337166,0.21369901,0.3632577,0.51860577,0.6859322,0.6373213,0.66965896,0.46744025,0.4739834,0.5104959,0.45437992,0.18731946,0.06102436,0.0,0.009388387,0.0,0.0,0.0,0.0,0.0,0.033758625,0.050731376,0.0,0.014962919,0.018709227,0.12395694,0.16376428,0.24652743,0.14743046,0.12227683,0.2721575,0.38051188,0.6304519,0.7033701,0.81381357,0.5978026,0.45647794,0.36784682,0.24963824,0.04301423,0.057272896,0.03695135,0.01526586,0.0,0.0,0.0,0.03131368,0.0,0.034201257,0.052889697,0.0,0.020285174,0.030664586,0.12633313,0.14421465,0.2382172,0.10971074,0.057992645,0.1818219,0.27422136,0.5816247,0.7662318,0.9189193,0.6498557,0.27595848,0.062797,0.0,0.0,0.07601988,0.07700766,0.00521408,0.0,0.0,0.0,0.06659703,0.0,0.03353464,0.04976955,0.017430052,0.029896393,0.029086791,0.115081154,0.1437505,0.22864926,0.065822,0.0,0.10639225,0.21266541,0.55841196,0.84413284,1.0,0.6894378,0.13882528,0.0,0.0,0.0,0.07945861,0.08874209,0.0,0.042793557,0.023467645,0.01325275,0.08902419,0.0,0.031454623,0.041778497,0.031980217,0.048085853,0.030208603,0.111852944,0.13331719,0.23023209,0.042860888,0.0,0.09406308,0.22049567,0.5704182,0.90339607,1.0,0.7619301,0.107236214,0.0,0.0,0.0,0.07622027,0.10493919,0.0,0.068528295,0.04384222,0.0224742,0.09378378,0.0,0.032178313,0.04220666,0.03098216,0.047417678,0.03357777,0.14906487,0.17754091,0.25006366,0.07950264,0.008094996,0.12329287,0.2554173,0.6172731,0.9305041,1.0,0.7604998,0.10609537,0.0,0.0,0.0,0.06676783,0.10968232,0.0,0.044677146,0.02709841,0.019463234,0.1013194,0.0,0.051472224,0.042285047,0.02594322,0.02249115,0.013232954,0.14408751,0.19871211,0.2535761,0.10911671,0.05065939,0.14405224,0.28781825,0.6483524,0.9460505,1.0,0.7717775,0.12011474,0.0,0.0,0.0,0.05526972,0.10524919,0.0,0.029234432,0.02413962,0.022187911,0.096438244,0.0,0.06079872],[0.0021585673,0.033505052,0.04280121,0.040675074,0.1741842,0.39698052,0.50592,0.39953786,0.24907088,0.25677752,0.18437465,0.17198229,0.12802711,0.082912624,0.0,0.14258179,0.4158693,0.8254873,1.0,0.87338364,0.53523475,0.20166999,0.048420854,0.0019598901,0.043016516,0.056457542,0.06332722,0.038199656,0.0027216524,0.026420847,0.03022775,0.055853784,0.17643721,0.41368884,0.51605654,0.4672507,0.35394496,0.38954145,0.33878136,0.3158419,0.22794288,0.16597858,0.095672466,0.33409888,0.5702105,0.8739603,0.86451995,0.5755585,0.24613383,0.06290716,0.03199546,0.013659731,0.03930769,0.0627064,0.0781872,0.045889705,0.012573071,0.027900249,0.03405693,0.06933772,0.15839487,0.37424645,0.46606666,0.48337424,0.43976623,0.5017004,0.46625614,0.45706856,0.34557176,0.25589472,0.24031836,0.4480304,0.5856199,0.75011945,0.60020185,0.2875058,0.06558863,0.0,0.027813658,0.024712145,0.030438773,0.05715836,0.062438056,0.042038336,0.035776556,0.049401708,0.05961264,0.09801657,0.1528784,0.31928068,0.40066046,0.4216777,0.40837157,0.4887991,0.5355226,0.5926953,0.50215787,0.35189947,0.3127488,0.43426067,0.5420593,0.6015249,0.35412538,0.06892875,0.0,0.0,0.0,0.0018439293,0.0025243908,0.05548632,0.043681383,0.030667469,0.05113031,0.06684453,0.082924865,0.12297958,0.14403294,0.28606158,0.38004017,0.40135497,0.37916058,0.45442563,0.57545656,0.7068892,0.64375633,0.4759028,0.39601135,0.42982596,0.4950142,0.4759614,0.20032331,0.0,0.0,0.0,0.0,0.0,0.0,0.06043192,0.041608892,0.035313815,0.059188098,0.06398462,0.09122388,0.12953508,0.12947224,0.23757443,0.33566472,0.3585921,0.35987467,0.41129804,0.6234499,0.81084794,0.7792825,0.5630677,0.4001932,0.33135602,0.33238113,0.28652763,0.055541836,0.0,0.0,0.0,0.0,0.0,0.0,0.07413983,0.05584728,0.03954702,0.06918299,0.06981266,0.08680674,0.12723267,0.122215524,0.20558858,0.3048041,0.33943808,0.36897618,0.3775541,0.6591381,0.89813894,0.9059771,0.6054688,0.32604015,0.1248751,0.14132144,0.16874696,0.0017378926,0.0,0.0,0.0,0.0,0.0020340383,0.0,0.08881542,0.07214424,0.048219092,0.056032605,0.07153929,0.08463043,0.14593649,0.14312863,0.2035965,0.28954434,0.3015257,0.38358575,0.35533756,0.7240793,1.0,1.0,0.6762805,0.258306,0.0,0.0007737577,0.1514515,0.010588288,0.03105922,0.026161976,0.038294762,0.04191553,0.062128395,0.03393387,0.10325249,0.09100118,0.05896291,0.045269474,0.07336519,0.06393036,0.15702197,0.14519371,0.19466652,0.28000253,0.26227677,0.39169395,0.37213612,0.7912108,1.0,1.0,0.7280509,0.21671237,0.0,0.0,0.13305454,0.0,0.08419003,0.08485399,0.09069599,0.071020566,0.11100338,0.062404558,0.09449965,0.09726167,0.06469795,0.047321953,0.08417229,0.0790216,0.1995233,0.19332005,0.24396998,0.3495045,0.3321557,0.48130453,0.43131423,0.844705,1.0,1.0,0.6845419,0.18589082,0.0,0.0,0.16988355,0.0180979,0.1192361,0.0992464,0.08028448,0.044287644,0.10881242,0.047915578,0.09225065,0.10930671,0.081457414,0.043807857,0.08249898,0.08197087,0.22405012,0.23024271,0.28796196,0.4196145,0.41241914,0.5440532,0.4692865,0.8618226,1.0,1.0,0.66870993,0.1937707,0.0,0.0,0.2128788,0.04439652,0.1473513,0.11991193,0.08276791,0.035106443,0.1140682,0.03864959,0.08014637,0.11792661,0.09875464],[0.023396663,0.09390203,0.044394508,0.030607037,0.3363484,0.6833335,0.6433893,0.58122826,0.3810395,0.17693846,0.12131114,0.10207713,0.002194047,0.0,0.0,0.24646133,0.7612241,1.0,0.9526286,0.6361654,0.2841244,0.0727274,0.007289529,0.019578896,0.06022355,0.03894046,0.040602647,0.024456754,0.036172815,0.07972571,0.05584549,0.038369156,0.32397437,0.6493586,0.6968812,0.6358485,0.5180612,0.32204422,0.2690754,0.19556344,0.08333536,0.098891236,0.14237128,0.47065312,0.8420262,1.0,0.7094451,0.31907755,0.043607287,0.015972555,0.0,0.01793944,0.07150148,0.09260489,0.09114869,0.048569255,0.0441937,0.073524736,0.049531616,0.04467228,0.29353943,0.56940484,0.67147803,0.6528273,0.62631613,0.4552334,0.41958976,0.30681053,0.19066553,0.18086655,0.23825067,0.55141455,0.7730259,0.7947895,0.45150054,0.095967084,0.0,0.0,0.0,0.008106455,0.06158083,0.11075128,0.1001967,0.054788537,0.061726674,0.09007056,0.03872981,0.053557903,0.25822508,0.48341006,0.602567,0.590355,0.6016487,0.49919057,0.5811638,0.517196,0.39309102,0.26336896,0.25639603,0.5225181,0.6676872,0.6218725,0.26285025,0.0075870752,0.0,0.0,0.0011969656,0.0,0.040528715,0.12291707,0.09354469,0.052784897,0.078769654,0.11269758,0.02252689,0.06523496,0.23461261,0.41909868,0.5746046,0.5537589,0.5731646,0.5273504,0.6945069,0.7143045,0.5905452,0.3755045,0.30598563,0.511319,0.56330246,0.45709306,0.17251666,0.01380787,0.0,0.0,0.0,0.0,0.012043156,0.1382552,0.09504459,0.06266599,0.08184023,0.11495803,0.0,0.06531161,0.23166247,0.3735659,0.5534221,0.5288918,0.5729664,0.57704866,0.8195623,0.8673836,0.6947228,0.37784255,0.27950293,0.41484857,0.41318196,0.2813804,0.09646633,0.05087898,0.0,0.0,0.0,0.0,0.012660205,0.167504,0.101374574,0.07301907,0.08525034,0.11108996,0.0,0.077138625,0.26087525,0.3684013,0.5694568,0.5343994,0.595883,0.6076362,0.900662,0.98238635,0.77074057,0.349953,0.19323123,0.24628717,0.26492557,0.2241354,0.12400683,0.11919593,0.07489136,0.059796162,0.04142718,0.07145731,0.07886016,0.1898037,0.10413174,0.09022296,0.07081681,0.09149693,0.0,0.12075744,0.30333263,0.380754,0.5666255,0.54493386,0.6175778,0.6628779,0.9978794,1.0,0.89422464,0.35057545,0.11640571,0.046407014,0.16488498,0.2202746,0.20556755,0.23435956,0.18555978,0.17070505,0.19456333,0.21529983,0.21054554,0.21824968,0.120395176,0.10551715,0.058885425,0.07185276,0.0,0.15080282,0.31810236,0.37143105,0.51951766,0.5329337,0.60174775,0.70602405,1.0,1.0,0.94708675,0.35012072,0.09421246,0.0,0.073185295,0.20379487,0.26918423,0.36554497,0.29459858,0.25811213,0.34481713,0.34766117,0.34332484,0.2212874,0.11913773,0.113046825,0.06677862,0.08167936,0.032516994,0.20125717,0.3890698,0.4703263,0.64414984,0.6463024,0.7070154,0.7641774,1.0,1.0,0.9174808,0.27739167,0.064378396,0.0,0.11637095,0.26615727,0.35784465,0.46824104,0.35598475,0.2706007,0.37560827,0.3674738,0.37110263,0.2346828,0.14091942,0.13488124,0.06437273,0.07039814,0.061931513,0.24107854,0.44454253,0.5473059,0.7574292,0.7595798,0.7763224,0.79324764,1.0,1.0,0.88119286,0.26216677,0.058698982,0.0,0.17220429,0.33004206,0.4346162,0.5564981,0.41570985,0.29027295,0.40376043,0.38767177,0.3834334,0.23250364,0.16273773,0.15943095],[0.013738349,0.07362935,0.049308144,0.24972016,0.54981434,0.9217025,0.9380653,0.5638614,0.29389304,0.16228768,0.0062403083,0.032551654,0.008709207,0.0,0.24689484,0.65224856,0.95474684,1.0,0.92392385,0.39469272,0.14087346,0.0063261017,0.019581646,0.015834063,0.07715869,0.021132052,0.035839826,0.0,0.012356125,0.07463914,0.06359977,0.24241516,0.5289557,0.88162607,0.9453312,0.65720564,0.48591757,0.3215375,0.16039549,0.10129488,0.095737174,0.1164484,0.4371279,0.8074945,0.96995026,0.8962056,0.59981406,0.13880162,0.004148841,0.0,0.0,0.0,0.07557137,0.06922902,0.09237996,0.03246884,0.031161807,0.08582654,0.06640984,0.20162335,0.4826846,0.80152816,0.9143128,0.7523706,0.69516426,0.50417167,0.30867624,0.20952007,0.2001769,0.18669586,0.47695363,0.7491713,0.8180099,0.66248137,0.35786158,0.0,0.0,0.0,0.0,0.0,0.06859061,0.06872654,0.08808103,0.044612028,0.057983242,0.098506406,0.06800306,0.16061012,0.43595183,0.71333575,0.853408,0.76634,0.80180806,0.67058396,0.53789735,0.4246683,0.37101907,0.27746043,0.45038044,0.64022994,0.6915116,0.5365288,0.25017095,0.0,0.0,0.009770706,0.0,0.0042325854,0.06398965,0.06469941,0.07336844,0.036569893,0.07462737,0.11766435,0.0819846,0.13691336,0.393475,0.6336602,0.8033987,0.7603587,0.86386764,0.84496987,0.7671824,0.6631003,0.5174043,0.39268947,0.42964482,0.527517,0.56762344,0.4347071,0.21164346,0.0,0.0,0.0,0.0,0.0,0.04617931,0.054012343,0.05405406,0.03705991,0.075099304,0.11345804,0.07369486,0.12485167,0.3694546,0.57901424,0.7746135,0.78056586,0.9494359,1.0,0.9741091,0.827637,0.5027475,0.3310604,0.29749364,0.3771411,0.42027575,0.32312524,0.20638154,0.025081031,0.0,0.0,0.0,0.0,0.03762223,0.06159339,0.054633297,0.043536134,0.07559257,0.1014287,0.059816964,0.1212899,0.39925086,0.6005045,0.7704329,0.8152209,1.0,1.0,1.0,0.9266967,0.4689718,0.25428185,0.14313413,0.26141825,0.3735355,0.35062933,0.28607255,0.12317328,0.01365184,0.0,0.016508251,0.039158948,0.050260775,0.07865785,0.059477642,0.057735696,0.06268353,0.08792959,0.06445846,0.14962652,0.45174432,0.6441224,0.76522285,0.8798891,1.0,1.0,1.0,1.0,0.4855078,0.19689798,0.017355628,0.13995522,0.2863593,0.3645674,0.3759659,0.2771703,0.15444759,0.11584009,0.15489425,0.16852272,0.15885524,0.124418125,0.07405375,0.05699583,0.0571929,0.0847341,0.07418872,0.16219932,0.46603316,0.6349453,0.70726115,0.863018,1.0,1.0,1.0,1.0,0.5133528,0.16465664,0.0,0.008507036,0.16151683,0.34272462,0.46745366,0.45438516,0.30571103,0.22602417,0.3055992,0.29251897,0.24580795,0.12291306,0.053748004,0.04752624,0.06501909,0.123045094,0.12580451,0.23324665,0.5986876,0.78041553,0.85477954,0.9962724,1.0,1.0,1.0,1.0,0.47203797,0.13114403,0.0,0.0414951,0.21306601,0.44222754,0.59246093,0.5788903,0.37783575,0.24389952,0.3102749,0.29402483,0.23798823,0.11400674,0.05482045,0.056782857,0.053322583,0.13570352,0.1609344,0.29827815,0.71706975,0.9284869,0.99299496,1.0,1.0,1.0,1.0,1.0,0.45426983,0.12716095,0.0,0.08850789,0.2938864,0.5326759,0.70241064,0.6992674,0.46975935,0.2972173,0.33441672,0.30555457,0.24153626,0.12176413,0.070663914,0.07427875],[0.0,0.08172578,0.03047628,0.21143398,0.61252177,1.0,1.0,0.82558745,0.5584599,0.32771784,0.31616616,0.15620278,0.20913348,0.42732078,0.7103959,0.9441381,1.0,1.0,0.5908375,0.15996471,0.010192648,0.0,0.0,0.0,0.0,0.0,0.020443775,0.0,0.0,0.10073986,0.054291755,0.19228171,0.5797635,0.997832,1.0,0.9468749,0.7570344,0.5165452,0.44105303,0.25378394,0.29810452,0.51692545,0.7904844,0.9513164,1.0,0.7151594,0.28297353,0.009676486,0.0,0.0,0.0,0.0,0.0,0.047991134,0.07190806,0.025752813,0.0040194243,0.12088895,0.07050194,0.1653431,0.53039896,0.9346787,1.0,1.0,0.95785075,0.69980836,0.5524501,0.37184954,0.35293877,0.5203103,0.70391953,0.792604,0.76394516,0.4673565,0.10937054,0.0,0.0,0.0,0.040921837,0.0,0.0,0.058503114,0.07721844,0.028417237,0.02451244,0.11200828,0.049971864,0.1199807,0.46916223,0.85616684,0.9662426,1.0,1.0,0.8785535,0.72842747,0.5333678,0.45839006,0.48673135,0.56428677,0.65273297,0.64289314,0.37266096,0.09146842,0.0,0.0,0.00036920607,0.058967486,0.0,0.0,0.053684145,0.060383618,0.007865682,0.048534527,0.10849847,0.04663778,0.096141174,0.41257453,0.7791015,0.9033492,1.0,1.0,1.0,0.9344751,0.679862,0.53151894,0.44425738,0.42911845,0.5239102,0.53901905,0.30855808,0.14105006,0.000116601586,0.0,0.011973992,0.09166138,0.0,0.0,0.03475479,0.04334464,0.00077974796,0.049781956,0.07511659,0.0279909,0.094881535,0.39003372,0.73938984,0.8668827,1.0,1.0,1.0,1.0,0.7325607,0.3866467,0.24615481,0.21523675,0.34285218,0.39922267,0.2160137,0.17772925,0.05786825,0.0,0.016797706,0.12471006,0.0,0.007982269,0.028842144,0.040146112,0.011806935,0.05030465,0.05047652,0.005005166,0.09403342,0.41060305,0.7442608,0.85893446,1.0,1.0,1.0,1.0,0.7237216,0.24857835,0.06985892,0.023104705,0.21604694,0.3942768,0.26952994,0.28546724,0.16493955,0.012034446,0.028709374,0.17771015,0.011530332,0.023287766,0.021639839,0.035910703,0.023973368,0.04926738,0.04869812,0.018515252,0.12567455,0.4580769,0.7275284,0.8364255,1.0,1.0,1.0,1.0,0.7847075,0.1637738,0.0,0.0,0.103208184,0.3378656,0.27962694,0.36363137,0.30294794,0.13196735,0.15813142,0.31515118,0.15468098,0.11536266,0.041882403,0.028845064,0.025567666,0.055436514,0.054888524,0.030322313,0.13900623,0.44702452,0.64772266,0.73946035,1.0,1.0,1.0,1.0,0.79925627,0.08707244,0.0,0.0,0.0,0.23499417,0.29005665,0.48391485,0.49334788,0.3108538,0.3230445,0.4676109,0.28793967,0.18738742,0.030271925,0.0010983348,0.024917826,0.0729884,0.089717545,0.06677759,0.22439072,0.5709562,0.81179863,0.86767304,1.0,1.0,1.0,1.0,0.80186003,0.028665923,0.0,0.0,0.0008211136,0.28134993,0.3883922,0.6087652,0.61555666,0.38669485,0.36580136,0.49631602,0.27523935,0.17517945,0.025202602,0.0,0.026526757,0.0740941,0.104601875,0.100793645,0.3021202,0.69629055,0.9658716,0.9675662,1.0,1.0,1.0,1.0,0.78746456,0.01731366,0.0,0.0,0.04703834,0.34941825,0.48768437,0.7182518,0.72607136,0.47645897,0.4258995,0.527724,0.27632874,0.17123356,0.03483203,0.0,0.03598982],[0.0,0.0372404,0.062146597,0.2921926,0.6331451,0.8959306,0.9865074,1.0,1.0,0.9163431,0.71324694,0.6403487,0.67435914,0.80511886,0.9129121,0.9570169,0.82038933,0.48800123,0.32677227,0.032544695,0.0,0.0,0.0,0.04529503,0.056287624,0.053873964,0.008529626,0.0,0.0,0.037336476,0.06911945,0.28850204,0.59914315,0.8658795,0.9752833,1.0,1.0,0.9874955,0.7404383,0.6599551,0.6528384,0.7269829,0.78718585,0.7799913,0.5657108,0.29437143,0.13686834,0.004458666,0.035723984,0.0,0.0,0.039521143,0.0635498,0.07415344,0.015042096,0.0,0.011126891,0.044530846,0.07447106,0.26917338,0.5539109,0.82145506,0.967697,1.0,1.0,1.0,0.76824695,0.66737,0.62449455,0.56709456,0.5903631,0.5894209,0.38334644,0.20804702,0.07478729,0.0014334768,0.062105417,0.0,0.0,0.031257257,0.07062341,0.08234903,0.007024884,0.0,0.019031942,0.049637884,0.04839743,0.2284548,0.47944456,0.7551351,0.93381584,1.0,1.0,1.0,0.7882195,0.6883508,0.5807428,0.40671593,0.4221909,0.45368725,0.3206064,0.20191202,0.08138088,0.012814879,0.07721832,0.0,0.0,0.01640702,0.0764571,0.08813261,0.0,0.0,0.024183333,0.056539193,0.017615065,0.20253721,0.42515373,0.6966771,0.86896926,1.0,1.0,1.0,0.8327388,0.7370548,0.5316309,0.26674002,0.24413754,0.32964167,0.29390514,0.22604083,0.13715774,0.022935182,0.07841675,0.0,0.0,0.006076075,0.0548949,0.071224436,0.0,0.0,0.020346008,0.04087603,0.0,0.16410288,0.368668,0.6402175,0.8163201,1.0,1.0,1.0,0.9250169,0.7425126,0.40257698,0.08613645,0.039462432,0.16219172,0.18519486,0.20698524,0.19702396,0.033656105,0.0742437,0.0075369626,0.010230027,0.0015050322,0.035058588,0.05367592,0.0,0.0,0.02125837,0.031679966,0.0,0.14639214,0.35687304,0.6220524,0.795701,1.0,1.0,1.0,1.0,0.7300171,0.28586847,0.0,0.0,0.08107361,0.16037548,0.24991941,0.2885124,0.062407926,0.06394475,0.013856992,0.03288632,0.0,0.013392441,0.035881728,0.0,0.0,0.024628617,0.050268702,0.0,0.16701782,0.36739704,0.57794875,0.7474181,1.0,1.0,1.0,1.0,0.74995196,0.21258238,0.0,0.0,0.04514958,0.116412915,0.2517976,0.34749594,0.12820242,0.13739146,0.11775619,0.14910018,0.09418047,0.06759056,0.037229225,0.0,0.004021302,0.030143633,0.065942004,0.016613506,0.17793553,0.33923578,0.42612696,0.5537932,0.9139674,1.0,1.0,1.0,0.7485745,0.15106037,0.0,0.0,0.022467256,0.081995614,0.28493926,0.4661876,0.28548962,0.28448984,0.28148606,0.2952332,0.18651748,0.11917181,0.023023747,0.0,0.0,0.026199445,0.06524709,0.035119906,0.23375964,0.42787874,0.5271204,0.6464909,1.0,1.0,1.0,1.0,0.7641235,0.13722685,0.0,0.0,0.04189398,0.13110144,0.38397014,0.5841828,0.3757205,0.34482765,0.31685418,0.3048082,0.1873458,0.12457375,0.02186399,0.0,0.0,0.008976802,0.046002395,0.044859022,0.27609843,0.50662357,0.618847,0.7232553,1.0,1.0,1.0,1.0,0.7517502,0.13058944,0.0,0.0,0.0673484,0.18626526,0.47403646,0.67032015,0.45807725,0.40643078,0.36040574,0.3222624,0.20514305,0.13496666,0.025769107,0.0,0.0],[0.0,0.030540027,0.0961692,0.2854609,0.45613497,0.6677509,0.808089,0.9455513,1.0,1.0,1.0,0.9740346,1.0,1.0,0.80798036,0.6218649,0.3504269,0.20978028,0.09828519,0.01955802,0.0,0.027178533,0.05289054,0.032036863,0.029805347,0.036543794,0.0,0.0,0.0,0.020304061,0.096075445,0.25496852,0.4517321,0.6462615,0.82639855,1.0,1.0,1.0,1.0,0.8774699,0.89455986,0.8441164,0.53650177,0.39337236,0.17478687,0.07436253,0.05046238,0.037663497,0.037259653,0.047699966,0.04457038,0.050486952,0.052078664,0.05856835,0.0,0.0,0.0063846856,0.03257426,0.089552075,0.22920528,0.4417252,0.6212758,0.856691,1.0,1.0,1.0,0.8656844,0.77243453,0.72954774,0.6051273,0.35130012,0.27797478,0.11569033,0.049866088,0.045862883,0.02911941,0.07792418,0.0390763,0.027119257,0.058669895,0.07772809,0.07171013,0.0,0.0,0.028289199,0.028756455,0.08049095,0.17483786,0.38658684,0.57223016,0.87337196,1.0,1.0,1.0,0.7433925,0.65455896,0.53422904,0.39009142,0.22783671,0.24925953,0.15670514,0.07601931,0.06696692,0.033505812,0.10322366,0.061418824,0.015878223,0.07449722,0.102447666,0.07249975,0.0,0.0,0.04937511,0.023902223,0.081516705,0.1463446,0.35903537,0.54089135,0.8327627,1.0,1.0,0.9431715,0.6929281,0.5421741,0.35699672,0.1556755,0.091759235,0.24910975,0.25121713,0.16349235,0.12006289,0.033234768,0.10132708,0.08508879,0.012082808,0.07845412,0.09793332,0.064702705,0.0,0.0,0.055951357,0.01180885,0.06787626,0.10918481,0.32637343,0.5201763,0.7929171,0.96252817,1.0,0.96044457,0.74029976,0.46757454,0.20151022,0.0,0.0,0.19277789,0.26404858,0.21136412,0.1541129,0.03460387,0.08011483,0.10133414,0.020660743,0.086711995,0.08914764,0.044263415,0.0,0.0,0.060328886,0.008474387,0.050969616,0.09776312,0.33470327,0.5293262,0.7771367,0.939503,1.0,0.9688753,0.7951855,0.41567034,0.115265235,0.0,0.0,0.16686013,0.30727684,0.25736198,0.17125058,0.016685978,0.034087084,0.09503531,0.013914473,0.094667785,0.06743711,0.024948373,0.0,0.0,0.06708261,0.020422846,0.0626211,0.114020586,0.33498847,0.49717033,0.71373653,0.87142557,1.0,0.9496575,0.8338739,0.41613686,0.09396753,0.0,0.0,0.13864273,0.26832646,0.2817111,0.14590208,0.02851101,0.06977668,0.13693577,0.06258493,0.14116779,0.07635757,0.033690087,0.0,0.0,0.07201134,0.019650206,0.055275068,0.13098946,0.30386025,0.36292267,0.54011047,0.7139456,0.9970615,0.9112311,0.84261316,0.42522037,0.1151981,0.0,0.0,0.100974776,0.23086406,0.3473939,0.2005893,0.101381585,0.1650443,0.22166227,0.13185616,0.17576662,0.075882375,0.041645214,0.0,0.0,0.06462821,0.015204236,0.051291503,0.16896671,0.36499056,0.42761976,0.6133679,0.7896683,1.0,0.9356195,0.87476623,0.43408698,0.12571412,0.0,0.0,0.11158591,0.2920218,0.45272243,0.27459687,0.13614252,0.19500965,0.22258294,0.11678824,0.18233886,0.07041621,0.040182702,0.0,0.0,0.04693959,0.004890859,0.039744906,0.19578028,0.41661465,0.47569996,0.64295477,0.793071,1.0,0.8913364,0.85786086,0.42709917,0.12941419,0.0,0.0,0.11152309,0.32954344,0.52084726,0.32336822,0.16911082,0.21882097,0.22333127,0.09300433,0.18958184,0.06467934,0.039946303,0.0,0.0],[0.0,0.05504906,0.09279163,0.19608359,0.28449464,0.29393706,0.314671,0.4982674,0.850629,0.96915627,0.97208,0.7450279,0.73169935,0.4947908,0.3142305,0.08172307,0.006635517,0.0,0.0,0.0,0.005951427,0.010820568,0.00023689866,0.0,0.02256833,0.0,0.0,0.0,0.0,0.05343935,0.0877835,0.17281854,0.26345682,0.3221752,0.36184937,0.50624,0.7816833,0.8874195,0.8382959,0.605043,0.56829375,0.356376,0.17936844,0.018717103,0.0,0.0,0.0,0.0,0.012221545,0.016369492,0.024614833,0.0,0.036667705,0.0,0.0,0.0,0.0,0.07386915,0.08932757,0.14459048,0.2225109,0.33814052,0.40476048,0.5032768,0.7015348,0.77089506,0.6788876,0.4696144,0.42387098,0.24744159,0.102044106,0.017536163,0.016840525,0.0,0.0,0.0,0.02142506,0.021492243,0.04621101,0.0,0.048457816,0.0,0.0,0.0,0.0,0.06393901,0.073007755,0.0800145,0.15792282,0.34724784,0.44927925,0.50583684,0.61864394,0.65085435,0.5344229,0.35900718,0.28824347,0.1709774,0.0927559,0.068280384,0.09234853,0.025907114,0.0,0.005667791,0.038767062,0.044967204,0.08286319,0.045290247,0.09770104,0.016678333,0.0,0.0,0.0,0.050623864,0.06347967,0.054853946,0.14467451,0.3503574,0.43573225,0.4819724,0.55333155,0.5990289,0.42889088,0.26203054,0.15041018,0.070889086,0.086209625,0.15227717,0.2039957,0.08867065,0.025008023,0.0007495731,0.02560746,0.044472314,0.07341145,0.026006438,0.07829851,0.01520659,0.0,0.0,0.0038260967,0.043385208,0.05650545,0.050220557,0.15213643,0.33979765,0.43725598,0.50746846,0.57473284,0.67837626,0.43840432,0.25822562,0.06778428,0.007345602,0.08239691,0.18423975,0.22538853,0.107882775,0.0329284,0.003072396,0.01816874,0.037746757,0.064835966,0.003946647,0.04828973,0.002201125,0.0,0.0,0.02062586,0.037090458,0.04567545,0.039308578,0.15156244,0.31692868,0.43212897,0.48942608,0.58086336,0.7272427,0.4941218,0.30279577,0.012482941,0.0,0.065329455,0.17583604,0.2111974,0.1318666,0.044571623,0.0,0.0,0.00778269,0.05592873,0.0,0.025105856,0.0,0.0,0.0,0.027911626,0.023165822,0.04019276,0.02811104,0.14761746,0.2608044,0.37647307,0.3951471,0.52677304,0.7103302,0.5470178,0.3543681,0.0071624666,0.0,0.06933437,0.14313751,0.16510764,0.13409527,0.03241589,0.0,0.0,0.005495712,0.05988936,0.0033688396,0.004858762,0.0,0.0,0.0,0.02733767,0.012650706,0.030828394,0.0023514181,0.12004997,0.09883459,0.22793984,0.2724376,0.5087958,0.7108071,0.60277754,0.42057925,0.05119516,0.0,0.089850724,0.12167247,0.17148015,0.16313484,0.08033487,0.017440215,0.0,0.04223062,0.07971094,0.0,0.0,0.0,0.0,0.0,0.0203178,0.011422783,0.024840325,0.0,0.12841165,0.100607544,0.25429684,0.29843622,0.5461266,0.74397606,0.6468774,0.47311372,0.108477786,0.0,0.09829514,0.1247817,0.22896552,0.24134503,0.1479172,0.046039045,0.0006597191,0.050937608,0.082169056,0.0,0.0,0.0,0.0,0.0,0.013388112,0.007558085,0.019953214,0.0,0.12757109,0.09953104,0.2535446,0.2825333,0.5257023,0.70590323,0.6287703,0.47995192,0.15857713,0.0,0.09943262,0.104613855,0.24811307,0.2934493,0.1912687,0.058754966,0.0027042925,0.051623017,0.07893013,0.0,0.0,0.0,0.0,0.0],[0.009136453,0.0,0.031218342,0.16079552,0.12101691,0.11270975,0.05388014,0.11214336,0.27303895,0.27270365,0.22879511,0.18088594,0.11640644,0.0,0.0,0.0,0.0,0.0011458844,0.008574367,0.0,0.07123478,0.0,0.0,0.0,0.000065639615,0.0,0.02359379,0.022489332,0.0037440509,0.0,0.008454852,0.14353065,0.11964634,0.15206721,0.07953107,0.10513505,0.24983668,0.25921583,0.19392553,0.14791133,0.102957025,0.0,0.0,0.0,0.0,0.0,0.0,0.0120700225,0.07098514,0.0,0.0,0.0,0.0,0.0,0.0018557906,0.017850198,0.009009652,0.0,0.0022311807,0.121643834,0.098599225,0.16997433,0.08786105,0.10099402,0.22789219,0.23764959,0.16781645,0.106083766,0.07102841,0.0,0.0,0.026855491,0.015659928,0.004332155,0.0,0.0,0.051703677,0.0,0.0,0.0,0.0,0.0,0.0,0.02187474,0.016902447,0.006145805,0.0,0.07264936,0.07929525,0.2052764,0.11226748,0.12597692,0.2027159,0.2259421,0.1250775,0.07162281,0.032854848,0.019227087,0.06100484,0.12141907,0.0795336,0.037897356,0.0,0.0,0.045207188,0.022787996,0.0,0.024957761,0.022642478,0.0021758378,0.0,0.025311247,0.020739421,0.018083662,0.0,0.06392381,0.09329942,0.21010563,0.09046627,0.14029907,0.20428127,0.24065766,0.12169819,0.03241896,0.0,0.005466953,0.10713903,0.19209926,0.12207527,0.05647686,0.0,0.0,0.008006431,0.024909675,0.0,0.012222454,0.022354193,0.0,0.0,0.024682105,0.027884014,0.02183336,0.0,0.08376442,0.13198438,0.20690258,0.13595046,0.20082602,0.28316414,0.3662809,0.18260698,0.042747326,0.0,0.021429583,0.12954336,0.21950704,0.10770756,0.06080836,0.0020007342,0.0,0.0,0.02361057,0.009111807,0.0069628432,0.018364154,0.0,0.0,0.007600963,0.030864261,0.010649033,0.0,0.10364583,0.17026404,0.21692611,0.22059949,0.25447962,0.3374576,0.49601936,0.31208342,0.10884872,0.0,0.024269857,0.140719,0.1993717,0.09780219,0.082303405,0.020186588,0.0,0.0,0.030153163,0.029340237,0.0050206184,0.0383655,0.0,0.0,0.0,0.03489691,0.0,0.0,0.12675251,0.19784501,0.19059196,0.22078693,0.22766954,0.29895326,0.55846274,0.44025725,0.15053664,0.0,0.056886747,0.16538264,0.17062026,0.08196004,0.06282691,0.029260777,0.0,0.0,0.04916314,0.04503087,0.005811937,0.08664331,0.0,0.0,0.0,0.04408884,0.0,0.0,0.13129717,0.18594033,0.06164754,0.124077864,0.17548813,0.28866336,0.6226604,0.56152767,0.17715523,0.0,0.09890466,0.20661491,0.18565106,0.14528964,0.07568632,0.08018081,0.05326338,0.024721496,0.11274801,0.07662509,0.0,0.14549258,0.008875787,0.0,0.0,0.050658382,0.0,0.0,0.14394283,0.1925548,0.05476792,0.126349,0.1857106,0.3110848,0.6738851,0.6331863,0.23825176,0.0,0.13461712,0.23590076,0.22135124,0.21530849,0.15354247,0.15149458,0.08372952,0.040864296,0.13332674,0.096015856,0.0,0.16308866,0.0020565987,0.0,0.0,0.052372873,0.0,0.0,0.14060558,0.19134478,0.040577263,0.11543256,0.15426233,0.28200373,0.6552654,0.6366643,0.26191628,0.013902329,0.15549982,0.23772179,0.22257364,0.25277984,0.19903624,0.19680095,0.093222514,0.039376505,0.13002272,0.0906637,0.0,0.16603164,0.0,0.0,0.0],[0.018957056,0.045088194,0.032442525,0.0,0.012818158,0.07085042,0.010616146,0.04568612,0.028387666,0.017544769,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004040107,0.0,0.0,0.0,0.0,0.037016697,0.023611002,0.015073523,0.0,0.0,0.027041964,0.01600857,0.0,0.0063112974,0.06545449,0.0044148117,0.07328728,0.04611469,0.019726269,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017473042,0.0,0.0,0.0,0.0,0.0151304975,0.0,0.0,0.0,0.037937395,0.0,0.09438996,0.068807036,0.019432202,0.0,0.0,0.0,0.033083536,0.032609724,0.0,0.0014371872,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0031579286,0.0,0.0,0.0,0.037036516,0.002120316,0.0808122,0.047947742,0.007851727,0.0,0.0,0.01918979,0.06528838,0.080713846,0.0045877397,0.024870247,0.0,0.0,0.0,0.00018948317,0.0,0.0,0.0,0.010919869,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021801107,0.045824744,0.00047126412,0.061246738,0.03019473,0.0055790097,0.0,0.0,0.03523364,0.05354677,0.094341174,0.03395655,0.05528661,0.0,0.004022971,0.0,0.0,0.0043487996,0.0019477159,0.0,0.002068445,0.0,0.0,0.0,0.0,0.0,0.00014300644,0.0,0.04036378,0.06330053,0.043919504,0.10435253,0.06612178,0.026815988,0.0,0.0,0.07586776,0.06350641,0.11687278,0.047733754,0.04967986,0.0,0.00903181,0.0,0.0,0.0056080967,0.014324464,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.044270538,0.09247138,0.08424409,0.1579286,0.10762178,0.06942273,0.027332626,0.05703409,0.13675192,0.067198105,0.12755725,0.03907533,0.039207354,0.0,0.013027124,0.0,0.0,0.0,0.019101582,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05947613,0.10887944,0.078012094,0.12524256,0.07876978,0.0926808,0.089662835,0.15011168,0.20361555,0.07010044,0.13567685,0.03454704,0.01718665,0.0,0.019929841,0.0,0.0,0.0,0.010697149,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.043259777,0.09185389,0.051839247,0.11078964,0.067617975,0.12936571,0.14989127,0.21002546,0.23824267,0.07741648,0.165492,0.09584647,0.041357286,0.041704066,0.06483831,0.023525082,0.0,0.0,0.014017373,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.043814562,0.11295004,0.07203826,0.13665462,0.07869237,0.16540974,0.20656377,0.27571154,0.29804453,0.08553169,0.18225741,0.12635417,0.08880976,0.10651744,0.12132925,0.058413893,0.01407478,0.0013212711,0.01081863,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.037302986,0.11604479,0.06273009,0.11307274,0.060108118,0.18202488,0.23166956,0.28589964,0.30897695,0.088508576,0.18064836,0.1372101,0.11557525,0.1362867,0.15214847,0.07441528,0.020099193,0.0,0.0016239583,0.0,0.0,0.0,0.0,0.0],[0.0,0.025160164,0.06693719,0.0,0.06286776,0.1312977,0.064011395,0.0830342,0.063474946,0.04417347,0.027660035,0.0,0.0,0.0476887,0.041998178,0.018680193,0.0678344,0.011580452,0.025013052,0.014307521,0.018259943,0.0,0.0,0.0,0.063078165,0.021485314,0.044542722,0.013709649,0.0,0.021033816,0.06718578,0.0,0.066849634,0.11703274,0.070922494,0.11417852,0.07772547,0.033286147,0.007056713,0.0,0.0062838495,0.060035273,0.031806618,0.0,0.055719905,0.0,0.0,0.0,0.016795106,0.00029812753,0.0,0.012746707,0.07590165,0.0008222163,0.02176264,0.0048252046,0.0,0.014158659,0.058283955,0.0,0.0468326,0.09486802,0.079935834,0.13333033,0.09741856,0.014543787,0.0,0.0,0.03264998,0.071532905,0.037518755,0.0,0.031069301,0.0,0.0,0.0,0.020625025,0.0031086504,0.0,0.012373395,0.05875831,0.0,0.0051470846,0.0,0.0,0.014045201,0.046624854,0.0,0.03526049,0.06796034,0.072075546,0.11209654,0.07837868,0.010270588,0.0,0.0015066117,0.0068530813,0.028262638,0.019124955,0.0,0.005275354,0.0,0.0,0.0,0.022877805,0.0137813315,0.0,0.020187803,0.051513657,0.0,0.0,0.0,0.0,0.008144163,0.033045627,0.012447111,0.034543492,0.03896308,0.04758594,0.086841956,0.048184194,0.01416374,0.0,0.010195896,0.019435078,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018928118,0.027522191,0.0,0.0091968775,0.030272998,0.0,0.0,0.0,0.0,0.016250461,0.023971394,0.0,0.025049716,0.024194464,0.04213196,0.09088336,0.06438517,0.037160337,0.0,0.026974909,0.04697963,0.0,0.0030246973,0.0,0.0,0.0,0.0,0.0,0.009435274,0.031591363,0.006793484,0.005252525,0.01974313,0.0,0.0,0.0,0.0,0.034381106,0.020812199,0.0,0.02943185,0.010011993,0.036844976,0.119323224,0.097799815,0.069364905,0.034563564,0.07239404,0.07537894,0.015196055,0.0013275295,0.0,0.0,0.0,0.0,0.0,0.0,0.021175705,0.01768186,0.013822809,0.031997427,0.0077420548,0.0,0.0,0.009569682,0.068731695,0.04880534,0.018114485,0.048926026,0.0059392005,0.015961774,0.11110526,0.10559579,0.09534786,0.11056462,0.12951714,0.10800154,0.04002335,0.017563686,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012956202,0.018400818,0.042674124,0.04895401,0.017695911,0.0,0.017872304,0.09354659,0.08483729,0.02104862,0.040428378,0.0,0.0,0.124563,0.13145511,0.15352464,0.17270777,0.17491114,0.109935805,0.08305676,0.092436105,0.0,0.0,0.0015598238,0.0,0.0,0.010584377,0.0,0.0,0.032435358,0.058338255,0.08494989,0.052831672,0.0,0.01093372,0.08166826,0.06996646,0.0008889586,0.04895076,0.0039278716,0.0,0.15122232,0.15958923,0.2082228,0.228817,0.22598797,0.13419314,0.08250737,0.0900556,0.0,0.0,0.03930337,0.031811453,0.0039164275,0.017493904,0.0,0.0,0.029349,0.065616034,0.094619736,0.071989045,0.0,0.0,0.052089915,0.044496596,0.0,0.043211132,0.003001824,0.0,0.1417605,0.16845831,0.25106052,0.24811278,0.23300394,0.13431865,0.07656064,0.092820495,0.0,0.0,0.06937467,0.05168052,0.008165896,0.026124798,0.0,0.0,0.013385482,0.060268775,0.0838482,0.07707156,0.0],[0.0,0.0208778,0.056516632,0.0033242702,0.08534804,0.026939772,0.025868773,0.0,0.011428706,0.0,0.0,0.0,0.013891116,0.019912042,0.020224683,0.0,0.025345683,0.0800749,0.06067542,0.0019666106,0.0,0.0,0.0,0.025202513,0.036648184,0.0040008724,0.0006483495,0.004066363,0.0,0.01830323,0.06504909,0.01873295,0.08652587,0.028521158,0.03729228,0.012239575,0.010728881,0.0,0.0,0.0030328333,0.035519116,0.028033718,0.0023944378,0.0,0.002497375,0.04313168,0.030754901,0.011958957,0.0,0.0,0.0,0.017787263,0.02434349,0.0,0.0,0.008039519,0.0,0.009965315,0.068148494,0.025538474,0.08258749,0.025964223,0.044017024,0.030139916,0.010974266,0.0,0.0,0.0,0.029643483,0.018501185,0.0,0.0,0.0,0.01459609,0.0071918666,0.02114202,0.00021649897,0.0,0.0,0.006448649,0.011387609,0.0,0.0,0.010244153,0.0,0.0005507171,0.065873906,0.026129,0.07285364,0.015114903,0.0314878,0.019025184,0.0047046393,0.0,0.0,0.0,0.00012047589,0.006496623,0.0,0.0,0.0,0.0,0.0,0.031456433,0.0057710037,0.0,0.0,0.0,0.0,0.0,0.0,0.011541724,0.0,0.0,0.05914031,0.03526268,0.07189136,0.0037243366,0.0032124072,0.0,0.0,0.0,0.0,0.0,0.0,0.0001129061,0.0,0.0,0.0,0.0,0.0,0.03895919,0.026724614,0.0,0.0,0.0,0.0,0.0,0.0,0.013159014,0.0,0.0,0.041507743,0.022929527,0.0445927,0.0,0.0,0.0,0.0,0.014320917,0.0,0.0,0.0048446357,0.014472224,0.0,0.0,0.0,0.0,0.0,0.030516937,0.029181048,0.0024586767,0.0,0.0,0.0,0.0,0.0,0.010948665,0.0008380711,0.008393198,0.026714914,0.012714766,0.01278659,0.0,0.0,0.0,0.0,0.023352847,0.032191828,0.033544414,0.022071876,0.009155959,0.0,0.0,0.0,0.0,0.0,0.021727748,0.024687268,0.007451929,0.0,0.0,0.0,0.0,0.0,0.010115646,0.013885461,0.034343854,0.03689403,0.01959055,0.0,0.0,0.0,0.0,0.0,0.042372227,0.07833663,0.077746406,0.04218322,0.0045358986,0.0,0.0,0.0,0.0,0.0,0.018434078,0.020920828,0.017836392,0.0,0.0,0.003616199,0.0,0.0,0.0073778555,0.026176281,0.057174526,0.05257172,0.019635215,0.0,0.0,0.0,0.005482942,0.02394431,0.07620632,0.13075666,0.10916269,0.05520591,0.019768216,0.0,0.0,0.0,0.023404561,0.0,0.01764702,0.012503959,0.029457316,0.0,0.0,0.021236405,0.0,0.0,0.0034894943,0.021916024,0.04749792,0.045884013,0.019056886,0.0,0.0,0.0,0.0091805905,0.041774333,0.11558788,0.17613496,0.13186088,0.06364381,0.018323258,0.0,0.0,0.0,0.04049267,0.0,0.0139343515,0.0057822317,0.037735388,0.0,0.0,0.030550085,0.0,0.0,0.013543151,0.013445452,0.029207133,0.030746758,0.011973627,0.0,0.0,0.0,0.0072911084,0.046073906,0.1409183,0.19609994,0.14026047,0.070683464,0.009813666,0.0,0.0,0.0,0.06631731,0.0,0.014702432,0.0043625683,0.04292717,0.0,0.0,0.027245715,0.0,0.0,0.01727032],[0.027720563,0.013411596,0.0,0.0,0.0,0.0,0.019210108,0.0,0.0,0.0,0.0,0.0,0.025424883,0.023158595,0.0,0.0,0.03347704,0.0,0.0,0.0,0.0,0.08579332,0.028905198,0.014604993,0.0,0.0,0.0,0.008875765,0.029977702,0.003584355,0.0,0.0,0.0,0.0,0.0140881315,0.0135990605,0.0032464713,0.0,0.0,0.0,0.018155254,0.027520224,0.0,0.0,0.02553694,0.0,0.0,0.0,0.0,0.08638358,0.025531285,0.0003439039,0.0,0.0,0.0,0.0,0.025436476,0.0,0.0,0.0,0.0,0.0,0.03093426,0.024488777,0.013572685,0.009211637,0.0,0.0,0.017988227,0.023061156,0.0,0.00007882714,0.0073383152,0.0,0.0,0.0,0.0,0.084741965,0.019224301,0.0,0.0,0.0,0.0,0.0,0.023288302,0.0,0.0,0.014593206,0.0,0.0,0.037618995,0.017590605,0.013580546,0.022527643,0.0,0.0,0.022128262,0.020447172,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07574064,0.0042630136,0.0,0.0,0.0,0.0,0.0,0.024537072,0.0,0.0024614036,0.030155636,0.0,0.00011628866,0.035571635,0.0066533834,0.008215375,0.042497903,0.0,0.0,0.029508896,0.021109171,0.0052244067,0.0,0.0,0.0,0.0,0.0,0.0,0.07049465,0.0,0.0,0.0,0.0,0.0,0.0,0.02951482,0.009559147,0.008846514,0.043524712,0.0,0.0,0.044595055,0.014199287,0.011749126,0.06991893,0.0,0.0,0.031892426,0.017267004,0.015437625,0.00880643,0.0,0.0,0.0,0.0,0.0,0.061860584,0.0,0.0,0.0,0.0,0.0,0.0,0.036879584,0.011807881,0.004180208,0.035636455,0.0,0.0,0.041809782,0.016577333,0.034846745,0.10955258,0.0,0.0,0.029392898,0.007041976,0.021578334,0.006818466,0.0,0.0,0.015628226,0.0,0.0,0.045917124,0.0,0.0,0.0,0.0,0.0,0.0,0.04518029,0.018010117,0.0,0.017831177,0.0,0.0,0.037702702,0.0254267,0.06405652,0.14176278,0.0,0.0,0.017415732,0.0,0.032497846,0.003393963,0.0,0.0037950426,0.027356833,0.0,0.0,0.021109745,0.0,0.0,0.0,0.008825362,0.0,0.0,0.05159826,0.0331634,0.0,0.0,0.0,0.0,0.014235608,0.004793912,0.047051206,0.1326008,0.0,0.0,0.014403962,0.0,0.049897477,0.0,0.0,0.01595752,0.03482128,0.0,0.0,0.004898131,0.0,0.0063553005,0.0064576045,0.0444958,0.0,0.0,0.056071416,0.049987674,0.0,0.0,0.0,0.0,0.0,0.0,0.010737881,0.102557294,0.0,0.0,0.0116417855,0.0,0.07726823,0.0,0.0,0.026810132,0.031518385,0.0,0.0,0.0,0.0,0.029375687,0.025240578,0.07614705,0.015621632,0.0,0.06027793,0.063814536,0.0055156946,0.0,0.0,0.0,0.0,0.0,0.0,0.08718718,0.0,0.0,0.012567073,0.0,0.089022756,0.0010778606,0.0,0.027843058,0.030450389,0.0,0.0,0.0,0.0,0.033095643,0.020575315,0.08019488,0.020853326,0.0],[0.0048589855,0.0,0.0,0.0,0.0,0.0,0.0076250657,0.0,0.0,0.0,0.0,0.012039557,0.060599066,0.022824913,0.0271013,0.01679755,0.04441821,0.047296062,0.0,0.0,0.05012568,0.029379047,0.07509354,0.035911895,0.03902805,0.0,0.0,0.0,0.0052589923,0.0,0.0,0.0,0.0,0.0,0.021002322,0.0023921877,0.009682752,0.0,0.0,0.0065300837,0.066983394,0.036927253,0.03241881,0.027875535,0.028303131,0.058962464,0.0,0.0,0.06709072,0.0595342,0.08339191,0.0,0.01847376,0.0,0.0,0.0,0.0026457012,0.0,0.0,0.0,0.0,0.0,0.035050057,0.013399608,0.025632776,0.0,0.0,0.010246761,0.06430168,0.04356479,0.029417984,0.0351604,0.019277975,0.06342863,0.0,0.002510786,0.079807654,0.0858266,0.08694586,0.0,0.012256734,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04606589,0.013679042,0.037611395,0.005964346,0.0,0.027591586,0.082326114,0.046521857,0.023536958,0.026492216,0.00072820485,0.051639304,0.0,0.0,0.06406807,0.07659223,0.07171473,0.0,0.0,0.0,0.0,0.0,0.0,0.0015606731,0.0,0.0,0.0,0.0,0.04465664,0.0056440383,0.03856568,0.012220591,0.0,0.041286252,0.10201954,0.051736735,0.019240968,0.004980862,0.0,0.040585853,0.0,0.0,0.035681844,0.06216205,0.06402029,0.0,0.00317882,0.0,0.0,0.0,0.0,0.008266427,0.0,0.0,0.0,0.0,0.049248196,0.0006161481,0.05094157,0.012509987,0.0,0.050500944,0.10073899,0.042052574,0.016643368,0.0,0.0,0.026308805,0.0,0.0,0.025104694,0.050865844,0.043042123,0.0,0.01480417,0.0,0.0,0.0,0.0,0.0075148866,0.0,0.0,0.0,0.0,0.04084023,0.00400351,0.08796007,0.02400335,0.0,0.05259771,0.08208348,0.030064017,0.014546357,0.0,0.0,0.013442278,0.0,0.0,0.043385968,0.04914497,0.012456752,0.0025209486,0.024573259,0.0,0.0,0.0,0.0,0.0077149346,0.0,0.0,0.0,0.0,0.03988512,0.015549913,0.1357218,0.029971793,0.0,0.03840421,0.056375958,0.00019617379,0.009104885,0.0,0.0,0.0,0.0,0.0,0.029297285,0.037563674,0.0,0.0146601945,0.042563044,0.0,0.0,0.0,0.0,0.01111871,0.0,0.0,0.0,0.0,0.010264985,0.0,0.13479434,0.0,0.0,0.04191217,0.06587905,0.0,0.012188211,0.0,0.0,0.0,0.0,0.0,0.0,0.025132403,0.0,0.028070077,0.07729211,0.0,0.016218327,0.0,0.0,0.0063465014,0.0,0.0,0.0,0.0,0.0,0.0,0.107780814,0.0,0.0,0.046004377,0.0743957,0.0,0.001955241,0.0,0.0,0.0,0.0,0.0,0.0,0.024076246,0.0,0.038009457,0.10224189,0.025262833,0.038603663,0.0,0.0,0.008254498,0.0,0.0,0.0,0.0,0.0,0.0,0.09419513,0.0,0.0,0.048860602,0.08447859,0.0,0.0024175048,0.0,0.0,0.0,0.0,0.0,0.0,0.02897548,0.0,0.036019422,0.10068383,0.020339958,0.04196292,0.0],[0.02081941,0.005466372,0.008088343,0.03669881,0.028661527,0.06952913,0.016893834,0.0,0.0869854,0.0,0.0,0.052615747,0.040297642,0.0,0.0,0.0,0.10134484,0.0,0.008329831,0.069276184,0.16267584,0.13044775,0.08493695,0.052560486,0.024536483,0.0,0.0,0.0,0.020267941,0.0,0.0,0.006257169,0.0,0.081712544,0.04899762,0.025283568,0.12708773,0.0,0.0,0.06669717,0.058574617,0.0,0.0,0.0,0.10192943,0.008326635,0.007244058,0.07845864,0.1511021,0.1457407,0.05173847,0.031434864,0.013291933,0.0,0.0067295656,0.0,0.024768904,0.0,0.0,0.00858973,0.0,0.07993543,0.073724784,0.04907863,0.14948039,0.008527972,0.0,0.07067785,0.07086016,0.0,0.0,0.0,0.090136215,0.023041181,0.0110547915,0.0932015,0.15917781,0.16129446,0.05006907,0.018711753,0.01841569,0.0,0.022626996,0.0,0.011398017,0.0,0.0,0.017137162,0.0,0.07757868,0.09326236,0.065601595,0.17056319,0.044370383,0.021719284,0.06592871,0.08304327,0.0,0.0,0.0,0.07203131,0.031663425,0.010083556,0.090283535,0.13960956,0.14860475,0.044936568,0.0,0.017126873,0.0,0.04323925,0.0,0.0,0.0,0.0,0.016142957,0.0,0.08542585,0.081217304,0.06878857,0.16684122,0.039320767,0.0234342,0.060170367,0.09802993,0.0,0.0,0.0,0.06317117,0.031230003,0.0,0.078581475,0.11359676,0.14773394,0.05608373,0.0,0.023814216,0.0,0.04933559,0.0,0.0,0.0,0.0,0.012933716,0.0,0.08793005,0.07465997,0.08325808,0.15851808,0.02461557,0.021010183,0.04586473,0.110347815,0.0052169263,0.0,0.0,0.054163083,0.0010568053,0.0,0.07980946,0.09255594,0.13914473,0.0542439,0.0,0.039081924,0.0,0.049629822,0.0,0.0,0.0,0.0,0.0014502853,0.0,0.05999632,0.05463586,0.10414478,0.1756466,0.014109127,0.007087715,0.039041467,0.12447861,0.029581375,0.009866253,0.0,0.058382906,0.0007971674,0.0,0.082720846,0.10803571,0.12616016,0.047999352,0.0031081736,0.0646521,0.0,0.05627513,0.0,0.0,0.0,0.0,0.0,0.0,0.026425518,0.051563114,0.115867406,0.20077863,0.0024604946,0.0,0.0294163,0.1462003,0.032761052,0.014503367,0.0,0.04298798,0.0,0.0,0.049164675,0.09427148,0.11879735,0.041121066,0.008620538,0.09446041,0.0,0.06609682,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034548245,0.1100563,0.19522002,0.0,0.0067063347,0.03647691,0.15272596,0.029113725,0.007013373,0.0,0.013521455,0.0,0.0,0.004571438,0.066225454,0.09424603,0.030662276,0.017405182,0.13073777,0.028851911,0.09227282,0.016275994,0.0,0.0,0.0,0.0,0.0,0.0,0.013997197,0.09855692,0.18996945,0.0,0.03622754,0.0537081,0.15145294,0.017280996,0.0,0.0,0.0,0.0,0.0,0.0,0.051737808,0.07813465,0.027212761,0.019589424,0.16044849,0.057439156,0.11376339,0.035593703,0.0,0.0,0.0,0.0,0.0,0.0,0.014980108,0.10111795,0.18245599,0.0,0.03332278,0.06525562,0.1569044,0.019519389,0.0,0.0,0.0,0.0,0.0,0.0,0.05439157,0.081122935,0.026469953,0.017238751,0.17425375,0.062797874,0.12541632,0.042624995],[0.0,0.051926762,0.059662543,0.022616498,0.03940645,0.06313949,0.0825599,0.027598597,0.02288191,0.06630096,0.028347634,0.06606211,0.0051992834,0.011429533,0.0,0.0,0.0,0.008925326,0.038302578,0.058268756,0.2944724,0.28641832,0.16806644,0.022319794,0.028990343,0.0,0.0,0.0076092854,0.0,0.03731642,0.036366902,0.0,0.01516436,0.06257083,0.103829876,0.0682424,0.043479055,0.056131333,0.028975613,0.09750044,0.041316263,0.050644144,0.014081642,0.0,0.012931794,0.0,0.01797796,0.035283275,0.27418917,0.25619143,0.13817716,0.026226036,0.0498539,0.0,0.0,0.00018265843,0.0,0.05537013,0.052806698,0.0088801235,0.011201754,0.0678938,0.11418246,0.08821575,0.062252536,0.069859385,0.038345344,0.11448102,0.06259211,0.056278437,0.011190496,0.0,0.0,0.0,0.012683846,0.049577057,0.29303706,0.26620805,0.14591098,0.031941652,0.06413886,0.0,0.0,0.0,0.0,0.054207005,0.054831766,0.012503423,0.012835629,0.06963436,0.12552243,0.10491298,0.08566944,0.09399314,0.04774367,0.10729724,0.06277496,0.049045846,0.0077650473,0.0,0.0,0.0,0.0009255409,0.05270318,0.29857787,0.2694179,0.15868284,0.02912923,0.06997469,0.0,0.0,0.0,0.0,0.0383661,0.0387197,0.0032529235,0.012119465,0.06847036,0.12182145,0.096388385,0.07324819,0.09244219,0.049987108,0.09349682,0.05729948,0.038255133,0.012433767,0.0,0.0,0.0,0.0,0.046364248,0.28272796,0.25383902,0.15630834,0.0072290003,0.04870791,0.0,0.0,0.0,0.0,0.02338785,0.015857466,0.0,0.013584323,0.07693397,0.13378432,0.10086472,0.068503916,0.085866876,0.057975143,0.06565183,0.047474213,0.03304924,0.037448466,0.016299851,0.0,0.0,0.0,0.08750916,0.27820176,0.20867154,0.109564155,0.0,0.023758553,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009494357,0.062955484,0.1351237,0.10347388,0.07855176,0.08526265,0.076051295,0.040685885,0.053702287,0.038890325,0.07059006,0.054024518,0.0058066994,0.0,0.0,0.12447948,0.26402545,0.16009021,0.039647743,0.0,0.01830218,0.010896914,0.0,0.0,0.0,0.0,0.0,0.0,0.0057522357,0.051455952,0.13334201,0.11283841,0.10684182,0.1185376,0.105396576,0.026259936,0.07164051,0.056219287,0.08664849,0.08201103,0.029472843,0.0,0.0,0.10665232,0.21618485,0.12914023,0.01213222,0.0,0.031506814,0.0067069754,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028454587,0.12588616,0.12311961,0.13607351,0.15307522,0.14724874,0.022847906,0.08051901,0.054030485,0.06571315,0.087155625,0.025779404,0.0,0.0,0.093227796,0.18380356,0.09340695,0.000054761767,0.0,0.056649543,0.025071606,0.0,0.0,0.0,0.0,0.0,0.0,0.0070671067,0.015475117,0.10899234,0.12862082,0.16119304,0.18510804,0.18986225,0.039275505,0.093172364,0.06402476,0.047612466,0.083945066,0.0,0.0,0.0,0.09792282,0.17136973,0.06942302,0.0,0.0,0.07866052,0.0359521,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.003876537,0.109567404,0.14229426,0.17067796,0.19386369,0.20052102,0.040934563,0.09160274,0.06528477,0.04362809,0.07780881,0.0,0.0,0.0,0.09794469,0.17408292,0.057456948,0.0,0.0,0.09366621,0.03489553,0.0,0.0],[0.0,0.016995624,0.020011611,0.0,0.000105306506,0.0045429766,0.0,0.0068125576,0.0,0.057451956,0.035569765,0.0,0.0,0.020719372,0.016270816,0.07910652,0.14678843,0.40149516,0.3182606,0.4205557,0.5215873,0.5482574,0.41014367,0.112227224,0.039135,0.016132124,0.03614167,0.0,0.0,0.0040247887,0.0,0.0,0.0,0.0015555769,0.0,0.030899353,0.0,0.062895894,0.042664252,0.0,0.0,0.0,0.0,0.056147292,0.039999418,0.31082138,0.24506372,0.39260292,0.5378321,0.5136956,0.39596593,0.118467934,0.051397733,0.014779821,0.028723754,0.0,0.0,0.02300018,0.0,0.0,0.0,0.017126985,0.0,0.048806727,0.0,0.07440908,0.049710587,0.00048145652,0.0,0.0,0.0,0.035693996,0.0061477423,0.24410656,0.22404851,0.36911386,0.55632013,0.51052547,0.38345855,0.13056278,0.053690977,0.017677948,0.027033858,0.0,0.010927565,0.0280146,0.0,0.0,0.0,0.034058668,0.004688978,0.067008555,0.025138192,0.08582468,0.053939722,0.011994615,0.0,0.0,0.0,0.01654213,0.0,0.18190281,0.19961607,0.32714945,0.54750395,0.5016167,0.37565032,0.13514178,0.043162815,0.024533622,0.01765424,0.0,0.019859888,0.021990687,0.0,0.0,0.0,0.04636962,0.013208427,0.04703074,0.024080873,0.08173345,0.051895857,0.011174731,0.0,0.0008535534,0.0019031614,0.0077048093,0.0,0.11671521,0.18258786,0.2892046,0.5132932,0.4538114,0.33891642,0.1012241,0.022134453,0.034000874,0.007947974,0.0,0.028965928,0.013543725,0.0,0.0,0.01365643,0.071857795,0.034152873,0.035266355,0.035669602,0.08908362,0.058309764,0.010835119,0.0,0.023023948,0.02338767,0.019250333,0.009987615,0.079482615,0.17383683,0.3269644,0.48380637,0.3663715,0.26832563,0.043182224,0.000860855,0.051062033,0.0,0.0,0.037041888,0.0,0.0,0.0,0.035341427,0.07637692,0.03421051,0.017562926,0.047443584,0.104114056,0.07330006,0.024295159,0.0,0.04173594,0.040594503,0.051174693,0.06023842,0.06919085,0.16447073,0.34775358,0.459898,0.2756402,0.19273695,0.0,0.0,0.034556136,0.0,0.0,0.040825106,0.0,0.0,0.0,0.06066224,0.07431746,0.034396887,0.024331167,0.076877445,0.14144476,0.09749773,0.043234207,0.0,0.04481805,0.059107147,0.1269802,0.13832432,0.09008315,0.13133074,0.31257236,0.43908292,0.22649705,0.18450285,0.016628996,0.010167435,0.0009792,0.0,0.0,0.042553224,0.010091424,0.0,0.0,0.06910283,0.09563173,0.06273901,0.037947595,0.11753744,0.1938,0.13804364,0.06788734,0.0,0.05481311,0.06455754,0.20661715,0.20038983,0.1196477,0.11326735,0.27395117,0.39551127,0.15762523,0.13519567,0.06273979,0.07464279,0.025434159,0.0,0.0,0.033619918,0.029829636,0.0,0.0114004165,0.078020446,0.12650207,0.102427326,0.056468666,0.1714683,0.22747287,0.17603076,0.10857853,0.0,0.083916664,0.07077187,0.23650134,0.22532472,0.1285931,0.11920573,0.258083,0.3765943,0.10863025,0.09310803,0.10981261,0.1354076,0.05887931,0.0,0.0,0.031656586,0.03624752,0.0,0.0,0.05891496,0.13337664,0.111207135,0.06870511,0.19992575,0.24512777,0.19736443,0.12076629,0.0,0.10122578,0.08381961,0.24482533,0.24115643,0.112910256,0.08955893,0.23870483,0.36326966,0.09625604,0.08727307,0.13054667,0.16550125,0.06516311,0.0,0.0],[0.0,0.05587008,0.007109493,0.0116021335,0.024160959,0.000059098005,0.015958034,0.0,0.0,0.0,0.040371396,0.08603391,0.07193108,0.14183633,0.32365865,0.5204781,0.7586126,0.9940182,1.0,1.0,1.0,1.0,0.7021837,0.34728116,0.15695971,0.032983206,0.013170816,0.01166825,0.0,0.0401207,0.0,0.0,0.033976294,0.0,0.023954973,0.0,0.0,0.0,0.07065231,0.052509755,0.026210554,0.04527702,0.18523487,0.37360883,0.6528428,0.8867153,0.9134631,1.0,1.0,1.0,0.69289637,0.3444084,0.15052141,0.015840665,0.0027366132,0.009764738,0.0,0.042550996,0.0,0.0,0.024268948,0.0,0.00818108,0.0,0.0,0.0,0.08696622,0.098883584,0.061841004,0.06063897,0.103630304,0.26805305,0.552442,0.78017396,0.7935887,0.9539008,1.0,0.99190587,0.6783612,0.33881438,0.14069673,0.010260962,0.0065021887,0.012242444,0.0,0.037260383,0.0020955652,0.0,0.017598428,0.0,0.0,0.0,0.0,0.013548255,0.094944835,0.13281323,0.09114976,0.06698691,0.032133684,0.1799286,0.4597448,0.66690445,0.6587824,0.8434871,1.0,0.9591814,0.66153234,0.3257048,0.12937701,0.005560294,0.0045164526,0.013779044,0.0,0.020525612,0.00074635446,0.0,0.028124727,0.0,0.0,0.0,0.0,0.028077282,0.10448975,0.16258138,0.123292886,0.07363926,0.0,0.09351008,0.36489487,0.5678687,0.5932448,0.79664487,0.97196573,0.8916295,0.60810965,0.2869131,0.11072078,0.0035603344,0.004715562,0.01646597,0.0,0.007969268,0.0,0.0,0.0398285,0.0,0.0,0.0,0.000071287155,0.03778162,0.12904647,0.19635695,0.1635466,0.09627804,0.0,0.036911994,0.2860304,0.51046985,0.66204566,0.88712066,0.9454408,0.7701832,0.5174195,0.20371592,0.07349918,0.0,0.0,0.017263614,0.0,0.0,0.0,0.0,0.053534076,0.0,0.0,0.0,0.019556776,0.040518664,0.14070992,0.22578248,0.21856257,0.15118384,0.019194767,0.05976606,0.25051403,0.46624196,0.7680017,0.9976204,0.94948995,0.65033156,0.43750542,0.11476238,0.048389457,0.0,0.0,0.0051127523,0.0,0.0,0.0,0.0,0.07593688,0.0,0.012593359,0.0,0.023383103,0.039886154,0.13981447,0.23718067,0.25904006,0.18068866,0.09426392,0.12215909,0.2780729,0.45131767,0.8387666,1.0,0.92749023,0.54699546,0.39597332,0.08483356,0.058467485,0.0,0.0,0.0,0.0,0.0,0.0,0.026749484,0.12932354,0.007057622,0.059908427,0.0,0.062590525,0.0724962,0.15968911,0.24279785,0.29806867,0.2224831,0.18249002,0.18852964,0.32072031,0.43539673,0.8496245,1.0,0.801614,0.35901287,0.32627124,0.08605647,0.10150492,0.0,0.0,0.0,0.0053321123,0.02095779,0.044135235,0.116867706,0.20800264,0.090971634,0.108878106,0.0,0.11602115,0.1070466,0.18795809,0.2581366,0.33981442,0.2539054,0.22541836,0.1939623,0.31405094,0.40202278,0.8425445,1.0,0.6736607,0.18775718,0.26517373,0.076458946,0.13146989,0.0,0.0,0.0,0.009321094,0.02279313,0.05232638,0.12969384,0.22314677,0.10555838,0.11400333,0.0,0.14026685,0.13173272,0.21274722,0.2846219,0.3725472,0.26763272,0.25439394,0.19476968,0.33336067,0.4034937,0.8421899,0.99460083,0.6638698,0.17728673,0.270212,0.09338862,0.14924094,0.0,0.0,0.0],[0.0026284754,0.029000059,0.034212217,0.014364123,0.0,0.014425024,0.08966828,0.0,0.0,0.0,0.10053475,0.15617369,0.18627015,0.4520489,0.64864,0.76491016,1.0,1.0,1.0,1.0,1.0,1.0,0.8420015,0.4329363,0.2551824,0.032998852,0.0,0.017705403,0.0,0.0,0.0003543049,0.012310967,0.0,0.0,0.13872826,0.0,0.014381506,0.0,0.10730885,0.089980856,0.097963005,0.33587041,0.49493593,0.61684006,1.0,1.0,1.0,1.0,1.0,1.0,0.84933424,0.4419887,0.27665797,0.03153743,0.0,0.040032953,0.002730593,0.0,0.0,0.008176051,0.0,0.0,0.14028536,0.0,0.049322434,0.007161416,0.10617213,0.115308374,0.090782404,0.26386338,0.36949402,0.4785033,0.8778009,1.0,1.0,1.0,1.0,1.0,0.82124364,0.41977102,0.2614526,0.034089617,0.0,0.05131556,0.0023217797,0.0,0.0,0.009636529,0.0,0.0,0.12807125,0.01053641,0.08284892,0.022780307,0.09508008,0.1519666,0.08826764,0.18621229,0.25748128,0.36418617,0.73867714,0.9916846,0.9486952,1.0,1.0,1.0,0.80249983,0.40452474,0.24916539,0.031270787,0.004169062,0.05444807,0.0,0.0,0.0,0.022382595,0.0,0.0,0.09778148,0.031083621,0.09787643,0.03469023,0.08662851,0.19438875,0.097615264,0.11825581,0.14911252,0.23723304,0.58571476,0.90072054,0.8918221,1.0,1.0,1.0,0.7559535,0.38670594,0.24799398,0.029611245,0.0018969029,0.054610156,0.0,0.0,0.0,0.037540242,0.0,0.0,0.06485342,0.044160157,0.09428937,0.046522126,0.088183686,0.23018047,0.12651804,0.102234825,0.09082854,0.14358202,0.43102032,0.8315337,0.9479642,1.0,0.9263365,0.8931301,0.6593189,0.34004453,0.23347405,0.014271565,0.0,0.04492026,0.0,0.0,0.0,0.047508024,0.0,0.0,0.04171668,0.06411375,0.092165604,0.06730088,0.09370645,0.2594154,0.17029858,0.14314824,0.09576397,0.10148309,0.3080338,0.8258076,1.0,1.0,0.8309675,0.7022324,0.50240856,0.2843134,0.2127802,0.0,0.0,0.028989948,0.0,0.0,0.0,0.0863572,0.012749143,0.0,0.034356922,0.050225243,0.07792339,0.09138507,0.073577404,0.26280716,0.19805154,0.18527514,0.12800524,0.085926816,0.22309381,0.82940173,1.0,1.0,0.7490997,0.5301566,0.38478965,0.25440386,0.21130913,0.0,0.0,0.00741861,0.0,0.0,0.018418558,0.14298417,0.06913621,0.0,0.05512041,0.06965785,0.1041108,0.15219814,0.079662114,0.22970748,0.19594681,0.23473859,0.16036871,0.05289398,0.163167,0.8209458,1.0,1.0,0.5615249,0.32215124,0.29741007,0.26294923,0.2480208,0.032141253,0.0,0.0,0.017022729,0.0,0.10871141,0.23280078,0.16468453,0.023488723,0.090635315,0.09793556,0.15052448,0.2133328,0.11480996,0.22024758,0.20544499,0.25565857,0.16221389,0.0,0.09139506,0.8141478,1.0,1.0,0.38177425,0.1518124,0.23456371,0.25958115,0.27046633,0.067499004,0.0,0.0,0.029281303,0.0,0.14367715,0.2646671,0.18720077,0.031463027,0.09479499,0.11164862,0.17755637,0.2521991,0.16024151,0.26622605,0.24056056,0.2890698,0.16626996,0.0,0.079980835,0.82998997,1.0,1.0,0.35294688,0.14813323,0.25724593,0.29720455,0.27769285,0.080375955,0.0,0.0],[0.0,0.025457956,0.031080388,0.0034065992,0.0,0.0466313,0.0013973713,0.0,0.0066931844,0.08618471,0.16675779,0.2739821,0.46292365,0.6847208,0.7896913,0.76973855,0.89127827,0.8818865,0.8967331,0.91393405,1.0,1.0,0.8528534,0.33612835,0.04219663,0.010757327,0.06531068,0.0,0.0,0.024042606,0.0108174905,0.0,0.0019686073,0.04677674,0.031840876,0.019549705,0.058706462,0.08460641,0.12138449,0.21180946,0.37847584,0.5890251,0.64963996,0.7455435,0.9854558,0.9931635,0.91145706,0.84556395,1.0,1.0,0.8393852,0.37809974,0.07953568,0.025832035,0.083330534,0.0032081455,0.0,0.025975592,0.005286783,0.0,0.020964526,0.045351513,0.040170886,0.034430273,0.073428586,0.073960155,0.105669506,0.1726529,0.3136406,0.45659608,0.47929525,0.6239826,0.9290366,0.96639377,0.8778838,0.8302848,1.0,1.0,0.79857975,0.37677428,0.085991874,0.039768316,0.104089126,0.012264311,0.0,0.02208624,0.0,0.0,0.03045699,0.035345778,0.045746535,0.047768116,0.08145042,0.059302457,0.1011296,0.13615632,0.24556956,0.32130992,0.32205474,0.50288147,0.86473954,0.9140564,0.84174484,0.8305856,0.9971219,0.9787968,0.78109366,0.38985968,0.09794419,0.05484353,0.1274952,0.024843305,0.0,0.007251762,0.0,0.0,0.037639767,0.036767066,0.06450451,0.08848085,0.107702136,0.094673306,0.1396757,0.13539475,0.2323297,0.20912325,0.16718474,0.36573583,0.7801104,0.8999834,0.8750295,0.8698106,0.9298416,0.88187546,0.7025546,0.39215684,0.11987853,0.07801748,0.13112931,0.026583202,0.0,0.0,0.0,0.0,0.04198944,0.043754406,0.10071942,0.14210223,0.13403319,0.108961076,0.16269636,0.15738922,0.2581398,0.14691305,0.034020133,0.22167437,0.6752266,0.9780526,1.0,0.94618493,0.7846068,0.6829345,0.52890337,0.3384182,0.12536852,0.07818265,0.09685607,0.003542319,0.0,0.0,0.0,0.0,0.04415641,0.04333912,0.12521367,0.18400508,0.15251398,0.10422701,0.1573606,0.19618566,0.32635278,0.14950185,0.0,0.06387422,0.5742204,1.0,1.0,1.0,0.6397141,0.45242566,0.33684108,0.23991978,0.114871785,0.056084782,0.038503215,0.0,0.0,0.0,0.014470845,0.025386676,0.10566722,0.03305181,0.11266128,0.16054352,0.13488062,0.1087124,0.15986502,0.24113469,0.37273848,0.15604162,0.0,0.0,0.47474194,1.0,1.0,1.0,0.47760832,0.2270378,0.19624469,0.19925986,0.13978572,0.038780965,0.0,0.0,0.0,0.04254192,0.08465974,0.09739253,0.18436348,0.044674926,0.108869776,0.14676411,0.15929814,0.14456892,0.1632562,0.23616275,0.35671157,0.14797677,0.0,0.0,0.4190712,1.0,1.0,0.93869096,0.2539441,0.104858056,0.18230683,0.23466001,0.20410323,0.04899455,0.0,0.0,0.0035060942,0.12912714,0.21621199,0.22713272,0.282435,0.08513658,0.11765924,0.15762009,0.20771056,0.19816242,0.17920049,0.22958839,0.34533566,0.13687943,0.0,0.0,0.42861503,1.0,1.0,0.7172636,0.053691283,0.055713356,0.2108493,0.28392094,0.26418793,0.055664465,0.0,0.0,0.01891797,0.16683283,0.27025986,0.29518557,0.334315,0.09701645,0.118882366,0.17317656,0.24650161,0.23930627,0.22412905,0.26384968,0.3809576,0.1674359,0.0,0.0,0.4622113,1.0,1.0,0.6906071,0.03774701,0.08370979,0.23645374,0.32489276,0.2952726,0.0709489,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.035232246,0.0,0.0,0.0,0.13810596,0.26634052,0.41609418,0.69062394,0.8734388,0.77210575,0.5719272,0.525736,0.48928434,0.6740886,0.83620894,0.9345434,0.8197729,0.57991457,0.26234937,0.0,0.005603552,0.0,0.0,0.0,0.016989,0.0,0.0,0.0,0.06395319,0.013705954,0.025976889,0.05270481,0.13850619,0.25122795,0.36092353,0.68472993,0.8077946,0.75481373,0.6448187,0.7107705,0.6505993,0.6969823,0.786296,0.8903214,0.80693483,0.59730977,0.3098883,0.0,0.033214457,0.0,0.0,0.0,0.027020454,0.008366808,0.0,0.0,0.05778996,0.019202583,0.040775873,0.060275592,0.11800668,0.21742892,0.2661568,0.5513409,0.64301133,0.58064723,0.5941177,0.73984075,0.69540685,0.71603614,0.79474413,0.8561628,0.8025183,0.61074096,0.32072487,0.0,0.0547169,0.0,0.0,0.005832359,0.026608832,0.025224194,0.0,0.0,0.050384127,0.021101825,0.049412444,0.059962697,0.09905049,0.19049644,0.15983774,0.39819604,0.4638576,0.41986746,0.56594074,0.77631676,0.710988,0.72410816,0.8126705,0.8394475,0.81139207,0.62515426,0.32883283,0.0056281537,0.076955125,0.0062872916,0.0009444654,0.018296205,0.022365361,0.033733703,0.0,0.0072616786,0.056956895,0.037474893,0.08260044,0.107729964,0.15504642,0.2243818,0.10791447,0.29852605,0.3281676,0.2746756,0.49944502,0.78477657,0.74603665,0.7806502,0.82689494,0.76546323,0.71688807,0.5580046,0.31237942,0.0056657344,0.08701496,0.015277691,0.01000651,0.026606984,0.028615601,0.04689022,0.0,0.03576605,0.09049839,0.08862846,0.13853706,0.15382764,0.18075706,0.21721339,0.079033956,0.23307735,0.20837569,0.1555407,0.4154215,0.80637646,0.8737424,0.93880063,0.8427494,0.61791503,0.5147142,0.38421392,0.22579056,0.0,0.07185301,0.0,0.0019091666,0.03314536,0.040070258,0.05575881,0.025991097,0.06540578,0.12340025,0.10987974,0.1799823,0.21265763,0.18047348,0.19400018,0.08560225,0.16772383,0.10922031,0.04049182,0.29616427,0.78928554,0.95381093,1.0,0.8272361,0.40625393,0.2848991,0.1777273,0.10031775,0.0,0.03791692,0.0,0.0,0.029802144,0.06558678,0.08083065,0.10971449,0.13962588,0.12790032,0.080342785,0.16705456,0.24185213,0.17289075,0.16668603,0.0893407,0.08565269,0.0047614574,0.0,0.20709048,0.7030164,0.9587811,1.0,0.7577204,0.1783179,0.07100266,0.05433785,0.064522214,0.0046904087,0.010830104,0.0,0.0029717237,0.03127539,0.10096039,0.11762523,0.19412196,0.22959633,0.15512127,0.054735593,0.16644186,0.28429163,0.16689005,0.11821497,0.048953503,0.0,0.0,0.0,0.16119719,0.6382823,0.92162067,1.0,0.56220967,0.0,0.0357335,0.0810363,0.071609534,0.058858953,0.0,0.0,0.012349501,0.04735806,0.15861253,0.21589127,0.31767595,0.34415597,0.21430783,0.043473646,0.18183921,0.34577483,0.17767125,0.092011034,0.024031565,0.0,0.0,0.0,0.13493647,0.63933706,0.8890325,0.832765,0.3178636,0.0,0.07903876,0.15566218,0.08566359,0.11232434,0.0,0.0,0.023773387,0.059167303,0.1905104,0.26386708,0.3844524,0.3947063,0.22315009,0.028912373,0.19809884,0.3848974,0.20726791,0.13012254,0.04168663,0.0,0.0,0.0,0.13445286,0.6651457,0.9011305,0.80373013,0.28025562,0.0,0.108909525,0.1828784,0.08938773,0.11952457,0.0,0.0,0.021473162],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026340425,0.12136,0.20937046,0.46841586,0.73934656,0.9667515,0.8146943,0.68582284,0.39149117,0.36474213,0.29460797,0.4672597,0.5388218,0.6163175,0.67655814,0.45731634,0.19135147,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04692167,0.14741457,0.18436863,0.39926904,0.6650694,0.9105555,0.8370638,0.7081308,0.5220614,0.48947155,0.39241803,0.5429165,0.5687562,0.61638886,0.6502543,0.45043492,0.16750056,0.0,0.0,0.0,0.0,0.0,0.00035731494,0.0,0.0,0.0,0.0,0.0,0.050934285,0.14397013,0.1390335,0.2969976,0.426233,0.649543,0.63876796,0.59024173,0.54423946,0.6006253,0.5053183,0.64162445,0.6058445,0.58769155,0.57635313,0.41338283,0.12871948,0.0,0.0,0.0,0.0,0.0060352236,0.012009673,0.0,0.0,0.0,0.012469642,0.0,0.07106511,0.17190996,0.12771215,0.19860485,0.17290433,0.3597052,0.4118032,0.49673063,0.55343604,0.7185848,0.6298978,0.7644372,0.6824706,0.5741382,0.5124438,0.3881145,0.118337125,0.0,0.0,0.0,0.0,0.012043551,0.022379234,0.0,0.009359799,0.017533265,0.06368827,0.02897793,0.13185841,0.23010182,0.16299629,0.20334095,0.12949361,0.22641128,0.2509521,0.36164564,0.55077374,0.8084547,0.7700451,0.89675426,0.75080866,0.51292825,0.41064858,0.31867957,0.09886263,0.0,0.0,0.0,0.0,0.024604931,0.039876267,0.0,0.052075148,0.072171375,0.13765496,0.10047977,0.19212152,0.2716525,0.18904391,0.20747598,0.13306354,0.14125839,0.12343559,0.18296915,0.51194775,0.88138556,0.91243875,1.0,0.7767947,0.41488218,0.24793153,0.16658512,0.0038647205,0.0,0.0,0.0,0.0,0.026803233,0.064307325,0.008511461,0.10907858,0.1225205,0.17379907,0.13994397,0.21824768,0.287719,0.20105165,0.20523053,0.14013445,0.07965715,0.042040378,0.008156724,0.463973,0.94333357,1.0,1.0,0.7713826,0.30746242,0.080991894,0.014189385,0.0,0.0,0.0,0.0,0.0,0.030041896,0.09249477,0.09024575,0.18165879,0.19236928,0.19726248,0.15285322,0.21191943,0.2906946,0.21262434,0.19076876,0.16415618,0.0042183846,0.0,0.0,0.39931357,0.906426,1.0,1.0,0.66169465,0.1544343,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034471363,0.12055052,0.17074233,0.25003433,0.28610492,0.23866764,0.15553188,0.19379959,0.30001968,0.22449431,0.15044361,0.16118984,0.0,0.0,0.0,0.353662,0.8635098,0.97465074,0.90018725,0.47628278,0.028285436,0.0,0.0,0.0025518388,0.0,0.0,0.0,0.0,0.04371479,0.15923263,0.28176194,0.35437292,0.3990804,0.277203,0.15775248,0.17306682,0.3080675,0.22955067,0.09937079,0.16950223,0.0,0.0,0.0,0.3124392,0.8454132,0.880635,0.6261571,0.24494126,0.0,0.0,0.0,0.104645334,0.07444076,0.0,0.0,0.0,0.0489394,0.18606949,0.34689772,0.42577875,0.45596755,0.28652245,0.14881289,0.16705425,0.31810808,0.2555059,0.12211403,0.20446497,0.0,0.0,0.0,0.31648934,0.84889835,0.89440113,0.6010226,0.22626702,0.0,0.0,0.0,0.118132256,0.07646006,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.055119008,0.18928218,0.45754367,0.6804869,1.0,0.9936019,0.8547307,0.65084386,0.32531133,0.3978117,0.4132957,0.37129563,0.4866985,0.64454615,0.682977,0.54573256,0.16252166,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011704341,0.069188744,0.19750819,0.4312141,0.6155191,0.91191894,1.0,0.88827705,0.66019183,0.36349463,0.43018895,0.39011604,0.44671506,0.608913,0.70389396,0.6530768,0.5008204,0.09834054,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017912053,0.0,0.03391415,0.09165749,0.18303049,0.3440165,0.45200175,0.613677,0.7956855,0.75295097,0.6048995,0.4315378,0.5524724,0.51139545,0.5795445,0.6232827,0.66541153,0.58362234,0.3797019,0.016550973,0.0,0.0,0.0,0.0,0.0025385767,0.0005633235,0.0,0.0,0.056174375,0.010308638,0.057236947,0.12868208,0.18481016,0.2818244,0.2797289,0.28848523,0.5565837,0.64592093,0.5873862,0.49239957,0.6774658,0.649921,0.74354666,0.6784986,0.6228723,0.504928,0.304632,0.0,0.0,0.0,0.0,0.0,0.0097458735,0.020873718,0.036636174,0.0352154,0.100156315,0.047650307,0.06939301,0.1642756,0.1725095,0.2555659,0.18200122,0.13931644,0.37619597,0.4647975,0.49753422,0.5554707,0.804854,0.80027616,0.90863574,0.739486,0.54513973,0.40553945,0.24451682,0.0,0.0,0.0,0.0,0.0,0.018903993,0.043406986,0.07973197,0.0866075,0.14344102,0.1021031,0.10427107,0.19481619,0.15423998,0.22589985,0.08564475,0.020805053,0.20762065,0.24819736,0.35254747,0.5824696,0.9199249,0.93520904,1.0,0.7083809,0.4072597,0.26825446,0.143429,0.0,0.0,0.0,0.0,0.0,0.013322644,0.048078053,0.10396563,0.1369208,0.15559243,0.13366248,0.10623455,0.16652021,0.122499645,0.22429837,0.039693415,0.0,0.07924605,0.05101584,0.20427674,0.60700965,1.0,1.0,1.0,0.62907785,0.25151426,0.12695898,0.033246033,0.0,0.0,0.003242612,0.0,0.0,0.009471975,0.07839812,0.1737724,0.17557248,0.17185941,0.16763045,0.09972736,0.12608916,0.084124744,0.18421397,0.0022335947,0.0,0.0,0.0,0.10434239,0.5816528,1.0,1.0,1.0,0.45566738,0.037628584,0.0,0.0,0.0,0.0033819675,0.028492115,0.0,0.0,0.0,0.10609597,0.2372584,0.20254704,0.21504328,0.20857625,0.10467947,0.11128311,0.0799987,0.12922901,0.0,0.0,0.0,0.0,0.057783782,0.5715906,1.0,1.0,0.9116817,0.3042689,0.0,0.0,0.0,0.0,0.05801115,0.06859331,0.0,0.0052020997,0.0,0.12569132,0.30616483,0.2694537,0.2877562,0.25279146,0.11309813,0.10506568,0.07078765,0.0604148,0.0,0.0,0.0,0.0,0.025778495,0.56728905,1.0,1.0,0.7230395,0.134826,0.0,0.0,0.009559631,0.07007989,0.1272944,0.12337461,0.027077898,0.01778806,0.0,0.13790913,0.351165,0.3249566,0.31387043,0.26370275,0.10596476,0.085023835,0.05546605,0.05918347,0.0,0.0,0.0,0.0,0.0002310425,0.5714046,1.0,1.0,0.7255418,0.117873624,0.031342007,0.0,0.0008892268,0.06777231,0.12042811,0.10927193,0.026498534,0.0066946],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10725068,0.40863204,0.7567985,0.9187493,0.9822358,1.0,0.9333312,0.696785,0.48922586,0.70298046,0.7016269,0.6507484,0.58304703,0.6986002,0.65161675,0.45763248,0.0893804,0.0,0.020554237,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12527825,0.4312076,0.68036765,0.8099504,0.87690794,1.0,0.92012596,0.6839153,0.4169653,0.636452,0.71132535,0.7573808,0.7263932,0.7262812,0.581332,0.38098025,0.048117265,0.0,0.046009533,0.022215337,0.007849105,0.0,0.0,0.0,0.0,0.0,0.009476282,0.0,0.13085468,0.3753487,0.50561565,0.6022134,0.6448539,0.8674436,0.8389026,0.65068835,0.42861092,0.6946812,0.7804803,0.81821597,0.6892241,0.63830936,0.44946802,0.26282707,0.0,0.0,0.062417515,0.048829384,0.010736845,0.0,0.0,0.0,0.0,0.0,0.013595797,0.010893032,0.17642951,0.3787226,0.39888012,0.39536732,0.4046852,0.68960446,0.76534194,0.65981835,0.47918403,0.8050793,0.9047795,0.92630297,0.6895425,0.53590727,0.34553313,0.18074487,0.0,0.011267088,0.059391424,0.06011252,0.015090145,0.0,0.028312758,0.0025053322,0.015360095,0.0,0.04087477,0.053284295,0.21575409,0.34107614,0.3364212,0.24196154,0.21061905,0.43749434,0.62312764,0.60171396,0.5177753,0.90853083,1.0,1.0,0.7409037,0.43377554,0.2678492,0.12779485,0.0,0.014903501,0.03327989,0.042605557,0.0069553554,0.0,0.06528998,0.048704274,0.045009986,0.0,0.058372177,0.06712045,0.22917552,0.2943784,0.28780752,0.11833217,0.05337899,0.16813932,0.4009949,0.46902615,0.57063913,0.9962572,1.0,1.0,0.6665704,0.2873699,0.19260429,0.080061674,0.0,0.040250823,0.027069315,0.03753276,0.003320396,0.0,0.07424128,0.061526485,0.03546022,0.0,0.03612908,0.051330052,0.20276879,0.24338871,0.24281445,0.061045863,0.0,0.0,0.19254959,0.36520582,0.6995377,1.0,1.0,0.99085695,0.5483806,0.1398915,0.1435804,0.040816315,0.0,0.07169579,0.047459953,0.049433395,0.0,0.0,0.09141317,0.10025042,0.0697907,0.0,0.019276552,0.03792882,0.16494942,0.15867242,0.17641793,0.008669764,0.0,0.0,0.05080972,0.3039996,0.8065796,1.0,1.0,0.78631693,0.30716276,0.0,0.08874604,0.023621857,0.0013554841,0.10382959,0.059170112,0.04743269,0.0,0.0,0.1017869,0.162904,0.149402,0.0,0.005648762,0.025237143,0.14547402,0.12142094,0.16031766,0.0,0.0,0.0,0.0,0.3119349,0.9154844,1.0,1.0,0.6449418,0.18110853,0.0,0.05980079,0.056464843,0.062552296,0.18562329,0.09494803,0.049822636,0.0,0.0,0.12243034,0.23112059,0.25017846,0.012329139,0.016845658,0.01355008,0.11799098,0.07720858,0.11899974,0.0,0.0,0.0,0.0,0.3217509,1.0,1.0,1.0,0.473881,0.06263587,0.0,0.109110706,0.16648367,0.2118184,0.34591717,0.17890102,0.08448069,0.0,0.0,0.14751266,0.29323792,0.31801182,0.042381786,0.0,0.0,0.10004011,0.07901381,0.11551315,0.0,0.0,0.0,0.0,0.3056738,1.0,1.0,1.0,0.47230184,0.066823676,0.0,0.13561755,0.18806267,0.22692966,0.35122412,0.16118708,0.06414834,0.0],[0.0,0.038517557,0.0,0.008298181,0.0,0.0,0.0,0.14625897,0.46466088,0.8614167,0.99949634,0.9793181,1.0,0.94677395,0.72864676,0.5751712,0.7803598,0.86680794,0.79888237,0.6080156,0.72129667,0.7012887,0.35927394,0.07310175,0.0,0.0,0.002793014,0.0,0.0,0.0038667768,0.0,0.0023960322,0.0,0.0,0.0,0.18900147,0.47830105,0.79951864,0.9236786,0.94756645,1.0,0.94688743,0.75820065,0.5092246,0.74292314,0.91115683,0.95907754,0.7616331,0.7572058,0.6415385,0.28202087,0.044709556,0.0,0.0,0.03865228,0.010335736,0.0,0.0023293197,0.0,0.0034081787,0.0,0.0,0.0,0.16874832,0.3731047,0.6169442,0.7114885,0.82084835,0.9850604,0.97330546,0.8400345,0.5652768,0.8348768,0.9519589,0.9647307,0.7140851,0.6192582,0.47109878,0.20029241,0.021924563,0.0,0.0,0.05772187,0.025494084,0.0,0.023316786,0.0,0.010846332,0.0,0.0,0.0011027753,0.17305481,0.3125412,0.4569804,0.47510213,0.6697363,0.888169,1.0,0.9387844,0.6782334,0.98444486,1.0,0.9513513,0.6551619,0.49551123,0.34563285,0.15408193,0.014476024,0.0,0.0,0.04893565,0.040647104,0.0011770427,0.04036033,0.0,0.021716848,0.0,0.022912458,0.030205928,0.14607772,0.22938493,0.31327268,0.2890453,0.44530612,0.73641276,0.96715903,0.9651776,0.77171856,1.0,1.0,0.97760946,0.6118447,0.37568277,0.25436705,0.126549,0.0,0.0,0.0,0.0032042712,0.04205022,0.0074600205,0.060752086,0.0,0.028353214,0.0,0.03795082,0.030201443,0.08340083,0.13588741,0.19768585,0.15097772,0.21603006,0.5047104,0.79707664,0.89558905,0.85807484,1.0,1.0,0.8824375,0.48480922,0.23874067,0.18375926,0.10774012,0.0,0.0,0.0,0.0,0.04973545,0.0069849193,0.07889345,0.0,0.022589713,0.0,0.031874657,0.016214736,0.034400232,0.091109455,0.14611378,0.08181591,0.052141756,0.26598793,0.5839026,0.7948887,1.0,1.0,1.0,0.7446489,0.33521974,0.129058,0.13772391,0.08591901,0.0,0.0018722415,0.0,0.0,0.04762581,0.013749868,0.10999778,0.047235407,0.043810174,0.0,0.030248344,0.021467604,0.0,0.0279115,0.07463722,0.009162217,0.0,0.041428946,0.37678498,0.69978756,1.0,1.0,0.9871829,0.48108613,0.08253205,0.0,0.10278642,0.06902501,0.0,0.0,0.0,0.0,0.029099159,0.01587049,0.1350571,0.1386207,0.12770617,0.0021372437,0.018007308,0.028777868,0.0,0.048643984,0.059779152,0.0,0.0,0.0,0.2563032,0.6701102,1.0,1.0,0.8897558,0.3094577,0.0,0.0,0.073807925,0.061960444,0.0,0.011989601,0.0,0.0,0.0058669522,0.015916318,0.14820829,0.20212835,0.20976762,0.041429207,0.020687781,0.028424136,0.0,0.057377785,0.015054993,0.0,0.0,0.0,0.17299026,0.68094367,1.0,1.0,0.75387996,0.13777734,0.0,0.0,0.115025446,0.15572694,0.06275437,0.10106375,0.0,0.0,0.0,0.015331052,0.16952068,0.24216497,0.25758052,0.04813818,0.0,0.007621266,0.0,0.063221164,0.010736838,0.0,0.0,0.0,0.13779213,0.65136945,1.0,1.0,0.766565,0.12549189,0.0,0.0,0.11963783,0.1887934,0.08013204,0.100728855,0.0,0.0,0.0],[0.0065136254,0.068424284,0.0,0.018863998,0.020125978,0.0039764643,0.08827342,0.31697434,0.69802,1.0,1.0,0.9383386,0.9930299,0.84560347,0.7239747,0.7300321,0.745218,0.7522986,0.8106347,0.79246503,0.79279846,0.6222353,0.35864407,0.077204034,0.0014594793,0.0,0.0,0.0,0.0,0.04747405,0.0,0.019367158,0.017946623,0.04799927,0.11096786,0.32411143,0.6795311,0.96488726,1.0,0.9725599,1.0,0.8835534,0.6798718,0.70021385,0.7411509,0.8829003,0.94993484,0.89698595,0.72345996,0.49054182,0.21694313,0.01697284,0.024323426,0.0,0.0,0.0039615184,0.0,0.05577097,0.0,0.004530847,0.0004759878,0.049300365,0.10733288,0.25634515,0.5245051,0.78326267,0.9175378,0.97623247,1.0,0.9660762,0.7062948,0.7342469,0.7709377,0.9010242,0.9487351,0.8166359,0.55350447,0.3298831,0.1549864,0.035274424,0.05777055,0.0,0.0032677203,0.0001771152,0.010433584,0.06200128,0.003913328,0.0006605983,0.0,0.055670694,0.11581658,0.23671833,0.40329254,0.6144176,0.7632156,0.942003,1.0,1.0,0.82319796,0.88173,0.88271654,0.95532715,0.90119135,0.69341964,0.35665342,0.21304674,0.11923163,0.031221263,0.064496025,0.0,0.0059135184,0.0042087436,0.022062227,0.04965969,0.005335927,0.0,0.022950232,0.07850772,0.13043915,0.22047153,0.28511485,0.41115564,0.53983504,0.8069939,1.0,1.0,0.88254845,0.9895876,0.9791611,1.0,0.87155914,0.59208876,0.21785037,0.1429549,0.07994565,0.010113388,0.038877994,0.0,0.0,0.014011003,0.030744433,0.04365132,0.009044878,0.0,0.047687322,0.08667225,0.10330551,0.17415026,0.17010318,0.2388725,0.28356722,0.5892102,0.8831018,1.0,0.8995172,1.0,1.0,1.0,0.7615467,0.46172154,0.10852344,0.08179861,0.044760555,0.009048432,0.03708814,0.0,0.0,0.026563019,0.03203792,0.039704584,0.018706836,0.0,0.06159997,0.052230142,0.059239097,0.11082272,0.10366943,0.14347792,0.08928174,0.37057436,0.6074199,0.9201512,0.95264804,1.0,1.0,0.9096816,0.546243,0.2843093,0.0039274395,0.037249133,0.008023404,0.0016877055,0.024045967,0.0,0.0,0.035043955,0.03532388,0.07245991,0.079850964,0.037432924,0.08303842,0.025194556,0.042504743,0.056231067,0.0024520755,0.0,0.0,0.17618757,0.34870055,0.8006392,0.9685089,1.0,1.0,0.6388417,0.17178708,0.0019584447,0.0,0.0,0.0,0.0,0.0045906305,0.0,0.0,0.036459133,0.026639067,0.14166595,0.18638334,0.12326617,0.08649159,0.0064888373,0.02457203,0.04942783,0.0,0.0,0.0,0.084228784,0.17686613,0.7249001,0.9885553,1.0,1.0,0.5129332,0.023599371,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.036964156,0.010149509,0.17733297,0.24051332,0.1977194,0.08657641,0.0,0.0,0.030745976,0.0,0.0,0.0,0.050875276,0.07992263,0.70206285,1.0,1.0,0.9804698,0.39688963,0.0,0.0,0.0,0.0,0.0,0.027785815,0.050066836,0.0,0.033737957,0.03815736,0.011674069,0.1968476,0.2525881,0.20282787,0.07592718,0.0,0.0,0.024209522,0.0,0.0,0.0,0.042917088,0.055585004,0.69609755,1.0,1.0,0.9817045,0.39129472,0.0,0.0,0.0,0.0,0.0,0.035900652,0.055390343,0.0,0.03459326,0.033502698],[0.03742858,0.08049448,0.020234987,0.015635021,0.03392818,0.07800488,0.26245528,0.4722442,0.7577462,0.93374825,0.91928244,0.8009214,0.7955525,0.63971823,0.3414145,0.4257074,0.6583341,0.8412612,0.8674399,0.9889176,0.8505972,0.55034745,0.32248592,0.083248585,0.0,0.0,0.0,0.026056543,0.00768698,0.07986513,0.00502868,0.002093181,0.023361303,0.08895478,0.28245926,0.4519689,0.7431471,0.9483513,0.9774571,0.89899653,0.92644227,0.6869591,0.35985672,0.43642688,0.72738314,0.9539932,0.9412846,0.947438,0.6866176,0.3421887,0.20205197,0.02282253,0.0,0.0,0.018327542,0.030528545,0.01797013,0.111499235,0.019989394,0.0,0.0,0.048308477,0.2323643,0.36161774,0.5769191,0.82385504,0.9318951,0.9651649,1.0,0.7579251,0.4356252,0.480031,0.7392904,0.94668734,0.8572479,0.74673176,0.50256735,0.21419296,0.13627812,0.018033527,0.0069034696,0.0,0.023404911,0.019048825,0.032720506,0.13535123,0.03843361,0.0,0.0,0.035162896,0.21544176,0.33515155,0.448021,0.68803173,0.84357435,1.0,1.0,0.8767421,0.6171868,0.644636,0.7985587,0.89147997,0.72337925,0.49679816,0.3199243,0.12851894,0.08322105,0.0026292056,0.01479014,0.0057062656,0.03663095,0.020011127,0.047744684,0.13164152,0.034225605,0.009706013,0.0,0.035804965,0.20244834,0.3298266,0.34436134,0.52906877,0.68314105,0.94234437,1.0,0.9511146,0.7576749,0.7905569,0.8474067,0.8275712,0.61354244,0.30456984,0.16814063,0.06979974,0.028023124,0.0010456741,0.016168818,0.0018243939,0.048544154,0.036732823,0.06278094,0.12136428,0.027180575,0.010082558,0.016199082,0.038114503,0.15011692,0.29414654,0.23863415,0.3561052,0.4942276,0.7640584,1.0,0.9909471,0.8773868,0.9133911,0.90361965,0.759419,0.52770114,0.20460358,0.06383295,0.02292449,0.0,0.017032944,0.042200863,0.012282215,0.07039874,0.0586942,0.059451364,0.097070575,0.017315708,0.019962199,0.040618457,0.010469526,0.09169197,0.2218602,0.16864653,0.23032027,0.29958987,0.5525908,0.91256106,1.0,1.0,1.0,0.9142098,0.59543407,0.34557122,0.116386205,0.011000469,0.0,0.0,0.030304998,0.047870584,0.015923306,0.08826928,0.07637492,0.049961552,0.09526746,0.059240818,0.0511382,0.059202656,0.002665922,0.06179326,0.15004477,0.03311126,0.04542789,0.08061384,0.34096113,0.7225645,1.0,1.0,1.0,0.7962841,0.2792268,0.06126304,0.0,0.0,0.0,0.0,0.055477083,0.03714724,0.0165774,0.09259084,0.089019455,0.03004092,0.11913033,0.14408259,0.07601702,0.041728318,0.0,0.016640335,0.10113965,0.0,0.0,0.00081044436,0.25559968,0.6126184,1.0,1.0,1.0,0.7384528,0.11815862,0.0,0.0,0.0,0.0,0.0,0.08326337,0.030669622,0.03053391,0.10980319,0.09851628,0.0,0.11518894,0.18111792,0.09400152,0.030082643,0.0,0.0,0.044032343,0.0,0.0,0.0,0.24599744,0.58385813,1.0,1.0,1.0,0.6958663,0.0,0.0,0.0,0.0,0.0,0.0009571165,0.12971002,0.037096664,0.07206513,0.1448793,0.106370464,0.0,0.12939794,0.16048966,0.07005069,0.008176558,0.0,0.0,0.03919228,0.0,0.007909343,0.0,0.25750476,0.60525894,1.0,1.0,1.0,0.70026505,0.0,0.0,0.0,0.0,0.0,0.008984119,0.14187032,0.028463587,0.06990383,0.15301424,0.10601126],[0.0,0.0077486336,0.015653849,0.053435937,0.086014464,0.17482944,0.39036405,0.4805442,0.7562006,0.6990643,0.7615016,0.55323386,0.41451532,0.2407305,0.098509334,0.07048792,0.22374335,0.6825234,0.9853807,1.0,0.86905885,0.534691,0.27065742,0.091205664,0.09426877,0.0,0.12154036,0.12213214,0.0,0.0,0.015338652,0.07733022,0.097108915,0.20374584,0.40745896,0.558135,0.7936556,0.7918201,0.9122404,0.7736314,0.5714684,0.27651674,0.092398115,0.10999039,0.33770698,0.8180292,0.9898071,0.9171236,0.51917034,0.20107254,0.116053104,0.0492998,0.11337696,0.00607647,0.10819876,0.107769,0.022052579,0.027998216,0.038273066,0.07174671,0.06545738,0.18725815,0.34125596,0.47883445,0.6808836,0.766518,0.9497921,0.8991983,0.70641804,0.36521024,0.17543748,0.18312174,0.39521796,0.8043708,0.84808755,0.6466777,0.22734502,0.031079032,0.075980775,0.032695077,0.09172119,0.0061203614,0.07372244,0.064015135,0.050217517,0.057931617,0.059804887,0.067696646,0.05855283,0.1979171,0.29344904,0.40310794,0.5581366,0.7123034,0.94526863,0.9933364,0.8393908,0.5458438,0.36143443,0.3122948,0.44507664,0.7037437,0.61810946,0.3526042,0.04396657,0.004270807,0.07792178,0.029115789,0.08321801,0.015858755,0.066126466,0.04652814,0.07235642,0.0672132,0.07026709,0.057211623,0.07294943,0.21499786,0.2736366,0.34225032,0.4461273,0.6089624,0.8312179,0.94740105,0.88668436,0.67370623,0.5114993,0.4096551,0.49925882,0.5917409,0.3921296,0.14629914,0.0,0.0,0.06035482,0.03560085,0.08372583,0.04328101,0.0844868,0.04745066,0.08382344,0.0657461,0.06382507,0.042116918,0.08684984,0.22857621,0.2592306,0.2842396,0.35716295,0.46824974,0.6470284,0.7934155,0.8689785,0.764462,0.63647413,0.48528355,0.5526667,0.5058092,0.26743263,0.08077278,0.0,0.0062941313,0.054951794,0.042839736,0.08661224,0.06817808,0.1036394,0.056796163,0.07775335,0.04423701,0.049599297,0.030908242,0.10021806,0.22914483,0.2204093,0.24786375,0.29401436,0.34122652,0.46451616,0.6551694,0.8450987,0.8641237,0.7512811,0.499586,0.4794616,0.33176115,0.17574361,0.070556164,0.0,0.02228441,0.053966887,0.048697315,0.09637589,0.09080102,0.11819485,0.06465936,0.067078926,0.035166495,0.05765468,0.04480201,0.11868579,0.23832253,0.18446098,0.14698963,0.18015778,0.12543948,0.24487402,0.5078019,0.8344042,0.9234158,0.77680445,0.39227062,0.26835543,0.08082381,0.04174926,0.08156701,0.0,0.043836586,0.055594593,0.046469823,0.115761,0.11350568,0.130597,0.07023522,0.04256864,0.025450677,0.055351265,0.049809486,0.101592876,0.22561577,0.13736789,0.07747294,0.12488556,0.048460864,0.17499442,0.446927,0.82229054,0.99767804,0.8343835,0.35570645,0.1875579,0.0,0.0,0.08003297,0.0,0.04112277,0.035151765,0.024814941,0.14396091,0.11859937,0.13786966,0.07336761,0.010054529,0.0,0.021373652,0.04363597,0.09266572,0.22615933,0.10645854,0.019412242,0.10911052,0.02758234,0.1752107,0.44843143,0.83928233,1.0,0.90305465,0.35480058,0.16306223,0.0,0.0,0.08175734,0.0,0.026988722,0.010392614,0.0,0.16715716,0.12353403,0.1459029,0.07835166,0.014548644,0.0,0.0,0.021305814,0.085799724,0.2335779,0.102011636,0.0073522255,0.13399334,0.0409521,0.21245125,0.48077965,0.8701642,1.0,0.9078507,0.35120153,0.17598584,0.0,0.0,0.09377673,0.0,0.021386296,0.0018459558,0.0,0.16154356,0.11370006,0.14462857,0.08566743],[0.0,0.0,0.0,0.0,0.08548348,0.3570784,0.5028952,0.5677709,0.5685709,0.4787137,0.36478046,0.30179662,0.1326607,0.039578974,0.0,0.0,0.24626368,0.7048864,1.0,1.0,0.659099,0.40503156,0.10087526,0.015909255,0.0,0.0,0.062279776,0.11291394,0.0,0.0,0.0,0.0,0.119163476,0.3682219,0.5465978,0.6286341,0.6131144,0.58594906,0.5530385,0.5309682,0.2794361,0.12598789,0.0,0.060009167,0.42815745,0.8732723,0.9970299,0.78564423,0.34078747,0.12073927,0.0,0.000053986907,0.0,0.0,0.058932975,0.108387694,0.019536339,0.0,0.004243031,0.0,0.11534374,0.3177653,0.4683783,0.5326303,0.5199941,0.5811765,0.627819,0.62619597,0.38455904,0.23496199,0.0117780045,0.16198833,0.4924062,0.868054,0.877069,0.51555866,0.09818392,0.009427533,0.0,0.0,0.0,0.0,0.023645334,0.076599225,0.04276128,0.0,0.013969913,0.0051266104,0.1303219,0.2864825,0.38692546,0.42550367,0.40429497,0.54266876,0.65089655,0.7010261,0.49962163,0.4044236,0.1618738,0.2933185,0.5209342,0.7670831,0.64184505,0.27896583,0.0,0.025996983,0.0,0.0,0.0,0.0,0.0,0.056664042,0.06020516,0.00034299493,0.023215584,0.008487627,0.15542676,0.2719458,0.3382317,0.33137405,0.29572245,0.46322644,0.58305526,0.6789283,0.55619526,0.53842986,0.2967864,0.38410354,0.53112936,0.6241338,0.3671516,0.108767234,0.0,0.013708912,0.0,0.0,0.0,0.010866195,0.0,0.050394177,0.071331754,0.0029063374,0.022631899,0.025570177,0.17579007,0.2600922,0.32622486,0.24911201,0.20408043,0.3770535,0.47090876,0.6227061,0.6130151,0.68411016,0.45137167,0.4305809,0.46948528,0.44060475,0.16058387,0.042521574,0.0,0.008018777,0.0,0.0,0.0,0.041965544,0.0,0.05332411,0.0655541,0.0,0.011050813,0.038041413,0.18405977,0.2494604,0.3117528,0.20931084,0.14312564,0.30371583,0.38286477,0.6206693,0.7153198,0.8293501,0.5938676,0.37223935,0.25967467,0.22135636,0.050340146,0.04473816,0.018020473,0.0019045323,0.0,0.0,0.0,0.06864698,0.0,0.05700308,0.06366077,0.017743178,0.032682076,0.042188317,0.18651439,0.23260126,0.28660864,0.1591641,0.06383825,0.17570202,0.27284902,0.6169641,0.826829,0.9455867,0.6421522,0.21280418,0.025494613,0.0,0.0,0.07486021,0.07441003,0.0,0.01047758,0.0,0.0,0.09403722,0.0,0.060786307,0.05527147,0.032874882,0.037270516,0.03938148,0.18029547,0.20443164,0.26527965,0.107084446,0.021616898,0.14567463,0.25285986,0.6286187,0.8994084,1.0,0.71060705,0.13393107,0.0,0.0,0.0,0.069219604,0.09792338,0.0,0.03130392,0.0,0.0028339922,0.0994578,0.0,0.0633073,0.040721186,0.01982101,0.037468694,0.029394299,0.17304799,0.21189317,0.26203093,0.10739127,0.038250633,0.14991762,0.28526142,0.66034997,0.9511907,1.0,0.7528523,0.10135974,0.0,0.0,0.0,0.054970466,0.10932791,0.0,0.019095011,0.011951029,0.014879197,0.10244866,0.0,0.06725803,0.038732648,0.013123237,0.017744832,0.013269678,0.17100692,0.22912297,0.258036,0.13078684,0.07023499,0.1641221,0.31036365,0.6989558,0.97172415,1.0,0.7531843,0.10321806,0.0,0.0,0.0,0.041495703,0.10736588,0.0,0.0,0.0052980185,0.012187034,0.101788536,0.0,0.08552503],[0.0,0.045234352,0.04383783,0.0699957,0.27604443,0.6150425,0.7316576,0.59281874,0.30695882,0.29378796,0.19471928,0.15042447,0.041452244,0.0,0.0,0.16621187,0.4302395,0.9361517,1.0,0.9920725,0.59733087,0.2472126,0.07108145,0.0009623319,0.053499028,0.083890066,0.11317876,0.070245445,0.0,0.030611917,0.03456413,0.09696661,0.28084302,0.62087125,0.7270443,0.64337337,0.41956735,0.44713432,0.35870332,0.30780518,0.13969831,0.061926924,0.02843412,0.3031422,0.5661321,0.989095,1.0,0.70138603,0.30185425,0.099202685,0.04186607,0.009571128,0.039825097,0.08413117,0.12212693,0.083447665,0.008465394,0.035160683,0.038290367,0.106988385,0.2385099,0.5373068,0.6327782,0.5839787,0.43346596,0.4826761,0.4231559,0.41836703,0.25585878,0.15102483,0.12246183,0.36278468,0.5954937,0.94046676,0.8272311,0.42553562,0.08343106,0.0,0.018406913,0.0063648,0.009026438,0.06490711,0.090418056,0.067488894,0.03255266,0.056082375,0.06264367,0.13158648,0.22403073,0.47633028,0.56488013,0.5297,0.4204498,0.48302436,0.47638923,0.53399473,0.39046657,0.25846893,0.22999445,0.40786827,0.59385943,0.8216698,0.6047059,0.24116932,0.0,0.0,0.0,0.0,0.0,0.06557487,0.07060224,0.05194062,0.056231096,0.08278769,0.0926138,0.16045865,0.22296669,0.42910558,0.51474106,0.48874545,0.39480907,0.46063632,0.5229309,0.65030104,0.5360762,0.3807596,0.3194168,0.40251654,0.5531769,0.6560173,0.3729437,0.074526094,0.0,0.0,0.0,0.0,0.0,0.063826576,0.05929502,0.051140554,0.07193415,0.093327,0.12073587,0.18371896,0.21861932,0.37955594,0.47333533,0.46010292,0.39514834,0.43628418,0.58385533,0.76431906,0.6781924,0.47544086,0.3475967,0.3334794,0.42615974,0.46839726,0.17514598,0.0,0.0,0.0,0.0,0.0,0.0,0.084681764,0.07049115,0.056115925,0.0734416,0.09058252,0.12074305,0.18879278,0.21990952,0.3654374,0.47086352,0.48298848,0.4605723,0.45175654,0.6634244,0.88075465,0.8127773,0.5407864,0.32005352,0.20537275,0.2673174,0.2956755,0.06948948,0.006236486,0.0,0.0,0.0,0.0,0.0,0.10694644,0.08423112,0.06383423,0.07378003,0.09199012,0.11226923,0.18361671,0.21130736,0.31664452,0.43924254,0.4571076,0.47931612,0.42533892,0.7250133,1.0,0.98287445,0.6021967,0.26673448,0.030339748,0.11694017,0.21061063,0.034433186,0.041301027,0.0,0.0,0.0,0.018254936,0.0,0.115677804,0.107000396,0.08332589,0.0612507,0.09273366,0.098308384,0.2029537,0.21233802,0.26606625,0.404194,0.41013896,0.507852,0.43797964,0.80945134,1.0,1.0,0.65857786,0.22287217,0.0,0.034052707,0.20703137,0.04144656,0.08827451,0.047318093,0.029444672,0.008451596,0.07572128,0.03140393,0.109939896,0.111813985,0.08745308,0.04230558,0.0853831,0.09137568,0.22844502,0.23584545,0.29020524,0.4128132,0.40689713,0.5520368,0.47906423,0.89153486,1.0,1.0,0.65004665,0.16757023,0.0,0.0,0.19785526,0.03120301,0.14143954,0.10008741,0.06599499,0.018632628,0.1049993,0.036160566,0.09187862,0.12247695,0.09912661,0.03632039,0.081245884,0.09808641,0.25429046,0.2694146,0.33324513,0.47468138,0.4764583,0.60263515,0.52123916,0.9233512,1.0,1.0,0.63325065,0.1697315,0.0,0.0,0.24383835,0.054371573,0.16614853,0.111496374,0.060942806,0.007660404,0.114395946,0.033336997,0.09080283,0.14315093,0.1294821],[0.030917995,0.108741686,0.051453203,0.02337493,0.43392617,0.930963,0.90759444,0.7802852,0.46372312,0.17795084,0.117984675,0.07541807,0.0,0.0,0.0,0.2837716,0.8488889,1.0,1.0,0.6845827,0.3251679,0.08429681,0.0,0.006747529,0.08600384,0.106393576,0.10767571,0.05554896,0.039832987,0.08938805,0.06019272,0.03263615,0.4170366,0.87238514,0.93999237,0.82488936,0.6062506,0.32128257,0.2789543,0.17288254,0.025878146,0.040625244,0.09074963,0.46862376,0.90622777,1.0,0.8401763,0.36672324,0.083042614,0.022979282,0.0,0.0062566027,0.077198535,0.1397549,0.15369858,0.08156641,0.042964682,0.079446584,0.04956065,0.045115,0.37081903,0.7610817,0.852748,0.7620057,0.6253412,0.35592005,0.38540322,0.28505403,0.13589995,0.13443486,0.14811122,0.52097607,0.8790795,1.0,0.66328025,0.1678646,0.0,0.0,0.0,0.0,0.047026493,0.14257416,0.1419304,0.07573231,0.058573484,0.09733771,0.039175466,0.060344398,0.34828147,0.68423545,0.79234326,0.7065263,0.6308031,0.38759935,0.5161735,0.4515,0.3085129,0.2129055,0.201392,0.530835,0.78886706,0.85066617,0.47255725,0.09611527,0.0,0.0,0.0,0.0,0.03199278,0.16284269,0.13840154,0.07285349,0.08184792,0.128441,0.03687889,0.08247766,0.3377423,0.6172688,0.75071,0.66458845,0.6234309,0.4518724,0.6549475,0.6507631,0.51452667,0.32007742,0.26033103,0.5228486,0.677967,0.6397731,0.29521972,0.057888195,0.0,0.0,0.0,0.0,0.0054992437,0.16748017,0.13006113,0.08152126,0.09619002,0.15069298,0.037536696,0.10726726,0.34761012,0.56657714,0.7238282,0.6450114,0.6313822,0.5204748,0.78928304,0.82400024,0.64233434,0.34884506,0.25854397,0.44519943,0.54845995,0.45072365,0.19640025,0.082593456,0.0,0.0,0.0,0.0,0.011064142,0.19411646,0.12929481,0.09581217,0.09668835,0.14606124,0.025858477,0.13122705,0.37200707,0.5711856,0.7746665,0.717084,0.7097391,0.62267476,0.9090343,0.9472928,0.7071608,0.3079583,0.19743727,0.34531772,0.42205435,0.33400908,0.19232431,0.16425659,0.051866375,0.017186105,0.0,0.03882116,0.05456247,0.21953566,0.1290435,0.111661136,0.09242662,0.13086149,0.020286456,0.15898402,0.393192,0.55949026,0.8031356,0.7313904,0.73211026,0.67367876,1.0,1.0,0.8123019,0.28238165,0.12535551,0.1849849,0.30393654,0.2912529,0.25314683,0.27058858,0.16660404,0.102816135,0.088569745,0.13866653,0.15191546,0.24180153,0.15092447,0.14061293,0.080788136,0.104794234,0.035041124,0.20081058,0.4136659,0.53348964,0.77091974,0.7269865,0.7555118,0.7458319,1.0,1.0,0.8860826,0.2751811,0.08742902,0.044796146,0.21896414,0.31228912,0.34890437,0.3992312,0.28033894,0.1915149,0.24642627,0.2776168,0.2881388,0.24832252,0.1538503,0.14463226,0.07098134,0.083275035,0.063449204,0.2454007,0.4497248,0.55098784,0.7616045,0.75471526,0.7823508,0.8052343,1.0,1.0,0.89316374,0.2236029,0.027524672,0.0,0.1571284,0.31295758,0.42047125,0.5427183,0.39968574,0.2754368,0.3963806,0.38230264,0.39302343,0.25065243,0.16505381,0.1587275,0.068251036,0.07477914,0.10117565,0.2893794,0.5006853,0.6241906,0.8650894,0.8512439,0.8309411,0.8299582,1.0,1.0,0.8756495,0.20243046,0.015332654,0.0,0.21281385,0.37406784,0.48738313,0.61768776,0.44760472,0.28885865,0.42442894,0.40865034,0.41889268,0.2650578,0.20687288,0.19864988],[0.00619328,0.09392048,0.0543017,0.31320888,0.68110895,1.0,1.0,0.672808,0.30792934,0.16036142,0.018241592,0.047708653,0.012637839,0.0,0.2812529,0.7440053,1.0,1.0,0.96848303,0.36045182,0.10579844,0.0005414337,0.02262754,0.025955558,0.10695507,0.0699706,0.09617097,0.017019078,0.003958896,0.09452221,0.07114622,0.2992148,0.6441495,1.0,1.0,0.7831602,0.50806737,0.3118158,0.1467784,0.11899826,0.09846133,0.094492085,0.4492175,0.85471463,1.0,1.0,0.6429348,0.10836833,0.0,0.0,0.0,0.000060096383,0.07793495,0.08409946,0.120192125,0.05367119,0.015248969,0.08676521,0.08251476,0.26958168,0.60157263,1.0,1.0,0.8266446,0.6378368,0.42918497,0.25582325,0.22685553,0.20114051,0.16932598,0.47497284,0.8105254,0.9905684,0.87674713,0.48120022,0.0,0.0,0.0,0.0,0.0,0.059429966,0.06875546,0.09920505,0.057513714,0.050794773,0.11713786,0.097543955,0.23725209,0.5638563,0.92921376,1.0,0.84800583,0.74624544,0.57964534,0.4267894,0.37445927,0.3378219,0.2639985,0.47844487,0.7282959,0.8419649,0.7306204,0.36569536,0.0,0.0,0.0,0.0,0.008148871,0.07159539,0.07974993,0.08867495,0.047520645,0.08020078,0.14634791,0.121996365,0.22559017,0.5466372,0.86370945,1.0,0.8572174,0.8361048,0.78973687,0.6788058,0.61980224,0.4878292,0.3826632,0.46369374,0.6172928,0.6997517,0.59181094,0.2936777,0.0,0.0,0.0,0.0,0.0062876865,0.048954003,0.06560107,0.070666,0.048956074,0.09255896,0.16547972,0.14004938,0.22914751,0.53875405,0.82543576,1.0,0.89647925,0.94949275,1.0,0.9172083,0.8226404,0.5170788,0.36500347,0.35461155,0.47773057,0.55926466,0.50039405,0.30478185,0.04016296,0.0,0.0,0.0,0.0,0.039145775,0.06792882,0.06930292,0.06011367,0.08740534,0.16084534,0.13713636,0.23681323,0.5747473,0.8491231,1.0,1.0,1.0,1.0,1.0,0.9105026,0.4626552,0.27841306,0.2133868,0.38557673,0.51034194,0.51541716,0.38634086,0.14565994,0.0,0.0,0.0,0.012282252,0.038824722,0.07886119,0.06712522,0.073835626,0.081247695,0.15891416,0.13900629,0.24854699,0.6328233,0.8930392,1.0,1.0,1.0,1.0,1.0,1.0,0.45272154,0.2056606,0.08236754,0.28435063,0.43570417,0.5226397,0.4770587,0.307732,0.119914174,0.050449148,0.05052182,0.07759586,0.08880122,0.1111216,0.093434334,0.09080861,0.07733928,0.15568632,0.14337903,0.26138866,0.6622828,0.903182,1.0,1.0,1.0,1.0,1.0,1.0,0.46456784,0.16407144,0.0,0.16989557,0.34992424,0.5300892,0.587511,0.48447496,0.27569366,0.1621159,0.19600265,0.20459807,0.17675883,0.114110865,0.069549605,0.071702346,0.067393824,0.15603109,0.16998518,0.2973402,0.7162462,0.92204994,0.9929742,1.0,1.0,1.0,1.0,1.0,0.4455657,0.10468094,0.0,0.063502185,0.25963777,0.5268975,0.6893729,0.6713827,0.42455405,0.2591032,0.3156399,0.29931873,0.2382673,0.11784007,0.065124266,0.06857858,0.060815156,0.17890388,0.21551582,0.36767197,0.83485806,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.42849767,0.09145322,0.0,0.10025525,0.32988632,0.6142151,0.7840415,0.76881397,0.49743897,0.30215326,0.3369924,0.31493175,0.24761045,0.13141184,0.08780964,0.09216553],[0.0,0.07963703,0.017586708,0.24637434,0.7442901,1.0,1.0,0.9311277,0.5879293,0.34387362,0.37506565,0.20409298,0.2492032,0.46678627,0.7798079,1.0,1.0,1.0,0.5684968,0.13642836,0.0,0.0,0.011707768,0.0,0.0,0.042579688,0.06656012,0.0062794536,0.0,0.098380044,0.05517772,0.24587247,0.7077661,1.0,1.0,1.0,0.80316025,0.5151761,0.48270994,0.3044299,0.32900077,0.53760755,0.83166665,1.0,1.0,0.74839574,0.26976776,0.0,0.0,0.0,0.037708446,0.0,0.0,0.06558674,0.095893234,0.03280308,0.0,0.11776472,0.09038315,0.25057155,0.6788681,1.0,1.0,1.0,0.95195496,0.6366134,0.5518793,0.39503175,0.36530793,0.52041143,0.70300853,0.8663977,0.9207984,0.6144243,0.1647141,0.0,0.0,0.0,0.070020996,0.0,0.0,0.065939225,0.09562826,0.026277311,0.028231189,0.1460329,0.103891686,0.22950828,0.6332141,1.0,1.0,1.0,1.0,0.7940061,0.66566014,0.49117285,0.42472488,0.4945317,0.5812851,0.72156394,0.7724334,0.5144406,0.16766155,0.0,0.0,0.0,0.08185413,0.0,0.0,0.072120436,0.08275895,0.0047942847,0.056619756,0.15057911,0.103624426,0.21581686,0.60062903,1.0,1.0,1.0,1.0,0.98772216,0.8791731,0.6372147,0.4971639,0.46070665,0.45374674,0.5909014,0.6565664,0.4315017,0.19491215,0.0,0.0,0.011688769,0.1209972,0.0,0.0,0.05305858,0.058113642,0.0,0.071492724,0.13834693,0.09882775,0.21256948,0.58721477,1.0,1.0,1.0,1.0,1.0,1.0,0.73674774,0.42440563,0.30706525,0.25915796,0.4158255,0.52247804,0.3560241,0.23749015,0.056761615,0.0,0.022258066,0.15490948,0.0,0.0016332716,0.036977634,0.043954805,0.009876326,0.071963385,0.12103495,0.08573991,0.2273396,0.61665106,1.0,1.0,1.0,1.0,1.0,1.0,0.71690774,0.26103997,0.11589138,0.06913173,0.29716152,0.50210124,0.40059364,0.34988225,0.17434898,0.0028890967,0.037411742,0.1912412,0.0,0.0063393265,0.022600196,0.03172882,0.022939034,0.07419744,0.11926094,0.0780597,0.24784976,0.65445024,1.0,1.0,1.0,1.0,1.0,1.0,0.76733214,0.14666902,0.0,0.0,0.186429,0.45825678,0.41953796,0.44581127,0.33794796,0.10666104,0.10608795,0.25707033,0.037229575,0.0478969,0.03152661,0.032228447,0.031320855,0.08312246,0.121061504,0.08871448,0.26657334,0.66593367,1.0,1.0,1.0,1.0,1.0,1.0,0.7930514,0.06772009,0.0,0.0,0.10039128,0.3969037,0.44839197,0.5678628,0.52088714,0.27819574,0.26152587,0.401533,0.1742464,0.12118487,0.027592003,0.00734213,0.02617997,0.08749984,0.12662901,0.10857551,0.30492818,0.69399285,0.9705721,0.9786642,1.0,1.0,1.0,1.0,0.8185708,0.0,0.0,0.0,0.016000874,0.325944,0.4710971,0.70628285,0.7071983,0.4441743,0.40364176,0.52403474,0.27160412,0.1737658,0.030809835,0.0,0.027916297,0.09496471,0.15650469,0.1521207,0.3887515,0.82459575,1.0,1.0,1.0,1.0,1.0,1.0,0.8135437,0.0,0.0,0.0,0.049172938,0.3892228,0.56030047,0.7979292,0.79914415,0.5186419,0.45886564,0.553113,0.27478772,0.17446479,0.043088898,0.0030786544,0.034181066],[0.0,0.04417765,0.064868525,0.36806276,0.76749474,1.0,1.0,1.0,1.0,1.0,0.8073476,0.72801495,0.6979363,0.7754431,0.8612451,0.9535121,0.81069607,0.50051296,0.30264473,0.019165322,0.0098579675,0.0,0.0,0.041102923,0.062862314,0.08332154,0.035529375,0.0,0.0,0.05056288,0.08547409,0.362533,0.7289474,1.0,1.0,1.0,1.0,1.0,0.82807225,0.736256,0.6865251,0.7145569,0.772273,0.8006316,0.56886214,0.31312275,0.12184178,0.0033501685,0.050587945,0.0,0.0,0.044732675,0.072055995,0.094107285,0.029835664,0.0,0.0,0.07710463,0.11680601,0.36462936,0.7041051,1.0,1.0,1.0,1.0,1.0,0.80515486,0.7075469,0.6314245,0.55482703,0.5902213,0.665778,0.47594714,0.27646756,0.083578005,0.0,0.057608858,0.0,0.0,0.029836878,0.08152901,0.0976408,0.01378081,0.0,0.027852885,0.09748123,0.110408634,0.32123488,0.64362156,0.96201456,1.0,1.0,1.0,1.0,0.786456,0.6976996,0.5890734,0.41123462,0.43467766,0.5236696,0.41608888,0.28551567,0.11366212,0.001222536,0.058745638,0.0,0.0,0.031565353,0.10854755,0.11196436,0.0,0.0,0.03687439,0.08895843,0.07535362,0.28927124,0.5995031,0.927308,1.0,1.0,1.0,1.0,0.82876086,0.7531055,0.55368465,0.28312477,0.25637352,0.3861826,0.37268525,0.31078428,0.18304786,0.012237877,0.058902457,0.0,0.0,0.008878194,0.07392183,0.083129555,0.0,0.0,0.034941673,0.06789443,0.032141328,0.24916166,0.54836386,0.88530743,1.0,1.0,1.0,1.0,0.9252931,0.7876754,0.46021223,0.11394085,0.052223526,0.22534676,0.27551693,0.31819087,0.26868144,0.04204355,0.066217154,0.0,0.0,0.0022129416,0.04939741,0.063481614,0.0,0.0,0.030989707,0.06686767,0.013826162,0.236601,0.5267253,0.8806375,1.0,1.0,1.0,1.0,1.0,0.7820584,0.34251606,0.0,0.0,0.13276781,0.24255234,0.35616374,0.36596733,0.097804554,0.08307855,0.0,0.0057043284,0.0016545653,0.028379321,0.05060157,0.0,0.0,0.028707005,0.0628507,0.009835906,0.2458104,0.5239906,0.845172,1.0,1.0,1.0,1.0,1.0,0.77558887,0.24754469,0.0,0.0,0.086011834,0.19760263,0.37212038,0.4464882,0.16640723,0.13945645,0.048887886,0.055792242,0.026527852,0.043625318,0.056618243,0.0,0.0,0.031726785,0.07072465,0.036767296,0.26631248,0.5158169,0.73903555,0.88094723,1.0,1.0,1.0,1.0,0.7783376,0.17876597,0.0,0.0,0.06922972,0.18148896,0.4120283,0.5564738,0.30534673,0.2745109,0.20305404,0.1973263,0.11769177,0.0819291,0.031243406,0.0,0.0,0.023211263,0.0645322,0.052780733,0.28455573,0.51354575,0.6272535,0.7263411,1.0,1.0,1.0,1.0,0.776558,0.12930758,0.0,0.0,0.06643059,0.17638661,0.4806589,0.688376,0.46000612,0.39607853,0.34772223,0.31592798,0.19955984,0.13695405,0.024911076,0.0,0.0,0.013028868,0.0546953,0.06763773,0.3309639,0.59936243,0.727999,0.80666894,1.0,1.0,1.0,1.0,0.77524203,0.12001877,0.0,0.0,0.10769028,0.23157191,0.56311566,0.76428074,0.5322432,0.45520508,0.39443004,0.3294236,0.22243086,0.15298039,0.03479039,0.0,0.0],[0.0,0.025730893,0.11313329,0.34681472,0.5694692,0.81090814,0.9267673,1.0,1.0,1.0,1.0,0.9805994,1.0,0.96737325,0.6966027,0.5638793,0.3393563,0.1909947,0.075290546,0.021283455,0.0,0.01977773,0.055961445,0.042214014,0.03523121,0.05548294,0.00033316016,0.0,0.0,0.031606734,0.12909766,0.3156724,0.562116,0.77861637,0.93989,1.0,1.0,1.0,1.0,0.8836478,0.8924062,0.845692,0.50269306,0.39580548,0.18785837,0.05693341,0.018350452,0.03722147,0.050579637,0.03808503,0.046531282,0.081335634,0.06892026,0.07335564,0.0,0.0,0.015083976,0.06536384,0.14708586,0.2994615,0.5591555,0.76459134,0.9865759,1.0,1.0,1.0,0.85469896,0.7401568,0.70590186,0.6259634,0.3637449,0.36179286,0.19796567,0.05958364,0.010559857,0.042768173,0.088207684,0.040947005,0.025515437,0.08884979,0.107075736,0.08721207,0.0025988221,0.0,0.03981542,0.074455656,0.13673502,0.24188343,0.51499933,0.73380005,1.0,1.0,1.0,1.0,0.71085197,0.6197841,0.5260159,0.42220014,0.22717018,0.3302338,0.24987379,0.11692446,0.067556106,0.0341781,0.094693094,0.03335301,0.0041196793,0.12033211,0.1531536,0.09219391,0.0011390448,0.0,0.060356647,0.061411873,0.14014317,0.2103675,0.4941697,0.6997513,0.9802856,1.0,1.0,0.9893894,0.6695171,0.5276165,0.38040888,0.20358366,0.093965255,0.3139591,0.33933377,0.22641812,0.14078267,0.031294093,0.0912517,0.048069254,0.0,0.10982208,0.12792358,0.06409689,0.0015186965,0.0,0.06748952,0.042476453,0.11629665,0.16803986,0.46659458,0.6848773,0.9389105,1.0,1.0,1.0,0.7359989,0.48409998,0.25357142,0.0,0.0,0.26744068,0.3773738,0.31259555,0.20465918,0.046882972,0.07948376,0.06371192,0.0,0.11216298,0.116456345,0.041789316,0.0,0.0,0.06571254,0.032327235,0.088289656,0.14568457,0.45674884,0.70234984,0.95804393,1.0,1.0,1.0,0.79200155,0.44583786,0.1619772,0.0,0.0,0.223596,0.42349958,0.3688794,0.23461503,0.04822558,0.048616268,0.06400978,0.0,0.120328724,0.09710064,0.024105325,0.0,0.0,0.06282123,0.018015094,0.06542629,0.15431812,0.45264566,0.68323475,0.9312879,1.0,1.0,1.0,0.8423796,0.4276361,0.11526992,0.0,0.0,0.18484028,0.38575888,0.39746797,0.22259101,0.051758677,0.058392964,0.078803614,0.0,0.13125294,0.09613179,0.04596874,0.0,0.0,0.06498109,0.013994016,0.05288004,0.17798272,0.43887234,0.5937967,0.8064455,0.9394486,1.0,0.9625345,0.8601101,0.4270391,0.10733464,0.0,0.0,0.15807068,0.35742348,0.45976222,0.26905012,0.11265818,0.14218009,0.15161096,0.056048676,0.15980813,0.06893644,0.036994226,0.0,0.0,0.057725377,0.014908515,0.050041363,0.20402472,0.43006885,0.49005467,0.6801422,0.83586156,1.0,0.94929445,0.9019495,0.44466674,0.13289289,0.0,0.0,0.12524289,0.3469483,0.55291533,0.34557325,0.17451757,0.22261226,0.21694894,0.10490697,0.19511832,0.070100024,0.040150486,0.0,0.0,0.043104663,0.010777138,0.04295069,0.23569365,0.49329728,0.5455855,0.71347654,0.8571408,1.0,0.9353181,0.9061862,0.44921786,0.14123707,0.0,0.0,0.1407196,0.38718367,0.62399924,0.39763844,0.20554805,0.2531831,0.21858966,0.08664076,0.20337588,0.06708187,0.040860467,0.0,0.0],[0.0,0.06137088,0.114501424,0.24366415,0.36640817,0.36149657,0.36480013,0.5249886,0.89032805,1.0,0.97335774,0.6692216,0.6297162,0.38241065,0.23317471,0.023500316,0.0011381507,0.0,0.0,0.0,0.0015710443,0.0,0.013208762,0.0,0.025441885,0.0,0.0,0.0,0.0,0.07319434,0.11985036,0.22194585,0.33798605,0.38425428,0.4142266,0.53875244,0.82327384,0.93116415,0.8226313,0.5467792,0.53653824,0.35798872,0.18328726,0.0,0.0,0.0,0.0,0.0,0.007824287,0.009910949,0.04616086,0.005313039,0.05026862,0.0,0.0,0.0,0.0,0.09816959,0.118860334,0.18511303,0.29154223,0.4070921,0.453458,0.51761353,0.7098919,0.79071873,0.6672898,0.4247594,0.39957392,0.28083444,0.15698163,0.033937298,0.022209883,0.0,0.0,0.0,0.022124477,0.033569545,0.06894694,0.028459676,0.069879636,0.0,0.0,0.0,0.0,0.09727779,0.09975057,0.124988645,0.23602903,0.4295606,0.5040046,0.52275646,0.6324292,0.6726124,0.5260542,0.3086958,0.25729465,0.18605447,0.12846512,0.0935463,0.12284931,0.03190545,0.0,0.0042809844,0.031030588,0.045934953,0.09922345,0.07729998,0.11767796,0.0,0.0,0.0,0.006184183,0.09247737,0.09678371,0.09376306,0.21674605,0.43217027,0.49661118,0.5029179,0.5912398,0.63221896,0.43471712,0.23281896,0.1538151,0.089626774,0.11129232,0.17896126,0.24107648,0.104336135,0.026695333,0.007509455,0.019929774,0.04183852,0.08222327,0.047605537,0.084344015,0.0,0.0,0.0,0.012440607,0.069106475,0.079333484,0.08777073,0.22546855,0.4357599,0.50362855,0.52692693,0.60111606,0.6986166,0.44129515,0.24650538,0.08469653,0.022923447,0.10704217,0.22911319,0.3013861,0.16286309,0.060031205,0.005467534,0.0070022494,0.02987355,0.072859526,0.023573652,0.05241713,0.0,0.0,0.0,0.016400002,0.052076958,0.051919833,0.07215479,0.21589133,0.43427366,0.5268232,0.5374318,0.61270136,0.76880074,0.49515307,0.2950857,0.03076563,0.0,0.089673184,0.22122687,0.3053344,0.20823155,0.08358252,0.0,0.0,0.005507067,0.058465414,0.011031248,0.037420996,0.0,0.0,0.0,0.013540603,0.02762647,0.03167206,0.049897693,0.19688722,0.38109487,0.5014076,0.4800384,0.58234286,0.77465767,0.55564296,0.3587905,0.032820433,0.0,0.08905472,0.18646625,0.25401396,0.21601865,0.07644061,0.0,0.0,0.0,0.049983017,0.013340637,0.02817896,0.011687897,0.0,0.0,0.014027245,0.011855654,0.024116054,0.02717074,0.17279789,0.24848196,0.3713771,0.34824508,0.5220655,0.73793656,0.5979053,0.43121874,0.07208894,0.0,0.10162048,0.15837353,0.24772131,0.24425697,0.12729426,0.030354433,0.0,0.023728423,0.061942995,0.0,0.0,0.0,0.0,0.0,0.014044195,0.009852029,0.01949124,0.003163904,0.14321645,0.10693972,0.27307808,0.30731997,0.5668734,0.76444703,0.6759445,0.49778068,0.14385492,0.0,0.10440866,0.12976617,0.28188246,0.32242715,0.2150607,0.066532955,0.0,0.050993845,0.080751345,0.0,0.0,0.0,0.0,0.0,0.008410275,0.008499935,0.018073678,0.007431902,0.15193318,0.11884469,0.2861036,0.31070775,0.56792045,0.76004183,0.68381214,0.5144963,0.18868303,0.0,0.11450198,0.12179835,0.30734828,0.38381153,0.26318747,0.08271083,0.0026979595,0.053721055,0.08334485,0.0,0.0,0.0,0.0,0.0],[0.0033418685,0.0,0.028611906,0.1888012,0.15679443,0.15265578,0.0399969,0.1137191,0.3044991,0.28856927,0.22100413,0.13752611,0.07588448,0.0,0.0,0.0,0.0,0.0,0.0,0.007740155,0.076690845,0.0,0.0,0.0,0.0,0.0,0.00253658,0.015990786,0.0063940883,0.0,0.010953382,0.17917325,0.15611322,0.18685001,0.054449536,0.103515685,0.28147468,0.2744506,0.18839651,0.14016408,0.109014146,0.018470824,0.0,0.0,0.0,0.0,0.0,0.0,0.050605,0.0,0.0,0.014683545,0.0,0.0,0.0,0.010311298,0.012845978,0.0,0.0,0.15491386,0.13349293,0.20677453,0.05560615,0.08048904,0.21971568,0.24179666,0.14526263,0.10435553,0.0727839,0.052997224,0.031308085,0.048047647,0.0,0.004372984,0.0,0.0,0.03232844,0.0,0.0,0.02105505,0.0,0.0,0.0,0.020257346,0.017757729,0.008697264,0.0,0.1168243,0.12272215,0.25394887,0.08796437,0.10502292,0.19565263,0.2259388,0.0970913,0.047359146,0.010470115,0.044833988,0.080917805,0.14120097,0.059890784,0.038655475,0.0,0.0,0.02333147,0.019097224,0.0,0.055859655,0.0018495768,0.0,0.0,0.024797045,0.02436535,0.032972462,0.0,0.096164286,0.12796122,0.24954376,0.06939959,0.1337134,0.22488265,0.25533342,0.102242984,0.027681746,0.0,0.024365656,0.12558837,0.22866243,0.124260694,0.070679575,0.0025110543,0.0,0.00027257204,0.020778991,0.0,0.025782466,0.0,0.0,0.0,0.026490517,0.027288094,0.033136472,0.0,0.12758787,0.19442455,0.26989663,0.12100575,0.18458109,0.28539333,0.36758333,0.17124514,0.053588882,0.0,0.033489317,0.14263985,0.27104506,0.15365076,0.11036639,0.038132623,0.0,0.0,0.016027965,0.018845424,0.018097691,0.0,0.0,0.0,0.011680551,0.030624747,0.018567204,0.0,0.14381067,0.23101465,0.29897165,0.2210607,0.24601454,0.34632313,0.50247526,0.29903448,0.110456586,0.0,0.04271201,0.15887183,0.26419273,0.16658995,0.15944275,0.07371387,0.0,0.0,0.021192342,0.044938304,0.013449833,0.0073278844,0.0,0.0,0.0,0.03446435,0.00011767447,0.0,0.15233539,0.235054,0.27168548,0.2605769,0.25715712,0.3390345,0.5955963,0.4376343,0.16893148,0.0,0.07056381,0.19049151,0.23366153,0.1499092,0.14990659,0.081959665,0.0,0.0,0.031500205,0.054217316,0.008092642,0.07750675,0.0,0.0,0.0,0.043974794,0.0,0.0,0.16016816,0.22957602,0.16476677,0.15980089,0.17623422,0.28777128,0.6376146,0.5674113,0.21976963,0.0,0.12413482,0.2290029,0.2434102,0.19690081,0.17032799,0.1385515,0.04605367,0.01311399,0.089816995,0.07994321,0.0,0.1236034,0.0,0.0,0.0,0.053062715,0.0,0.0,0.15982577,0.20749134,0.053500034,0.12116739,0.18461621,0.31756198,0.7112198,0.6822805,0.2751299,0.01044365,0.14755154,0.2568748,0.24769056,0.27062926,0.22223035,0.21719995,0.109109156,0.046672106,0.14541942,0.112770915,0.0,0.17715947,0.0,0.0,0.0,0.05562628,0.0,0.0,0.16785377,0.21541277,0.047025107,0.11177071,0.16962811,0.3085134,0.7182709,0.70461154,0.30483276,0.029361688,0.17290755,0.2655114,0.24716502,0.30958527,0.28039062,0.26665136,0.12086392,0.049724154,0.15508427,0.11205551,0.0,0.17545101,0.0,0.0,0.0],[0.0,0.04201559,0.036168285,0.0,0.007650107,0.07986985,0.028611831,0.07302239,0.038196385,0.033210315,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017763063,0.003949508,0.0,0.0,0.0,0.009663962,0.0,0.0,0.0,0.0,0.030350871,0.02350574,0.0,0.0,0.064016506,0.01137206,0.096301034,0.048131935,0.02490411,0.0,0.0,0.010440916,0.026679873,0.019384928,0.0,0.007964522,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0073928833,0.0,0.0,0.0,0.043215543,0.0,0.07041995,0.027769774,0.014883816,0.0,0.0,0.060960643,0.08346963,0.08234554,0.0,0.019251108,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.058371164,0.0037682354,0.06283837,0.01737167,0.0042144656,0.0,0.0,0.038737454,0.08514321,0.10680247,0.016983747,0.04926812,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00017489493,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026810199,0.072350234,0.0068194047,0.05240103,0.020632252,0.012178279,0.0,0.0,0.05423305,0.06467454,0.115246,0.047812738,0.084132895,0.0,0.009604327,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0057190433,0.06571984,0.1080373,0.054173082,0.09231685,0.05216179,0.036145635,0.0,0.0,0.09713799,0.060953476,0.13629942,0.06991434,0.09794981,0.010564737,0.031197563,0.0,0.0,0.0,0.004967645,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07444815,0.13625734,0.102592126,0.14930227,0.09539156,0.073753975,0.03504938,0.04675048,0.15602615,0.06777053,0.15171093,0.079153925,0.10807392,0.032590084,0.043975852,0.0,0.0,0.0,0.0096701905,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07799409,0.1511556,0.123231724,0.16628,0.102054514,0.110972576,0.10822968,0.16103593,0.22650366,0.07842626,0.16626464,0.072280906,0.08648977,0.04351957,0.055218823,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06943549,0.12818255,0.07630679,0.115997955,0.061539017,0.1420448,0.17886592,0.24253714,0.2942081,0.10220463,0.20397483,0.11538085,0.10008778,0.08985445,0.110585146,0.034495026,0.0,0.0,0.0036689192,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0462327,0.12527649,0.07626405,0.14369847,0.07884016,0.18665877,0.24016574,0.30947107,0.32687974,0.08764285,0.18536532,0.14731514,0.1240519,0.15282992,0.17119166,0.097112626,0.03780567,0.0052164346,0.00959672,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04360141,0.12936322,0.07016024,0.1303188,0.06733756,0.20849779,0.27451688,0.32887295,0.34258068,0.08520579,0.1809712,0.1573633,0.15445937,0.18522586,0.20322502,0.10804298,0.044818476,0.0072400346,0.003079936,0.0,0.0,0.0,0.0,0.0],[0.0,0.029423006,0.077883825,0.0,0.06300583,0.14991651,0.09321116,0.13675173,0.082333416,0.050999172,0.020674787,0.0,0.0,0.033746317,0.031878352,0.021452121,0.067731015,0.0,0.0021855682,0.016058363,0.028017804,0.0,0.0,0.0021864474,0.06828681,0.0,0.019880272,0.0,0.0,0.031563103,0.08965803,0.0,0.049286537,0.12667507,0.096698835,0.16698052,0.094218835,0.039162032,0.0,0.014134161,0.08653833,0.092140496,0.036483817,0.0,0.07382645,0.0,0.0,0.0,0.03089258,0.007685162,0.0,0.0150003955,0.08124904,0.0,0.0,0.0,0.0,0.009765223,0.071867585,0.0,0.032355875,0.10136911,0.07666248,0.1516099,0.084954806,0.0299626,0.0,0.04688164,0.08798683,0.08600451,0.02650091,0.0,0.027027808,0.0,0.0,0.0,0.017390974,0.0066518337,0.0,0.018005326,0.067868456,0.0,0.0,0.0,0.0,0.0,0.0545377,0.0011147112,0.03872806,0.09305772,0.07203962,0.13423654,0.07538663,0.025534108,0.0,0.023718223,0.04190985,0.033584565,0.014567576,0.0,0.0048478246,0.0,0.0,0.0,0.017765075,0.022863671,0.005212635,0.023278825,0.061324008,0.0,0.0,0.0,0.0,0.0038247406,0.048726276,0.024555631,0.05175525,0.079773076,0.046834387,0.10774186,0.06217347,0.03284082,0.0,0.032054335,0.050874285,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0038049966,0.01609128,0.0,0.007462561,0.032339945,0.0,0.0,0.0,0.0,0.021091178,0.047122285,0.011794083,0.060429297,0.06595783,0.04187289,0.10482661,0.07643445,0.06516275,0.0,0.05014757,0.06884456,0.0,0.0014933944,0.0,0.0,0.0,0.0,0.0,0.0,0.01581461,0.0,0.00081057847,0.01310236,0.0,0.0,0.0,0.0,0.016376704,0.01619146,0.0,0.045787223,0.03832531,0.03677731,0.12358393,0.104547985,0.10436436,0.025059737,0.08696298,0.09475458,0.003721118,0.0046188533,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00430654,0.0,0.011210725,0.00019276142,0.0,0.0,0.0,0.03335669,0.02642215,0.0,0.049312614,0.02197577,0.017881036,0.14213242,0.13048504,0.14785212,0.12069039,0.15810318,0.1358426,0.030506335,0.015213825,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010471746,0.042436637,0.044568576,0.014078915,0.0,0.0,0.06466336,0.052155666,0.0,0.04966309,0.0037617087,0.0,0.13398139,0.14535092,0.20367041,0.20577084,0.21233897,0.14866333,0.072083905,0.07754862,0.0,0.0,0.027361609,0.013505951,0.0,0.0,0.0,0.0,0.017819509,0.057684444,0.07240169,0.049157806,0.0,0.00060865283,0.06628444,0.05629769,0.0,0.050892077,0.00989794,0.0,0.17113149,0.18015368,0.2544179,0.25957495,0.25643516,0.15000907,0.07528801,0.083486214,0.0,0.0,0.06726367,0.06078267,0.022317663,0.03817922,0.0,0.0,0.017171122,0.06548952,0.09629983,0.08208708,0.0,0.0,0.0477873,0.040538117,0.0,0.04772237,0.0049731284,0.0,0.1712744,0.18850236,0.3073337,0.2877608,0.27918553,0.15593086,0.06580803,0.07827836,0.0,0.004598528,0.09669812,0.08335984,0.01822748,0.0453571,0.0,0.0,0.0014637262,0.06480686,0.08280155,0.08167658,0.0],[0.0,0.030247785,0.08398883,0.017142564,0.08358265,0.022202104,0.044151478,0.022974528,0.027050123,0.0,0.0,0.0,0.029820941,0.0198142,0.01392401,0.0,0.018356815,0.06734573,0.055665083,0.0070495084,0.0,0.0,0.0,0.025297694,0.024232164,0.0,0.0,0.015779257,0.0,0.028362803,0.09570434,0.036380462,0.09113263,0.025188588,0.051698342,0.038990967,0.023511186,0.00026111305,0.000049695373,0.023878902,0.06884443,0.032354318,0.0,0.0,0.00542067,0.03713096,0.032428503,0.019306429,0.0,0.0,0.0,0.019184932,0.018713966,0.0,0.0,0.018884867,0.0,0.008548833,0.08799426,0.043556385,0.096751,0.024718955,0.044823915,0.03511776,0.012067199,0.0021897405,0.0,0.011416748,0.06448036,0.03334724,0.0,0.0,0.0,0.0,0.0,0.015134454,0.0,0.0,0.0,0.005325556,0.009961419,0.0,0.0,0.02081646,0.0,0.0,0.08281697,0.053388163,0.10582066,0.027957857,0.039369456,0.03321015,0.013519175,0.0,0.0,0.0,0.024766982,0.021799468,0.0,0.0,0.0,0.0,0.0,0.024942212,0.013960704,0.0,0.0,0.0,0.0013694912,0.0,0.0,0.021554261,0.0,0.0,0.082155675,0.07223362,0.1087408,0.021260507,0.0032936335,0.009267129,0.0031662732,0.0025960654,0.0,0.0,0.0010883957,0.0037883818,0.0,0.0,0.0,0.0,0.0,0.028322943,0.020464905,0.0,0.0,0.0,0.0,0.0,0.0,0.020568103,0.0,0.0068493187,0.068674825,0.06110882,0.077738866,0.0,0.0,0.0,0.0007532984,0.023515858,0.004888952,0.0,0.017034575,0.008293219,0.0,0.0,0.0,0.0,0.0,0.022365548,0.01972191,0.0,0.0,0.0,0.0,0.0,0.0,0.018916748,0.0,0.0,0.030592218,0.036517695,0.041311964,0.0,0.0,0.0,0.0,0.042160794,0.045035213,0.025605202,0.026619472,0.00740546,0.0,0.0,0.0,0.0,0.0,0.014891401,0.0130768195,0.0,0.0,0.0,0.0,0.0,0.0,0.021263346,0.0,0.012403548,0.03221914,0.034972183,0.009789318,0.0,0.0,0.0,0.011412993,0.07646288,0.11023788,0.08106321,0.048312612,0.003743276,0.0,0.0,0.0,0.0,0.0,0.009584926,0.008058332,0.0065032616,0.0,0.0,0.00091558695,0.0,0.0,0.02222675,0.0071378127,0.032806046,0.04141009,0.02668675,0.0,0.0,0.0,0.005071953,0.034934968,0.11564986,0.16610532,0.11345334,0.057839878,0.015777275,0.0,0.0,0.0,0.030415528,0.0,0.013837263,0.00754907,0.030131578,0.0,0.0,0.02262181,0.0,0.0,0.021216251,0.013598308,0.034738444,0.03962297,0.021006644,0.0,0.0,0.0,0.011531636,0.05545044,0.14582962,0.20874918,0.14937171,0.071938515,0.009826891,0.0,0.0,0.0,0.06071695,0.0,0.017144732,0.004792884,0.047443636,0.0,0.0,0.027564183,0.0,0.0,0.020105548,0.004417166,0.017897576,0.028660998,0.019300371,0.0,0.0,0.0,0.013085008,0.06454658,0.17573176,0.23767786,0.16503286,0.08168836,0.0,0.0,0.0,0.0,0.08494485,0.0,0.017419823,0.0045681745,0.057124883,0.0,0.0,0.025634967,0.0,0.0,0.02498798]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"dim1\"},\"tickmode\":\"array\",\"tickvals\":[14,42,70,98,126,154,182,210,238,266,294],\"ticktext\":[\"-3.00\",\"-2.40\",\"-1.80\",\"-1.20\",\"-0.60\",\"-0.00\",\"0.60\",\"1.20\",\"1.80\",\"2.40\",\"3.00\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"dim2\"},\"tickmode\":\"array\",\"tickvals\":[14,42,70,98,126,154,182,210,238,266,294],\"ticktext\":[\"-3.00\",\"-2.40\",\"-1.80\",\"-1.20\",\"-0.60\",\"-0.00\",\"0.60\",\"1.20\",\"1.80\",\"2.40\",\"3.00\"]},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(0,0,0)\"],[0.125,\"rgb(37,37,37)\"],[0.25,\"rgb(82,82,82)\"],[0.375,\"rgb(115,115,115)\"],[0.5,\"rgb(150,150,150)\"],[0.625,\"rgb(189,189,189)\"],[0.75,\"rgb(217,217,217)\"],[0.875,\"rgb(240,240,240)\"],[1.0,\"rgb(255,255,255)\"]]},\"title\":{\"text\":\"Autoencoder latent space visualization\"},\"width\":640,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b04fa1e3-88ab-47bb-b5b0-f5ad5189e3c1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def create_grid_of_latents(\n",
        "    model, interpolation_range=(-1, 1), n_points=11, dims=(0, 1)\n",
        ") -> Float[Tensor, \"rows_x_cols latent_dims\"]:\n",
        "    \"\"\"Create a tensor of zeros which varies along the 2 specified dimensions of the latent space.\"\"\"\n",
        "    grid_latent = t.zeros(n_points, n_points, model.latent, device=device)\n",
        "    x = t.linspace(*interpolation_range, n_points)\n",
        "    grid_latent[..., dims[0]] = x.unsqueeze(-1)  # rows vary over dim=0\n",
        "    grid_latent[..., dims[1]] = x  # cols vary over dim=1\n",
        "    return grid_latent.flatten(0, 1)  # flatten over (rows, cols) into a single batch dimension\n",
        "\n",
        "\n",
        "grid_latent = create_grid_of_latents(autoencoder, interpolation_range=(-3, 3))\n",
        "\n",
        "# Map grid latent through the decoder (note we need to flatten (rows, cols) into a single batch dim)\n",
        "output = autoencoder.decoder(grid_latent)\n",
        "\n",
        "# Visualize the output\n",
        "utils.visualise_output(output, grid_latent, title=\"Autoencoder latent space visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW7oub_W6ejv"
      },
      "source": [
        "This code generates images from a vector in the latent space which is zero in all directions, except for the first two dimensions. (Note, we normalize with `(0.3081, 0.1307)` in the code above because this is the mean and standard deviation of the MNIST dataset - see discussion [here](https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457).)\n",
        "\n",
        "This is ... pretty underwhelming. Some of these shapes seem legible in some regions (e.g. in the demo example on Streamlit we have some patchy but still recognisable 9s, 3s, 0s and 4s in the corners of the latent space), but a lot of the space doesn't look like any recognisable number. For example, much of the middle region is just an unrecognisable blob. Using the default interpolation range of `(-1, 1)` makes things look even worse. And this is a problem, since our goal is to be able to randomly sample points inside this latent space and use them to generate output which resembles the MNIST dataset - this is our true goal, not accurate reconstruction.\n",
        "\n",
        "Why does this happen? Well unfortunately, the model has no reason to treat the latent space in any meaningful way. It might be the case that almost all the images are embedded into a particular subspace of the latent space, and so the encoder only gets trained on inputs in this subspace. To further illustrate this, the code below feeds MNIST data into your encoder, and plots the resulting latent vectors (projected along the first two latent dimensions). Note that there are some very high-density spots, and other much lower-density spots. So it stands to reason that we shouldn't expect the decoder to be able to produce good output for all points in the latent space (especially when we're using a 5-dimensional latent space rather than just 2-dimensional as visualised below - we can imagine that 5D latent space would have significantly more \"dead space\").\n",
        "\n",
        "To emphasise, we're not looking for a crisp separation of digits here. We're only plotting 2 of 5 dimensions, it would be a coincidence if they were cleanly separated. We're looking for efficient use of the space, because this is likely to lead to an effective generator when taken out of the context of the discriminator. We don't really see that here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "2F1LLu-86ejv",
        "outputId": "7789f400-adb2-4a1f-d13c-f403398f74dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3306efd4-2f32-47f2-8b9f-3cd669d363fa\" class=\"plotly-graph-div\" style=\"height:700px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3306efd4-2f32-47f2-8b9f-3cd669d363fa\")) {                    Plotly.newPlot(                        \"3306efd4-2f32-47f2-8b9f-3cd669d363fa\",                        [{\"hovertemplate\":\"label=0\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"0\",\"showlegend\":true,\"x\":[0.3568769,-0.72608644,-2.1546302,0.7382238,1.4496195,-1.9734242,0.21790195,0.9849719,1.2060442,0.6675657,1.2146301,-1.1768284,1.6971277,-2.132482,1.0074472,0.24558246,-0.7779281,0.7995397,-0.93222487,0.7016077,1.0498528,0.65457964,0.76723564,-0.19173884,-0.898227,1.3589966,0.13728493,1.2004156,-0.44912797,0.8350177,-0.70781493,-1.4415771,0.38010907,0.100782394,1.2063459,-1.7121432,0.41922462,-0.70396966,1.2721244,0.64365065,-0.89586663,-0.17786004,1.017231,-0.8831549,1.3391097,-1.6829363,-0.71517444,1.1512545,-1.1976196,0.6196228,-0.104745686,-0.44475845,-1.0667099,-0.8116541,0.8367621,1.943988,-1.3328085,1.9627038,-0.4056225,1.8288697,-0.112716585,-1.7936733,0.1899904,1.4429625,-0.95259196,-1.4417297,0.711216,1.7165109,1.1927611,1.6954054,0.47974914,-1.3590487,-0.5502144,0.6591978,-0.0977501,0.9745563,-0.07663572,0.26938117,-0.8564,-0.31262198,-0.5547156,1.2451848,-0.72102046,0.37545425,0.74929726,-0.017227322,-0.81335986,0.25493377,0.7606996,0.37050515,-0.07551488,-0.44939384,0.06451169,-1.6948453,-0.7329955,0.6021144,-1.2495205,0.05840051,0.122351944,0.48061633,-0.21532764,-0.19206545,-0.32630292,0.30183172,-0.26402298,0.07244125,0.50301284,0.7919216,0.18626803,0.81682503,-0.6962953,-2.0942807,-1.2964587,-0.5824571,1.2061894,-0.49432784,-0.26304746,1.6948782,0.14171177,1.2291615,1.2912923,1.1562688,-0.53369987,-0.21417707,-0.29785174,-0.3120042,-1.2282392,-0.13383529,2.3034453,-0.3702544,0.071683645,-1.6361705,0.33043373,-1.1580756,-0.9141546,-0.3806376,-1.8449469,-1.8161551,0.8370315,-0.48347676,-0.15262656,0.6009389,1.0233706,0.045321167,-0.69529927,-0.8197328,1.0819448,0.65580237,1.8091618,-2.0923202,0.7695489,0.78592396,0.3545075,0.4319505,-1.3009174,0.22814798,0.86597276,1.4603295,0.9755392,1.0773338,0.2761351,2.163406,1.3891898,0.12699848,-1.7198685,0.8646076,-0.30583733,-0.8100134,0.56593525,0.8142762,1.101509,0.9860935,0.7764324,-0.692039,0.18034363,-0.21866041,-0.93714863,2.0426073,0.13599175,0.6592277,1.0702848,0.86926496,0.50300485,1.5590181,0.46056968,0.05972299,1.5404857,-1.483453,0.91593516,0.38977545,1.872027,0.90707314,1.1541346,2.0056906,2.0493565,-0.5312014,0.97440505,1.1584172,0.9335848,1.4830396,0.8825234,1.908152,0.25922877,-0.30528277,-0.118563056,-0.44177815,0.6040796,1.7290567,0.9187943,-0.21374658,0.61985934,0.37570506,0.37350172,0.1819607,0.2543494,0.8599782,0.44732136,0.9893278,-0.21558101,1.7090491,0.5892896,1.2061993,-1.8572824,-0.7973385,0.50790095,0.20598114,2.0416894,1.3859053,0.14924937,0.6217594,-1.1003866,-0.3771761,-0.2864523,0.62099254,-1.369807,2.2353616,-0.63713956,-1.4357328,1.2239078,-0.8934529,-0.6757063,-0.18340151,1.3847978,0.9776858,-0.10083127,-0.5435019,0.9029528,-0.2387819,-1.2880045,2.480926,-1.4943037,-0.56823933,1.6814808,0.9125756,-0.9773662,1.1674984,-0.41810688,0.7770114,0.8241317,-0.88565683,-0.43068334,0.11098391,-0.4879346,-0.32569003,-0.6410326,-0.68377817,-0.07032493,-0.22905989,1.5705463,2.5119004,1.6551076,-0.47321725,1.2401185,-2.1746268,-1.807967,0.21243113,0.9157531,0.7148857,1.1046677,-0.6129612,0.28332132,-0.24238068,0.35468453,-2.0584297,1.3455034,-1.0965235,-0.57546127,-2.2767103,0.6004032,0.061223447,0.112229705,-0.28396252,-0.7618648,0.3502671,-1.5595068,0.8825116,-0.69846094,-0.8883612,-1.2592449,0.83948827,0.3602267,-0.733413,-0.4141226,0.36551648,1.4658082,0.9296864,-0.20822394,0.5452474,-0.28663224,1.7853316,-0.018638998,0.94537365,-2.0523038,0.902596,-0.35340363,-1.8169711,-1.9209512,0.4634115,-1.465954,-0.4005842,-1.6461746,0.1609394,-0.72218025,0.17461431,-1.3399456,-0.94438124,0.6407503,-0.068350226,-0.75932115,-0.8124598,-0.9463511,-0.37447345,1.0643076,0.91030157,-0.91828316,1.3237503,-1.3351977,2.2185411,0.64811265,-0.73066914,-1.3570949,-1.076555,0.5801825,-1.4551342,0.9936968,0.05266443,-0.6431142,-0.3789545,0.4418924,-1.5155953,0.12530869,-0.6525679,0.55791295,0.078676224,-0.7746709,-0.27144355,-0.8757458,0.6672549,-0.4233341,-0.38724205,-0.073442966,1.5231037,-0.66049653,-0.3682015,1.3425273,0.40312958,0.040343583,0.83165944,-0.88583827,-1.070735,-1.1769967,-1.8482932,0.3980183,0.51323086,-0.5119386,1.3611983,-0.42735225,0.34883547,-0.90659153,0.8034018,-2.0108886,0.6640451,0.22954285,-0.43919665,-0.3122165,-1.2093319,0.029699653,-1.5805488,-0.30761382,0.46768296,-0.7453042,-0.659472,-1.0209976,-0.39577693,0.006535977,-1.8398354,0.19604814,0.7526045,-1.7313476,-2.2459784,1.5548971,0.13028383,-0.42325455,0.31642443,1.1869397,0.14119142,-0.6616334,-0.31776875,-0.0062439144,-0.70509195,2.0186553,-2.1707544,-0.69984114,0.23558736,1.1733236,-1.4614613,0.93849814,-0.40968966,-0.011294544,1.9472483,-1.995335,1.3285041,1.1871521,-0.008983463,1.8694061,-1.2162795,0.14387757,0.45425153,0.69802713,1.7730623,-0.6448437,0.75563145,0.14341551,0.9585819,1.456381,-0.9615407,0.48209244,-1.6645885,0.2709204,0.89145887,-0.51174146,0.62346697,-0.20378083,1.2854214,1.550845,0.5798283,0.50444365,0.5308331,0.056697488,-0.15330577,1.7380947,0.8899373,0.733394,0.08418,-0.5426713,1.0851755,-0.7831429,0.87732446,0.3514018,1.1179328,0.1649493,-1.5470368,1.7988681,0.03919518,0.84146965,1.8554989,1.9502329,0.7234527,1.0423988,0.8862777,0.97535074,-0.24066652,0.078469604,1.6164283,0.09304649,1.2751226,1.6871678,0.8259406,1.719566],\"xaxis\":\"x\",\"y\":[-0.46585387,-1.8937464,-2.055584,-0.68309844,-0.1629516,-2.1782045,-0.31528148,-0.61421055,-0.5570058,-0.9471615,-0.18239152,-1.5242853,0.41697294,-2.3674192,-0.43322814,-1.219619,-1.0173122,-0.026153952,-0.81051975,0.23156492,-0.35976595,1.5370708,0.39386266,-1.5772817,-1.9031421,-0.72954625,0.11037837,-0.1703327,-1.9030123,0.027375773,-0.88920385,-2.4120858,-0.5549478,-0.9387937,0.26231575,-1.4713093,-1.0247073,-0.74719965,0.1735517,-0.9447352,-1.2523365,-0.958084,0.4464273,-2.1532826,0.9188262,-1.3967463,-1.1457418,-1.023546,-2.9024,-2.0622568,-0.44192827,-0.83670497,-1.956068,-1.493006,1.1903273,0.4504236,-1.4890311,0.105518,-2.52965,-0.061223872,-1.8898672,-3.0768957,-0.38831627,-0.3436703,-2.802849,-1.6280488,-0.13075782,0.34391874,-0.28576374,0.6278555,2.1098533,-1.6425321,-0.7698441,-1.3704821,-0.521769,-0.6606276,-0.9162557,-1.4276378,-1.468438,-0.3849335,-1.10239,-0.12873161,-1.2923352,-1.2930691,-1.5934049,-1.1115489,-2.3487682,-1.1821924,-1.3168913,-1.0441778,-1.8715785,-1.8548357,-1.0375901,-2.0621996,-2.4632993,1.3073688,-1.9746827,-1.6827642,-0.9889983,-1.1709033,-1.9109795,-1.1281879,-1.5583906,-0.5921692,-1.5881553,-0.5983189,-0.2566964,1.8650273,-0.14649628,-0.25434268,-2.5117047,-2.0929449,-1.8163989,-2.2381723,-0.02964165,-2.0263479,1.4397486,0.7923399,-1.5171065,-0.35449705,-0.5730889,-0.5405853,-1.2972794,-1.6472389,-1.3043153,-1.027751,-2.625351,-0.87929666,0.5294192,-1.9036616,-1.8675888,-1.5636103,-0.6803965,-0.9029549,-1.563016,-1.0316644,-2.1946473,-1.9497743,-0.5941869,-2.4753804,-1.8255988,-0.7935348,-0.40411347,-0.81843865,-1.3302383,-2.1732183,-0.61932474,0.8500432,0.91008973,-1.9618115,-1.6772696,-1.2793756,1.3044429,-0.6457761,-1.3210362,-0.8489537,-1.1366365,-0.86966264,-0.7424486,-0.43423033,-1.3646594,0.4961316,-0.30432373,-0.79084855,-2.2287652,-0.64670396,-1.2184212,-1.2688794,0.38733965,-0.7854277,1.0063603,1.0629535,-0.3481226,-0.97189665,-0.90038395,-1.4945129,-2.52283,0.4071294,-0.689626,-1.0051205,-0.05141496,-0.41953474,-0.9162369,-0.19109942,-0.79174626,-0.7149939,-0.35899112,-2.926517,-0.30397573,-1.7137369,-0.946683,-0.797886,-1.1847558,0.39101213,-0.37290853,-0.59503824,-1.0202658,-1.275406,-0.3919887,0.6065179,-1.3762523,-0.7857893,-0.7056665,-1.1869532,-0.66790885,-0.5505416,1.0901657,-0.322416,-0.32979718,-0.20489083,1.7804172,-1.2825925,-0.25155455,-2.0385482,-1.0617512,0.049873903,1.1680554,1.6389778,-0.5196649,0.3744005,-0.88484293,0.09439553,-2.3537843,-1.2947427,0.7269656,-1.4029208,0.51671255,1.8074241,-0.36718726,-0.9770123,-2.4429083,-0.6294995,-1.0301815,-1.1448351,-2.4292426,0.5982769,-2.4821627,-2.2592654,-0.670978,-1.9192498,-1.9499162,-1.5538706,0.82354563,-0.7909718,-0.7809532,-2.4633067,-1.4869983,-0.47290456,-2.1702466,1.8899986,-2.307542,1.8001755,-0.12778993,1.5423439,-1.0197635,-0.6932802,-0.25468627,0.11759041,1.7990711,-0.8772575,-1.150368,-0.5233978,-0.74495846,-0.55110574,-1.4173622,-1.7918093,-2.4408777,-0.8169083,-0.6083706,0.624922,-0.37326282,-1.1638256,0.9067575,-1.5029774,-1.7905406,-0.45669752,-0.20781103,-0.66685736,-0.14488651,-0.9200791,-0.6120404,-0.32832354,1.4083495,-1.9799937,-0.1853939,-1.6311536,-1.1344868,-2.140371,-0.9552642,-1.079439,1.0991176,-2.099703,-1.7541685,-1.6604769,-2.2341661,0.13868384,-0.79628485,-2.3916392,-2.0053902,1.1219985,-0.6047821,-1.2765545,-0.9241476,-1.2416908,1.3052568,-0.93689513,-1.5085406,-0.54032695,-1.0428951,0.8934263,-1.4364858,1.1556913,-2.089694,1.1121532,-0.892902,-2.3098378,-2.1330457,-0.5232881,-2.4033942,-0.5681724,-1.7355745,2.062182,-0.83681643,-1.8414685,-1.572398,-2.1572342,-0.19178516,1.248067,-2.397361,-1.3325623,-1.4749049,-2.2491078,0.47262174,-0.63725287,-0.92259973,-0.085971564,-2.1010935,0.81854486,-0.29378384,-1.3113068,-2.1488492,-1.2736659,0.948665,-2.2760413,-0.090925425,-0.9428279,-1.4160316,-1.16228,-0.9530174,-2.2454257,-0.6376914,-2.8817024,-0.9885991,-0.6678763,-2.0680852,-0.1485015,-1.0802449,-0.92635816,-1.5695188,-0.60221195,-2.768477,-0.7656426,-1.4436476,-1.4075491,0.03598398,-1.1994193,0.11788325,0.041090697,-0.1290285,-1.4832827,-1.847112,-1.7601025,-0.25582546,-0.6487019,-0.797794,1.3797185,-0.6353706,0.5150528,-2.3804445,-0.25598294,-2.2950041,-1.3487155,-0.81190324,-2.388886,-1.5001369,-1.3685687,-0.63925874,-2.3940322,-0.8350215,0.5258776,-0.9627964,-1.9548715,-0.9172689,-1.572945,-1.7908796,-2.219039,-0.11744672,0.47891688,-1.9374765,-2.3341446,0.62326723,-1.3093116,-0.43585998,-0.37463397,-0.40368873,1.1717356,-1.410202,-0.7287947,-0.4828158,-0.6999265,1.0946112,-2.0686767,-1.0522128,-0.7916451,-0.95265234,-2.3817298,-0.9544108,-0.6091992,-2.0893548,0.5867372,-2.6407254,-1.0235512,-0.90115714,-1.4400858,-0.35651383,-1.8596288,-0.5869329,-0.5536978,-0.5821619,0.0010568053,-1.7214233,0.90737426,-1.2986898,-0.5916865,0.67596316,-2.0202022,-1.0308558,-2.6094525,-0.39273417,0.5237063,-2.1267304,-0.54576665,-0.3335157,-0.6507303,0.8004298,-1.7757899,-1.1004653,-0.49831146,-0.3390474,-1.6161318,1.3657502,-0.89419436,0.035023943,-0.6180958,-2.0306137,-1.3302174,-1.4321004,-0.42610842,1.5574024,-0.30157587,-0.91937584,-2.5324523,0.19278939,-1.155573,1.326276,0.45190406,1.3162206,-1.22614,1.1322062,0.02958177,-0.07220175,-1.1939621,-1.6689628,0.042732,-0.9445056,1.8600253,-0.70407206,-0.8385697,1.9491292],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=1\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"1\",\"showlegend\":true,\"x\":[0.082239926,-0.16413142,0.025571376,-0.22268781,-0.40869322,-1.3529733,-0.13550076,0.15638131,-0.94193244,-0.113425374,-1.3331072,-0.73494166,-0.9555622,0.43943363,0.443721,0.44580054,-1.9064633,-1.2507272,-2.6121182,0.66804504,0.22230834,-1.3653432,-0.37331283,0.6877351,-1.6325517,-1.2144015,-2.443159,-1.7379329,-1.4540159,-0.5237584,-0.5216777,-0.9790161,-1.6790943,-0.6033821,-1.6789519,0.29891002,-2.5306654,-0.331732,-0.2380293,-1.9757869,0.38435906,-0.36284858,-1.3771619,-0.2753964,0.14339525,-2.5649633,0.4828313,-0.043715894,-2.6876378,-0.1331613,0.39920276,0.7220874,0.1982094,0.20747203,-1.4040126,-0.18561813,0.7648562,0.35431325,0.25383687,-0.56379557,0.18978155,-1.3051432,-1.4392308,-0.86293983,0.2808131,-0.4580629,-1.6690549,0.3719027,-1.9329038,-3.1481557,0.5711548,-0.7723036,0.17259598,0.0007444918,0.82531893,-0.1614678,-0.11371231,-1.2570767,-2.114874,0.29469824,0.58949554,0.36319798,-1.9929909,-1.8297329,-0.52812934,0.0690248,-0.60665184,-1.4976981,0.47973102,0.34126115,-0.9569402,-0.09338716,-1.7722137,0.2733755,0.37462598,-0.54171175,-1.6339157,0.07971537,-1.6259874,-1.5007252,-2.3468628,-1.3335426,-2.4697695,-1.8145387,-0.19523504,-2.0144916,-0.51043135,0.6935984,-0.59774,-0.7389182,-1.1038157,-1.268075,-1.4391778,0.6760541,-1.3087454,0.3232242,-0.82183915,0.5640125,-0.022640467,-1.024123,0.21975821,0.72870874,-0.46780968,-0.12055224,-0.108270794,-2.0219278,-1.7493027,-0.91951966,0.5965171,-1.3304291,-1.9074329,0.823351,-1.4680771,-0.51339644,-1.8002687,0.25850052,-0.4152117,-0.57914245,-0.7761692,-1.1617744,-0.8659813,-0.3613705,0.50900394,-1.7343626,-1.2695258,-1.2561033,0.07442501,-0.72613096,-0.28126898,0.09779444,0.07053417,-0.04829234,-1.958212,-0.3321651,-1.3581438,-0.22125123,-1.9959307,-1.1471622,0.232261,-1.1417472,-1.6646512,-0.07435554,-2.3655176,0.2779529,-1.1197524,-0.06332132,-0.06687617,-1.5085588,-1.4476818,-1.1908917,0.35629445,-1.2187731,-0.5369418,-2.085658,0.023152024,-0.007818341,-0.820076,-0.66808367,-1.7565689,-0.61973554,-1.8243042,-0.6113113,-0.081843555,-1.9850677,-0.2329148,-1.7609409,-0.23884985,0.054412454,-1.8807433,0.3178228,0.13809204,-2.1434994,0.1283052,0.33811456,-0.3677564,-2.3761413,-2.2471528,-1.7194967,0.31308496,-2.7265034,-0.13284534,0.09051877,0.100207925,-1.7244446,-0.2995109,-1.9187912,0.14351386,0.535405,-0.3972732,-0.31624827,-2.2039294,-0.35992652,0.19876915,0.08228716,-0.11860761,0.4510581,0.25265008,-2.193973,-1.3857942,0.33616263,-2.0313902,-1.2678144,-1.0312852,-0.4202126,0.60321605,0.07015726,0.23484969,-0.9286629,-2.263462,0.35517418,-0.6853727,0.16926527,-1.9486352,0.516702,-2.2676406,0.38719457,-1.5497853,-1.1565127,-2.094408,-0.71043587,0.4012301,-0.23484734,-0.05530384,-0.5158622,0.528022,0.69019103,0.27884424,-1.2541451,-1.4448067,-0.29437864,-0.27792472,0.08325565,-1.6425531,-1.7508451,0.46300668,-1.5031304,0.002595991,-0.5339447,-1.6348548,-1.509017,-0.06198144,-1.2878102,-0.7874017,0.6328416,-1.1999563,-1.6097018,-0.0930886,0.13141787,0.14376038,-1.339796,0.039083004,0.005494833,-1.8384161,0.23445648,-0.89729744,0.37012762,0.023206353,-2.0552254,0.6346251,0.40705723,0.07693669,-1.5207621,0.12549764,-1.4420495,0.08524084,0.5142846,-0.68828285,-0.101792514,0.09811059,0.32144737,-0.82138985,0.36220974,0.21696877,-0.20820837,-0.92755526,-1.0000196,0.5166774,0.53503406,0.34590024,-0.9429866,-1.7995495,0.15729213,-0.58100003,-0.40507686,0.04362464,-1.8725386,0.4940613,0.044276655,-1.4804281,-1.1799692,0.4878257,0.54167736,-1.4637762,-0.031608433,0.2932034,0.38503742,0.35646552,-0.8276268,-1.0468023,-1.62918,-0.06501466,0.3564,-1.651096,0.57699484,-0.40696588,-1.5545081,-2.0446749,0.39273506,-0.08030182,-1.9959655,-1.9714786,-0.0077177286,-1.7477033,-0.2355398,0.54764587,0.10224122,-0.96148723,-1.7545214,0.36592472,0.5798812,0.39088666,-1.651853,-1.730062,0.058316678,-2.132747,-1.355406,-1.8869895,-0.07478982,0.2930957,-1.7854033,-1.6739205,0.08678982,-2.3251724,-0.862023,-1.3579681,-0.13068843,-1.6420968,0.3136109,-0.068694174,-1.6416684,-0.17565547,-1.389229,0.96430933,0.05802709,-2.3684807,0.4604643,-1.926815,-1.9194105,-2.0454602,0.29520404,-0.6453067,-0.59820426,-1.3024933,-2.1113625,0.15972507,-0.044235438,-1.1941987,-1.7691306,-0.07273239,-1.855378,-1.9788995,-2.1017938,-1.260232,-1.3704499,-1.842074,-1.8735385,-0.22758813,-2.123855,-1.8629332,-1.9039398,-1.6222899,-0.6761688,0.396771,-0.3380657,-2.3767648,-2.0627773,-0.55096185,-1.1348311,-0.5752228,-1.7358917,-0.7996346,-1.3106728,-2.4058971,-1.4859385,-0.22893016,0.4005192,0.8388047,-0.40831617,-1.7757409,-1.5985547,-2.6017041,0.29359365,-0.683825,-1.2486372,-1.318597,-1.5358336,0.393183,-1.8780482,0.125045,-1.999461,-0.6777072,0.177988,-1.964522,-0.4102228,-2.0688443,0.44930744,-0.39719743,0.40347916,-2.0412564,-0.28348827,-0.68446684,1.6183211,-1.6571941,-0.28081405,-1.7964073,-1.1827997,-0.33208287,-1.1556913,-2.101521,-0.77134764,-0.020580113,-0.7539083,0.2543043,-0.33486995,0.05409035,-1.475708,0.39136082,-1.6691645,-1.1769645,-1.9941572,-1.3590155,0.46915787,-0.5595161,-3.13273,-2.2515125,0.025049835,0.8503972,-0.5240736,0.4379211,-0.9634858,-1.5273519,-0.36523807,-0.0432896,-1.9591365,-0.075683236,-0.030851275,-1.3514521,-0.1511019,-2.4066114,-0.3051367,-1.1890917,-1.4492528,0.38405323,0.18676275,-0.5024967,-1.113236,-1.476874,-1.7952173,-0.35120192,0.07919204,-2.1129422,-0.34576452,-1.5387417,0.252523,-0.8682898,-1.0581498,0.112009645,-0.50805575,-0.48098886,-1.2103527,-2.299097,-1.4125106,-1.4572577,-0.11965105,0.05858475,0.28190398,0.42000133,-0.0645366,-1.4126999,-0.41608226,-0.8266465,0.28713667,0.33439523,-0.6968609,-1.1975975,-1.5471194,0.41344535,0.49348438,0.21136606,0.14581615,-1.5127635,-2.147083,0.0033869743,-2.1292632,0.4273916,0.6212783,-0.9626719,-1.3771174,-1.1907506,-1.6125975,0.5386939,-0.3208742,0.0005785525,0.52061373,-0.95799917,-1.5040534,-2.331046,0.7875037,0.031118989,-2.0204506,-0.70027864,-1.2378062,-0.16125706,-1.8074255,-1.9116176,0.041731864,-0.17931497,0.6397971,-0.16419607,-0.025860757,-1.4739712,0.47359312,0.41892874,0.26811552,0.0149027705,-1.4480274,-0.7934741,0.32618958,0.13642025,0.2190302,-1.0564761,-1.2901812,-0.4430096,-0.41314653,-2.0616307,-0.10614431,0.39487636,-0.48620096,0.6873946,-1.6142268,-0.41281375,-0.09577051,0.6648948],\"xaxis\":\"x\",\"y\":[-0.3091762,0.108616576,0.06987162,0.19356503,0.051640317,-1.0802319,0.12657417,-0.40553772,-0.93881106,0.58263487,-1.2470359,-0.87215716,-0.5299104,0.26611674,0.7929375,0.9531152,-1.525806,-1.5319961,-2.1054518,0.75357443,0.5574232,-1.2452794,-0.56975114,0.39675206,-1.0891746,-0.750907,-1.7967867,-1.6032854,-1.2155461,-0.4751547,-1.1320798,-1.3117466,-1.5706512,-0.3515708,-1.2090569,0.8538259,-1.7689477,-0.3812466,0.09696327,-1.6003765,0.84591705,-0.4056238,-1.6025313,-0.4782092,0.7160244,-1.6953284,0.834001,-0.567086,-1.9066905,-0.12433947,0.6301035,0.42035908,-0.20934604,0.13242178,-1.3303664,0.41367137,0.8546797,0.21950589,0.4819823,-0.31036794,0.2217726,-1.0801914,-1.4084435,-0.6736437,0.46092921,-0.93603766,-1.6548359,1.0384235,-1.9624391,-1.5439014,1.0771472,-0.7962477,0.3766719,0.18168135,1.0668689,-0.30174035,0.4269969,-0.80769956,-1.673503,-0.23431462,0.7551678,0.97649205,-1.6844251,-1.3198396,-0.3293952,0.77328527,-0.9160743,-1.625988,0.82313865,0.5587448,-0.76820356,0.5039207,-1.2283462,0.5927004,0.8139399,-0.3406855,-1.5763911,-0.1645451,-1.7999334,-1.0368474,-1.822313,-1.0947199,-1.6217154,-1.4576302,0.34340614,-1.4684916,-0.20740862,0.5414143,-1.1418577,-0.48445684,-1.230678,-1.2301774,-1.2766366,0.86917615,-1.2550178,0.096529186,-0.82804394,1.624157,0.7521233,-0.92021495,0.5436181,0.8271053,-0.5782764,-0.17764546,0.76086724,-1.4197866,-1.6540736,-0.6655604,0.3146749,-0.96753275,-1.7219825,0.7306521,-1.5540851,0.15522371,-1.4788657,0.34063512,-0.13724926,-0.53986883,-0.79788595,-1.0917389,-0.8641089,0.1270716,1.0336567,-1.823513,-1.0607206,-1.1470746,0.34738576,-0.7466068,-0.2585324,0.60719377,0.97242427,0.009120509,-1.3420494,-0.049676448,-1.0355122,0.3899951,-1.5030247,-1.1656917,0.67953855,-1.3408306,-1.5520298,-0.2652835,-1.7184328,0.0028916448,-1.0661744,0.10883178,0.5840629,-1.2992388,-1.8567219,-0.5697219,1.0461446,-1.2427076,0.21850498,-1.9541658,0.05407785,-0.38118094,-1.3336574,-0.23616827,-1.4259546,-0.34866786,-1.3628378,-0.16014041,-0.6171021,-1.6695924,-0.13381487,-1.186505,-0.2015863,0.08020893,-1.4889722,0.82093054,0.48978627,-1.5513649,0.84716445,0.6655305,-1.1429617,-2.0450292,-1.9150428,-1.5100653,0.6622905,-2.17595,-0.08806558,0.36999285,0.32926548,-1.2873751,-1.0563076,-1.4650092,0.39258844,0.71049535,-0.039681256,0.11559035,-1.6969682,-0.030991621,0.5545844,0.42537045,-0.085491784,0.71395254,0.30413282,-1.3264285,-1.8561335,0.72182596,-1.6805552,-1.3981521,-1.3452678,-1.0572942,0.85092866,0.44125956,1.0180101,-0.89750993,-1.4889386,0.8304206,-0.69613224,-0.044380106,-1.3228322,1.0514705,-2.168859,0.6116844,-1.4610622,-0.6902282,-1.5754412,-0.5315814,0.81945354,-0.035458058,-0.08669138,-0.34082836,0.22494023,0.72189456,0.88154733,-1.7358311,-0.76662064,-0.19666804,0.47272915,0.8030316,-1.3965957,-1.3752487,0.7073549,-1.3911691,0.4581312,-0.3922634,-1.668766,-0.9825541,0.41400456,-0.89469004,-0.80083764,0.7141787,-1.2399148,-1.6611499,0.597648,0.02290979,0.29504895,-1.2424643,0.15580271,0.120186284,-1.5806978,0.3296768,-0.7257039,0.4529788,-0.05657474,-1.6901821,0.9595525,0.7880301,0.39765936,-0.93977815,-0.48494875,-1.1917785,0.18589361,0.67032665,-0.9280324,0.09133802,0.57134295,0.8211998,-0.31030783,0.94926834,0.6425797,-0.10683268,-0.5309297,-0.40605468,1.1211569,1.054211,0.86852276,-0.9845856,-1.6002465,0.5136815,-0.46213472,-0.4376306,0.09715466,-1.749623,0.77690476,0.3997339,-1.0687712,-0.986563,1.0294452,0.8673717,-0.69295037,0.16169472,0.81990004,0.71089095,0.7882887,-0.3681504,-1.2104377,-1.1105667,0.10183127,0.6756169,-1.6054432,1.0930482,0.2738527,-1.1567484,-1.5116737,0.95381975,-0.30740273,-1.6694777,-1.6593314,0.34955126,-1.286313,0.16526325,0.7647474,0.14280613,-0.7306604,-1.373757,0.7220706,0.88171554,0.47025442,-1.7687495,-1.3636545,0.5489618,-1.7031589,-0.9860199,-1.3762338,0.062071264,0.6035859,-1.4297767,-1.1453693,0.46238482,-1.7796154,-0.29252002,-1.0486076,0.0037695467,-1.5014752,0.0050317943,0.077089965,-1.2768749,0.10850586,-0.91598535,2.1844368,-0.17264232,-1.9821913,0.9553404,-1.6312099,-2.0607557,-1.6897297,0.43285424,-0.78067887,-0.079515874,-1.0145464,-1.8115499,0.35123587,0.0195726,-1.4768227,-1.4611546,0.06710112,-1.6008319,-1.5833957,-1.9028893,-1.0014141,-1.2641615,-1.4833312,-1.7154166,0.22320299,-1.9736615,-1.723278,-0.9518974,-1.5053129,-0.78637266,0.5790597,-0.00024463236,-2.1075902,-1.5570184,-0.013558596,-0.9681695,0.24910368,-1.388498,-0.689614,-1.220595,-1.8981287,-1.4934415,0.51103115,0.7180781,1.3442957,-0.3956159,-1.5610815,-1.4212267,-1.7998946,0.5948984,-0.5420701,-0.9290089,-1.1835308,-1.2618344,0.97882724,-1.2831316,-0.013336331,-1.5903215,-0.23457736,0.2879842,-1.4979894,0.13822518,-1.8617153,0.57393765,-0.5947491,0.5650066,-1.5139418,-0.32234603,-0.79184866,1.8270072,-1.460566,-0.40164733,-1.9394015,-0.3634003,-0.8882832,-1.4001931,-1.908338,-0.92190576,0.31734145,-0.9815417,0.37351608,0.059681237,-0.14084736,-1.1351516,0.35128993,-1.635717,-0.75387883,-2.2984996,-1.5252033,1.4113882,-0.35077572,-1.4209269,-1.3901255,-0.24620984,0.643161,-0.34909987,0.48409063,-1.1201216,-1.4337686,-0.25320107,-0.13308764,-1.741715,0.16376089,0.093647614,-0.9201146,-0.29189008,-1.8533909,-0.07087293,-1.19358,-1.1565729,0.65371555,-0.10667914,-0.7050847,-1.2571745,-1.1091967,-1.4961088,-0.3676179,-0.20901501,-1.533928,-0.23541455,-1.0627598,0.3949436,-0.08402072,-1.0631286,0.9797456,-0.2555135,-0.24490197,-1.0695568,-1.6648682,-0.52712595,-1.014463,0.22971903,0.4428727,0.50369984,0.35631126,0.38400346,-0.82444453,-0.09575225,-0.31279558,0.035852045,0.9533706,-1.186004,-0.92197245,-1.4473741,0.93145394,0.90769637,0.02426283,0.4029492,-1.4172101,-1.6627116,-0.19361518,-1.4740889,0.852281,0.8513205,-0.94267726,-0.8948876,-0.97329295,-1.3528132,0.8806617,-0.026924528,0.6131348,1.0517157,-0.5508664,-1.6167662,-1.685648,0.8995055,0.21208777,-1.6003757,-0.8313795,-0.91392726,0.20352925,-1.6050287,-1.5211743,0.3235271,-0.11289874,1.0834684,0.4659295,0.25439322,-1.3680627,0.7140352,0.71583414,0.8230611,0.29116142,-1.363271,-1.1125461,0.6672687,0.39162272,0.62185085,-0.89670134,-1.0483834,-0.17096753,-0.2815746,-1.7876718,0.39484662,0.39762533,-0.37173855,1.2305821,-1.3513153,-0.4183895,0.18274574,0.96746075],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=2\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"2\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"2\",\"showlegend\":true,\"x\":[2.2792082,2.0350661,1.1257855,1.6547159,2.7090645,3.0663786,0.9692477,3.3379664,-1.3635895,3.3689919,1.4736387,1.9072336,1.5260116,1.7249645,2.2312212,-0.24107368,2.3798509,0.65120745,-0.4380305,0.46534073,0.6077606,1.1708435,3.0339532,-0.24788411,1.6796175,1.9814819,-0.98567605,2.2539659,1.078476,-1.421718,-1.9465014,2.7053132,0.29055142,0.15945381,0.44231427,0.59737766,0.67479277,1.5477104,1.723832,1.7925466,2.856368,0.564766,0.589702,-1.341083,2.266923,-0.47829247,2.962525,2.2825518,1.5986278,2.136407,0.11104393,1.0563434,2.7274427,1.2615235,0.7181984,1.5909925,-0.04414329,0.75212073,2.390708,1.5986962,0.71802413,2.3020935,1.4397933,2.2296796,1.6315225,0.24248815,-0.3698025,0.682425,1.7651116,2.2442665,1.1252286,1.9457642,-2.6022654,-1.376476,1.3627006,2.139957,1.5952046,0.29422295,0.15621531,0.8707522,0.12754941,2.9230232,2.105812,0.85595274,2.341908,1.437181,2.810082,2.4907842,1.7448639,-1.4175044,-1.2267827,2.6142282,0.040703475,1.1386576,1.26201,1.8600184,2.0518174,1.8797954,1.5416905,1.266846,1.6886915,-0.50902,1.3576919,2.427188,1.4320167,2.1012192,1.6099955,2.2370954,1.9963452,-0.13555232,1.6501452,0.22627658,-0.8106782,0.99275994,2.2425852,1.2311927,2.347869,2.1518946,2.3198814,2.8060498,0.2734412,-0.06686661,0.9855312,0.63083744,2.1077986,-0.83494216,-0.33494604,2.500525,2.2785525,1.282615,0.8446454,-0.33130494,2.2208576,2.236699,2.7639003,2.4290514,2.1034484,2.354051,2.329061,-2.4010816,-0.7058188,2.041027,1.8975867,2.2676458,1.4113401,2.065909,2.2261043,-1.8193476,2.4381518,2.399663,1.0158486,-0.97771555,2.082819,1.4893875,1.7446338,1.7170182,2.2574873,2.498127,1.7929884,0.6063783,2.9528246,2.9250584,1.0585775,1.1737301,1.7752839,0.69531333,1.876635,2.6343231,1.2153257,2.4241962,0.6568401,1.9714726,2.2878337,0.16726637,1.8356527,3.1964788,-0.8144491,2.4924908,2.9921446,2.1874533,2.507722,2.48112,1.4831644,1.8186837,2.4206362,3.6664968,1.853628,2.497374,-0.1732335,2.3322163,3.2067895,2.1138444,4.401562,0.8407074,0.8413584,1.139401,-1.4715961,-0.20524678,0.9680723,2.938219,2.700828,-0.78919834,1.0711043,2.734807,1.133365,1.9645432,1.674405,0.6240113,1.5636733,1.7173253,0.0146963,2.3789048,2.2229195,2.1459327,0.3219831,0.6124712,1.4425033,1.508147,-1.2262874,1.7194945,2.7577472,3.3652234,-1.1881421,0.74776304,2.9017434,-1.3706303,2.60956,1.6275679,1.8432926,1.8286022,0.9147314,1.0324659,1.8111569,1.7646235,2.9965281,-1.3468301,1.5754766,1.2994556,2.3818636,0.9195585,-0.41888034,1.0289603,1.3339312,2.9188752,1.1300927,2.1503701,-0.10584682,1.5261004,-1.9922028,0.47536933,-1.5902233,0.3761106,1.3622445,1.9158713,2.5933676,2.3668504,1.0319117,1.0975814,2.0425267,0.86586654,0.30769223,2.8920903,2.991197,1.4314047,1.75679,1.8327414,2.411796,-1.5983331,1.1622194,2.078136,2.4568777,1.9843167,1.0220503,2.5935984,1.7928132,2.817957,2.099194,1.4986687,1.3810874,2.2808151,1.9722029,-0.2710851,0.7028574,1.4993467,2.3752847,1.2168857,2.9858017,0.7013179,1.297484,0.90241563,1.471485,0.4078359,1.9717222,-1.4891845,0.45142812,1.5514386,2.2977214,3.4503946,2.3813152,1.0010697,1.2963415,-1.5119536,-0.8445809,1.1735778,2.762775,1.1833655,1.287533,2.1863475,2.4690142,-0.6487762,0.5240074,2.4690223,0.64797425,2.8966799,2.2119308,1.9438363,2.4104772,1.1067047,1.6660231,0.13060015,1.5820824,2.9236612,2.2948656,0.8185382,-0.26716858,0.9037236,0.35097474,0.7884053,-1.9907501,1.4914732,1.6287006,-0.63983077,-0.5839491,1.3733174,1.8159004,0.16756976,1.5752189,0.99324644,1.2158755,2.499815,1.5624804,0.7350334,1.6889628,0.14638388,1.6237227,-1.7768418,2.018805,2.333478,-0.56160235,0.5025348,1.9260079,2.3523874,1.1184022,2.1992984,1.6626734,0.72742724,0.042667717,1.5140667,1.0239726,1.1333638,2.4156919,0.55641544,2.1732821,2.0199976,1.3233138,0.86574066,2.2304893,1.9613141,1.7365807,0.2713387,-0.01015082,1.2583253,-1.0976439,-2.5381284,-0.4203974,-1.0212748,-0.7651266,1.3997172,1.9354881,2.2880335,0.49535102,2.615026,2.6242328,-0.30158,2.8734083,1.2378976,2.4227657,0.6637176,2.6683989,1.0299652,0.61860967,-0.48057255,1.7633048,2.0328083,2.2742991,1.9307581,2.7194405,0.72875476,2.5999546,2.4732432,-1.228923,1.023195,2.5591898,1.9959553,0.3802371,0.68874717,2.1022983,3.0181217,0.589199,-1.5996618,-0.34078917,2.420144,-2.076048,1.967517,2.0661178,2.1030855,3.0359354,1.9051718,1.9216491,1.897477,-0.42515844,1.4228303,-0.103075296,2.9194007,1.4292518,0.26530212,2.855208,1.3643324,2.2020936,0.7903755,1.8840808,2.247037,-0.6317029,2.8184028,2.1046972,-0.36036396,1.9932674,0.84499514,3.01901,-0.77686894,0.72689784,1.5324429,2.4713898,0.08234209,1.1873475,2.7710013,1.5370904,-0.745654,2.1946297,1.4252522,2.0787163,2.2149968,1.0423534,1.8017823,0.5896396,1.0291497,1.287666,2.4626079,-0.26171416,-0.89149773,2.4970393,2.7036452,1.2311782,1.5716518,0.05788201,2.4993787,2.5442533,2.1300054,1.5352457,1.6793238,1.9076003,1.698378,0.667465,-0.16350715,2.1162357,-0.30678695,2.1477194,2.4398031,2.2652588,1.0311824,1.5333873,2.6916437,0.463166,-2.5513625,2.70544,1.9569892,2.6911106,-1.5300734],\"xaxis\":\"x\",\"y\":[2.7652235,1.9372221,2.043673,2.9594615,2.1658456,2.9673195,2.3434508,3.4844563,-2.460914,3.9045498,2.0063496,3.607199,3.0101273,2.7572675,1.2840327,-0.37114966,3.566924,1.3405471,0.970621,2.6213317,1.8044765,1.8831755,2.5812404,1.6768571,3.2767088,3.0736985,-2.267423,2.7203414,2.480851,-1.6436805,-2.639611,2.6951277,1.2598124,1.9055973,1.1925752,2.575174,0.90190005,3.1086206,3.2970345,3.061813,3.5988543,2.0196676,1.5470241,-1.9971827,3.379379,-1.1162773,3.8285975,3.3467083,3.020501,3.281328,1.6642153,1.4787165,4.191503,2.7546532,0.21990673,0.8796623,-0.7988368,0.9910083,2.995219,2.6685967,0.20410483,1.8741444,2.300489,3.7730067,2.1149433,1.4389515,-0.283746,2.1380792,2.0318732,2.2502406,2.2122204,2.4408395,-3.35574,-2.032193,2.4763055,2.9019647,3.151639,2.1864479,1.4299027,2.1094863,0.5633201,3.8047934,4.1773205,1.8788882,4.7395897,1.7029487,2.5575144,2.093579,3.1646726,-0.13466744,-1.7210745,2.2720447,-0.5401484,1.9585098,2.7168896,2.1065392,2.0238147,1.8660849,1.2612402,1.7638644,1.6357069,-1.7519983,1.0790465,2.3463986,1.0918261,1.9883031,2.8766696,2.0158956,1.8189782,-0.2924832,3.50287,0.5092224,-1.9327027,1.0890793,3.702523,1.4426017,3.7313008,2.6921346,3.9433095,5.1685243,1.3980849,0.62582695,1.2830731,0.7582978,2.6596153,-0.92011994,1.0271678,3.6853647,3.412971,2.8458066,2.1874957,-0.47277534,4.0087857,2.557399,3.380617,4.0353045,2.3203278,2.148767,2.7832987,-2.735688,0.9874052,3.5046172,2.3590744,4.1690927,1.5928395,4.1779323,3.8912332,-2.6410508,4.736378,1.9491862,2.1223915,-0.67622596,2.4339056,2.5062428,2.2994924,3.6224241,2.785187,2.5304637,2.8115895,1.919221,2.6992085,2.6650856,1.2814239,1.6478198,1.3433956,0.8667501,3.3474324,2.7870069,2.6158898,2.1063786,1.7875863,3.4891853,3.0643113,0.32488394,2.7403097,3.6812105,-0.8150176,2.542879,3.257969,3.386647,2.6725473,3.9700763,1.4778209,3.8293004,3.5404758,4.334249,3.0312715,3.5361128,0.8770094,2.4235687,3.1784358,3.6599731,5.0139937,2.3397875,1.746044,0.7676201,-1.2540674,0.17476414,1.2682643,2.4266322,3.3939846,-1.6167614,2.4676719,3.3662958,2.6991315,2.1160953,3.1060312,-0.26826784,2.214263,3.1528409,0.94645035,2.4689822,1.8967108,3.0877917,0.94792676,1.218227,0.959965,3.2490084,-1.1748877,2.7104216,3.2647505,3.1897483,-0.54104704,0.10009256,4.041068,-1.5646102,2.3732297,3.1614141,2.1211042,2.5276334,1.571404,2.2346928,2.730508,3.707532,4.5375786,-1.6011443,2.7541144,2.4213881,2.9713724,1.2526166,1.8887073,2.71699,2.5994465,3.0804393,0.586638,2.1135106,-1.3640251,1.0826759,-2.4048414,0.6126555,-2.0395284,1.7395014,2.1544702,3.3313622,2.3561625,3.4532957,2.3664474,2.1522243,3.8377752,1.8236773,1.7948241,2.941355,4.3053384,2.0553014,2.6748247,4.578477,4.057534,-2.3700266,2.7673562,2.9565575,3.0808728,2.3744435,1.5608239,4.308684,2.5279827,2.7510571,3.736153,3.8716195,2.284824,2.0285468,1.7045879,-0.30921102,0.26869506,3.2978408,2.344358,2.4115288,2.9416869,2.424409,1.9913319,2.74198,1.8526255,1.8360572,2.2229798,-1.6580452,0.8772725,2.8032517,3.1628792,4.6284375,1.8930589,1.5145049,1.5890663,-1.4711266,-1.2614895,2.434026,4.114428,1.7508792,2.4823987,2.2505512,2.3402536,0.9428854,2.1414711,3.242794,1.5192418,4.2797236,2.9622264,0.5576185,4.0216975,2.6592717,2.760058,1.1259468,2.864187,2.838062,3.3758204,2.2645414,-0.26418352,2.5536506,1.03865,1.9831537,-2.162807,2.8104026,1.5774409,-0.39781907,-1.1187469,2.4444385,2.0276902,1.5083032,1.7190349,1.6436675,2.2039394,3.486777,1.885003,2.3206153,3.2004554,0.732485,1.6783959,-2.8741276,2.38991,2.6827087,0.9901545,1.6698906,2.6036704,2.2886562,2.3670316,3.4406753,2.0594394,2.427222,1.2375329,0.89845634,1.4371973,1.6493185,4.4192014,1.6884594,3.4986403,4.1640844,1.6621823,2.000084,1.9052731,1.4213375,2.1800683,0.3069809,0.14055325,2.7047808,-0.95080924,-3.4072218,1.6648856,-1.2165148,-1.3015047,0.65358335,3.824725,1.5043278,0.2560439,2.4417443,3.8789866,-0.9688507,4.1796646,2.1180327,4.066372,0.86233544,3.7532718,2.3941243,1.6689756,-1.866922,0.7671697,1.893118,3.1931818,1.4084538,3.935799,1.4231279,2.7515538,2.4422107,-2.4727538,1.3567326,4.647601,1.7494832,0.8472663,1.8243675,3.2920384,3.4168756,0.80970466,-2.0029173,1.017073,1.4057755,-2.462245,3.2728283,1.8755783,1.9954756,3.4844618,2.1100962,1.8313378,3.9450448,-0.13705803,0.52471143,1.5384507,2.684003,2.8660333,1.5820326,2.3910608,2.9918995,2.1757627,1.7457446,3.9210956,1.5938962,-1.1981295,2.786901,3.9898803,1.2583362,2.233347,1.2078245,2.8969612,-0.9908856,1.5677577,2.2980592,2.21405,-0.9452056,2.8141067,2.7864623,2.5935879,-0.17399041,1.858971,2.9122562,2.3706515,2.6636167,1.4195437,1.4621737,2.3030617,2.1490085,2.4726908,2.751619,0.24520119,-1.5750614,3.181381,2.1209624,2.5000505,2.8762383,1.6401685,2.6734126,2.5320106,2.5522022,2.5449305,0.9852735,2.5807488,1.5354147,2.1353486,0.48702502,1.1910157,0.18888877,1.9521354,3.8046432,1.4698178,2.5162635,3.3347504,2.2606914,2.277473,-1.8968599,4.278932,3.4763474,2.8163788,-0.73064893],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=3\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"3\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"3\",\"showlegend\":true,\"x\":[-1.9313505,-1.9828657,-2.4437947,-2.7834973,-1.2240396,-1.1100848,-1.7075274,-1.8113185,-2.334703,-2.037943,-1.5485171,-1.8033412,-2.0539596,1.602238,-2.2374759,-0.6910308,0.5900824,-1.1690693,-0.57352984,-3.8823514,-2.7172241,-3.8546977,-2.2413816,-2.4054275,-0.8244622,-0.11188862,-0.80367327,-2.5122743,-0.09810126,-0.8701678,-1.8061193,-0.6612748,0.36876392,-2.419848,-1.2428551,-0.051859707,-3.1211324,-2.1604877,-0.10913968,-0.5303896,-3.786982,-2.924386,-1.7405139,-1.3505707,-0.7887428,-2.2250156,-1.9858942,-1.7519915,-0.77293414,-1.0403314,-0.41738963,-0.78797734,-0.991314,-1.3294995,1.2914519,-1.7882087,-0.23951177,-0.78876066,0.021843076,-2.3360028,-2.628481,-3.110763,-0.8090799,-0.60443133,-2.4553065,-0.7156612,-1.892571,-1.794001,-2.177093,-0.6170317,-1.5065267,-2.2670918,-0.79607457,-0.46364266,-2.7412348,-1.3900423,-2.8197174,-1.5144364,-1.9409083,-1.5759355,-3.0695972,0.3651728,-0.6129247,0.32930183,-1.9252628,0.7858838,-1.9661871,-3.4190836,-4.3405623,-0.99343944,-0.60394746,-1.1136429,-1.7400947,-3.0572977,-1.2942581,-0.25903422,1.0592093,-2.989605,-1.0719157,-2.1582608,-1.323569,-2.1229768,-1.1017969,-2.071797,-3.4437895,-0.8747183,0.07471126,1.9674178,-1.2607572,-0.06590554,0.5744112,-0.073782206,-1.5355059,-0.029595584,0.14655316,-1.2717345,-2.4639568,-1.3620999,-3.0726938,-0.77715355,-0.5965006,-2.1828337,-1.0574543,-2.2814066,-2.0971904,-0.2688205,-0.0037156641,-0.40649322,-0.7180053,-2.8543425,-1.0219154,-2.8160324,-2.9409232,-0.8812612,-1.6357957,-1.8299451,-0.02304247,0.74806726,-2.5596695,-1.9564477,-0.7376267,-0.37801388,-2.3226504,-0.5399852,-1.8351635,0.26027763,-2.4973125,-2.6259441,-1.3701956,-2.03846,-1.4657989,0.52119255,-0.18195184,-1.4580405,-1.9683763,-0.3373689,0.011748463,-1.867108,-0.8902285,-1.8463249,0.10371566,0.33052623,-0.111252755,-3.0346012,0.07994604,-0.2079325,-1.9041762,-1.7473202,-2.4380584,-2.412808,-3.0028558,-0.5388319,-3.0663524,0.038912296,-1.3882706,-1.0381066,0.28451288,-2.4623113,-1.276188,-1.6921725,-1.558308,-0.11412224,-3.3493466,-0.71225166,-1.0628024,1.7718555,-3.1476588,-3.7416592,-1.7979724,-2.7779026,-0.74528646,-1.3394628,-1.2749848,0.10015261,-1.3993778,-0.3853356,-0.057947785,-1.4438399,-1.5415596,-4.7892375,-3.5844984,-2.167079,-0.60221636,-4.0904484,0.3682502,-0.375592,-1.3507187,-2.466476,-0.7326921,-2.454369,-3.081046,-3.4344935,-2.8153334,-0.50962174,-1.4592793,-2.9969916,-1.2893206,-0.2773402,-1.3781259,-3.4943223,-0.49583572,-2.2234945,-1.6123233,-3.9992414,-2.3198867,-3.097436,-1.159222,-1.0792395,-2.6199865,-3.253109,-0.36671788,-2.1591415,-2.079349,-1.2397878,-0.3713903,0.123873174,-1.8094186,0.7951522,-1.0441633,0.23203915,-1.3555025,-0.8740919,-3.3929462,-2.1284418,-4.110242,-1.4829286,-1.3327299,-2.759119,-1.8826185,-2.1193151,-3.4517689,-1.8121315,-1.7268695,-0.8250458,-2.2878752,-1.3330176,1.2924829,-1.6768516,-2.217784,-0.4973083,0.79224074,-1.2923646,-1.1228101,-0.46815434,-0.96253437,-3.2198687,-1.5517187,-1.2808651,-1.446794,-1.7289916,-2.073295,-0.22151724,-0.5899961,-1.5957035,-2.646297,0.29493183,-0.39922056,-3.0486999,-2.4918184,0.16483754,-1.8742297,-0.33273357,-0.3270356,-1.6516924,-0.45822677,-1.5843861,0.053720593,-2.2840962,-1.7037389,-0.12610742,0.73945594,0.26832807,-3.2806244,-2.679253,-1.3145447,-2.539513,-1.7178861,-1.7958916,-1.6410949,0.9243994,-1.7350804,-4.072079,0.14522445,-0.1277298,-0.46491912,-2.3363094,-1.3456423,-0.46449336,-0.21117702,-3.0436277,-0.32180217,0.17229491,-2.035212,-0.4165356,1.2384676,-1.3479941,-2.1174479,-1.0458863,-0.9202439,-0.7142524,-0.3101912,-3.5137162,-1.3398479,-0.659943,-1.2715394,0.15957701,-2.1850038,-1.499043,-3.479197,-1.0789561,-2.7381582,0.2011509,-1.2470589,-3.8413553,-1.3257363,-1.2016034,-3.8074307,-3.2660913,-3.3149834,-1.1182542,-2.6775103,-3.237647,-0.4889052,-2.2591019,-1.1309984,0.8085475,-1.3451045,1.1640619,-2.4218469,-3.9599338,-0.26196465,-2.693511,-1.0819502,-0.85589015,0.08832446,-0.9995392,-2.80929,0.096647084,-1.0296295,-2.5511112,-1.3427182,-3.1665192,-0.9704794,-1.3440614,-0.7416379,-2.388651,-1.7140926,-1.1576066,0.58944756,-2.4624252,-2.5741057,0.1009863,-2.7549877,-2.7092233,0.031381488,0.13990337,-4.1642227,0.6347892,-1.2009199,-2.748033,-0.68796253,-0.273306,-0.26950905,-2.8233624,-0.35827577,-2.1154552,-0.077454865,0.2556196,-0.33290982,-2.19418,-0.774304,0.5738136,-1.6925958,-1.264049,-1.6771836,-3.147708,-0.56909543,-2.6554103,0.23052537,0.72544086,-1.6131132,-1.7030889,-0.787485,-0.3081811,-2.4258842,-2.0833092,-1.1833274,-2.3045979,-1.466704,-1.550898,-2.284696,-2.6555948,-0.3542807,-0.89051235,0.8505101,-1.8441514,-2.269405,-1.5130221,-2.3185668,0.9676261,-3.110425,-1.4330137,-2.3280663,0.3452767,-3.2261891,0.015265554,-1.5802984,-3.0128226,-3.1176572,-0.78146946,-1.4963869,-0.14272663,-0.25299945,-3.8833575,-1.6002516,-1.6463299,-0.5775445,-1.7722398,-2.3071575,-2.8239536,0.48093456,-1.351478,-2.6439438,-1.2278941,-0.72063494,-3.0863633,-1.853875,-0.6344769,-1.2523658,-2.0858545,-0.53366476,-0.5987114,-1.0072451,-0.88127935,-0.7909109,-1.5381838,1.722288,-0.9865655,-0.77581155,0.2423876,-1.0049015,-1.8371576,-0.030128866,-2.6701784,-2.0679564,-0.7647282,-2.1657977,-2.780119,-3.4322715,-0.36480302,-0.0062035024,-2.5307198,-1.8911335,-1.2482486,-0.60328597,-1.4583968,-0.888953,-3.5958881,-3.695778,-3.156003,-1.4013942,-0.95447695,-1.1572715,-1.6973871,-2.2488394,-2.0390935,-0.9136692,-3.060503,-1.9680429,-1.1831645,-2.5103722,-1.0079054,-1.1155002],\"xaxis\":\"x\",\"y\":[-2.5868692,-2.4626946,-3.667403,-3.830938,-3.8503692,-2.462893,-3.4257994,-3.8722353,-3.7235105,-4.1062355,-4.4618945,-3.828195,-3.4848702,1.1580648,-4.602239,-2.9987543,-0.8355845,-0.80453753,-2.6679282,-5.9502378,-5.254346,-5.7678704,-5.522529,-4.981452,-3.1330671,-1.9008524,-2.2044613,-4.8257427,-1.2285719,-1.9566075,-2.4160454,-1.9878445,0.029568195,-3.005167,-3.0362587,-2.5353663,-3.440049,-2.0401413,-2.5318623,-1.9800632,-5.5945272,-5.3533926,-4.328587,-1.2319523,-2.37882,-2.64808,-3.4130766,-2.2493439,-3.0742366,-3.368985,-0.90852576,-2.1160686,-2.0781715,-2.3726943,0.07567085,-3.1234975,-0.9077085,-2.8910863,-2.0135314,-4.603158,-2.6783664,-3.842481,-3.4518383,-2.415645,-2.3985267,-2.6655364,-3.3589265,-2.607695,-1.6728737,-2.7722318,-2.5407941,-2.1377618,-1.6159968,-2.7372909,-4.4275637,-3.2236516,-4.88255,-2.7638583,-3.4169106,-4.377651,-4.796402,-0.36278668,-1.254964,-1.1289763,-3.0037236,0.21089874,-3.0152326,-6.1897697,-4.500023,-1.8535683,-3.1215801,-3.6774464,-4.091314,-2.6989918,-2.8457403,-0.79457927,0.43274003,-4.1887965,-4.031395,-4.6422787,-3.0959094,-3.0182228,-2.0213768,-3.566736,-2.6589634,-0.72099495,-1.7928025,1.1585925,-2.2560394,-0.5354119,-0.71625173,-1.9931562,-3.573128,-2.0699708,-0.339018,-3.8110359,-3.8464909,-2.0196145,-2.9517424,-3.8903623,-3.0405557,-3.6242366,-2.7176216,-3.949444,-3.5233965,-1.6501385,-2.34381,-2.8339725,-2.9238222,-3.871005,-0.779653,-4.8980136,-4.8654046,-1.0990608,-4.3129325,-3.2494137,-1.8234304,-0.41999584,-3.1555598,-4.1531167,-1.9178699,-2.5731313,-5.178252,-1.5526348,-3.5704892,-1.2304207,-5.158509,-3.361626,-4.592379,-4.2030554,-2.085467,-1.8584155,-1.8229779,-3.1862059,-3.188945,-2.2925277,-2.0698338,-2.0890625,-3.5398047,-3.6584141,-1.2873001,-1.0453227,1.3971645,-5.1478643,-1.0521424,-2.4098248,-2.2173522,-4.0518947,-5.53376,-5.4329267,-4.475737,-3.3456302,-4.8268943,-0.7411718,-2.110531,-1.6516114,-1.5645354,-2.2880733,-3.101265,-3.5140567,-1.4733644,-2.0772836,-4.6186805,-2.657013,-3.4435244,1.5394081,-4.6564307,-5.480313,-1.3762714,-4.2179813,-2.124108,-3.709064,-0.50753915,-0.9801885,-1.7597016,-1.5327061,-1.6057498,-2.5836182,-3.0053768,-4.85016,-5.5507493,-1.9868675,-3.8188093,-5.4296207,0.2615115,-1.8146019,-3.7905784,-3.9114072,-3.55509,-3.509717,-4.8754554,-5.4967465,-4.5130343,-1.6241957,-2.7828207,-4.0423675,-2.829998,-3.1824446,-3.2685776,-4.1701126,-3.2072196,-4.486746,-2.508021,-5.3000293,-4.47692,-4.4680524,-3.9304419,-2.5158246,-2.7847657,-2.6701849,-2.008427,-3.9232848,-3.1425118,-2.536217,-2.3303926,-0.7592125,-2.1892607,-0.013702005,-3.5458875,-1.3309176,-3.3624878,-3.6406498,-5.41091,-3.272291,-6.912554,-3.469795,-2.1320515,-4.628312,-3.144749,-2.891851,-3.5405624,-4.007435,-3.0875716,-2.8788612,-4.233977,-2.6106606,0.42112434,-1.5542793,-4.282116,-2.5270414,-0.6064689,-2.548716,-1.8835475,-1.8802279,-2.3681965,-3.8361204,-2.0281854,-4.211208,-0.7320753,-2.5836046,-3.5939755,-2.3745944,-2.4462383,-2.9828076,-2.4672656,1.7334485,-2.866138,-4.483992,-2.41068,-1.0087084,-3.9781854,-2.4951675,-2.2772207,-3.2990751,-1.4613671,-2.4718733,-1.7247542,-2.7779555,-2.6260011,-2.6430175,-0.5236852,-1.9833622,-4.419812,-2.0095136,-4.5741234,-4.259288,-2.8125372,-4.0481296,-3.4863546,0.009000629,-1.5129327,-3.0105176,-1.4963393,-2.8295555,-2.689733,-2.4932232,-3.1253805,-2.283094,-1.0603751,-3.0901384,-2.030423,-0.8300147,-3.8488648,-3.1606388,0.7004706,-1.0821167,-3.8081148,-3.0202417,-1.7437638,-3.1200056,-2.5520866,-3.1269083,-3.2729905,-1.9465758,-1.9105839,-1.8914071,-4.141581,-3.2842565,-5.7359943,-1.3230906,-3.5940986,-1.0509279,-2.6788516,-3.9500093,-3.1414142,-3.2576869,-4.165606,-4.1732106,-5.7779484,-3.131434,-4.0942574,-3.6934984,-2.11955,-4.6176085,-1.5795609,-0.11353603,-4.2008586,0.527873,-5.487126,-4.527958,-1.354059,-3.4666715,-2.4958608,-3.7432098,-1.6576861,-1.3898851,-4.0551453,-0.94884294,-2.6451442,-3.0518754,-2.6476078,-5.7906632,-2.4952393,-3.7966821,-2.5920463,-3.3264878,-2.8148594,-3.5075085,-0.9449062,-3.5147378,-5.6348944,-1.9411671,-4.332151,-4.0878983,-2.319076,-1.4154819,-4.4160633,-0.17446053,-3.5463016,-5.232615,-2.0459723,-1.1530739,-2.6077728,-3.7312965,-3.2578251,-3.982972,-1.3952901,-0.34567416,-1.6582842,-4.4524484,-0.6924581,0.15897758,-4.5428143,-3.004595,-4.850983,-4.096766,-1.3360558,-2.4757583,-1.4523702,-0.44665748,-1.306743,-2.732517,-2.302954,-2.2624502,-5.1554923,-2.132281,-2.8875153,-2.9896872,-4.1821885,-2.948583,-4.706646,-4.0264597,-2.6885533,-3.3803318,0.7080757,-3.8442662,-4.385942,-4.035457,-3.3596525,-0.39172614,-1.5708538,-4.127367,-2.822613,-1.1475588,-4.1986394,-0.33591723,-0.94042355,-4.126012,-2.439286,-2.6762729,-2.9010963,-1.3842924,-1.844654,-4.348234,-4.6834145,-2.126959,-2.4258087,-0.5652704,-5.463411,-5.2309546,-0.12064116,-2.2451394,-4.7630696,-4.048756,-2.2446733,-3.2341046,-1.3437592,-1.1130685,-2.7365038,-1.7261857,-2.7064626,-3.3871162,-1.8057233,-3.5868447,-3.1495287,-2.992332,-0.058496244,-0.50351334,-2.9702487,-1.1237533,-1.5126894,-4.1567183,-1.4861753,-2.7983518,-0.52121145,-2.8106623,-3.283233,-3.7330687,-5.365462,-2.9787145,-1.7356269,-5.0472646,-3.5274105,-0.8462872,-1.1300864,-1.8264887,-2.6469326,-5.0011797,-4.1593223,-5.1014066,-3.3454406,-2.1812606,-1.218492,-4.550081,-3.3099284,-3.8513348,-1.9889952,-2.8565478,-4.019043,-1.2549435,-5.236183,-2.9974403,-0.05849713],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=4\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"4\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"4\",\"showlegend\":true,\"x\":[-1.2791274,-4.101342,-1.1535127,-1.393716,-2.910133,-1.0147407,-0.06782666,-1.043932,-1.7737365,-1.6370546,-1.5599809,1.3248932,-3.3125114,-2.6563406,-1.1212094,-0.43709335,-0.29660755,-0.54538673,-0.5289989,-2.9936066,-2.5198927,-1.804856,-1.4141057,-2.1381574,-3.195794,-1.1841092,-2.0702972,-0.57166004,-1.827446,-2.6362557,-1.0730057,-0.4460069,-0.33350843,-1.0714407,-1.5705274,-1.8099451,-0.71094775,-2.8435125,-0.9629936,-0.38255635,-1.2689104,-1.1265686,-0.31763187,-1.7592925,-4.199901,-1.3701183,-2.385798,-3.018795,-0.018962443,-2.4212952,-1.3222635,-0.47283065,-1.756091,-2.2823977,-0.54612875,-2.9650793,-2.7775269,-0.7177011,-1.08938,-1.7822677,-1.6609895,-1.9078878,-3.3759832,-1.5618099,-2.3325844,-0.31239963,-0.77965665,-1.4961935,-2.1565282,-1.5604095,-1.374073,-1.7013379,-3.3536563,-0.6889219,-0.13946494,-0.0585739,-2.4068646,-0.13754019,-0.7823506,-0.35114264,-2.9537163,-1.5442487,-0.29194984,0.3286119,-1.9681265,-1.5103017,-2.0771215,-2.0510588,-1.1881547,-0.84018606,0.2009145,-2.4849315,-1.7650404,-2.122045,-3.2936196,-0.7897001,-1.7573965,-1.7363361,-1.976356,-0.5184214,-0.9424878,-1.8361923,-3.2979665,-1.0796981,-1.3003314,-0.08690944,0.8479612,0.23486286,-0.5186818,-0.15219034,0.08060333,-1.6793245,-2.5536876,-2.7098022,-0.8935421,-1.1478767,-1.154838,-0.99628496,-2.923119,-0.009016961,-0.2501232,-2.7897224,-0.46868333,-0.3423312,-1.3296547,-2.7071486,-3.2571464,-0.58507353,-1.6277872,-0.6869863,0.14308286,-1.3664572,-0.9307416,-1.6002357,-0.7804563,-0.79345775,-0.76049256,-0.47838563,-1.7951307,-2.2722135,-3.148501,-0.5106,-0.32527918,-1.4270763,-1.8928422,-1.4801251,-2.1030803,-1.5304829,-1.8899648,-0.58873874,-0.8172422,-1.3496851,-2.2153788,-2.0842476,-2.3489947,-0.8321555,-2.829208,-1.1144867,-3.2667556,-1.0270011,-0.10946864,-0.6971369,-0.18755399,-0.23903951,-1.8215624,-2.3516264,-1.3961145,-1.4578053,-1.4497741,-1.343683,-3.647698,-0.54002374,-0.09010902,-2.451736,-0.9629507,-2.7241607,-1.5308187,-1.5566031,-3.1910095,-0.69428444,-2.286164,-4.3692436,-1.6407396,-1.6922083,-0.8201252,-1.5297016,-3.080038,-0.86141217,-2.661985,-0.55930895,-1.4812114,-2.3542824,-2.996439,-3.5057425,-1.5018796,-3.2778654,-2.3690815,-2.2021046,-0.7095938,-3.7841945,-1.0466218,-2.2566876,-0.6578795,-2.1963239,-0.36421266,-3.5145345,-2.591354,-0.6345638,-1.9511073,-2.9586391,-0.7884245,-1.1157775,-0.6314766,-1.3444997,-1.7499672,-2.0911775,-0.14188215,-1.3118104,-0.82545435,-2.8813791,-3.1562877,-0.5369392,-2.9234905,-0.33867222,-0.20073241,-1.9143801,-0.31502572,-1.432429,-2.9479942,-0.81373984,-1.0228881,0.020940244,-0.51149464,-1.2758205,-1.7687542,-1.5862364,-1.5696726,-0.7177336,-0.8402021,-1.0026169,-1.1631774,-0.1838365,-1.0837568,-4.128745,-1.7933892,-0.8779723,-1.0541551,-3.0767717,-0.60493934,-4.176273,-3.481557,-0.984774,-1.062407,-2.1209373,-0.5386211,-0.39716357,-1.5553956,-1.165971,-1.1748719,0.11371058,-2.892766,0.5950689,-0.2519623,-1.6544449,-1.8322095,-1.9406322,-3.640602,-2.3373976,0.05304119,-3.7368808,-1.7807537,-2.455688,-2.926725,-0.118862,-0.66739476,-3.2046995,-0.18799935,-2.442687,-0.5394241,-2.7353902,-3.2089448,-1.8027791,-0.99992496,-0.9572324,-0.23632166,-2.794798,-2.6193128,-1.8170406,-2.0913591,-1.5202577,-0.5488345,-2.9129605,0.5391157,-1.8324857,-0.6656877,-0.8776131,-1.9427748,-0.832991,-2.8336744,-2.7503133,-1.2547514,-2.510541,-0.73665553,-1.8839556,-1.4201485,-0.96477085,-1.8786712,-0.8228,-2.2005906,-1.5358707,-1.7610676,-0.6590833,-3.0186658,-1.7336916,-1.3330331,-0.6844896,-2.929109,-2.0235028,-1.6312206,-0.19337709,-0.10879704,-0.7655135,-2.3976436,-0.8549161,0.24213141,-0.15112232,-4.4261103,-3.1100416,-2.4328127,-0.4191806,-0.7872653,-4.3413973,-2.1304803,-2.1122549,-1.2497715,-2.0630603,-0.5039735,0.047905266,0.64891636,-1.20263,-4.583493,-0.5492822,-4.0876236,-2.2286358,-1.653923,-2.8287039,-3.0342722,-0.28392267,-0.81563985,-3.196453,-0.7159985,-1.0680791,-0.3585397,-2.4865212,-0.12689081,-1.5515001,-0.1625302,-0.98792315,-1.0840311,-0.7498108,-0.8890735,-0.6754179,-0.9986964,-2.2819142,-0.5072347,-1.2929683,-0.36778504,-0.4262286,-2.5290594,-3.275723,-1.5400898,-1.8044494,-1.573412,-2.4317303,-1.5562979,0.27897435,1.7142633,-0.46729708,-1.0965334,-2.9183717,-2.4899616,-2.3374872,-2.4671936,-1.2790955,-2.515792,-1.5533437,-2.3143625,-3.2292461,-2.2135026,-2.0382142,-2.351171,-2.6326847,-2.3876364,-1.3716102,-0.785632,-3.2101626,-2.3535657,-2.5512257,-0.43960992,-2.1047816,-0.5643244,-1.3735182,-0.7068397,-0.12688267,-2.952582,-1.884523,-1.3691746,-0.83576524,-1.8088516,-3.6748195,-3.3475485,-2.663577,-0.21106231,-1.4879574,-0.6247559,-0.91407555,-0.46671516,-0.4509294,-1.0447507,-1.8336641,-0.6209532,-2.057818,-0.51853335,-1.7446344,-2.085489,-1.7094053,-3.1056838,-1.2488972,-0.6052574,-0.14555871,-2.657876,-0.63557416,-3.6973758,-1.2636601,-2.3704247,-0.14590584,-0.8125349,-2.068901,-1.2064956,-1.7026033,-0.14969864,-1.4447527,-2.3885465,-2.0066772,-0.5325253,-2.4692187,-1.872864,-4.495455,-1.581613,-1.8551947,-0.84672403,-1.194486,-2.1970093,-1.5266653,-1.3278291,-0.9935181,-1.3117688,-0.6261516,-1.8233799,-2.359971,-0.113251925,-1.7913866,-2.949401,-1.2013882,-0.52123266,-2.5084953,-1.8713592,-1.1197224,-2.5964537,-1.7514328,-0.828365,-4.3003078,-1.0980278,-2.920785,-1.0097113,-0.8457955,-1.0792849,-3.094324,-0.015851706,-3.6058712,-3.2040143,-1.7611127,-1.3370979,-1.6662339,-0.20988844,-1.4178185,-1.468858,-0.5726228,-1.9335878,-1.0728782,-1.1895399,-3.1435828,-3.1890712,-2.3002388,-3.4662848,-1.844082,-0.59648013,-0.039966524,-1.8403732,-3.3951106,-0.7199048,-3.2931223,-1.2576222,-2.6554031,-0.040062428,-1.2462554,-1.1709366,-0.18832599,-1.2316258,-1.0431659,-2.9655542,-2.7440066,-3.080278,-0.61232466,-0.74832606,-2.2124195,-1.5148127,-0.29662216,-1.4614404,-0.8163402,-0.69465744,-2.2300487,-0.10696778,-1.5590131,-0.84079266,-0.9006757,-1.2277081,-1.4822384,-0.8864528,0.40520173,-2.8615317,-1.09005,-2.473989,-0.3504029,-0.7236953],\"xaxis\":\"x\",\"y\":[0.029941127,-0.8858163,0.2780115,0.6506374,-0.19754502,0.42114967,0.6185583,0.49612868,1.1021125,0.08798018,0.39335418,1.6066914,-0.81641257,0.52153313,0.5411051,0.81452286,0.98649275,0.5444682,-0.12776205,-0.97330153,-0.29048374,-0.19984415,-0.49114478,0.17304002,-1.1418021,0.29722798,0.02817221,0.7385272,0.75963205,-0.6187902,0.6604219,0.8924514,0.77713704,-0.029962815,-0.48324645,0.14244859,3.4028563,-0.78986967,1.842656,-0.09232385,0.33420587,0.07120946,0.6754955,-0.6069966,-0.93989074,0.4067093,-0.21122906,-0.026260488,0.69147736,-0.15525897,0.97932136,1.0146425,0.59854084,-0.14288418,0.4749751,-0.96866494,-0.88137627,0.8910953,0.3626942,-0.26979995,1.0174431,-0.2899564,-0.008690208,0.046823427,-0.76658624,0.671056,0.26597625,0.15125774,-0.6977229,0.5017299,0.11885755,0.5278645,-0.21600872,1.1503937,1.0943831,0.60024804,-0.4012112,0.36063766,0.44014943,0.7976089,-0.6166774,-0.03173513,0.62724376,1.8195168,0.53729135,0.39037317,-0.19727118,0.4336645,1.6612929,0.85272396,0.8008086,-0.28630957,0.64690846,0.10354762,-0.90888846,0.91546,0.023964196,-0.14906004,-0.043637387,1.0433853,1.037956,0.35792798,0.02925457,0.5276843,0.7050245,1.0456254,2.8299572,0.39675218,0.6048506,0.7780794,1.2452563,0.19692583,0.39846593,0.1853558,0.9234992,0.52096295,0.43482435,0.4872206,-0.26789212,1.3475848,0.87770915,-0.5701336,0.5593045,0.55316234,0.17913432,-0.5768724,-1.1803018,0.7853432,0.639897,1.2964754,0.68210995,0.6732462,0.5219159,0.43399233,0.29726362,-0.014256433,1.0203874,0.719,0.28524667,0.19057633,-0.7601444,0.21742357,0.6717653,0.6609717,0.0759086,0.25472844,0.32303149,-0.6131133,-0.14380948,0.6204363,0.81710756,-0.65154856,-0.068704456,0.33044744,-0.12815957,0.83156794,-0.2091987,1.5499948,0.009399012,0.9745542,0.7316429,-0.038031794,0.52591014,0.7469836,0.09246613,-0.45344728,0.23565559,0.17667116,0.35657263,0.61035675,-0.6234182,0.6902727,1.4399571,-0.07024985,0.5163972,-0.3095515,0.5183967,0.5928255,-0.49920523,0.44847548,-0.33310646,-1.4442663,0.008497313,-0.3988968,0.18079208,-0.13892847,-0.30302274,0.54367876,-0.45494604,0.84742606,0.40334505,-0.7155363,0.3849522,-1.2143027,-0.31845954,0.18551756,-0.2988494,0.15989853,0.57732564,-1.0916989,-0.31399962,-0.022320196,0.87239885,-1.2858988,0.7863438,-0.9266635,-0.28931785,0.58520645,0.107102856,-0.26881796,0.71472293,1.1314652,0.63433975,0.50479066,0.040106893,0.08178902,0.89851224,0.36418027,0.8376438,-1.3105392,-0.42092913,0.7270828,-0.38484007,0.6065276,0.44031692,0.16561528,0.29920775,0.33882338,-0.0886676,0.25729328,0.7432893,0.23249157,0.5670442,0.6833244,0.410886,1.1805817,0.07968064,0.8039082,0.39454198,-0.06794974,0.092286274,0.90440965,1.416911,-0.7964586,0.04991044,0.77432406,0.3382433,-0.11485895,0.5095536,-1.2041994,-1.0974101,0.4883151,0.07910311,-0.010677338,0.5710575,0.9069183,-0.079245575,0.45595145,0.5852852,0.9875177,-0.783943,1.5582482,1.0397298,-0.19638532,-0.37653285,0.56657904,-1.1587895,-0.08599008,1.2846812,-0.8963021,0.44451433,-0.23727712,-0.52127475,0.9026817,0.7788163,-0.93602216,0.88120663,1.392853,0.46116215,0.09133585,-0.519683,-0.53413063,0.4283437,1.8217347,-0.043480672,-0.2890905,-0.032167397,0.33684444,0.00888285,0.5706619,0.19872765,-0.63116044,1.9374324,0.61568844,0.6792962,0.28507155,0.26061344,0.44541436,-0.57901496,-0.29448074,0.3899154,-0.19256927,0.8371965,0.15562011,0.43403375,0.41194117,-0.08942248,0.28958714,0.056279495,1.6337055,0.37726015,0.64027053,-0.8019079,0.110817805,1.1325278,0.82272726,-0.07430913,-0.5199622,0.32512397,0.8354011,0.8194305,0.5462763,-0.112975076,1.2078817,0.8411406,1.216138,-1.1779225,-0.7625954,0.09322719,0.7010209,1.3542763,-1.1790581,0.04899776,-0.36888635,-0.080802605,-0.27978027,0.95415854,1.2423671,3.74093,0.70006096,-1.285808,0.87609816,-1.6494727,0.3733309,0.6263415,-0.11427924,-0.9544324,0.6041417,-0.29065323,-0.86851615,1.2848747,0.37488216,0.6708685,-0.15474351,0.8656547,0.5709378,0.8379447,0.2463998,0.4693396,0.1844895,0.3448683,0.7679206,0.13615172,0.15233694,0.1816635,0.8279364,0.91533864,0.95003545,-0.07141972,-1.1193131,1.8398241,-0.5658366,-0.16633964,-1.0482627,0.6819294,1.1531554,2.2992563,0.6231861,0.45186508,-0.2795489,-0.37947553,0.42721868,-1.4210196,0.4023801,0.03101778,0.3479759,-0.37368748,-0.75949717,0.11637007,0.012286156,-0.8794202,-0.20485918,-0.8364458,-0.088890284,0.8445293,-0.20487113,-0.07663077,-0.5055847,1.1086731,-0.77920365,0.8335617,0.20918341,1.1668159,0.84043825,0.11387874,-0.032609776,-0.023210004,0.03308539,0.37027878,-0.5564134,-0.383834,0.25649637,0.70512444,0.8208163,0.9148114,0.8311552,0.40311623,1.2016875,0.70683604,0.93273056,0.60050404,1.1369914,1.0271771,-0.17291495,0.2152821,-0.10588804,-0.55832154,0.33920354,0.26394272,1.267425,-1.174449,0.70783293,-1.4719112,0.68033177,-0.19065695,0.7749891,1.0176104,0.35710585,1.2177016,0.34505814,0.7745719,0.048608974,-0.28770027,-0.90471077,1.254461,-0.035922296,-0.5411831,-1.9482564,0.060299724,0.13379411,0.003627181,0.6384363,-0.14696227,0.47021228,-0.4646812,0.97626996,0.34819973,1.0015143,-0.00657098,0.36168623,0.19866635,0.09203778,-1.0105197,0.48037857,1.120324,-0.7408998,0.8057097,0.034072503,-0.14608261,-0.04710932,0.6195641,-1.2487917,-0.2187564,-0.43296558,0.2762118,1.3744779,0.5948795,-0.14872773,1.0390908,-0.12709033,-0.99877864,0.3114289,0.3718254,0.4011023,0.6748244,0.21893232,-0.04228162,0.8863727,0.12752281,0.69755566,0.8421816,-0.57524747,0.022611499,-0.39479983,-0.11821312,0.10436644,0.89160573,0.9923289,0.27670598,-1.6280967,0.66024595,-1.654278,1.9382037,0.08198051,0.45537573,-0.51695186,0.32422453,0.485528,-0.06660828,-0.15768631,-0.7528077,0.66137195,0.1356832,0.9557308,0.9459708,-0.28874397,-0.4442271,0.82331765,0.42570698,1.1008033,0.8123189,-0.6990267,0.8184743,0.66569424,0.86110413,0.59214234,0.5657585,-0.23488742,0.24875231,1.2777709,-0.17514947,-0.4615863,0.5749077,0.71889836,0.3942188],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=5\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"5\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"5\",\"showlegend\":true,\"x\":[-1.1014669,-3.5666146,0.49945176,0.12612265,-1.3875986,0.5487937,-0.37728438,-0.30136818,-0.9262156,-2.0192547,-1.2339213,-0.12007257,-2.7289033,0.5838527,-1.9547064,0.30450732,0.3123138,-1.1098517,-2.8217092,-0.84491146,0.15082908,0.9456618,0.8369585,-0.1989576,-3.270894,-0.121796876,0.65209997,-1.2225832,-1.1738923,-2.3546565,-0.5174765,-0.28664938,-1.2335266,-1.22564,-2.2001348,0.69640756,-0.7799561,-1.0662549,-0.23577163,-1.440991,-0.15761384,-1.745062,-2.3523092,-0.10153553,-2.5416107,-2.485548,0.6402929,-0.50189793,0.15963751,-1.7550775,-2.5826716,-1.9473838,-2.3671515,-1.425075,0.5253615,-0.515141,-0.5814623,0.43255657,-0.2098255,-2.568749,-0.41965407,-0.9463658,-0.38223848,-1.0594708,-1.7966257,-0.10126251,-1.2914995,-0.14421424,0.14862025,1.9690558,-1.7824794,-0.21045464,0.5376664,-1.2703376,-0.59803885,0.3008219,-0.2515312,-0.76189744,-0.69949067,0.7600231,0.68203104,0.18099713,-1.0235145,-1.0220488,-0.32251835,0.26378262,1.1101822,0.48691493,0.15593755,-1.8853801,-1.404478,-0.43701687,0.8631803,-2.4907126,0.59045136,-3.0327444,-1.6490171,-0.6808245,0.20698649,0.49620908,0.17436904,-0.014709055,-2.484541,0.2936681,-3.482141,-1.2558978,-1.1940135,-0.08611351,-0.64065015,-1.5023723,-0.65037,0.12417871,-0.6422048,-2.4897785,-1.47426,-1.7812645,-0.0018674433,-2.8839374,-3.5714455,0.82212925,-1.5852941,-1.3055291,-1.1289694,-2.219482,0.62806857,-0.6222945,-0.65444756,-1.120215,-1.5084097,0.47643417,0.26781732,-0.34472477,-0.08711642,0.27162898,-0.49272138,-0.9613265,-0.1702674,-0.640435,-1.1216081,-0.3439697,-0.94453084,-0.38584524,-0.39434668,-1.5783312,0.06396106,-0.4121035,0.1756708,-0.4719463,0.032357246,-0.0694159,-1.3532242,-1.1491272,-3.0592928,0.5590918,0.49000263,0.14354861,-2.2896051,0.6804482,-1.018492,0.019716084,0.16642672,-1.3018373,0.009778231,0.3129382,0.6632116,-0.9221449,-1.5549865,1.0263262,0.65914154,0.019686729,-0.6399777,-1.2934606,0.4566993,-1.5381453,0.8739166,-2.7444773,0.13357294,0.46106756,-1.9498259,-1.1032239,-0.6452882,-1.4876449,-0.726446,-1.2655737,-0.9804745,-2.7050967,0.31575745,0.9655025,0.069406986,0.724581,-1.4320562,0.22763675,0.013988227,-0.9729253,-1.8188537,-0.52145076,-0.97733873,-2.70791,-3.5876694,0.7950525,-2.8177428,-0.62064433,-1.7534498,0.4833355,0.42468172,-2.0227501,-0.69648916,-0.064709425,-0.9656436,-1.5145094,-1.3862579,-0.46333498,-2.5457187,0.69875586,0.33632874,0.4732877,-0.9414165,-3.2809663,-0.23772596,-0.7265205,-0.82014465,-1.4614048,0.21904564,-3.3352418,0.16774285,0.5293038,0.5169939,-2.0099201,-0.85209584,-2.6155038,-3.0926523,0.09236288,0.38422346,0.42090923,0.4158312,1.0752105,-0.33411658,0.35697025,0.091049165,0.7366899,-3.1682692,-2.8603368,-1.102634,1.0555362,-1.8076613,0.78959715,-0.022972673,-0.39222527,-0.0011996329,-0.58429694,0.7409996,-1.477094,0.68855643,-2.740982,0.4727189,0.6307602,-3.2529116,-0.47316948,-1.8167598,-1.2415645,-1.8683493,-1.7438561,-2.6932473,0.49732357,-1.918875,-1.7440298,-1.090584,-0.79171103,0.1245119,0.121203065,-2.5488014,-0.5636003,0.5988631,-1.5197667,0.33148158,-1.439286,-2.3452272,-0.9531651,-0.87747335,-0.7727594,-3.4078465,0.52010274,-1.3101926,-1.6521543,-1.8045579,-1.8907353,-0.78048694,0.580476,-0.51152754,-0.5846257,-2.3221273,-1.9960419,-1.670364,0.411595,-1.9039594,-1.2361267,-1.3854578,-2.1222486,-0.46630248,0.04457152,0.4106257,-0.6950074,0.35110217,-1.917839,0.6754049,0.8937994,-1.1558867,0.7626649,-0.018008709,-2.8373265,-0.35390857,0.10517499,-0.9359163,0.6691854,-0.9575805,-2.6347475,-1.1344482,-1.9943444,-0.7641247,-0.78472805,0.89524806,1.328439,-0.6728882,-2.5066853,-1.0386869,0.16668743,-0.8128564,-0.43793595,-1.2101226,-1.6083295,-0.49589205,0.73486054,-0.7140415,-0.19624433,-2.157969,-1.7722067,0.787102,-1.9494512,-2.533411,-1.8612046,-0.2469819,1.2300788,-1.8554324,-0.34391478,-1.2494452,-0.8581512,-0.75855124,-0.9977223,0.6630732,-1.3928149,-0.5304085,-1.539175,0.48460346,-1.2647612,0.1601693,-4.047992,-1.9206642,-2.2969017,0.27072257,0.8451835,0.5812944,-1.5418622,0.9129995,-1.7150189,-1.9499081,0.33145112,0.25652963,0.7399763,-1.8128268,-0.74686676,0.27794212,-1.8318843,-0.5849813,-1.9046986,-1.3856122,-3.5043545,-1.3545443,-1.097642,-2.6727343,-2.3792753,-2.571931,0.674204,0.8954551,0.9793421,0.5644299,-0.92441,-0.47879052,0.21901393,-0.9093769,0.1389513,0.96779835,-1.7882811,-0.010086536,0.61649394,-1.9997625,-1.6081651,0.5496527,0.8510933,-0.7271028,-2.2147899,-3.7685394,0.5525277,1.4055513,0.43983233,-0.49808282,-0.0013202131,0.35370266,0.8452568,-0.9761889,0.27573812,-0.69848406,-1.5986742,-2.1641016,-2.4124908,-2.7217026,-2.6708703,-1.4827046,-2.5307932,0.103544414,0.7851505,-1.5748448,-1.7109368,0.6480638,0.38930875,1.4005195,-1.063684,-3.8410277,1.03745,-0.5360819,0.8483144,0.63584507,0.65719426,0.47090375,0.35759044],\"xaxis\":\"x\",\"y\":[-1.9959749,-3.9945369,0.9973022,-2.0010948,-3.519244,1.1276169,-1.6914011,-1.3839471,-2.1674056,-2.0818484,-3.1635706,-1.1045287,-2.3426702,0.2462442,-3.397653,0.47240943,-1.5064422,-1.414118,-1.6063253,-0.4630229,-0.8735951,1.0812165,0.987164,-0.9488508,-3.6530402,-1.4860632,0.874889,-1.2856115,-2.1500554,-3.0105677,-1.367244,0.34035683,-1.8943217,-3.3867338,-2.9799483,1.3714432,-1.5698569,-2.483435,-1.1257548,-1.0294592,-1.6328319,-2.9600685,-3.9972005,-0.909857,-0.9648831,-4.1293283,0.9851749,-1.5082419,-0.04789857,-2.5754116,-2.8206408,-2.4480622,-3.4238257,-2.1336446,0.5566655,-0.8302402,-2.3085613,-0.017366782,-1.151974,-2.7095861,-1.6987398,-2.7411034,-1.8390188,-1.4585394,-3.7677412,-2.1035752,-1.6806303,-2.1165462,-0.6628536,1.4201603,-2.9642384,-1.5258117,0.85533285,-0.9016682,-0.98165584,0.44423223,-0.7077554,-1.7608945,-2.5483882,-0.07888662,0.7572554,-0.2920552,-0.87151444,-0.56198424,-1.2658167,0.038480803,0.65937746,0.7581033,-0.7098618,-1.8999475,-1.3400842,-0.15399934,0.5305457,-3.1092548,0.86652863,-2.9875376,-1.7901672,-1.4014503,-0.32109582,0.21210061,-0.33746123,0.4904614,-2.3566852,0.12723424,-2.5088453,-1.5686301,-2.1631494,-1.5079547,-1.9724491,-2.852957,-0.9919081,-0.82449883,0.5058427,-1.4949901,-1.7900889,-2.669233,-1.6456536,-1.8852143,-3.6086411,0.50460225,-1.283737,-1.6000098,-1.174026,-2.4572468,0.39666528,-0.3710757,-1.7437586,-1.720167,-2.8230393,-0.27978644,-0.02014187,-1.9739289,-0.07529676,-0.08575039,-2.289832,-0.9135872,-1.1644877,-2.3743296,-1.1826023,-0.8705749,-1.4144927,-1.6692566,-1.1130773,-2.660029,-0.08356037,0.05523184,0.74247897,-1.7502747,-0.18802659,-0.00048963726,-1.3324372,-1.0369246,-3.7736437,-1.0185542,1.01076,-1.4891028,-3.7448046,0.81931126,-2.6714823,0.010337919,-1.3489628,-2.8479655,-1.6109678,-0.040256463,0.61951864,-2.1253953,-2.9704485,0.75225216,0.67295706,0.7958766,-1.2956253,-3.4794466,0.67513555,-0.71685916,0.54158753,-3.845946,-0.035416692,0.7350682,-2.489116,-1.777619,-1.9979751,-2.3916829,-1.0017065,-3.6309764,-0.98540735,-2.655847,-1.5395213,0.9625056,-0.71801156,-0.22974905,-3.1092255,-1.1299295,-0.657158,-1.8707229,-2.7074845,-0.08067126,-1.3724701,-3.8602202,-4.1315045,0.7944184,-3.3731275,-1.9998598,-2.2608743,0.1480421,0.9117911,-1.7577919,-0.24228403,-1.8807272,-1.9886659,-2.3811953,-3.0056105,-1.418642,-3.96474,-0.23293221,0.2637686,0.4339677,-1.684751,-2.3875718,0.14572038,-2.0631185,-0.8978373,-3.4739718,-0.06850349,-1.9948542,-0.91654485,0.73430073,0.99012446,-2.195725,-1.65691,-1.7329276,-4.464847,0.009361073,0.67591023,0.60809195,0.28004843,1.1371384,-1.1022784,0.4856661,-0.5816097,0.515474,-3.5639,-3.5182943,-1.6196641,0.58679396,-1.9510366,0.68568647,-2.0839312,-1.3036141,-0.84607446,-0.8824773,0.67185706,-1.7340523,0.63961256,-4.3141704,-0.6040177,0.4291793,-4.659661,-1.6985334,-1.784766,-2.0603895,-2.3469963,-2.5493553,-4.3112683,0.77868533,-4.451479,-3.1349456,-0.3606444,-1.9916958,0.4645064,-1.0338155,-3.582365,-1.9508269,0.5444706,-2.3966856,-0.80189145,-2.7278452,-1.2341386,-1.5215334,-2.1600902,-2.3770196,-2.0853136,0.79300374,-3.2164326,-2.7947385,-3.5379465,-2.3814795,-1.1620798,0.7675661,-2.2621791,-2.4382854,-4.3465967,-1.380455,-3.3327816,-0.10327601,-2.382811,-1.0165011,-2.668871,-3.957209,-2.8695822,-1.4686109,1.3416344,-2.41369,-0.046316423,-3.8662126,0.9607967,0.53324604,-1.8236204,1.1966846,-0.217127,-5.284491,-1.5177292,-0.052036688,-2.4187405,0.9446362,-2.1039486,-3.3010824,-1.598676,-1.2192999,-1.0855147,-1.0304022,1.3328367,0.7686755,-2.4945488,-2.884727,-0.2821125,-0.21867132,-3.2455835,-1.1902226,-1.521652,-3.3865688,-2.577683,0.768192,-1.4823306,-1.8905207,-3.989825,-2.7268527,1.1750915,-2.7280374,-2.3677063,-2.8713734,0.9210714,1.1495721,-3.1219032,-0.99055153,-1.9826173,-0.7382241,-2.024066,-2.7169101,0.8572973,-3.0222473,-1.6482427,-0.9560133,-0.068517596,-1.7745521,-0.5540239,-5.029006,-1.6287372,-2.5447624,0.91327226,0.39183867,-0.46872973,-1.2959853,0.7886095,-1.1414529,-3.8118262,-0.22528072,-0.23993853,1.0272225,-2.2788026,-0.58356994,-0.20519722,-3.4376264,-1.394386,-2.435779,-1.9275664,-3.9827666,-2.1732984,-1.4913375,-4.268796,-3.7120602,-3.2380252,0.90194976,0.45614254,1.0096965,0.0044143945,-0.957072,-1.0181435,0.96188223,-2.1149366,-0.12680045,1.2102412,-2.742915,-1.1728873,0.19901054,-3.0535462,-3.5537858,1.3455591,1.6331718,-2.435387,-1.4791756,-5.21249,0.7647069,0.9453064,-0.8942935,-0.55045426,0.9784732,1.0518603,0.6792704,-2.3402147,-1.4085501,-3.1516619,-1.7077327,-3.446134,-3.5442543,-1.010024,-3.652932,-2.517061,-3.9865408,-1.0069636,0.53361624,-2.6187713,-0.7145652,0.7292127,0.95160174,1.2767615,-1.968144,-5.6328835,0.8469644,-1.9019126,0.519985,0.788373,0.79774,1.0077171,0.06663787],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=6\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"6\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"6\",\"showlegend\":true,\"x\":[0.7748349,0.40446764,1.0922248,0.89749825,1.2608075,0.928221,0.5453529,0.61222434,0.32925975,0.6215776,0.47020584,0.87554955,0.8320341,0.8582951,0.9804146,0.9404712,1.1190695,0.2845142,0.5646735,0.11410934,0.0005520582,0.5618737,0.80324876,0.8604624,0.5187853,0.60789824,0.7597519,0.6690223,0.8304993,0.67292166,1.2288654,0.6403396,0.5142497,0.35200018,0.40062112,1.5459384,0.21534032,0.79552066,0.94907725,0.83696985,0.78377855,1.9584926,0.6961937,1.2951365,0.88004506,0.76788473,0.21121275,0.93194425,0.8547529,0.8056861,1.0064472,1.1124148,0.39217442,1.1696765,0.9113884,0.42977935,-0.46120483,0.5878088,1.0796756,1.2224058,1.6559881,0.9533372,1.070056,1.226125,1.0916574,0.81621337,0.96532667,0.98555374,1.6921302,0.76105666,1.1708962,1.3749541,0.21358031,1.1781069,1.1172446,0.89452696,0.9722729,1.564989,0.31033528,1.3564998,0.8046546,1.2199239,1.6157271,0.386317,0.29052097,0.6432624,1.2537261,-0.2170343,1.097743,0.20472491,-0.5069421,1.2709247,1.003203,1.6882232,-0.29722995,0.5256442,1.2098106,0.7874981,0.56166023,0.5791459,1.3640755,1.1313677,0.4856081,1.1092563,1.0039437,0.1984939,1.0256937,0.30879003,0.7737969,1.4537909,1.7730788,0.19907397,1.1539819,0.6245123,0.76990116,-1.1942503,-0.19433609,1.4914343,-0.09304041,0.80745006,1.5524422,0.4994257,0.6273736,0.8948045,0.71316016,0.88525724,0.17396617,0.1948247,0.13754427,0.31946015,0.5811208,0.82324123,0.85380375,0.557682,1.2442896,-0.114560306,1.2077299,0.48895216,1.5600102,0.74370813,0.25401068,0.26270032,1.1096293,1.386388,0.747352,0.99337983,-1.6070069,0.540855,0.69682646,0.9117092,1.2527853,1.330228,1.0894995,0.8708179,0.3358075,1.9753007,1.1033062,0.7115742,0.45784736,1.9006761,1.6910132,-0.7423036,0.46608776,-0.005803168,0.22330588,0.15567893,0.5732972,1.029557,-0.08468318,1.0709349,0.38846892,-0.66365135,0.6267065,0.46562636,0.08268955,1.1695713,0.2640187,0.83059335,0.60199183,0.02491948,1.5712541,0.9066578,1.094732,1.151355,0.29671496,0.49873298,0.85959315,1.0514731,0.1683414,-0.36142963,0.32322007,1.7214352,0.7468984,0.6534469,0.70710504,1.107409,-0.13965684,0.59468615,-1.1911168,1.1697149,1.0639175,0.727759,0.78665924,0.57851106,0.6334655,0.37035716,0.7375276,-0.18061754,0.73582685,0.77459633,1.1298923,0.9312122,-0.39594555,0.5650078,0.69184804,1.176647,1.1102774,1.1744574,1.0400703,1.293486,0.6450119,1.203778,0.7593367,-0.7173736,0.4354387,1.5321668,1.0499476,0.9967109,0.71785414,0.9959924,0.24689424,0.32656312,1.1910355,0.5820579,0.4449836,0.6208093,0.7335137,0.74279916,0.86362326,1.0526056,0.5705884,0.18298686,0.9898542,1.0740241,0.90573204,1.224005,1.1179904,1.2162087,0.6888126,-0.12871069,1.1345611,0.9308075,1.3177122,1.2502424,1.3941443,2.3536491,0.5294491,-0.6485688,1.5962268,-1.942059,1.0851921,0.7826365,1.2669222,1.7030338,1.7357236,1.5438243,0.40241873,1.3331658,-1.0543303,1.2336862,-0.25191468,0.8769847,0.6889292,0.78526044,0.44862545,1.148222,0.8809211,0.7458234,0.58913857,0.72034967,-0.12486258,0.8149625,0.32877237,0.8187096,0.90820384,1.1455997,0.66036236,0.7708101,1.1279098,0.15994549,0.9417633,0.12882453,1.2839748,1.3571923,1.1026733,0.28853047,1.1384231,0.70823514,0.57057786,0.29119527,0.89602625,0.60712147,0.68359315,0.48163557,0.7605237,0.38590956,1.1437526,-0.72045714,0.9030962,0.68184936,0.9272405,0.61571145,0.66715264,1.8218504,1.1634138,0.36858243,0.9900317,0.58779615,1.0648285,1.8279818,0.3029973,1.3311813,0.025000304,0.44027442,1.3849436,0.11834973,0.7276249,0.3504004,1.0414943,1.0101067,1.0317744,0.5673351,0.8157141,-0.7472014,-0.1428859,1.4000808,1.7581455,1.1552501,1.2109474,1.409346,1.6200825,1.6340548,1.0557684,1.0988897,0.24342626,0.7817944,0.5315631,1.5058868,1.156502,-1.0555408,0.7461643,-0.8686936,0.5689086,-0.6167006,1.2887274,0.58918715,1.0165094,0.6087953,0.91216767,0.9892452,1.0656734,1.0999177,0.12117088,0.6067718,0.21444404,0.7451669,-0.40341863,0.3036021,1.1481035,0.3811261,0.42821681,1.0340916,0.7933526,0.18708915,1.5567733,1.1650009,0.5506194,0.43402284,1.2804176,1.1778985,1.1949396,0.25870496,0.73567736,1.1220471,1.8843664,1.2253951,1.2488139,1.514266,0.8752885,1.1108965,1.0820874,0.5509224,-1.0271702,0.6160542,0.7251148,0.82675433,0.29274982,1.2952635,0.27301383,0.6472297,0.6218698,0.3294376,-0.5381728,0.84415615,0.879539,0.43026274,0.9588487,1.4978713,1.471437,0.9479859,1.062189,0.1443817,1.1555339,1.0987588,-0.33270684,1.380914,0.97112226,1.0352913,1.0340048,1.7134348,0.28958088,0.84882474,0.96748483,0.4939344,0.57736075,1.345093,0.90717685,0.5060073,0.5626553,0.77994454,0.678753,-1.5985202,-0.706915,0.6994313,1.2781056,0.31056613,1.6011964,1.1665832,1.396284,0.9934089,1.6544036,1.0321233,1.4549365,1.3101977,1.3042567,0.81497455,0.29266787,0.9317018,0.44469333,1.3805392,0.34717643,1.3927513,0.5381071,0.26379263,0.6954764,1.0858364,0.3801722,0.9797225,0.6349627,0.8467876,0.48452914,0.5412799,1.7132918,0.61577153,1.1545258,0.86490965,1.216096,-1.1074977,1.0814064,-0.16316299,0.680405,0.4785474,0.4735372,1.1021798,0.6664995,0.46712595,1.1965798,0.476223,0.83887017,1.5809059,0.8216015,-0.15129267,0.6175585,1.0584127,1.1327226,0.77151096,1.4501208,0.66147244,1.2852405,0.53422415,0.96218455,0.85004675,1.7117037,1.1082793,1.2655963,0.5383577,-0.28865173,1.4207324,1.1079472,1.5524086,1.2480699],\"xaxis\":\"x\",\"y\":[1.2690089,1.0580786,1.9897207,5.007312,2.722874,1.7756399,1.3603423,1.4470489,3.8370357,1.6180761,1.2756757,1.9569157,2.2704864,1.1653103,1.2122154,1.2576219,3.1859555,1.4996989,2.0283945,2.7956572,2.599332,3.2542148,1.4249703,1.3767583,1.7835896,3.4838915,2.9319632,3.0086985,1.1807423,2.0041978,1.5134844,1.6325967,2.6345978,3.7755413,1.5948218,2.3339806,1.3610355,0.74551654,1.7217593,1.9899796,0.90266085,3.4827325,0.50228536,2.7740061,2.7622845,1.0749774,2.8046327,1.7849267,2.289867,2.0299046,4.4369683,1.8968269,1.823323,1.6316745,0.12563144,2.3717456,-0.13038655,2.9672368,2.3265266,1.874921,2.9635954,1.6689746,2.5105362,1.9282376,1.9164854,1.4311843,2.4788587,3.0879579,2.0813408,2.2371857,1.7822012,1.1387854,3.006714,1.9970642,1.4317155,1.4400014,1.3769426,3.8560507,1.1108623,2.355635,1.4434456,2.3982522,1.7595559,1.9133924,2.6648962,1.1654232,3.3775468,1.9723984,2.6968892,3.3746696,2.091461,2.0958586,1.8703495,3.2506511,1.5418317,1.0499994,2.9209213,1.4851226,1.8197768,1.5926415,1.5468773,2.4478612,1.045775,2.53245,1.9331416,3.148831,3.8732932,2.0918791,1.4947832,2.2147691,2.4219284,3.3311253,1.7822732,1.4517578,1.7186524,-1.302169,3.3404255,2.8594968,-0.4977286,3.8407562,3.239865,1.5779928,2.3354764,1.7348083,1.9753581,1.4425815,2.250201,1.78539,1.664687,2.6758587,1.6325166,1.5310938,0.5259416,2.0615113,1.8208677,0.49732292,0.966609,1.7003664,1.6097577,1.6320764,1.8011572,2.4836588,2.05507,3.5169666,2.5152,1.2492958,-1.3208215,2.0266314,2.645604,1.36525,3.749362,2.5934541,2.1749437,1.9553951,3.8988292,2.8830943,1.2935365,2.349639,1.6153443,2.5164783,2.72644,-1.2552934,1.6784576,2.1360464,-0.92080367,3.0350025,1.7895436,2.3357065,2.4846249,1.84735,1.2247466,1.8539575,1.785229,1.948893,1.2032338,1.8623902,2.4866817,1.5054631,1.5678898,2.8819816,3.7434983,1.5303404,2.2472181,2.308275,1.6470311,2.0893152,0.9916675,2.1441958,3.1517613,-1.1973281,1.1542293,3.3080964,1.3609642,3.1825163,1.4229584,2.1145482,3.335928,2.0589986,-2.4733799,0.89939916,3.9664524,1.5939404,3.2314491,1.4562037,1.5839727,3.549858,2.1303802,2.2727509,1.9407517,1.5585016,2.1517735,3.3815699,2.9361336,3.6035554,3.5791843,1.2075542,2.0518744,2.5320673,1.4321454,3.149229,2.9102323,2.0559623,1.1182791,-0.7816121,1.774847,2.0796463,2.1284473,1.6509778,1.4540435,0.91242266,0.9689473,2.0611823,1.5519079,1.9849125,2.431542,2.3957336,2.5586128,1.264507,2.291074,2.1421611,0.7202426,0.74209696,1.5059576,2.4617608,1.4116192,2.8537874,1.8313121,2.0293343,1.5312561,2.125933,1.6254114,1.9219798,4.3391643,2.1535811,3.8849618,3.0619004,1.7722735,1.6189064,1.8676442,-2.1688259,1.2778349,2.663003,2.8487828,1.7088878,2.2311668,1.9145318,1.8635098,2.2731028,-0.25530618,1.8204389,2.5055792,1.5234481,2.490423,2.6284866,3.8303964,4.768902,1.4604516,1.0441757,1.0921997,0.9975774,-0.900296,2.3386607,2.8074043,2.8017933,3.7770329,1.1866944,1.3790606,2.0228994,1.4370297,1.060818,1.4680009,1.7111119,3.214468,2.2954597,1.9841582,1.8912231,2.1175733,2.3880017,2.280909,2.0638754,2.8400497,1.5802588,2.9069092,2.0942585,2.0752118,2.4875588,3.4401174,-1.0004643,1.6221331,2.033246,1.2286695,2.3822463,2.1526067,1.7835552,1.9803361,2.8371148,2.1471531,1.6556315,1.2508627,2.3290956,2.5913067,1.4697318,2.689976,1.6020615,1.5701847,2.1230764,2.3426037,0.891224,0.81631684,1.5672491,1.8152467,1.0311507,1.3296367,2.964351,-0.5618173,2.4479787,2.3692377,2.2229807,2.0538738,1.8578213,2.399635,2.0521982,3.1685789,1.6435283,0.89731944,1.8167571,2.7878525,2.2642205,1.2285733,-1.2744137,1.3779209,-1.6759391,3.8436322,2.1600535,1.712749,0.95341396,1.0271606,1.6718907,1.4728479,1.8342733,3.432261,1.8820726,2.5906136,2.4606063,1.9105197,1.5557112,1.6383077,2.6840556,1.4297382,1.0546784,2.7725997,2.2528634,2.522347,1.5149096,1.5997849,1.7614112,2.409507,2.8788974,1.7664258,2.653208,1.7485969,2.1064844,2.073053,1.8230127,2.3642263,3.5463486,2.1834226,2.787296,2.3466063,2.0474107,1.0092304,3.7890887,-1.2044611,1.3178493,2.7591836,1.7817543,3.1222079,3.042472,2.5481956,3.296678,1.6206248,1.2476425,1.4570018,1.7557901,2.170419,1.7609372,2.7878563,2.9950995,2.973236,1.5493962,1.7926883,2.7480226,2.736573,1.4261941,2.0416262,3.004839,1.4366016,2.5983474,2.6548367,1.8611401,2.0381887,1.7598737,1.606379,1.0673468,4.0450487,1.7286253,3.3121598,1.4986854,2.168206,1.6759603,1.7400116,-1.913524,-0.93062216,1.3325838,3.2617474,0.5713215,3.0148528,2.3072407,1.9778119,2.987999,2.2888079,2.8891797,1.7792351,2.0633962,2.5880065,1.5655283,1.3500319,2.1225877,0.9219878,2.386677,2.1305776,1.7020769,1.4252398,1.6608993,2.6927855,2.2848535,2.0251698,1.4658458,1.2788404,3.0268497,2.5847661,1.163055,3.6473572,1.8497967,1.364517,2.2617006,2.0217812,-1.6454164,3.0036676,1.5429606,2.0990226,1.5189804,1.3729776,2.4943223,2.3601635,1.8696998,1.6246104,2.2846327,1.5786182,1.9386598,1.648843,3.2833333,1.3487527,1.236554,1.4659276,2.201273,2.9679787,0.92240167,2.0874815,2.5771096,2.1662354,2.67357,2.038785,0.9847362,1.7608833,2.396155,-0.87139213,1.4625485,1.6814318,1.7400603,2.2583728],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=7\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"7\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"7\",\"showlegend\":true,\"x\":[-1.2603989,-1.7962683,-0.732203,0.25061947,-3.2488127,-1.3542814,-1.0572392,-0.4273035,-1.2601517,-1.1455255,-0.30504853,-0.47467482,-0.08513218,-1.020358,-0.45994383,-1.558634,-1.3480802,-0.4692043,-0.17161305,-0.32456502,-2.22614,-1.4202365,-2.088442,-1.543892,-2.4940333,0.10180262,-0.8641882,-0.598478,-2.3476696,-0.37113586,-3.41395,-0.45588696,-1.2740204,-1.7692168,-1.2518623,-1.3074323,0.55698925,-1.5660843,-0.93502986,-0.46677035,-0.43514448,-1.6404002,-0.6286994,-0.2273593,-0.8796346,-0.79247004,-1.5141077,-2.793274,0.27572936,-0.77051425,-1.0861592,-2.7888618,-1.5010654,-1.935791,-0.96970105,-0.76295424,-1.5159235,-0.66273993,-0.63884336,-0.376053,-1.2163036,-0.84665716,-0.09666705,-1.7935913,-0.37972745,-2.2293448,-1.1575358,-1.5418538,-1.4974314,-0.87562287,-0.99571174,-0.2408679,-3.145667,-1.5387825,-0.20028564,-0.4171815,0.11663586,-0.46708614,-2.349188,-3.4195862,-1.8743393,-0.5052176,-0.51489663,-0.83011186,-2.4062672,-0.11240375,-0.7057724,-0.4418397,-1.7155339,-0.9034979,-0.30325285,-3.2103586,-1.7093279,-1.726777,-0.10855925,-1.4811535,-0.89798373,-0.47799212,-1.4973156,-1.6808041,-2.5313478,-0.15768266,0.011674911,0.40855515,-0.37732914,-1.8030244,0.029252559,-0.6576475,-1.4791514,-1.7731596,-0.80088747,-0.85407174,-2.4495592,-0.58278704,-0.36463508,-0.9229913,-0.29081392,0.48259616,-0.5320081,-1.2713971,-1.2457478,-0.19035691,-0.9402521,-1.6904979,-0.5132473,-0.9226992,-1.3764586,-0.52568555,-0.15400854,-0.49763125,-0.7730665,-2.3982472,-0.61495644,-1.088229,-2.0907273,-0.46561942,-0.93797964,-0.2399378,-3.1619687,-0.5194584,-1.2621044,-0.1909707,-0.17307849,-2.6839604,-1.6163827,-1.0840492,-0.66269267,-0.32130075,-2.1175947,-2.2681518,0.016979843,-0.7873883,-1.2700907,-0.8174461,-2.517799,-1.5788051,-1.356744,-1.5006758,-0.2371844,-3.4459853,-1.2328508,-1.466779,-2.8520703,-0.18066007,-0.84163547,-2.1959567,-1.2236183,-1.5317644,0.29990733,0.3410523,-0.97589296,-0.8064208,-1.1497273,-1.3834338,-0.42173,-1.78698,-1.3033981,-1.3971615,-0.24445695,-1.2621666,-2.197964,-3.2112927,-2.083265,-0.2965824,-1.237247,-3.116869,-2.1683843,-0.5544364,-1.7730035,-1.3822119,-0.30469674,-1.3136537,-0.53448737,-0.42671362,-1.4872924,-2.0594792,-1.3708317,-1.6876736,-0.46397996,-0.6325064,-2.1305084,-0.6608626,-1.7690339,-1.9380479,-0.60028815,-0.6465718,-0.25039086,-1.6976657,-0.5975993,-1.2646886,-0.25546312,-1.5211853,-1.7573961,-1.6015524,-1.8007044,-0.28417385,-1.1816597,-1.337785,-0.7331769,-0.33316588,-1.3686582,-0.9681439,-1.0583687,-1.3579099,-1.6966953,-1.8511479,-0.24658313,-0.5448153,-0.32041234,-0.22889213,-1.3439417,-0.38293067,-1.467835,-1.7217461,-0.64236486,-2.2351046,-0.52592677,-1.3087511,-0.2079039,-0.6360444,-0.30086154,-2.1220183,-1.6960917,-0.36781666,-0.32142293,-0.8442253,-0.5559494,0.0059191287,-1.7989299,-0.11926797,-1.2687583,-2.0786262,-1.189892,-0.28772312,-0.08887985,-0.28642958,-0.7864479,-0.2874667,-1.291426,-0.26632774,-1.3595735,-1.9198202,-0.21358795,-1.496231,-1.6208727,-1.7095118,-0.6990067,-0.18355502,-1.3761711,-2.0192058,-0.987649,-1.7539327,-1.1567183,-0.4963063,-1.7588072,-0.37120515,-0.35014275,-1.4032463,-0.87111366,-1.884999,-1.7285681,-1.0636493,-0.69892496,-2.620926,-0.97289205,-0.5256696,-0.51747525,-1.206541,-1.7788174,-0.43331206,-0.2032102,-0.26253536,-1.6867615,-0.50663185,-1.7130448,-1.7423091,-0.1453623,-1.108527,-0.3592558,-0.5937217,-1.1291564,-1.8315022,-1.0696986,-0.45105153,-1.1529738,-0.7028588,-0.33931676,-1.004004,-0.9463503,-1.0804007,-1.0991096,-0.38201538,-1.4180474,-1.6011992,-2.3241851,-0.6117619,-0.6814345,0.13207996,-0.45905846,-1.3600183,-0.4462054,-0.6785177,-0.12100828,-2.159762,-0.15442808,-0.53350055,-0.3712602,-0.23921071,-1.7035921,-0.35274103,-1.595292,-0.36832023,-1.5827035,-0.5419767,-0.41451603,-0.8152827,-0.42563564,-1.8010572,-0.16050245,-0.6062745,-1.3053763,-0.30679762,0.49216688,-0.9703815,-1.2631792,-1.461298,-0.40035975,-0.53551143,-1.4678484,-2.549242,-0.47660452,-1.1026753,0.51322156,-0.41488537,-1.0576019,-0.1849579,-2.250567,-0.5982111,-0.91826785,-0.44881535,-0.8531274,-1.9636682,-1.1357565,-0.44936568,-1.5334783,-1.6888713,-0.89277226,-0.58458704,-1.6072047,0.0207178,-0.96762335,-0.39692652,-0.29276204,-0.20743845,-1.2727236,-0.28178942,-0.21906699,-1.8757823,-0.6405821,-1.3683066,-1.9827329,-0.32046777,0.21501404,-0.3176738,-0.3561185,-0.4498641,-0.07903966,-0.8332454,-0.36018813,-1.7791624,-0.719267,-0.58721334,-1.7360816,-0.28806978,-0.9532391,-0.15259115,-0.35591447,-2.1444886,-0.34607825,-0.30354965,-1.7195033,-1.9191452,-0.88531387,-0.17248671,-2.2812195,-0.5156127,-0.9306455,-0.60740334,-0.9870734,-0.5243466,-1.590382,-1.8966298,-0.41470265,-0.15988424,-1.5181072,-0.07640362,-1.350915,-1.2497764,-0.34247792,-1.8840536,-1.2251515,-0.26868308,-0.26379806,-2.0820298,-0.2583198,-0.87960947,-1.5296253,-0.34916055,-1.235704,-0.78820384,-1.0023894,0.31457406,-0.34837416,-1.3513911,-2.3194597,-1.8935306,-1.0966506,-0.39828196,-0.9185449,-0.32541424,-0.2512598,-0.33072904,-1.3425043,-1.0253937,-0.25081277,-2.7941236,-1.0432081,-0.20221978,-0.9466948,-1.1481446,-0.6146116,-0.35230312,-0.57213664,-0.49526605,-0.5169682,-0.23331189,-1.8682176,-0.7407361,-2.2146177,-0.19049206,-0.7912635,-0.116148144,-1.8493927,-0.234787,-0.83608246,-1.1555474,-1.4567224,-0.94783485,-0.1450315,-0.95878017,-1.1532962,-0.22449657,-1.1027477,-0.022958994,-0.20910248,-0.6746298,-1.0061791,0.2582441,-1.0836711,-0.24334835,-1.8310966,-1.9381963,-2.146422,-0.600639,-0.06062275,-1.4328378,-1.0844951,-0.35478926,-1.5684644,-0.49153703,-1.4842724,-0.111364484,-0.6495047,-1.0658369,-0.7956634,-1.2950451,-1.9559153,-1.0808177,-0.65323853,-1.6349584,-3.0110903,-2.1447783,-1.9713789,0.06000644,-1.1847868,-0.774269,-0.6415293,-0.25124907,-0.9252716,-1.6687863,-0.11647415,-1.8435308,-0.6021602,-0.78838503,-1.286617,-1.1707482,-0.6826941,-0.98471797,-0.17873512,-0.1003983,-2.7313704,-1.8094649,-1.7751498,-1.5436536,-1.3378019,-1.04143,-0.3358891,-1.2248094,-0.66772854,-1.2500196,-0.11081529,-0.1615261,-0.7625936,-0.02455023,-1.5080448,-0.48246777,-0.4189749,-1.4853514,-0.7448108,-0.7778462,-1.9281777,-1.1035559,-1.3180618,-0.68409455,-0.5363969,-0.9582984,-0.7639873,-0.2953716,-0.049255967,-1.0214877],\"xaxis\":\"x\",\"y\":[-0.42006415,-0.54389167,0.087521106,0.99583817,-1.2156817,-0.017794892,-0.04538258,0.030421212,-0.34135967,-0.27840847,-0.012202099,0.2905537,0.047197938,-0.14223902,0.08662577,-0.33696193,-0.13898036,0.14317916,0.48543578,0.3563884,-0.75853837,-0.105979964,-0.9011856,-0.5416562,-1.4069397,0.04026246,0.1032712,0.07869236,-0.6080118,0.44211102,-1.1448426,0.16080244,-0.33123073,-0.5673109,-0.3651204,-0.33882892,0.58360785,-0.52942437,-0.118926115,0.26576823,0.26669645,-0.1637947,-0.012168601,0.22521268,-0.013333783,-0.005771756,-0.44705558,-1.1862594,0.47455084,0.14204271,-0.1809463,-0.90147763,-0.59528893,-0.9123358,-0.21786277,0.022259936,-0.6861982,0.11091809,-0.057821758,0.099901155,-0.53238916,0.5599835,0.41478604,-0.69311726,0.13231306,-0.99567264,-0.29926592,-0.03384804,-0.24976847,-0.29289147,-0.21283579,0.08512132,-1.259592,-0.6000439,0.17449631,0.21600516,0.44602025,0.0013650358,-0.7108114,-0.87519014,-0.6744942,-0.2670642,0.1963823,0.24606268,-0.95889163,0.22874288,0.05363454,0.65232176,0.008936077,-0.1228938,0.17202504,-1.3379452,-0.45903832,-0.85098016,0.1760049,-1.2788788,-0.050632104,0.06086673,-0.42650014,-0.37262678,-1.249107,0.30924422,0.32447022,0.3764459,-0.059363768,-0.50713116,0.17429225,-0.10925503,-0.36783874,-0.4442824,-0.20834586,-0.073187076,-0.27617162,0.4261889,-0.30481178,-0.1318017,0.08023292,0.45359558,-0.071142174,-0.6066177,-0.08617985,0.49954146,-0.08923271,-0.16744126,-0.22972485,-0.26094532,-0.64113975,-0.1156067,0.10579772,0.15990679,-0.16771024,-0.4020787,-0.8366116,-0.39974225,-0.75483996,0.2536767,-0.11853019,0.3320915,-0.88334465,0.08731958,-0.6083014,0.025241166,0.18800144,-1.1335739,-0.89102626,-0.28065658,-0.04138305,0.20895873,-1.1097744,-0.4746896,0.36311293,-0.06162139,-0.019236147,0.11260466,-0.9652749,-0.86396855,-0.015546158,-0.6380291,0.36974174,-1.205056,-0.1862638,-0.14979208,-0.36645535,0.21234538,-0.19317631,-0.48095822,-0.27020442,-0.14610033,0.4653988,0.5284153,-0.06352105,0.30769557,-0.28366572,0.16683768,0.11204378,-0.58092666,-0.3374344,-0.39166278,0.23742492,0.10871072,-0.6728216,-0.67557263,-0.5401225,0.05233033,-0.116770506,-1.0216876,-0.6395448,0.09916386,-0.92047507,-0.6853054,0.12879787,-0.17854968,0.17436342,0.09713736,-0.7039252,-1.2281036,-0.3626225,-0.34983984,0.19557725,0.22593783,-0.8031717,0.0239719,-0.40678453,-1.0875305,0.031366795,0.10540618,0.26442075,-0.8751136,0.00015665591,-0.38907892,0.4299022,-0.41708815,-0.8345069,-0.60666287,-0.400828,0.015448034,0.069252566,-0.4854493,-0.42398882,0.22808702,-0.5011142,-0.3950287,-0.2051767,-0.34763983,-0.567619,-0.7799175,0.17146184,0.2542116,0.17450322,0.42280954,-0.2736941,-0.38110805,-0.43899316,-0.4116974,-0.12680075,-0.44124252,0.20002477,-0.27553248,0.08285013,0.07835093,0.090728104,-0.84269917,-0.7892613,0.21602635,0.04961677,-0.0058220625,-0.08367733,0.36313874,-0.75443447,0.65104717,-0.4574561,-0.047477826,-0.24018407,0.09473351,0.3460816,0.2491983,0.8400549,0.07208222,-0.26272634,0.1328607,-0.1435252,0.29095995,-0.14750381,-0.31653747,-0.22434455,-0.60513973,-0.0408703,0.10962285,-0.579052,-0.6681361,-0.24099669,-0.4118386,-0.22486965,0.105919406,-0.6509245,0.10591583,0.16089188,-0.35820445,-0.13431545,-0.57897925,-0.6451125,-0.2133607,0.03382206,-0.76177514,-0.20256788,0.14547198,0.14326696,-0.03720341,-0.8311084,0.16327341,0.4989739,0.06719279,-0.6000146,-0.11425288,-0.41166043,-0.7740463,0.2579792,-0.20331712,0.36715084,-0.19425687,-0.41169566,-0.46520007,-0.20915061,0.14077164,0.22288553,-0.08600719,0.51771975,-0.1701093,-0.18568255,-0.118423596,-0.42260462,0.26152557,-0.3638772,-0.57159364,-0.8452709,0.017761245,-0.19450442,-0.2275716,0.20809485,-0.25612217,0.23120351,-0.15864123,0.92983544,-1.0323178,-0.0331363,0.01588063,0.5925879,0.097298756,-1.0129509,0.09962329,-0.6616132,0.12825511,-0.82928765,-0.26575363,0.014705658,0.2904026,0.07849978,-0.35900787,-0.24691704,0.023536816,-0.88882345,0.08575438,1.2014133,-0.6206197,-0.38106042,-0.56404227,-0.001608938,0.015424281,-0.119626395,-1.5099083,-0.011338249,-0.028579533,1.2661235,0.17176197,-0.17465256,0.114906386,-0.59273535,-0.4603094,-0.1326513,-0.08747688,-0.07121937,-0.7777511,-0.19148263,0.38706458,-0.17734009,-0.55994374,-0.3100617,-0.09929888,-0.31951407,0.038214743,-0.3123126,0.43999135,0.3306045,0.122342154,-0.34515986,0.9630053,0.07796121,-0.64470613,-0.8465795,-0.7499765,-0.34590596,0.019835234,0.3316216,0.1939104,0.14667203,0.08441636,0.15545745,0.14585187,0.11204855,-0.36483455,-0.09858316,-0.06723932,-1.2252676,0.39847642,-0.1470464,0.6090156,0.0860478,-0.79082406,0.037922353,0.111913666,-0.4934339,-0.94359154,-0.24139327,0.22346501,-0.79050237,0.07687393,-0.022234306,-0.041186944,0.0033197403,0.096163005,-0.447029,-0.79795563,-0.123132795,0.05034545,-0.37180018,0.9410167,-0.41702694,-0.45305455,0.057689562,-1.1117973,-0.29282102,0.027708694,0.05109714,-0.6797696,0.19752042,-0.25490773,-0.3233335,-0.029581197,-0.6398221,0.18172778,-0.22965714,0.4104495,0.1265196,-0.95359856,-0.4281193,-0.62517583,-0.00713782,-0.053230457,-0.12889795,0.15183766,0.21953107,0.037971288,-0.27866903,-0.22878082,0.2624678,-1.1490879,-0.23526865,0.34354854,-0.119846046,0.0027737767,-0.016736284,0.11737026,-0.24125667,0.010300085,0.20027326,0.18021242,-0.313551,0.030103162,-0.7804898,0.20430143,-0.107425295,0.31724298,0.048082814,0.3001654,-0.071382195,-0.3692886,-0.20004767,-0.12544556,0.241248,-0.11467303,0.20583396,0.44928008,-0.47435784,0.40010208,0.17564197,0.1327744,-0.74153954,0.71669984,-0.36457762,0.21642484,-1.1219902,-1.1465886,-0.5862945,0.0075710565,0.3643518,-0.56939256,-0.7796755,0.006359175,-0.7189175,0.11555402,-0.6772462,0.25875157,-0.2742491,-0.17223783,-0.03483706,-0.52110165,-0.7690474,-0.338818,-0.38208848,-0.51707584,-0.9012026,-0.29742947,-0.555318,0.1547469,-0.19691238,-0.2093164,-0.106900126,0.15699993,-0.2797343,-0.32435906,0.49286997,-2.0502396,0.07803342,-0.1625123,-0.23613635,-0.2842843,0.05554025,-0.22756314,0.28648537,0.24571027,-1.2490239,-0.62744284,-0.1997757,0.8083978,0.009457603,-0.30951256,0.105403885,-0.6377057,-0.15406884,-0.0279736,0.363909,-0.14681952,-0.25492597,0.37721533,-0.26750433,-0.12113335,0.008150682,-1.1822387,-0.12270296,-0.54796916,-0.98267764,-0.30608833,-0.63733476,0.073458046,0.01594998,-0.22339313,-0.3742165,-0.23321739,0.23187847,-0.31772253],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=8\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"8\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"8\",\"showlegend\":true,\"x\":[-2.1924613,-2.095836,0.30902296,0.3270079,-0.2872766,0.3054765,0.17056686,0.17242777,-1.1086489,-1.7809336,-0.93317974,-2.6409178,0.07169101,-1.6830642,1.2233236,1.324547,-1.1437309,-1.5637419,-0.0003298521,0.70968306,-0.21502727,-0.50544643,-0.32359463,-3.633267,-2.6566286,-0.5794793,-1.7808634,-2.3475566,-0.10390973,-0.9137491,-2.9588122,-0.48743463,-0.5468105,-0.027409256,-0.5593623,0.34734726,-0.11973706,-2.0850234,-0.8132795,-2.4476056,0.22837669,-0.92181736,-0.8854574,-2.4496856,-0.7023181,-2.0864077,-0.38564456,-2.7016988,-0.49893308,0.1295011,0.4597472,0.5197376,-0.90957767,-0.10760307,-1.8506653,0.17757696,-0.9290313,0.24152929,1.0420526,-1.7023313,-0.19696192,-0.586705,0.1250459,-0.9740135,-0.5428977,0.0026403964,0.21376562,-0.041257948,-0.46385908,-0.66583735,-0.22376493,-1.3732405,-1.5558782,0.35076803,0.074875325,-1.094476,-2.043346,0.84944606,0.26429695,-0.407177,0.045670033,-0.14880441,-2.2314372,-0.048669994,1.007768,0.29727423,-0.8881283,-0.046092093,-2.8451953,0.19839507,0.16317868,0.2396425,-0.047573358,1.1547235,0.18738472,-0.027641118,-0.7763252,-0.061266273,-3.4432797,-0.82586884,-0.2917446,-0.93708485,-0.7013177,-1.7074128,-1.0972044,-1.52627,-0.8487419,-1.3360622,-1.6971965,-0.23326752,-1.9713422,-1.963912,-0.4520755,-2.6076927,-1.2355288,-1.0792873,-1.0353291,-1.7876071,-1.709183,-0.51216644,-2.7476702,-0.42741984,-1.9126451,-0.88775325,-1.3027074,-1.1234068,-0.7947185,-0.6673672,-1.3398572,-0.67065907,-0.15205207,-1.1708939,-2.7736,0.10878593,-0.42480618,-2.2398138,-0.2539035,-0.16663195,-1.0171406,-2.5707154,-1.8180934,-0.17974824,-1.7824204,-0.8243236,-0.7517512,-0.017462343,-0.08186078,-0.37521508,-2.0528626,-0.8678502,-2.5627189,-0.15992391,-0.2337335,-1.4420093,-1.4111289,-1.0042006,-0.71302605,0.0743725,-1.3947314,-2.253222,-2.642892,-0.47820815,0.7411889,-0.69428873,0.5343328,-2.6577878,-3.234789,-1.3702657,-1.3510892,-1.0978987,-1.2092799,-1.0908307,1.3379524,-2.5393472,-0.44035104,0.26465714,-1.075869,-0.2159282,-2.2042642,-0.68689394,-0.82144064,-1.8385538,-0.48908514,-0.46132264,-0.39651218,-1.0963124,-2.127605,0.37450594,0.17364705,-1.428274,0.5993009,-0.44949326,-2.2915945,-1.4356506,-1.5346695,-1.9217589,-0.29289174,0.29978365,-1.6547699,-0.5122811,0.9499066,0.11516547,-1.1627856,0.3626008,-1.0452789,0.20503765,-1.040025,-2.7901797,-2.1196861,-0.8065928,-1.4783096,-1.971198,-1.6573973,-1.2178267,-1.1606531,-0.4957845,-1.445807,-1.2137865,-0.40384635,-0.45476314,-3.2775211,0.2827314,-0.3949853,-1.9758347,-1.7644861,-0.53302956,-0.08753705,0.54546654,-1.9191483,-0.12531328,-2.5682058,-2.4126067,-0.024110049,-0.81160146,-0.076749265,-1.6360155,-0.47451326,-1.2716367,-1.1813278,-2.094851,-0.16503206,-0.988607,-2.6234226,-2.0860605,0.061544,-2.0759702,-2.2055542,-0.26444644,-1.139548,-0.10461646,-2.4550333,0.38485575,-1.3282962,0.14117104,-3.3549519,-0.2623456,-0.35605374,-1.1741202,-2.2590897,-0.8811625,0.19790995,-3.318675,-1.3982521,-0.049263954,-1.2812783,0.24653816,-1.7038889,-1.9832076,-1.1220553,-0.3034953,0.14502376,-2.0490336,-1.6288925,-0.19999143,-0.5456224,-0.33735815,-0.8014555,-0.32542917,-2.3744667,0.20020074,-2.4520693,0.2800339,-0.65934986,-1.3925532,0.0074299276,-1.682163,-1.0564774,-2.791521,0.2517867,0.18987083,-0.6836027,-0.17932431,0.57041913,-0.53888404,0.26626474,-0.68838847,-2.0109286,-0.39388773,-1.8389547,0.23196411,-0.408668,-1.8791384,-0.19632742,-2.372491,-1.5912036,-0.8182312,-0.2712501,0.21441108,1.0815488,-1.4931709,-0.81700194,-0.089148134,-0.506821,-0.965169,-0.32860702,-1.0882611,-1.993783,-0.3777871,-1.0259322,-0.2765869,-1.1955048,-1.3074777,-3.1500754,-0.3387346,-0.7174504,-1.694191,-0.9142781,-2.035584,-0.10679141,-2.808394,-2.437004,0.34745014,-0.38256907,-1.2013086,-1.2710016,-0.69676936,-1.1021682,-2.8690815,-0.08417845,-1.8204985,-2.350224,-1.3302515,-0.9208965,-1.3213639,-0.6238886,-1.9059094,0.1301915,0.16276234,-0.36271885,-2.510148,-1.9727118,-0.960177,-0.28866896,-1.0209134,-0.9246763,-1.3507715,0.5110746,-3.1265411,-0.68087083,-0.3148611,-1.6934896,-2.0342925,0.45174253,-2.128767,-0.9079269,-2.7128901,-0.84568596,0.3206849,-1.6475464,-3.4759016,-0.8331151,-1.5452288,-0.55905825,-0.29705265,-1.5932018,-1.3085161,0.28483433,0.29421926,0.48527372,-0.69772685,0.61042976,-1.0075381,-0.50115764,-2.3778524,-0.6240077,-0.61946726,0.28699332,-4.2670226,-1.3986267,-1.0368414,-1.481627,0.13091576,-0.74409574,0.14668435,-0.73541534,-0.2879148,-0.57390606,0.18885452,-0.96166474,-0.21557193,0.28195155,-0.04616341,-2.9655457,-0.95889664,-1.9629743,0.07216847,-1.3472246,0.28173208,-1.2998732,-0.79718816,-1.8641717,-1.1841123,-0.36602882,0.19512242,-0.027911246,-0.2015472,-1.5784155,1.1713256,-0.21672645,0.50332135,-0.48348814,0.04192266,-1.9030367,-1.1258548,-1.9126812,0.32488418,-2.4063668,-2.3287835,0.49401563,-1.3156314,-1.0428468,-2.5828457,-1.9932575,-2.0999057,0.41045624,-0.09313911,0.8937787,-0.031416982,0.3264464,0.23783958,0.8985336,0.24863446,-1.4242505,-0.49469516,-2.1617188,-2.4173326,-2.1446488,-0.31247434,0.32901746,-1.2771207,-1.519,-0.8465421,0.2606032,0.0043670237,-1.1560307,-1.1154861,-2.0664716,-1.0251584,-0.3725767,0.5602323,0.050032854,-1.8727872],\"xaxis\":\"x\",\"y\":[-2.554123,-2.1666348,-0.9913736,-0.24248171,-0.77421594,-0.048346452,-0.98256195,-0.37826455,-1.422666,-1.9046829,-0.24463257,-3.15431,-1.0999256,-2.2407506,1.1324035,0.7428182,-1.1725037,-1.7144476,-0.55992544,1.2662609,-1.410118,-1.8228232,-0.2369719,-3.9160664,-2.6530478,-0.9787633,-2.0070066,-2.80437,-1.2409766,-0.92109764,-3.3261817,-2.3447783,-0.8980416,-0.84013176,-1.8813311,-0.3950752,-0.9654435,-2.5389435,-0.8420566,-2.0857127,-0.7562274,-1.2363887,-1.4413619,-2.2357235,-1.4241741,-2.279819,-0.92564017,-2.7825153,-1.6576949,-0.37018493,-0.68011606,-0.5952238,-0.93100876,-0.87759954,-2.334936,-0.7461438,-1.4028406,-0.6156335,1.2326092,-2.3735344,-1.014584,-0.75584894,-1.5452013,-1.4808984,-1.8686959,-0.9677837,-0.8197601,-0.3292215,-1.5028527,-0.907413,-0.7317043,-1.3607799,-1.689501,-0.69321173,-0.5031396,-0.77704895,-2.016479,0.43254226,-0.73360056,-1.1929077,-0.44049233,-0.669551,-2.1377227,-0.80477095,0.7760246,-0.6940256,-1.2000263,-1.0562879,-2.6613836,-0.62401253,-0.72595274,-0.7037619,-0.3259158,0.7342203,-0.64736813,-1.1399012,-1.3515329,-0.58590525,-4.47066,-1.4112885,-1.100167,-1.2672995,-0.48246247,-2.704858,-1.5390357,-1.2274903,-1.72829,-1.1282067,-1.4493403,-1.1168828,-3.2729568,-1.6181891,-0.86001486,-2.884522,-1.44296,-1.2644904,-0.92423224,-2.164598,-1.5962081,-0.60371053,-3.4648771,-0.8212699,-2.3463593,-1.2131325,-1.4035822,-1.6103003,-0.7037907,-0.30210507,-1.462238,-0.99072784,-1.4128901,-2.035596,-2.7868826,-0.9067538,-1.9009644,-3.2610042,-0.53170455,-0.6978424,-1.3209952,-2.9382782,-1.4227287,-0.87075126,-2.2839987,-1.283478,-1.3109304,-0.77690506,-1.271314,-1.3974209,-3.133671,-1.1939111,-3.3137486,-1.0827371,-1.5265417,-1.5035088,-1.6954705,-1.3864454,-0.68048465,-0.6374868,-1.715419,-1.9686182,-2.8242784,-1.1261493,-0.45139378,-1.0772035,0.03815697,-2.556945,-3.4822521,-1.7869632,-1.2299498,-1.7317865,0.26543617,-1.3643146,1.0700929,-2.3229709,-1.0448959,0.10654263,-1.8070744,-1.1406434,-2.2637029,-2.0330741,-1.0677704,-1.542823,-1.0852029,-0.91588265,-1.4306165,-1.2326391,-1.5568888,-0.16170047,-1.3615628,-2.0220273,0.5266496,-1.182237,-1.9894133,-1.517284,-1.7744467,-1.9863541,-1.5732229,-0.023743525,-1.725574,-0.7652672,0.40414107,-1.3490397,-1.8605615,1.7370988,-0.9766387,-0.16638874,-0.81618255,-3.1610768,-2.6307633,-0.1400663,-2.0411637,-2.8073754,-1.4968485,-1.4525839,-1.3601456,-1.0600978,-0.8951315,-1.9642296,-1.3073968,-1.3782841,-3.576044,-0.748828,-0.99238986,-2.1296701,-1.6857063,-1.8821354,-0.38811213,-0.15180404,-2.4657173,-1.0857413,-2.613261,-2.9778485,-0.94845355,-1.2376581,-0.8460352,-1.4220707,-1.63983,-1.226194,-1.5634226,-2.6114783,-0.930078,-1.1869209,-2.5444357,-2.2403138,-0.77209944,-2.1515324,-3.4878523,-1.1073978,-1.3216511,-0.6563845,-3.5250185,-0.63792044,-0.7456,-0.36508065,-3.8944309,-0.6575486,-1.055381,-1.7205375,-2.3624816,-1.4567233,-0.51718825,-2.921824,-2.827127,-0.79305524,-1.8118691,-0.6467804,-1.9780788,-2.8713832,-1.8739829,-0.85519075,-0.8843839,-2.298235,-1.3052273,-1.0433029,-1.6055335,-0.7293971,-2.0178814,-1.0012273,-2.7836626,-0.18019581,-2.9525046,0.06283511,-1.0771476,-1.684917,-1.0012261,-1.8002988,-2.303301,-2.8673604,-0.65197,1.5313531,-0.06769134,-1.4953047,1.6518625,-1.1032822,-0.69211763,-1.1044527,-1.9224111,-1.0562463,-2.929672,-0.4314245,-0.663055,-1.923588,-1.1362202,-2.56335,-0.9039744,-1.1754929,-0.7852836,-0.35028017,-0.8253289,-1.7110418,-1.402279,-0.46100777,-1.2434115,-1.6385093,-1.2073272,-0.9360929,-1.7066859,-1.1189011,-1.906788,-1.180607,-1.7918444,-1.7642717,-3.2110906,-1.512694,-1.2362953,-2.542412,-1.4488413,-2.8262224,-0.29286075,-2.959877,-2.417001,-0.6678975,-1.0591435,-1.4416717,-2.9185162,-1.5346223,-1.2625871,-1.4018737,-1.5001017,-1.582244,-2.3077242,-1.3246597,-1.1958816,-1.601363,-1.2873546,-1.4845268,-0.5142913,-0.55028,-1.768745,-3.1764743,-1.2929649,-1.3128407,-1.685133,-1.9896406,-0.49271095,-1.7434857,-0.4635263,-3.7497988,-1.3504984,-0.9826175,-2.561843,-3.1924927,-0.81546044,-2.2561598,-1.0336788,-3.079389,-1.8653439,0.7575352,-2.2942288,-3.5180345,-1.7976544,-2.5752325,-1.2930329,-1.4775461,-3.7086883,-1.9317006,-0.69083494,-0.3892873,-0.13688876,-1.3359662,1.5508683,-2.0915484,-1.2970803,-2.4390442,-0.8999239,-1.1780931,-0.17716816,-3.0721157,-1.2691242,-2.4365244,-2.00912,-0.7445742,-1.8256822,-0.60431427,-0.89938086,-0.25193602,-0.9093581,-0.34538913,-1.13942,-0.76617473,-1.118225,-1.1742353,-2.9717855,-1.7770424,-2.3803144,-0.96339357,-1.2928971,0.95451343,-1.4226153,-1.2079164,-2.9541163,-2.242157,-0.5115858,-0.58839196,-0.5587107,0.4848777,-1.3396729,3.2917793,-1.8649057,0.11095156,-0.9008418,-0.56353545,-1.8512899,-1.6149305,-3.0293114,-0.5705302,-2.5908341,-2.3034096,-0.13089481,-2.184179,-1.7123891,-2.6310916,-2.2731912,-3.0761626,-0.24750435,-1.0210822,-0.0027707368,-1.0604991,0.65189373,-0.9578876,0.67131907,0.51195204,-3.2901888,-1.7128136,-2.573969,-2.8644493,-3.788425,-1.6139754,0.4860291,-1.7399712,-3.1024675,-1.1742318,-0.509228,-0.8108779,-2.2405698,-1.1434205,-1.5262486,-1.7380934,-1.3301532,0.737317,-1.075707,-3.1947834],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"label=9\\u003cbr\\u003edim1=%{x}\\u003cbr\\u003edim2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"9\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"9\",\"showlegend\":true,\"x\":[-1.0118375,-2.518612,-1.3610771,-1.4478745,0.18244481,-1.7607942,-3.322626,-1.647703,-0.26278982,-1.6692291,-1.3928071,-1.1169586,-1.2753525,-0.30459931,-1.4063127,-2.7681127,-2.3053536,-0.9396628,-1.8278514,-1.8198763,-1.5922856,-2.1304035,-1.0541391,-1.0015092,-3.4414763,-2.5884795,-2.5412207,-2.074042,-0.98957664,-0.9202772,-2.0815442,-0.45907634,-2.523325,-0.95740163,-3.395451,-0.36672378,-1.9938883,-2.3758574,-2.9145598,-3.4842615,0.024671167,-0.9752284,-0.97950083,-0.6640748,-1.5905087,-2.343758,-0.55891263,0.04500574,-0.528875,-2.539949,-0.51711684,-1.7904675,-3.473796,-1.6138898,-1.9746026,-2.759553,-0.8331505,-2.6770358,-2.2587013,-0.7204924,-2.3639455,-1.105212,-0.90076274,-0.6696222,-3.1660233,-1.3783945,-1.4845439,0.1679753,-3.7475138,-0.8393601,-2.55551,-1.2226676,-0.21653415,-0.3583513,-2.5992002,-1.6113207,-0.852135,-0.66840565,-0.24177262,-1.3467968,-1.0419047,-1.0031207,-1.7489159,-2.2262592,-2.708972,-2.7029061,-1.2015722,-2.04959,-0.54393166,-2.684866,-0.30907854,-0.6882894,-0.7255094,-2.4178839,-2.6325545,-2.325737,-3.8068376,-0.19013558,-1.7890924,-3.2438078,-1.659343,-1.6972448,-1.5867323,-1.5878737,-1.507559,-1.334512,-1.7589785,-3.406352,-2.064786,-0.43087745,-0.5779666,-1.723046,-0.7923323,-0.17555138,-0.11883825,0.06270814,-1.8946346,-0.96761227,-1.1653755,-0.25048923,-0.15187405,-2.2638586,-0.15706532,-0.3931653,-2.913031,-2.278023,-1.6421344,-2.1133382,-1.7309773,-1.2457464,-1.7426894,-0.23930961,-1.0656769,0.26039666,-0.27797908,-0.013549447,-1.8381135,-1.5931426,-0.364786,0.21707183,-0.868922,-0.67817867,-0.93644136,-2.7640023,-3.099278,-0.8710022,-1.8009003,-0.6490266,-0.72715807,-2.4462867,-3.6956072,-1.3959786,-2.2038572,-1.9539114,-1.6357131,-3.187724,-2.4341908,-1.1019981,-0.23674308,-0.88294655,-0.9352367,-0.58735955,-2.2612948,-0.9462361,-0.15441589,-1.8074933,-1.8792881,-1.9878438,-0.6459489,-2.339063,-1.8530172,-2.513905,-1.2834902,-3.917307,-1.6992185,-0.41506252,-2.073944,-1.2340342,-3.0828238,-0.071697,-0.11765581,-0.54586655,-1.540693,-0.09884566,-2.2197728,-1.0102265,-1.9115065,-3.0633693,-1.7162514,0.04690504,-0.4511069,-0.6242826,-2.6856503,-3.6746788,-1.233695,-1.554047,0.038348347,-1.1674927,-1.0464611,-2.609243,-1.1632576,-1.8179357,-3.5324392,-0.6870696,-1.579108,-0.9018965,-3.0451126,-0.56053495,-0.37287498,-2.9855685,-0.24552926,-0.72632325,-0.9566807,-1.1885178,-1.5967467,-0.74251556,-2.5494757,-0.5831057,-0.4813273,-1.38766,-0.24600329,-1.6311948,-1.6679926,-0.89281034,-0.22797775,-0.14162701,-1.0476015,-0.21557726,-1.5805843,-1.351336,-0.34267175,-0.2523555,-2.6086178,-0.35688168,-0.36413178,-1.3395948,-0.7476882,-0.9229805,-2.4618955,-0.33286405,-1.5362338,-0.5584605,-1.078675,-1.1161315,-1.1800466,-1.5444292,-3.3043637,-2.6309052,0.13253653,-0.02922538,-2.0909812,-2.574592,-0.29974964,-3.6737742,-1.2527635,-1.2679706,-1.3507874,-0.34266704,-2.0314488,-0.39051992,-3.8195672,-2.0392857,-0.8285232,-3.6732965,-2.2727757,-0.6136339,-0.39426076,-1.0835195,-0.048659384,-2.3658218,-0.4181298,-3.0051637,-2.0050354,-0.9916618,-2.2540002,-1.4449021,-1.2089562,-2.2824042,-0.9201509,-2.0375648,-2.7261524,-0.9794459,-2.3326883,-0.8268874,-0.50939673,-3.0850668,-0.99853575,-3.6028352,-0.16838895,-0.94138336,-0.68726295,-3.0787406,-1.9620962,-2.1327066,-0.7898145,-0.84468496,-2.8542037,-3.1741333,-0.01575765,-4.043051,-0.35948366,-1.43273,-0.61615413,-0.6051837,-1.7687435,-2.4694443,0.01650545,-1.7126348,-0.587854,-0.80991316,-1.104008,-0.5948223,-0.56518835,-0.74814236,-3.1201444,-3.3378668,-1.1024895,-1.1936822,-2.4566288,-3.6344972,-2.5869522,-1.2839999,-0.42687508,-1.053235,0.016291022,-2.516776,-0.5067661,-1.1625135,0.013243288,-0.31654584,-0.9410073,0.079015404,-0.7341256,-0.6020783,-0.4367007,-0.66073096,-0.67838717,-0.5079051,-1.9544479,-3.071465,-0.75478816,-1.9501337,-1.4666908,-1.3455703,-1.2905936,-0.3603452,-2.574997,-2.7724013,-1.7572695,-0.11641064,-1.2583702,-1.4357746,-2.2160819,-1.3965919,-1.2012742,-0.8074076,-1.2351339,-0.40283522,-0.71165556,-1.6618973,-0.49061188,-0.7707806,-0.50806564,-0.78875506,-0.7865592,-0.4849786,-0.5744939,-2.1123524,-1.4744052,-0.22724526,-1.3941822,-1.3987008,-0.7877451,-0.30234584,-0.83367074,-2.9413438,-1.6969441,-2.6370168,-1.8395814,-0.5324219,-1.0821168,-2.8003612,-0.08809596,-2.5398679,-1.2148333,-2.306561,-1.3122656,-0.863348,-2.4047132,-0.79518664,-1.5201162,-3.2969937,-0.9416078,-0.42013082,-1.3842694,-1.2591863,-0.7952278,-3.8620095,-2.6274161,-1.5000529,-1.3431559,-0.97159886,-0.5367222,-0.4345454,-1.5686425,-0.9402331,-3.3033442,-0.81798756,-3.028205,-0.7094979,-0.95340973,-1.2186694,-2.5678701,-0.896872,-2.4479604,-2.5133805,-3.0874977,-2.495679,-0.97928697,-0.69266105,-2.0868511,-3.1119967,-1.1143204,-3.0674396,-0.8440824,-0.47360584,-0.14487875,-2.4798303,-0.74674845,-0.6866232,-1.287293,-0.4269939,-2.2939315,-1.5978895,-1.0566733,-3.6082315,-2.3237076,-1.688902,-2.0075066,-1.0053575,-2.4819436,-0.5957499,-1.3722625,-0.9013922,-0.29246846,-0.47122175,-3.4251218,-0.4971198,-1.5216627,-0.09902227,-1.6284007,-0.24005547,-4.5182185,-0.7798339,-3.2001853,-0.8207655,-0.24950898,-1.4259324,-1.7175822,-1.6620696,-0.8548677,-0.7981911,-1.3534603,-0.74805295,-2.8578105,-0.9116365,-1.4212121,-2.782103,-0.8329467,-0.09044105,-0.5864619,-0.77905047,-1.0799129,-0.2807145,-2.1173143,-2.5993795,-0.63171625,-1.7776085,-1.2686329,-2.599502,-0.93036664,-0.7404389,-0.3068058,-0.9378849,-0.9259817,-1.5887176,-3.281798,0.1056166,-2.0175548,-1.9959272,-1.6340454,-1.1733294,-0.7927533,-1.3726614,-3.2004461],\"xaxis\":\"x\",\"y\":[-0.3071685,-0.77011937,-0.05978249,-0.15056805,0.35027242,-0.34165007,-1.0044602,-0.32415104,0.306476,-0.24902922,-0.065131724,-0.39543605,-0.3932218,-0.32791463,-0.3645749,-0.51359016,-0.81116927,-0.33076876,-0.2619626,-0.25222877,-0.81760573,-0.61613685,-0.25852558,-0.040237963,-1.5328432,-1.01961,-0.8240912,-0.770083,-0.02665113,-0.30296904,-0.6644768,0.35302114,-1.0212613,-0.91969,-1.3834867,0.26297677,-2.5726979,-0.7822753,-0.56687284,-1.0530592,-0.056974374,0.12345646,0.04568769,-0.13060415,-0.578615,-0.8621662,0.7395665,0.37498558,-0.34743297,-0.6752547,0.28301919,-0.29725015,-1.5957437,-0.21183392,-0.23472717,-1.0360615,-0.2019522,-1.0613067,-0.9043153,0.25328845,-0.62569016,-0.22719646,-0.384466,-0.16108231,-1.1686946,-0.112212494,-0.2920381,0.294308,-2.0067787,-0.21124686,-4.3443356,-0.31040648,0.2462653,0.17117484,-0.9567768,-2.6394165,1.8533086,0.094601646,-0.03482856,-0.08979349,0.048729375,1.1933559,-0.099872805,-0.54858106,-1.1812527,-0.88823664,-0.0533456,-0.45634395,0.09486802,-1.2135208,0.4582777,-0.28576726,-0.16456212,-0.3415466,-0.9656516,-0.3262951,-1.7478952,-0.43507648,-0.40297216,-0.8769548,-0.5312252,-2.1357188,-0.20750691,-0.5795628,-0.76204705,0.024734735,-0.68463665,-1.0833379,-0.6890893,0.20675574,0.19664653,-0.5336368,0.07435578,0.28177744,0.22212423,0.15856405,-0.76410025,-0.40254265,0.025381103,0.644586,-0.12719941,-0.5191019,0.1543402,-0.04399205,-2.1603794,-0.496342,-0.34991434,-0.6041545,-3.339374,-0.7322094,-0.7260738,0.13588317,0.07040669,0.49541426,-0.11217069,0.056018442,-0.53224546,-0.8845132,-0.010408476,-0.48718143,0.029556394,-0.1674873,-0.32373554,-1.5496374,-1.150646,-2.1772804,-0.3852877,0.02657555,-0.16576198,-0.93652457,-1.3003951,0.06395058,-0.25914586,-0.73219913,-0.3004083,-1.3618075,-0.42158312,-1.8054944,0.13686194,-0.3950995,0.16271727,-0.082573906,-0.5712233,0.10718773,-0.13162865,-0.6109541,-0.5627213,-2.3053653,0.07758185,-1.2703542,-0.6310319,-0.9475458,0.25537455,-1.7945508,-0.66793936,0.000162974,-2.3932397,0.18181844,-1.061006,0.17087175,0.19084652,0.28711563,-0.077796765,-0.08947303,-0.6195196,-0.3530349,-0.4510454,-1.0676049,-0.2292994,0.2590397,0.5083986,0.2355135,-0.81612,-1.4057388,-0.12759413,0.07962726,0.20109703,0.061627492,-0.0077676326,-0.33605954,-0.10838747,-0.5030234,-1.0711309,-0.22628134,-0.18469724,0.18476255,-0.8370639,0.28273165,0.33316898,-1.136045,0.2699725,-0.12192995,-0.08627519,0.19581531,-0.35402423,0.09439789,-0.5665288,0.0659038,-1.339416,0.09397225,0.2155162,-0.6569192,-0.61720353,-0.30030358,-0.07517461,0.100304365,-0.21786603,-0.13049665,-0.267366,-0.29375827,0.2777455,-0.08059927,-1.8630673,0.31227535,-0.079781845,-0.46581447,-0.82040256,-0.04680161,-0.61816627,-0.00648275,-0.21340378,0.37335372,-0.0035958588,0.122565284,-0.029570498,-0.37169105,-1.4979817,-1.0462244,0.3774687,0.013474986,-0.47526163,-1.0656257,0.47131026,-1.5245464,0.06521964,-0.19695213,-0.11300948,-0.013750508,-0.5213164,0.2837149,-1.6034491,-0.5231648,0.10061194,-1.7739718,-0.69974256,0.10983254,-0.40743768,0.52277845,-0.048443668,-0.89150065,-0.22982724,-0.9070978,-0.73913157,-0.31528643,-0.7695052,-0.32710743,-0.44221473,-0.68002266,-0.42274618,-0.7542167,-1.0801961,0.13424732,-1.0455483,0.29385358,0.18230616,-1.2889537,0.06779891,-1.9787372,-0.059688956,0.4214465,-0.0037370175,-1.2984602,-0.44937956,-0.8879906,0.3442707,-0.1557286,-0.6086826,-1.7804961,-0.6027559,-1.8448142,0.19552933,-0.37797862,0.46418816,0.68576676,-0.71923184,-0.98568964,0.5952657,-0.40340203,0.43497932,0.27500868,-0.29457808,0.08850041,0.14149089,-0.24208108,-0.9225856,-1.6059037,-0.16729514,-0.15604787,-0.9390082,-1.7050014,-0.6669097,-0.5550301,0.3184749,-0.36699307,-0.2045579,-0.6018657,0.24472825,1.3202814,0.015349835,0.4154204,-0.12369646,2.029659,-0.038834333,0.18500353,-0.0684984,0.07431215,-0.1902261,0.31054205,-0.41555655,-1.2286288,0.34484065,-0.80345726,-0.7518538,-0.15102877,-0.46209878,0.03273289,-0.8739011,-0.6963738,-0.35811275,0.28294164,-0.028013356,0.11324872,-0.36320645,-0.116790205,0.06339052,0.012129217,-0.098305054,-0.016241297,0.26305354,-0.47992104,0.32839084,0.23213689,0.3593778,0.00494954,0.23060794,0.11021362,-0.01739937,-0.36992213,-0.27722907,0.15177633,-0.06434357,-0.15348989,0.39887965,0.05667749,-0.05954215,-1.5757214,-0.00627172,-0.69467074,-0.5510375,0.34078622,-0.19733708,-0.92097765,0.36396503,-0.8095077,-0.76848435,-0.7088242,-0.16832907,-0.007858112,-0.9287342,0.2967276,-0.44121528,-1.3367409,-0.24064472,0.18540867,-0.76924944,-0.4049552,-0.04730025,-2.3279521,-1.3596644,-0.47980863,-0.21999153,-0.37568998,0.09219575,-0.09041087,-0.53195935,-0.0799986,-1.5440905,-0.20745698,-0.94263136,-0.26324558,0.08634961,-0.31054556,-0.87742585,-0.16550207,-0.32584482,-0.61482656,-1.4287585,-0.9110236,-0.64764756,0.111143455,-0.69672114,-1.4476714,-0.14164914,-0.84726894,0.24336515,-0.20574194,-0.054518126,-0.94909894,0.29900616,0.16523804,-0.2916159,0.29453522,-0.39126265,-0.30377722,0.05304748,-1.8118122,-0.3679119,-0.43104768,-0.46197397,0.03448592,-0.7632449,0.19611208,-0.48904508,0.07305847,0.49881947,0.13742153,-1.3574113,0.27298772,-0.37365407,0.21414377,-0.081387416,0.015042514,-2.3097994,0.029825777,-1.3333113,-0.23215815,0.030926079,-0.027872644,-0.65405977,-0.12992942,0.12820612,-0.15727475,-0.5756841,0.06967704,-1.202596,-0.041835606,-0.13681252,-0.63765526,0.2772712,0.10399909,0.0745461,0.06642516,-0.1804926,0.039061904,-0.67310995,-0.6418842,0.12967514,-0.8607929,-0.4292872,-0.44332725,0.009002835,0.18350677,0.24293776,-0.03923583,-0.09077209,-0.46483088,-1.3948154,-0.2046366,-0.09118779,-0.9457537,-0.51317483,-0.26111922,0.23645376,-0.41735345,-1.198077],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"dim1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"dim2\"}},\"legend\":{\"title\":{\"text\":\"Digit\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"height\":700,\"width\":700,\"title\":{\"text\":\"Scatter plot of latent space dims\"},\"images\":[{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA\\u002f0lEQVR4nGNgGHhgPP\\u002fvfCMccgbv\\u002fvz58xa7nNnjv3\\u002fev\\u002fxjwYopxWlz\\u002f8\\u002ffP6dC\\u002fvythAgwIUnOOiDLwMBgxHOQQQ9D0tibkfFQCeOL85OYGLG5ZTOPd4UoA8Pfz2gOVlv69+WFEAj775+lKHJsm\\u002f58cBeWgUkeRpG0+PPHHs5Blzz6dx+C8\\u002f\\u002fvEWTX+hj+34iQ\\u002fPf\\u002fArLG0D\\u002fPJOHWt\\u002f\\u002fdxYMqeR8u1\\u002fznoTsDquREKMtg6Z+1DKgg7O9DCKPw3d9FaHIMoX9+TDKQDd308O\\u002f95RaYkn\\u002f+PL3+58+fI03oUgwMMsf\\u002f\\u002fPn758\\u002fLiZhSDAwMkg1\\u002f\\u002fv7pVcUqR1cAAJnvbjlv7UinAAAAAElFTkSuQmCC\",\"x\":0.7710797786712646,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":-0.492114782333374,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGPyg+u9\\u002fe1xyCV9+\\u002f7WDMJkwJOXYcRvq8vr3JXkc8jZPfv+Ow6Vx9t+\\u002fe3HJifz9\\u002fdoJh5zC2b+\\u002fa3FpTP\\u002f9dwcfDrmAD78PiuMy9O\\u002ffv\\u002fNxGTr99+\\u002ff6jjkDO7+\\u002fr0Gl8ZXv38f4cEl+ff370hccvP\\u002f\\u002f\\u002f0rj8vGJ3+\\u002f9+CKEIfff++gi2HGJzbJG8fwKaMqAABWcDs7De9sKAAAAABJRU5ErkJggg==\",\"x\":0.34025871753692627,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":0.49864333868026733,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABD0lEQVR4nGNgGGSAEY3Pw+sl1vsLq1LF6Rf+\\u002fPkzCZuUxowvf\\u002f7ev\\u002fTnhQaGFN+M93\\u002f+\\u002fLkhr\\u002frnjw2GZMKfP3\\u002f+3JRlQJJkgkuGMjA8WO36mAHJTBY4KzVt151XDAwMYti9BQFzEcayoEjkcjP+12U4dgxTC6fp5r9\\u002f\\u002f\\u002f\\u002f9+0QZQ4rF7PGfz09Wffrz53kpK5ocq9+fPzXWDEIX\\u002fvz58yeMDVVf+58\\u002fWwQYRE\\u002f\\u002f\\u002fd649s+fHU6GhnA5po4\\u002fHzMFGUxP\\u002fLnhyMDrsfjjnz\\u002f34ZIZfz5FCHmu+vKnVpaBgYGBIXLLFlW45PM\\u002fX8\\u002fe+PPnTzUiwBDg\\u002fJ8\\u002ff\\u002f5sKlZB9TU0snkCjV7Of\\u002fcbi7bBBQBNMXIN9dTaRAAAAABJRU5ErkJggg==\",\"x\":2.096250534057617,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":2.4970481395721436,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEUlEQVR4nM2RMUsDQRSEvw1ntImgVZoDK5uYQjtRUYtAiP4AIWlECDbW\\u002fgg7m2BhfkEUtAkEBH+AYEAbG4UoFloISWGQWc7icouuZ2fhNPvYefPeDA\\u002f+MWYLu5G11trTMZ8qHDz0ZCVJauY88lxSQmoJgMCRnQovTROxuJqyMQjDPECuJ7WynlKP8VuegqePdMtbF5J8PzGqt++Sribwxs7USrAcQX+\\u002fPfQ0xfskypn7y7jKGGNMxhizWXEBkuJmrdoZAjt76UYBmJScMuOT5Z\\u002f9wcbI\\u002fXb\\u002fizLGSlshwHTtTRqsO48AdOdoDIDSQsRl4+S7sju6lOzz0bi\\u002fcv5YknR3fVhMCZCtv6pVz\\u002f8S74\\u002fxCbZZcmz1xUaVAAAAAElFTkSuQmCC\",\"x\":-0.3260076642036438,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":-2.1763269901275635,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA00lEQVR4nGNgGArA+YU6AwMDAwMTAwMDg10gqqTJGQaEpH0QihyjkhwjgndnMYqk9L9FSDqZUE2dw3ALIaknjirJx7AHIenJiSInrsTwFCGpwXAFWbJH\\u002fNZnCIuFgYGBgeEMXIbXM8aNofkDsqQQAwODPpOTLFs00\\u002feTP1nOwvzEwMAwLf3DIwYGPcY\\u002f366eOnPwxVNBNgaEzqwH1gwMDI82XD\\u002fBwMDAkCp6jwEnWPmvE8ZkwiK9Hp8kAx5JRjU8kv+Z8EgyWOIzFo+d2\\u002f\\u002fjdCCVAAB8tSxE89zPVwAAAABJRU5ErkJggg==\",\"x\":-2.3301897048950195,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":0.3936194181442261,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA\\u002fklEQVR4nGNgGMyASUhIqLZjvdSy\\u002f9\\u002frGBgYGFhgEnJsVjYCwQwMDAxPJgV+vniIgYGBgREqZ7iXH8r6l\\u002fSV4dn7m8gmCt3++\\u002ffv379Ht33\\u002fiMW+gDlZf\\u002f+e5WLQnoXNNbwMs\\u002f5GojkQzvrM8JEhlZEBF+Da99cNpySD8seHC7JxygZ++Pu3TBKXrO6uv3+nSeOSFYj983c3bot\\u002f\\u002fP3hAGWyoMrohZiyMlw\\u002fiE2T+pSnf\\u002f\\u002f+\\u002fbUNi5RE4d2\\u002ff\\u002f\\u002f+PemHKSXudPXv379\\u002fjwZiBpLQ6tt\\u002f\\u002f\\u002f79eziAA0PKfM2jv3\\u002f\\u002f\\u002fv3SyoUqzsLAwMAQGMjAcH3z354P2FxJfQAASeNdcNmBuhcAAAAASUVORK5CYII=\",\"x\":-0.6688565015792847,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":-1.887892484664917,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+ElEQVR4nNWPoUtDYRTFTxiyYBAMCwNNe0lwYvnKeBinwrJ\\u002fgUV8CmqzzGBZc3XNpcGQmcX0sJpmkTccM8wgzwUt5\\u002fgtCML79GsrO+lyf9xzzwFmpiB58bKrN954UCEWH5c9lj3qdMtzaEjtebNINV+YC94WfSz+fC5lN7nfqWZs58sDlyrA+wjA4QpOXNPFeysDHB8lknVf71KDEspdctLXw2r28ICjOoK2xtcbofpZWCXPUegxbS6sPaXNrOsZCcRkCEM2nJeX6qL8qghBouhPFWuBb7s+zA8qH24TQ5r9lNR420XA5oQiSTfLj3buRLai8D82H5oC9LRtaSIZblEAAAAASUVORK5CYII=\",\"x\":0.9660578966140747,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":1.748124599456787,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA50lEQVR4nN3QMUtCURjG8SfBQJBIctDJ8VbOTQ4RRps0NImzQ0aLk59AaHB10FGCaHSRGiQahYYWMTAlP0EFkdj\\u002fYIsR93LfL+AzvYffeeE8R1qbbATO1c39kkbZkJuHldsfgMUwAOmH2ewDNwDgzW\\u002fHUwC8He9oCj0\\u002f3gNfFweSmjBO+uzkEyY5SVIXGv7FO3jMS1Ki+L6a\\u002fnP21E9JkmrwnAopIkmFb+bnhslB2bL60jnPsGjPUQl+6CqxMq6zHW7xG7g09rQHL9ZjdtsMMxZeQ7Bh5G\\u002fIbqnVtxaveLUaSnlOTQvNLzj9X2GrnRfMAAAAAElFTkSuQmCC\",\"x\":-0.44644543528556824,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":0.26138049364089966,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+ElEQVR4nGNgGAKA6\\u002fRTBQYGBgYGFjQJKVGG947GN99gSOrmyjOoyTF0aDE+Zf+Cblzu379\\u002fvy188vfvvxgMqxq+\\u002fp3XKcpg8PLvS3YMye5\\u002f9yUZGFRW\\u002ffuSielI8yt\\u002fF3JJbfr7ugCLD9hm\\u002f30ScP\\u002fv3xys\\u002fuv9+\\u002ffvv7+zZLFK5v79+\\u002fffZjWsckyr\\u002f\\u002f37txlZBCkQVgb9Z2D4j1WfVNW\\u002fv6fn\\u002fD2BVTL2778Knti\\u002f87DJObz\\u002f68OucPtvLYoroLQr\\u002f6Etf735Gd9gk\\u002fz\\u002f\\u002fz9L4CTGOdOxGTvz78oDf\\u002f\\u002f6YnUOQ\\u002f7fv\\u002f9eN3JglxQs\\u002fby\\u002fALsU1QEAgO5ih22YOBoAAAAASUVORK5CYII=\",\"x\":-0.023175418376922607,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":-0.5364435911178589,\"yanchor\":\"top\",\"yref\":\"y\"},{\"sizex\":0.612719980875651,\"sizey\":0.612719980875651,\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1UlEQVR4nN3QPwtBYRQG8OOmSG5ZyGSQyRe4JmUyYTMZ7gcwKGUzKJNF4UNgMmEhA4P1LmLD4JaJksFzYjDc3vve1wfwrL9zOn+I\\u002fjPGwGKulQeGh5Vt8MICeCiRP3PHMucPT8F1CU1gphNVgGPUbW1GTyeiHVByW5OfkyBRoPjgltsiNiZElNoCo5AbY0Ai1tjcGK+CtE3kAgZwOuPicaNx5X0nHV+h64HfZN9cVWKeId3oRERN7BRLRUz+wrXmU4+kAzJqNLFIK1GfYyz91tE+1K1CPmMAVMlpsFSJAAAAAElFTkSuQmCC\",\"x\":-1.3690721988677979,\"xanchor\":\"right\",\"xref\":\"x\",\"y\":0.025400832295417786,\"yanchor\":\"top\",\"yref\":\"y\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3306efd4-2f32-47f2-8b9f-3cd669d363fa');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get a small dataset with 5000 points\n",
        "small_dataset = Subset(get_dataset(\"MNIST\"), indices=range(0, 5000))\n",
        "imgs = t.stack([img for img, label in small_dataset]).to(device)\n",
        "labels = t.tensor([label for img, label in small_dataset]).to(device).int()\n",
        "\n",
        "# Get the latent vectors for this data along first 2 dims, plus for the holdout data\n",
        "latent_vectors = autoencoder.encoder(imgs)[:, :2]\n",
        "holdout_latent_vectors = autoencoder.encoder(HOLDOUT_DATA)[:, :2]\n",
        "\n",
        "# Plot the results\n",
        "utils.visualise_input(latent_vectors, labels, holdout_latent_vectors, HOLDOUT_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rYYy75D6ejv"
      },
      "source": [
        "## Variational Autoencoders\n",
        "\n",
        "Variational autoencoders try and solve the problem posed by autoencoders: how to actually make the latent space meaningful, such that you can generate output by feeding a $N(0, 1)$ random vector into your model's decoder?\n",
        "\n",
        "The key perspective shift is this: **rather than mapping the input into a fixed vector, we map it into a distribution**. The way we learn a distribution is very similar to the way we learn our fixed inputs for the autoencoder, i.e. we have a bunch of linear or convolutional layers, our input is the original image, and our output is the tuple of parameters $(\\mu(\\boldsymbol{x}), \\Sigma(\\boldsymbol{x}))$ (as a trivial example, our VAE learning a distribution $\\mu(\\boldsymbol{x})=z(\\boldsymbol{x})$, $\\Sigma(\\boldsymbol{x})=0$ is equivalent to our autoencoder learning the function $z(\\boldsymbol{x})$ as its encoder).\n",
        "\n",
        "From this [TowardsDataScience](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73) article:\n",
        "\n",
        "> Due to overfitting, the latent space of an autoencoder can be extremely irregular (close points in latent space can give very *different* decoded data, some point of the latent space can give *meaningless* content once decoded) and, so, we can’t really define a *generative* process that simply consists to sample a point from the *latent space* and make it go through the decoder to get new data. *Variational autoencoders* (VAEs) are autoencoders that tackle the problem of the latent space irregularity by making the encoder return a *distribution over the latent space* instead of a single point and by adding in the loss function a *regularisation* term over that returned distribution in order to ensure a better *organisation* of the latent space.\n",
        "\n",
        "Or, in fewer words:\n",
        "\n",
        "> **A variational autoencoder can be defined as being an autoencoder whose training is regularised to avoid overfitting and ensure that the latent space has good properties that enable generative process.**\n",
        "\n",
        "At first, this idea of mapping to a distribution sounds like a crazy hack - why on earth does it work? This diagram should help convey some of the intuitions:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/vae-scatter-one.png\" width=\"800\">\n",
        "\n",
        "With our encoder, there was nothing incentivising us to make full and meaningful use of the latent space. It's hypothetically possible that our network was mapping all the inputs to some very small subspace and reconstructing them with perfect fidelity. This wouldn't have required numbers with different features to be far apart from each other in the latent space, because even if they are close together no information is lost. See the first image above.\n",
        "\n",
        "But with our variational autoencoder, each MNIST image produces a **sample** from the latent space, with a certain mean and variance. This means that, when two numbers look very different, their latent vectors are forced apart - if the means were close together then the decoder wouldn't be able to reconstruct them.\n",
        "\n",
        "Another nice property of using random latent vectors is that the entire latent space will be meaningful. For instance, with autoencoders there is no reason why we should expect the linear interpolation between two points in the latent space to have meaningful decodings. The decoder output *will* change continuously as we continuously vary the latent vector, but that's about all we can say about it. However, if we use a variational autoencoder, we don't have this problem. The output of a linear interpolation between the cluster of $2$s and cluster of $7$s will be ***\"a symbol which pattern-matches to the family of MNIST digits, but has equal probability to be interpreted as a $2$ or a $7$\"***, and this is indeed what we find.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/vae-scatter-two.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugBPiDgH6ejv"
      },
      "source": [
        "### Reparameterisation trick\n",
        "\n",
        "One question that might have occurred to you - how can we perform backward passes through our network? We know how to differentiate with respect to the inputs to a function, but how can we differentiate wrt the parameters of a probability distribution from which we sample our vector? The solution is to convert our random sampling into a function, by introducing an extra parameter $\\epsilon$. We sample $\\epsilon$ from the standard normal distribution, and then express $\\boldsymbol{z}$ as a deterministic function of $\\mu$, $\\sigma$ and $\\epsilon$:\n",
        "\n",
        "$$\n",
        "z = \\mu + \\sigma \\odot \\epsilon\n",
        "$$\n",
        "\n",
        "where $\\odot$ is a notation meaning pointwise product, i.e. $z_i = \\mu_i + \\sigma_i \\epsilon_i$. Intuitively, we can think of this as follows: when there is randomness in the process that generates the output, there is also randomness in the derivative of the output wrt the input, so **we can get a value for the derivative by sampling from this random distribution**. If we average over enough samples, this will give us a valid gradient for training.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/vae-reparam-l.png\" width=\"800\">\n",
        "\n",
        "Note that if we have $\\sigma_\\theta(\\boldsymbol{x})=0$ for all $\\boldsymbol{x}$, the VAE reduces to an autoencoder (since the latent vector $z = \\mu_\\theta(\\boldsymbol{x})$ is once again a deterministic function of $\\boldsymbol{x}$). This is why it's important to add a KL-divergence term to the loss function, to make sure this doesn't happen. It's also why, if you print out the average value of $\\sigma(\\boldsymbol{x})$ while training, you'll probably see it stay below 1 (it's being pulled towards 1 by the KL-divergence loss, **and** pulled towards 0 by the reconstruction loss).\n",
        "\n",
        "---\n",
        "\n",
        "Before you move on to implementation details, there are a few questions below designed to test your understanding. They are based on material from this section, as well as the [KL divergence LessWrong post](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence). You might also find [this post](https://lilianweng.github.io/posts/2018-08-12-vae/#vae-variational-autoencoder) on VAEs from the readings helpful.\n",
        "\n",
        "<details>\n",
        "<summary>State in your own words why we need the reparameterization trick in order to train our network.</summary>\n",
        "\n",
        "The following would work:\n",
        "\n",
        "We can't backpropagate through random processes like $z_i \\sim N(\\mu_i(\\boldsymbol{x}), \\sigma_i(\\boldsymbol{x})^2)$, but if we instead write $\\boldsymbol{z}$ as a deterministic function of $\\mu_i(\\boldsymbol{x})$ and $\\sigma_i(\\boldsymbol{x})$ with the randomness coming from some some auxiliary random variable $\\epsilon$, then we can differentiate our loss function wrt the inputs, and train our network.\n",
        "\n",
        "<!-- Our encoder works by generating parameters and then using those parameters to sample latent vectors $\\boldsymbol{z}$ (i.e. a **stochastic process**). Our decoder is deterministic; it just maps our latent vectors $\\boldsymbol{z}$ to fixed outputs $x'$. The stochastic part is the problem; we can't backpropagate gradients through random functions. However, instead of just writing $\\boldsymbol{z} \\sim N(\\mu_\\theta(\\boldsymbol{x}), \\sigma_\\theta(\\boldsymbol{x})^2I)$, we can write $\\boldsymbol{z}$ as a deterministic function of its inputs: $z = g(\\theta, x, \\epsilon)$, where $\\theta$ are the parameters of the distribution, $\\boldsymbol{x}$ is the input, and $\\epsilon$ is a randomly sampled value. We can then backpropagate through the network. -->\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Summarize in one sentence what concept we're capturing when we measure the KL divergence D(P||Q) between two distributions.</summary>\n",
        "\n",
        "Any of the following would work - $D(P||Q)$ is...\n",
        "\n",
        "* How much information is lost if the distribution $Q$ is used to represent $P$.\n",
        "* The quality of $Q$ as a probabilistic model for $P$ (where lower means $Q$ is a better model).\n",
        "* How close $P$ and $Q$ are, with $P$ as the actual ground truth.\n",
        "* How much evidence you should expect to get for hypothesis $P$ over $Q$, when $P$ is the actual ground truth.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIL_WZ1_6ejv"
      },
      "source": [
        "## Building a VAE\n",
        "\n",
        "For your final exercise of this section, you'll build a VAE and run it to produce the same kind of output you did in the previous section. Luckily, this won't require much tweaking from your encoder architecture. The decoder can stay unchanged; there are just two big changes you'll need to make:\n",
        "\n",
        "### Probabilistic encoder\n",
        "\n",
        "Rather than your encode outputting a latent vector $\\boldsymbol{z}$, it should output a mean $\\mu$ and standard deviation $\\sigma$; both vectors of dimension `latent_dim_size`. We then sample our latent vector $\\boldsymbol{z}$ using $z_i = \\mu_i + \\sigma_i \\cdot \\epsilon_i$. Note that this is equivalent to $z = \\mu + \\Sigma \\epsilon$ as shown in the diagram above, but where we assume $\\Sigma$ is a diagonal matrix (i.e. the auxiliary random variables $\\epsilon$ which we're sampling are independent). This is the most common approach taken in situations like these.\n",
        "\n",
        "Note - we actually calculate `mu` and `logsigma` rather than `mu` and `sigma` - we get `sigma = logsigma.exp()` from this. This is a more numerically stable method.\n",
        "\n",
        "How exactly should this work in your model's architecture? You can replace the final linear layer (which previously just gave you the latent vector) with two linear layers returning `mu` and `logsigma`, then you calculate `z` from these (and from a randomly sampled `epsilon`). If you want, you can combine the two linear layers into one linear layer with `out_channels=2*latent_dim_size`, then rearrange to split this up into `mu` and `logsigma` (this is what we do in the solution, and in the diagram below).\n",
        "\n",
        "You should also return the parameters `mu` and `logsigma` in your VAE's forward function, as well as the final output - the reasons for this will become clear below.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ae-before-after-fixed.png\" width=\"750\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi8C5uEM6ejw"
      },
      "source": [
        "### Exercise - build your VAE\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Build your VAE. It should be identical to the autoencoder you built above, except for the changes made at the end of the encoder (outputting mean and std rather than a single latent vector; this latent vector needs to get generated via the reparameterisation trick).\n",
        "\n",
        "For consistency with code that will come later, we recommend having your `model.encoder` output be of shape `(2, batch_size, latent_dim_size)`, where `output[0]` are the mean vectors $\\mu$ and `output[1]` are the log standard deviation vectors $\\log \\sigma$. The tests below will check this.\n",
        "\n",
        "We've also given you a `sample_latent_vector` method - this should return the output of your encoder, but in the form of sampled latent vectors $\\mu$ and $\\sigma$ rather than the deterministic output `model.encoder(x)` of shape `(2, batch_size, latent_dim_size)`. This will be a useful method for later (and you can use it in your implementation of `forward`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tSMa_PSF6ejw"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    encoder: nn.Module\n",
        "    decoder: nn.Module\n",
        "\n",
        "    def __init__(self, latent_dim_size: int, hidden_dim_size: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.latent, self.hidden = latent_dim_size, hidden_dim_size\n",
        "        c2l = Rearrange('b c h w -> b (c h w)')\n",
        "        l2c = Rearrange('b (c h w)-> b c h w', c = 32, h=7, w=7)\n",
        "        split_v = Rearrange('b (n d) -> n b d', d = self.latent, n =2)\n",
        "        self.encoder = Sequential(\n",
        "            #convolutional block\n",
        "            Conv2d(in_channels=1, out_channels=16,kernel_size=4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            BatchNorm2d(num_features=16),\n",
        "            Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            BatchNorm2d(num_features=32),\n",
        "            c2l,\n",
        "            Linear(in_features=32*7*7, out_features=self.hidden),\n",
        "            ReLU(),\n",
        "            Linear(in_features= self.hidden, out_features=2*self.latent),\n",
        "            split_v\n",
        "        )\n",
        "        self.decoder = Sequential(\n",
        "            Linear(self.latent, self.hidden),\n",
        "            ReLU(),\n",
        "            Linear(self.hidden, 32*7*7),\n",
        "            ReLU(),\n",
        "            l2c,\n",
        "            ConvTranspose2d(32, 16, 4, 2, 1),\n",
        "            BatchNorm2d(16),\n",
        "            ReLU(),\n",
        "            ConvTranspose2d(16, 1, 4, 2, 1)\n",
        "\n",
        "        )\n",
        "\n",
        "    def sample_latent_vector(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Passes `x` through the encoder, and returns a tuple of (sampled latent vector, mean, log std dev).\n",
        "        This function can be used in `forward`, but also used on its own to generate samples for\n",
        "        evaluation.\n",
        "        \"\"\"\n",
        "        e = self.encoder(x)\n",
        "        mu, logsigma = e[0], e[1]\n",
        "        epsilon = t.randn_like(logsigma)\n",
        "        z = mu + logsigma.exp() * epsilon\n",
        "        return (z, mu, logsigma)\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Passes `x` through the encoder and decoder. Returns the reconstructed input, as well as mu and logsigma.\n",
        "        \"\"\"\n",
        "        z, mu, logsigma = self.sample_latent_vector(x)\n",
        "        dx = self.decoder(z)\n",
        "        return dx, mu, logsigma\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_vae(VAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPwQ37eo6ejw"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class VAE(nn.Module):\n",
        "    encoder: nn.Module\n",
        "    decoder: nn.Module\n",
        "\n",
        "    def __init__(self, latent_dim_size: int, hidden_dim_size: int):\n",
        "        super().__init__()\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.hidden_dim_size = hidden_dim_size\n",
        "        self.encoder = Sequential(\n",
        "            Conv2d(1, 16, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            Conv2d(16, 32, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            Rearrange(\"b c h w -> b (c h w)\"),\n",
        "            Linear(7 * 7 * 32, hidden_dim_size),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim_size, latent_dim_size * 2),\n",
        "            Rearrange(\"b (n latent_dim) -> n b latent_dim\", n=2),  # makes it easier to separate mu and sigma\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            Linear(latent_dim_size, hidden_dim_size),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim_size, 7 * 7 * 32),\n",
        "            ReLU(),\n",
        "            Rearrange(\"b (c h w) -> b c h w\", c=32, h=7, w=7),\n",
        "            ConvTranspose2d(32, 16, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            ConvTranspose2d(16, 1, 4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "    def sample_latent_vector(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Passes `x` through the encoder, and returns a tuple of (sampled latent vector, mean, log std dev).\n",
        "        This function can be used in `forward`, but also used on its own to generate samples for\n",
        "        evaluation.\n",
        "        \"\"\"\n",
        "        mu, logsigma = self.encoder(x)\n",
        "        sigma = t.exp(logsigma)\n",
        "        z = mu + sigma * t.randn_like(sigma)\n",
        "        return z, mu, logsigma\n",
        "\n",
        "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Passes `x` through the encoder and decoder. Returns the reconstructed input, as well as mu and logsigma.\n",
        "        \"\"\"\n",
        "        z, mu, logsigma = self.sample_latent_vector(x)\n",
        "        x_prime = self.decoder(z)\n",
        "        return x_prime, mu, logsigma\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmbswBTs6ejw"
      },
      "source": [
        "You can also do the previous thing (compare your architecture to the solution), but this might be less informative if your model doesn't implement the 2-variables approach in the same way as the solution does."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLmvyohM6ejw"
      },
      "source": [
        "## New loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_7W80SS6ejw"
      },
      "source": [
        "We're no longer calculating loss simply as the reconstruction error between the original input $\\boldsymbol{x}$ and our decoder's output $\\boldsymbol{x}'$. Instead, we have a new loss function. For a fixed input $\\boldsymbol{x}$, our loss is:\n",
        "\n",
        "$$\n",
        "L_{\\mathrm{VAE}}(\\boldsymbol{x}, \\boldsymbol{x}') = \\|\\boldsymbol{x} - \\boldsymbol{x}'\\|^2 + D_{\\mathrm{KL}}(N(\\mu, \\sigma^2) || N(0, 1))\n",
        "$$\n",
        "\n",
        "The first term is just the regular reconstruction loss we used for our autoencoder. The second term is the KL divergence between the generator's output distribution and the standard normal distribution, and it's designed to penalize the generator for producing latent vectors which are far from the standard normal distribution.\n",
        "\n",
        "There is a much deeper way to understand this loss function, which also connects to intuitions around diffusion models and other more complicated generative models. For more on this, see the section at the end. For now, we'll move on to the practicalities of implementing this loss function.\n",
        "\n",
        "The KL divergence of these two distributions has a closed form expression, which is given by:\n",
        "\n",
        "$$\n",
        "D_{KL}(N(\\mu, \\sigma^2) || N(0, 1)) = \\frac{\\sigma^2 + \\mu^2 - 1}{2} - \\log{\\sigma}\n",
        "$$\n",
        "\n",
        "This is why it was important to output `mu` and `logsigma` in our forward functions, so we could compute this expression! (It's easier to use `logsigma` than `sigma` when evaluating the expression above, for stability reasons).\n",
        "\n",
        "We won't ask you to derive this formula, because it requires understanding of **differential entropy** which is a topic we don't need to get into here. However, it is worth doing some sanity checks, e.g. plot some graphs and convince yourself that this expression is larger as $\\mu$ is further away from 0, or $\\sigma$ is further away from 1.\n",
        "\n",
        "<details>\n",
        "<summary>Derivation of KL divergence result</summary>\n",
        "\n",
        "If you'd like a derivation, you can find one [here](https://statproofbook.github.io/P/norm-kl), where a slightly more general form of the KL divergence between two normal distributions is derived. Our result is a special case of this, for $\\mu_2 = 0$, $\\sigma_2^2 = 1$.\n",
        "In this derivation, they use $\\langle \\cdot \\rangle_{p(x)}$ to denote the expectation of a function under the distribution $p$, i.e. $\\langle f(x) \\rangle_{p(x)} = \\mathbb{E}_{p} [ f(x) ] = \\int_{\\mathcal{X}} p(x) f(x) \\; dx$.\n",
        "A more general result for multi-variate normal distributions with different means and covariances\n",
        "can be found [here](https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/).\n",
        "</details>\n",
        "\n",
        "One can interpret this as the penalty term to make the latent space meaningful. If all the latent vectors $\\boldsymbol{z}$ you generate have each component $z_i$ normally distributed with mean 0, variance 1 (and we know they're independent because our $\\epsilon_i$ we used to generate them are independent), then there will be no gaps in your latent space where you produce weird-looking output (like we saw in our autoencoder plots from the previous section). You can try training your VAE without this term, and it might do okay at reproducing $\\boldsymbol{x}$, but it will perform much worse when it comes time to use it for generation. Again, you can quantify this by encoding some input data and projecting it onto the first two dimensions. When you include this term you should expect to see a nice regular cloud surrounding the origin, but without this term you might see some irregular patterns or blind spots:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/vae_latent_space.png\" width=\"700\">\n",
        "\n",
        "Once you've computed both of these loss functions, you should add them together and perform gradient descent on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advaK-KL6ejw"
      },
      "source": [
        "### Beta-VAEs\n",
        "\n",
        "The Beta-VAE is a very simple extension of the VAE, with a different loss function: we multiply the KL Divergence term by a constant $\\beta$. This helps us balance the two different loss terms. Here, we've given you the default value of $\\beta = 0.1$ rather than using $\\beta = 1$ (which is implicit when we use regular VAEs rather than beta-VAEs).\n",
        "\n",
        "As a general comment on tuning hyperparameters like $\\beta$, it's important to sweep over ranges of different values and know how to tell when one of them is dominating the model's behaviour. In this particular case, $\\beta$ being too large means your model will too heavily prioritize having its latent vectors' distribution equal to the standard normal distribution, to the point where it might essentially lose all structure in the data and ignore accurate reconstruction. On the other hand, $\\beta$ being too small means we just reduce to the autoencoder case where the model has no incentive to make meaningful use of the latent space. Weights and biases hyperparameter searches are a good tool for sweeping over ranges and testing the results, but they'll only work if you log the relevant data / output and know how to interpret it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVWp7wlp6ejw"
      },
      "source": [
        "### Exercise - write your VAE training loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should write and run your training loop below. This will involve a lot of recycled code from the corresponding `Autoencoder` exercise - in fact, depending on how you implemented the `train` method before, you might literally be able to copy and paste that method here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8KWzYFJ6ejw"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class VAEArgs(AutoencoderArgs):\n",
        "    wandb_project: str | None = \"day5-vae-mnist\"\n",
        "    beta_kl: float = 0.1\n",
        "\n",
        "\n",
        "class VAETrainer:\n",
        "    def __init__(self, args: VAEArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True, num_workers=8)\n",
        "        self.model = VAE(\n",
        "            latent_dim_size=args.latent_dim_size,\n",
        "            hidden_dim_size=args.hidden_dim_size,\n",
        "        ).to(device)\n",
        "        self.optimizer = t.optim.Adam(self.model.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step(self, img: Tensor):\n",
        "        \"\"\"\n",
        "        Performs a training step on the batch of images in `img`. Returns the loss. Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluates model on holdout data, either logging to weights & biases or displaying output inline.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        output = self.model(HOLDOUT_DATA)[0]\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output.cpu().numpy()]}, step=self.step)\n",
        "        else:\n",
        "            display_data(t.concat([HOLDOUT_DATA, output]), nrows=2, title=\"VAE reconstructions\")\n",
        "\n",
        "    def train(self) -> VAE:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        # YOUR CODE HERE - iterate over epochs, and train your model\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A43iyNd6ejw"
      },
      "outputs": [],
      "source": [
        "args = VAEArgs(latent_dim_size=5, hidden_dim_size=100, use_wandb=False)\n",
        "trainer = VAETrainer(args)\n",
        "vae = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQY3S5gO6ejw"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class VAEArgs(AutoencoderArgs):\n",
        "    wandb_project: str | None = \"day5-vae-mnist\"\n",
        "    beta_kl: float = 0.1\n",
        "\n",
        "\n",
        "class VAETrainer:\n",
        "    def __init__(self, args: VAEArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True, num_workers=8)\n",
        "        self.model = VAE(\n",
        "            latent_dim_size=args.latent_dim_size,\n",
        "            hidden_dim_size=args.hidden_dim_size,\n",
        "        ).to(device)\n",
        "        self.optimizer = t.optim.Adam(self.model.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step(self, img: Tensor):\n",
        "        \"\"\"\n",
        "        Performs a training step on the batch of images in `img`. Returns the loss. Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        # Get the different loss components, as well as the total loss\n",
        "        img = img.to(device)\n",
        "        img_reconstructed, mu, logsigma = self.model(img)\n",
        "        reconstruction_loss = nn.MSELoss()(img, img_reconstructed)\n",
        "        kl_div_loss = (0.5 * (mu**2 + t.exp(2 * logsigma) - 1) - logsigma).mean() * self.args.beta_kl\n",
        "        loss = reconstruction_loss + kl_div_loss\n",
        "\n",
        "        # Backprop on the loss, and step with optimizers\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Log various values, and also increment `self.step`\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log(\n",
        "                dict(\n",
        "                    reconstruction_loss=reconstruction_loss.item(),\n",
        "                    kl_div_loss=kl_div_loss.item(),\n",
        "                    mean=mu.mean(),\n",
        "                    std=t.exp(logsigma).mean(),\n",
        "                    total_loss=loss.item(),\n",
        "                ),\n",
        "                step=self.step,\n",
        "            )\n",
        "        return loss\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluates model on holdout data, either logging to weights & biases or displaying output inline.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        output = self.model(HOLDOUT_DATA)[0]\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output.cpu().numpy()]}, step=self.step)\n",
        "        else:\n",
        "            display_data(t.concat([HOLDOUT_DATA, output]), nrows=2, title=\"VAE reconstructions\")\n",
        "\n",
        "    def train(self) -> VAE:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            # Iterate over training data, performing a training step for each batch\n",
        "            progress_bar = tqdm(self.trainloader, total=int(len(self.trainloader)), ascii=True)\n",
        "            for img, label in progress_bar:  # remember that label is not used\n",
        "                img = img.to(device)\n",
        "                loss = self.training_step(img)\n",
        "                self.step += 1\n",
        "                progress_bar.set_description(f\"{epoch=:02d}, {loss=:.4f}, batches={self.step:05d}\")\n",
        "                if self.step % self.args.log_every_n_steps == 0:\n",
        "                    self.log_samples()\n",
        "\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model\n",
        "\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU-U2XzW6ejw"
      },
      "source": [
        "You might be disappointed when comparing your VAE's reconstruction to the autoencoder, since it's likely to be worse. However, remember that the focus of VAEs is in better generation, not reconstruction. To test it's generation, let's produce some plots of latent space like we did for the autoencoder.\n",
        "\n",
        "First, we'll visualize the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nePJ0g3M6ejw"
      },
      "outputs": [],
      "source": [
        "grid_latent = create_grid_of_latents(vae, interpolation_range=(-1, 1))\n",
        "output = vae.decoder(grid_latent)\n",
        "utils.visualise_output(output, grid_latent, title=\"VAE latent space visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bLAP3HQ6ejx"
      },
      "source": [
        "which should look a lot better! The vast majority of images in this region should be recognisable digits. In this case, starting from the top-left and going clockwise, we can see 0s, 6s, 5s, 1s, 9s and 8s. Even the less recognisable regions seem like they're just interpolations between digits which are recognisable (which is something we should expect to happen given our VAE's output is continuous).\n",
        "\n",
        "Now for the scatter plot to visualize our input space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFFr_4QA6ejx"
      },
      "outputs": [],
      "source": [
        "small_dataset = Subset(get_dataset(\"MNIST\"), indices=range(0, 5000))\n",
        "imgs = t.stack([img for img, label in small_dataset]).to(device)\n",
        "labels = t.tensor([label for img, label in small_dataset]).to(device).int()\n",
        "\n",
        "# We're getting the mean vector, which is the [0]-indexed output of the encoder\n",
        "latent_vectors = vae.encoder(imgs)[0, :, :2]\n",
        "holdout_latent_vectors = vae.encoder(HOLDOUT_DATA)[0, :, :2]\n",
        "\n",
        "utils.visualise_input(latent_vectors, labels, holdout_latent_vectors, HOLDOUT_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50bOhpds6ejx"
      },
      "source": [
        "The range of the distribution looks much more like a standard normal distribution (most points are in `[-2, 2]` whereas in the previous plot the range was closer to `[-10, 10]`). There are also no longer any large gaps in the latent space that you wouldn't find in the corresponding standard normal distribution.\n",
        "\n",
        "To emphasize - don't be disheartened if your *reconstructions of the original MNIST images* don't look as faithful for your VAE than they did for your encoder. Remember the goal of these architectures isn't to reconstruct images faithfully, it's to generate images from samples in the latent dimension. This is the basis on which you should compare your models to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho8MzlO86ejx"
      },
      "source": [
        "## A deeper dive into the maths of VAEs\n",
        "\n",
        "If you're happy with the loss function as described in the section above, then you can move on from here. If you'd like to take a deeper dive into the mathematical justifications of this loss function, you can read the following content. I'd consider it pretty essential in laying the groundwork for understanding diffusion models, and most kinds of generative image models (which we might dip into later in this course).\n",
        "\n",
        "> *Note - this section is meant to paint more of an intuitive picture than deal with formal and rigorous mathematics, which is why we'll play fairly fast and loose with things like limit theorems and whether we can swap around integrals and expected values. This can be formalized further, but we'll leave that for other textbooks.*\n",
        "\n",
        "Firstly, let's ignore the encoder, and suppose we're just starting from a latent vector $\\boldsymbol{z} \\sim p(z) = N(0, I)$. We can parameterize a **probabilistic decoder** as $p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})$, i.e. a way of mapping from latent vectors $z$ to a distribution over images $\\boldsymbol{x}$. To use it as a decoder, we just sample a latent vector then sample from the resulting probability distribution our decoder gives us. Imagine this as a factory line: the latent vector $\\boldsymbol{z}$ is some kind of compressed blueprint for our image, and our decoder is a way of reconstructing images from this information.\n",
        "\n",
        "On this factory line, the probability of producing any given image $\\boldsymbol{x}$ can be found from integrating over the possible latent vectors $\\boldsymbol{z}$ which could have produced it:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p(\\boldsymbol{x})&=\\int_z p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z}) p(\\boldsymbol{z}) \\; d \\boldsymbol{z} \\\\\n",
        "&= \\mathbb{E}_{\\boldsymbol{z} \\sim p(\\boldsymbol{z})}\\big[p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})\\big]\n",
        "\\end{aligned}\n",
        "$$\n",
        "What if we estimate this value over random samples $x_i \\sim \\hat{p}(\\boldsymbol{x})$ from our dataset? We could perform gradient ascent on $\\theta$ using this estimate to find a decoder $p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})$ that makes this estimate high, in other words a factory line that is *likely to produce images like the ones in our dataset*. Then we're done - right?\n",
        "\n",
        "Unfortunately, it's not that easy. Evaluating this integral would be computationally intractible, because we would have to sample over all possible values for the latent vectors $\\boldsymbol{z}$:\n",
        "$$\n",
        "\\theta^*=\\underset{\\theta}{\\operatorname{argmax}}\\; \\mathbb{E}_{x \\sim \\hat{p}(\\boldsymbol{x}),\\, \\boldsymbol{z} \\sim p(\\boldsymbol{z})}\\big[p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})\\big]\n",
        "$$\n",
        "In our ideal factory line, for any given image $\\boldsymbol{x}$ there's probably only a small cluster of latent vectors $\\boldsymbol{z}$ that could have produced it, and it's that small cluster that we should be concentrating our probability mass over. Without this, it'll take an exponentially long time to get full sampling coverage of the latent space of $\\boldsymbol{z}$.\n",
        "\n",
        "This is where our encoder function $q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})$ comes in! It helps concentrate our guess for $\\boldsymbol{z}$ for any given $\\boldsymbol{x}$, essentially telling us **which latent vectors were likely to have produced the image $\\boldsymbol{x}$**. We can now replace our original integral with the following:\n",
        "\n",
        "<!-- <img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/vae-graphical.png\" width=\"500\"> -->\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p(\\boldsymbol{x}) &=\\int q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x}) \\frac{p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z}) p(\\boldsymbol{z})}{q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})} \\;d \\boldsymbol{z}\\\\\n",
        "\\theta^*&=\\underset{\\theta}{\\operatorname{argmax}}\\; \\mathbb{E}_{\\boldsymbol{x} \\sim \\hat{p}(\\boldsymbol{x}), \\boldsymbol{z} \\sim q_\\phi(\\boldsymbol{z}\\mid \\boldsymbol{x})}\\left[\\frac{p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})p(\\boldsymbol{z})}{q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right] \\\\\n",
        "&=\\underset{\\theta}{\\operatorname{argmax}}\\; \\mathbb{E}_{\\boldsymbol{x} \\sim \\hat{p}(\\boldsymbol{x})}\\left[\\mathbb{E}_{\\boldsymbol{z} \\sim q_\\phi(\\boldsymbol{z}\\mid \\boldsymbol{x})}\\left[\\frac{p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})p(\\boldsymbol{z})}{q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right]\\right]\n",
        "\\end{aligned}\n",
        "$$\n",
        "Why is this easier? Well, now that we've rearranged it by introducing this $q_\\phi$ term, our distribution of $\\boldsymbol{z}$ is conditioned on $\\boldsymbol{x}$. So for any given sample $x_i$, we don't need to sample a huge number of latent vectors $\\boldsymbol{z}$ to estimate the inner expected value in the expression above - we can just sample from $q_\\phi(\\boldsymbol{z}\\mid \\boldsymbol{x_i})$, which already concentrates a lot of our probability mass for where $\\boldsymbol{z}$ should be.\n",
        "\n",
        "We now introduce an important quantity, called the **ELBO**, or **evidence lower-bound**. It is defined as the value inside the expectation in the expression above, but using log instead.\n",
        "$$\n",
        "\\operatorname{ELBO}(\\boldsymbol{x})=\\mathbb{E}_{\\boldsymbol{z} \\sim q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\left[\\log \\frac{p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})p(\\boldsymbol{z})}{q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right]\n",
        "$$\n",
        "Why do we call this the ELBO? Answer - because it's a lower bound for the quantity $\\log p(\\boldsymbol{x})$, which we call the **evidence**. The proof for this being a lower bound comes from **Jensen's inequality**, which states that $\\mathbb{E}[f(X)] \\geq f(\\mathbb{E}[X])$ for any convex function $f$ (and $f(\\boldsymbol{x})=-\\log(\\boldsymbol{x})$ is convex).\n",
        "\n",
        "<!-- In fact,  [we can prove](https://lilianweng.github.io/posts/2018-08-12-vae/#loss-function-elbo) that the difference between $\\log p(\\boldsymbol{x})$ and the ELBO is equal to the KL divergence between the distribution $q_\\phi$ and the **posterior distribution** $p_\\theta(\\boldsymbol{z} \\mid \\boldsymbol{x})$ (the order of $\\boldsymbol{z}$ and $\\boldsymbol{x}$ have been swapped). KL divergence is always non-negative, hence the lower bound. -->\n",
        "\n",
        "<!-- $$\n",
        "\\log{p(\\boldsymbol{x})}=\\mathbb{E}_{\\mathbb{z} \\sim q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\left[\\log \\frac{p(\\boldsymbol{z}) p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right]+D_{\\mathrm{KL}}\\left(q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x}) \\,\\|\\, p_\\theta(\\boldsymbol{z} \\mid \\boldsymbol{x})\\right)\n",
        "$$ -->\n",
        "\n",
        "It turns out that by looking at log probs rather than probabilities, we can now rewrite the ELBO as something which looks a lot like our VAE loss function! $p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})$ is our decoder, $q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})$ is our encoder, and we train them jointly using gradient ascent on our estimate of the ELBO. For any given sample $x_i$, the value $\\operatorname{ELBO}(x_i)$ is estimated by sampling a latent vector $z_i \\sim q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x_i})$, and then performing gradient ascent on the ELBO, which can be rewritten as:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\operatorname{ELBO}(\\boldsymbol{x}) & =\\mathbb{E}_{\\mathbb{z} \\sim q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x} \\mid \\boldsymbol{z}) + \\log \\frac{p(\\boldsymbol{z})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right] \\\\\n",
        "& =\\underbrace{\\mathbb{E}_{\\boldsymbol{z} \\sim q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x} \\mid \\boldsymbol{z})\\right]}_{\\text {reconstruction loss}}-\\underbrace{D_{\\mathrm{KL}}\\left(q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x}) \\,\\|\\, p(\\boldsymbol{z})\\right)}_{\\text {regularisation term}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "which if you tilt your head a bit, is just like our VAE loss function! To see this:\n",
        "\n",
        "* **The first term** is playing the role of reconstruction loss, since it's equivalent to the log probability that our image $x$ is perfectly reconstructed via the series of maps $\\boldsymbol{x} \\xrightarrow{\\text{encoder}} \\boldsymbol{z} \\xrightarrow{\\text{decoder}} \\boldsymbol{x}$. If we had perfect reconstruction then this value would be zero (which is its maximum value).\n",
        "* **The second term** is the KL divergence between $q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})$ and $p_{\\theta}(\\boldsymbol{z})$. The former is your own encoder's distribution of latent vectors which you may recall is $N(\\mu(\\boldsymbol{x}), \\sigma(\\boldsymbol{x})^2)$, and the latter was assumed to be the uniform distribution $N(0, I)$. This just reduces to our KL penalty term from earlier.\n",
        "\n",
        "The decoder used in our VAE isn't actually probabilistic $p_\\theta(\\cdot \\mid \\boldsymbol{z})$, it's deterministic (i.e. it's a map from latent vector $\\boldsymbol{z}$ to reconstructed input $\\boldsymbol{x}'$). But we can pretend that the decoder output is actually the mean of a probability distribution, and we're choosing this mean as the value of our reconstruction $\\boldsymbol{x}'$. The reconstruction loss term in the formula above will be smallest when this mean is close to the original value $\\boldsymbol{x}$ (because then $p_\\theta(\\cdot \\mid \\boldsymbol{z})$ will be a probability distribution centered around $\\boldsymbol{x}$). And it turns out that we can just replace this reconstruction loss with something that fulfils basically the same purpose (the $L_2$ penalty) - although we sometimes need to adjust these two terms (see $\\beta$-VAEs above).\n",
        "\n",
        "And that's the math of VAEs in a nutshell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyhSS0xs6ejx"
      },
      "source": [
        "## Bonus exercises\n",
        "\n",
        "### PCA\n",
        "\n",
        "In the code earlier, we visualised our autoencoder / VAE output along the first two dimensions of the latent space. If each dimension is perfectly IID then we should expect this to get similar results to varying along any two arbitrarily chosen orthogonal directions. However, in practice you might find it an improvement to choose directions in a more principled way. One way to do this is to use **principal component analysis** (PCA). Can you write code to extract the PCA components from your model's latent space, and plot the data along these components?\n",
        "\n",
        "<details>\n",
        "<summary>Template (code for extracting PCA from the Autoencoder)</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "@t.inference_mode()\n",
        "def get_pca_components(\n",
        "    model: Autoencoder,\n",
        "    dataset: Dataset,\n",
        ") -> tuple[t.Tensor, t.Tensor]:\n",
        "    '''\n",
        "    Gets the first 2 principal components in latent space, from the data.\n",
        "\n",
        "    Returns:\n",
        "        pca_vectors: shape (2, latent_dim_size)\n",
        "            the first 2 principal component vectors in latent space\n",
        "        principal_components: shape (batch_size, 2)\n",
        "            components of data along the first 2 principal components\n",
        "    '''\n",
        "    # Unpack the (small) dataset into a single batch\n",
        "    imgs = t.stack([batch[0] for batch in dataset]).to(device)\n",
        "    labels = t.tensor([batch[1] for batch in dataset])\n",
        "\n",
        "    # Get the latent vectors\n",
        "    latent_vectors = model.encoder(imgs.to(device)).cpu().numpy()\n",
        "    if latent_vectors.ndim == 3: latent_vectors = latent_vectors[0] # useful for VAEs; see later\n",
        "\n",
        "    # Perform PCA, to get the principle component directions (& projections of data in these directions)\n",
        "    pca = PCA(n_components=2)\n",
        "    principal_components = pca.fit_transform(latent_vectors)\n",
        "    pca_vectors = pca.components_\n",
        "    return (\n",
        "        t.from_numpy(pca_vectors).float(),\n",
        "        t.from_numpy(principal_components).float(),\n",
        "    )\n",
        "```\n",
        "\n",
        "And then you can use this function in your `visualise_output` by replacing the code at the start with this:\n",
        "\n",
        "```python\n",
        "pca_vectors, principal_components = get_pca_components(model, dataset)\n",
        "\n",
        "# Constructing latent dim data by making two of the dimensions vary independently in the interpolation range\n",
        "x = t.linspace(*interpolation_range, n_points)\n",
        "grid_latent = t.stack([\n",
        "    einops.repeat(x, \"dim1 -> dim1 dim2\", dim2=n_points),\n",
        "    einops.repeat(x, \"dim2 -> dim1 dim2\", dim1=n_points),\n",
        "], dim=-1)\n",
        "# Map grid to the basis of the PCA components\n",
        "grid_latent = grid_latent @ pca_vectors\n",
        "```\n",
        "\n",
        "Note that this will require adding `dataset` to the arguments of this function.\n",
        "\n",
        "\n",
        "You can do something similar for the `visualise_input` function:\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def visualise_input(\n",
        "    model: Autoencoder,\n",
        "    dataset: Dataset,\n",
        ") -> None:\n",
        "    '''\n",
        "    Visualises (in the form of a scatter plot) the input data in the latent space, along the first two latent dims.\n",
        "    '''\n",
        "    # First get the model images' latent vectors, along first 2 dims\n",
        "    imgs = t.stack([batch for batch, label in dataset]).to(device)\n",
        "    latent_vectors = model.encoder(imgs)\n",
        "    if latent_vectors.ndim == 3: latent_vectors = latent_vectors[0] # useful for VAEs later\n",
        "    latent_vectors = latent_vectors[:, :2].cpu().numpy()\n",
        "    labels = [str(label) for img, label in dataset]\n",
        "\n",
        "    # Make a dataframe for scatter (px.scatter is more convenient to use when supplied with a dataframe)\n",
        "    df = pd.DataFrame({\"dim1\": latent_vectors[:, 0], \"dim2\": latent_vectors[:, 1], \"label\": labels})\n",
        "    df = df.sort_values(by=\"label\")\n",
        "    fig = px.scatter(df, x=\"dim1\", y=\"dim2\", color=\"label\")\n",
        "    fig.update_layout(height=700, width=700, title=\"Scatter plot of latent space dims\", legend_title=\"Digit\")\n",
        "    data_range = df[\"dim1\"].max() - df[\"dim1\"].min()\n",
        "\n",
        "    # Add images to the scatter plot (optional)\n",
        "    output_on_data_to_plot = model.encoder(HOLDOUT_DATA.to(device))\n",
        "    if output_on_data_to_plot.ndim == 3: output_on_data_to_plot = output_on_data_to_plot[0] # useful for VAEs later\n",
        "    output_on_data_to_plot = output_on_data_to_plot[:, :2].cpu()\n",
        "    data_translated = (HOLDOUT_DATA.cpu().numpy() * 0.3081) + 0.1307\n",
        "    data_translated = (255 * data_translated).astype(np.uint8).squeeze()\n",
        "    for i in range(10):\n",
        "        x, y = output_on_data_to_plot[i]\n",
        "        fig.add_layout_image(\n",
        "            source=Image.fromarray(data_translated[i]).convert(\"L\"),\n",
        "            xref=\"x\", yref=\"y\",\n",
        "            x=x, y=y,\n",
        "            xanchor=\"right\", yanchor=\"top\",\n",
        "            sizex=data_range/15, sizey=data_range/15,\n",
        "        )\n",
        "    fig.show()\n",
        "```\n",
        "    \n",
        "</details>\n",
        "\n",
        "### Beta-VAEs\n",
        "\n",
        "Read the section on [Beta-VAEs](https://lilianweng.github.io/posts/2018-08-12-vae/#beta-vae), if you haven't already. Can you choose a better value for $\\beta$?\n",
        "\n",
        "To decide on an appropriate $\\beta$, you can look at the distribution of your latent vector. For instance, if your latent vector looks very different to the standard normal distribution when it's projected onto one of its components (e.g. maybe that component is very sharply spiked around some particular value), this is a sign that you need to use a larger parameter $\\beta$. You can also just use hyperparameter searches to find an optimal $\\beta$. See [the paper](https://openreview.net/pdf?id=Sy2fzU9gl) which introduced Beta-VAEs for more ideas.\n",
        "\n",
        "### CelebA dataset\n",
        "\n",
        "Try to build an autoencoder for the CelebA dataset. You shouldn't need to change the architecture much from your MNIST VAE. You should find the training much easier than with your GAN (as discussed yesterday, GANs are notoriously unstable when it comes to training). Can you get better results than you did for your GAN?\n",
        "\n",
        "### Hierarchical VAEs\n",
        "\n",
        "Hierarchical VAEs are ones which stack multiple layers of parameter-learning and latent-vector-sampling, rather than just doing this once. Read the section of [this paper](https://arxiv.org/pdf/2208.11970.pdf) for a more thorough description.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/vae-and-hvae-final.png\" width=\"1100\">\n",
        "\n",
        "(Note - the KL divergence loss used in HVAEs can sometimes be more complicated than the one presented in this diagram, if you want to implement conditional dependencies between the different layers. However, this isn't necessary for the basic HVAE architecture.)\n",
        "\n",
        "Try to implement your own hierarchical VAE.\n",
        "\n",
        "Note - when you get to the material on **diffusion models** later in the course, you might want to return here, because understanding HVAEs can be a useful step to understanding diffusion models. In fact diffusion models can almost be thought of as a special type of HVAE.\n",
        "\n",
        "### Denoising and sparse autoencoders\n",
        "\n",
        "The reading material on VAEs talks about [denoising](https://lilianweng.github.io/posts/2018-08-12-vae/#denoising-autoencoder) and [sparse](https://lilianweng.github.io/posts/2018-08-12-vae/#sparse-autoencoder) autoencoders. Try changing the architecture of your autoencoder (not your VAE) to test out one of these two techniques. Do does your decoder output change? How about your encoder scatter plot?\n",
        "\n",
        "***Note - sparse autoencoders will play an important role in some later sections of this course (when we study superposition in mechanistic interpretability).***\n",
        "\n",
        "If you're mathematically confident and feeling like a challenge, you can also try to implement [contractive autoencoders](https://lilianweng.github.io/posts/2018-08-12-vae/#contractive-autoencoder)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgLlf91F6ejx"
      },
      "source": [
        "# 2️⃣ GANs\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand the loss function used in GANs, and why it can be expected to result in the generator producing realistic outputs.\n",
        "> - Implement the DCGAN architecture from the paper, with relatively minimal guidance.\n",
        "> - Learn how to identify and fix bugs in your GAN architecture, to improve convergence properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv26lnXB6ejx"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* Google Machine Learning Education, [Generative Adversarial Networks](https://developers.google.com/machine-learning/gan) (strongly recommended, ~15 mins)\n",
        "    * This is a very accessible introduction to the core ideas behind GANs\n",
        "    * You should read at least the sections in **Overview**, and the sections in **GAN Anatomy** up to and including **Loss Functions**\n",
        "* [Unsupervised representation learning with deep convolutional generative adversarial networks](https://paperswithcode.com/method/dcgan) (optional, we'll be going through parts of this paper later on in the exercises)\n",
        "    * This paper introduced the DCGAN, and describes an architecture very close to the one we'll be building today.\n",
        "    * It's one of the most cited ML papers of all time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBrV23WT6ejx"
      },
      "source": [
        "## How GANs work\n",
        "\n",
        "The basic idea behind GANs is as follows:\n",
        "\n",
        "* You have two networks, the **generator** and the **discriminator**.\n",
        "* The generator's job is to produce output realistic enough to fool the discriminator, and the discriminator's job is to try and tell the difference between real and fake output.\n",
        "\n",
        "The idea is for both networks to be trained simultaneously, in a positive feedback loop: as the generator produces better output, the discriminator's job becomes harder, and it has to learn to spot more subtle features distinguishing real and fake images, meaning the generator has to work harder to produce images with those features.\n",
        "\n",
        "### Discriminator\n",
        "\n",
        "The discriminator works by taking an image (either real, or created by the generator), and outputting a single value between 0 and 1, which is the probability that the discriminator puts on the image being real. The discriminator sees the images, but not the labels (i.e. whether the images are real or fake), and it is trained to distinguish between real and fake images with maximum accuracy. The discriminator's loss function is the cross entropy between its probability estimates ($D(x)$ for real images, $D(G(z))$ for fake images) and the true labels ($1$ for real images, $0$ for fake images).\n",
        "\n",
        "### Generator\n",
        "\n",
        "The architecture of generators in a GAN setup is generally a mirror image of the discriminator, with convolutions swapped out for **transposed convolutions**. This is the case for the DCGAN paper we'll be reading (which is why they only give a diagram of the generator, not both). The generator works by taking in a vector $z$, whose elements are all normally distributed with mean 0 and variance 1. We call the space from which $z$ is sampled **latent dimension** or **latent space**, and we call $z$ a **latent vector**. The formal definition of a latent space is *an abstract multi-dimensional space that encodes a meaningful internal representation of externally observed events.* We'll dive a little deeper into what this means and the overall significance of latent spaces later on, but for now it's fine to understand this vector $z$ as a kind of random seed, which causes the generator to produce different outputs. After all, if the generator only ever produced the same image as output then the discriminator's job would be pretty easy (just subtract the image $g$ always produces from the input image, and see if the result is close to zero!). The generator's objective function is an increasing function of $D(G(z))$, in other words it tries to produce images $G(z)$ which have a high chance of fooling the discriminator (i.e. $D(G(z)) \\approx 1$).\n",
        "\n",
        "### Convergence\n",
        "\n",
        "The ideal outcome when training a GAN is for the generator to produce perfect output indistinguishable from real images, and the discriminator just guesses randomly. However, the precise nature of the situations when GANs converge is an ongoing area of study (in general, adversarial networks have very unstable training patterns). For example, you can imagine a situation where the discriminator becomes almost perfect at spotting fake outputs, because of some feature that the discriminator spots and that the generator fails to capture in its outputs. It will be very difficult for the generator to get a training signal, because it has to figure out what feature is missing from its outputs, and how it can add that feature to fool the discriminator. And to make matters worse, maybe marginal steps in that direction will only increase the probability of fooling the discriminator from almost-zero to slightly-more-than-almost-zero, which isn't much of a training signal! Later on we will see techniques people have developed to overcome problems like this and others, but in general they can't be solved completely.\n",
        "\n",
        "<details>\n",
        "<summary>Optional exercise - what conditions must hold for the discriminator's best strategy to be random guessing with probability 0.5?</summary>\n",
        "\n",
        "It is necessary for the generator to be producing perfect outputs, because otherwise the discriminator could do better than random guessing.\n",
        "\n",
        "If the generator is producing perfect outputs, then the discriminator never has any ability to distinguish real from fake images, so it has no information. Its job is to minimise the cross entropy between its output distribution $(D(x), 1-D(x))$, and the distribution of real/fake images. Call this $(p, 1-p)$, i.e. $p$ stands for the proportion of images in training which are real. Note how we just used $p$ rather than $p(x)$, because there's no information in the image $x$ which indicates whether it is real or fake. Trying to minimize the cross entropy between $(p, 1-p)$ and $(D(x), 1-D(x))$ gives us the solution $D(x) = p$ for all $x$. In other words, our discriminator guesses real/fake randomly with probability equal to the true underlying frequency of real/fake images in the data. This is 0.5 if and only if the data contains an equal number of real and fake images.\n",
        "\n",
        "To summarize, the necessary and sufficient conditions for $(\\forall x) \\; D(x) = 0.5$ being the optimal strategy are:\n",
        "\n",
        "* The generator $G$ produces perfect output\n",
        "* The underlying frequency of real/fake images in the data is 50/50\n",
        "\n",
        "</details>\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/dcgan-9-solid.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrLzceE26ejx"
      },
      "source": [
        "### Exercise - some more modules\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You'll also need to implement a few more modules, which have docstrings provided below (they should be fairly quick, and will just serve as a refresher for the structure of modules). They are:\n",
        "\n",
        "* [`Tanh`](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html) which is an activation function used by the DCGAN you'll be implementing.\n",
        "* [`LeakyReLU`](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html) which is an activation function used by the DCGAN you'll be implementing. This function is popular in tasks where we we may suffer from sparse gradients (GANs are a primary example of this).\n",
        "* [`Sigmoid`](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html), for converting the single logit output from the discriminator into a probability.\n",
        "\n",
        "They should all be relatively short. You can go back to day 2's exercises to remind yourself of the basic syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr4uSQZR6ejx"
      },
      "outputs": [],
      "source": [
        "class Tanh(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class LeakyReLU(nn.Module):\n",
        "    def __init__(self, negative_slope: float = 0.01):\n",
        "        super().__init__()\n",
        "        self.negative_slope = negative_slope\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"negative_slope={self.negative_slope}\"\n",
        "\n",
        "\n",
        "class Sigmoid(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_Tanh(Tanh)\n",
        "tests.test_LeakyReLU(LeakyReLU)\n",
        "tests.test_Sigmoid(Sigmoid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_O1Hqn76ejx"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Tanh(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return (t.exp(x) - t.exp(-x)) / (t.exp(x) + t.exp(-x))\n",
        "\n",
        "\n",
        "class LeakyReLU(nn.Module):\n",
        "    def __init__(self, negative_slope: float = 0.01):\n",
        "        super().__init__()\n",
        "        self.negative_slope = negative_slope\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return t.where(x > 0, x, self.negative_slope * x)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"negative_slope={self.negative_slope}\"\n",
        "\n",
        "\n",
        "class Sigmoid(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return 1 / (1 + t.exp(-x))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0I3Nb1b6ejx"
      },
      "source": [
        "## GANs\n",
        "\n",
        "Now, you're ready to implement and train your own DCGAN! You'll be basing your implementation on the [DCGAN paper](https://arxiv.org/abs/1511.06434v2). Implementing architectures based on descriptions in papers is an incredibly valuable skill for any would-be research engineer, however in these exercises we've given enough guidance on this page that you shouldn't need to refer to the paper much if at all. However, we do encourage you to skim the paper, and think about how you might go about this replication task without guidance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnlqBf9b6ejx"
      },
      "source": [
        "### Discriminator & Generator architectures\n",
        "\n",
        "We refer back to the diagram at the start of this section for the basic discriminator and generator architectures. Rather than hardcoding a single set of values, we're going to make our architecture more flexible - giving us the ability to change the number of layers, or the sizes of each layer, by using different input arguments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RZP_2ug6ejx"
      },
      "source": [
        "#### Discriminator\n",
        "\n",
        "The discriminator starts with a series of blocks of the form `(Conv -> BatchNorm -> ActivationFunction)`. Following the paper's conventions:\n",
        "\n",
        "* Each convolution should have kernel size 4, stride 2, padding 1. This will halve the width and height of the image at each step. The output channels of each convolution are given by the `hidden_channels` argument. For instance, if `img_channels=3` (because the image is RGB) and `hidden_channels=[128, 256, 512]`, then there will be three convolutions: the first mapping from 3 -> 128 channels, the second from 128 -> 256, and the third from 256 -> 512.\n",
        "* All blocks have a batchnorm layer, **except for the very first one**.\n",
        "* All blocks' activation functions are `LeakyRelu`.\n",
        "\n",
        "Lastly, we flatten the output of the final convolutional block, and use a fully connected layer to map it to a single value (i.e. a vector of length `batch_size`) which we then pass through a sigmoid to get a probability that the image is real. Again, we recommend the `Rearrange` module from the `einops` library for this.\n",
        "\n",
        "None of the convolutions or linear layers should have biases (this is also true for the generator).\n",
        "\n",
        "The diagram below shows what we'd get with the following arguments:\n",
        "\n",
        "```python\n",
        "img_size = 64\n",
        "img_channels = 3\n",
        "hidden_channels = [128, 256, 512]\n",
        "```\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/dcgan-d-help-9-solid.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNTmN27K6ejx"
      },
      "source": [
        "#### Generator\n",
        "\n",
        "The generator is essentially the mirror image of the discriminator. While the discriminator had convolutions which halved the image size on each layer, the generator has transposed convolutions which double the size on each layer (so apart from the very start of the generator / end of the discriminator, all the activations have the same shape, just in reverse).\n",
        "\n",
        "We start with the latent vector of shape `(batch_size, latent_dim_size)`, and apply a fully connected layer & reshaping to get our first tensor which has shape `(batch_size, channels, height, width)`. The parameters `channels` and `height` (which is equal to `width`) can be calculated from the `img_size` and `hidden_channels` arguments (remember that image size doubles at each transposed convolution, and after applying all the transposed convolutions we'll eventually get back to `img_size`). Then, we apply batchnorm and relu.\n",
        "\n",
        "After this, we apply a series of blocks of the form `(ConvTranspose -> BatchNorm -> ActivationFunction)`. Following the paper's conventions:\n",
        "\n",
        "* Each transposed convolution has kernel size 4, stride 2, padding 1. Like for the discriminator, the input & output channels of the convolutions are determined by the `hidden_channels` argument (although this time they're in reverse order).\n",
        "* All blocks have a batchnorm layer, except for the very last one.\n",
        "* All blocks' activation functions are `ReLU`, except for the last one which is `Tanh`.\n",
        "\n",
        "The diagram below shows what we'd get with the following arguments:\n",
        "\n",
        "```python\n",
        "img_size = 64\n",
        "img_channels = 3\n",
        "hidden_channels = [128, 256, 512]\n",
        "latent_dim_size = 100\n",
        "```\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/dcgan-g-help-10-light.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7H2aQC06ejx"
      },
      "source": [
        "### Exercise - building your GAN\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴🔴\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 30-50 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should implement your code below. We've provided one possible design choice and the corresponding forward functions:\n",
        "\n",
        "- The generator is made of an initial `project_and_reshape` block that performs the first linear map, and then `hidden_layers` which are a stack of blocks each consisting of a (transponsed convolution, optional batchnorm, activation fn).\n",
        "- The discriminator is made of `hidden_layers` which are a stack of (convolution, optional batchnorm, activation fn) blocks, and a final `classifier` block which flattens and maps to a single output (which represents the probability pre-sigmoid).\n",
        "\n",
        "We've also given you the `DCGAN` class - note that we've not included a `forward` method here, because you'll usually be calling your discriminator and generators' forward methods directly. You can think of the DCGAN class as essentially a wrapper for both.\n",
        "\n",
        "If you're stuck, you can import the generator and discriminator from the solutions, and compare it with yours. We've given you this option in place of test functions.\n",
        "\n",
        "```python\n",
        "print_param_count(Generator(), solutions.DCGAN().netG)\n",
        "print_param_count(Discriminator(), solutions.DCGAN().netD)\n",
        "```\n",
        "\n",
        "Lastly, remember that `torchinfo` is a useful library for inspecting the architecture of your model. Since it works by running input through your model, it provides another useful way to check your model's architecture is correct (since errors like the wrong convolution size will often cause forward passes to fail).\n",
        "\n",
        "```python\n",
        "model = DCGAN().to(device)\n",
        "x = t.randn(3, 100).to(device)\n",
        "print(torchinfo.summary(model.netG, input_data=x), end=\"\\n\\n\")\n",
        "print(torchinfo.summary(model.netD, input_data=model.netG(x)))\n",
        "```\n",
        "\n",
        "You can also check that the output of your model is the correct shape. **Note - we're using a 3-layer model rather than the 4-layer model shown in the diagram and described the paper.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPHW4Xy36ejx"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim_size: int = 100,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the generator architecture from the DCGAN paper (the diagram at the top\n",
        "        of page 4). We assume the size of the activations doubles at each layer (so image\n",
        "        size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            latent_dim_size:\n",
        "                the size of the latent dimension, i.e. the input to the generator\n",
        "            img_size:\n",
        "                the size of the image, i.e. the output of the generator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the generator (starting closest\n",
        "                to the middle of the DCGAN and going outward, i.e. in chronological order for\n",
        "                the generator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # self.project_and_reshape = ...\n",
        "        # self.hidden_layers = ...\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.project_and_reshape(x)\n",
        "        x = self.hidden_layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the discriminator architecture from the DCGAN paper (the mirror image of\n",
        "        the diagram at the top of page 4). We assume the size of the activations doubles at\n",
        "        each layer (so image size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            img_size:\n",
        "                the size of the image, i.e. the input of the discriminator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the discriminator (starting\n",
        "                closest to the middle of the DCGAN and going outward, i.e. in reverse-\n",
        "                chronological order for the discriminator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_layers = ...\n",
        "        self.classifier = ...\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.hidden_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.squeeze()  # remove dummy `out_channels` dimension\n",
        "\n",
        "\n",
        "class DCGAN(nn.Module):\n",
        "    netD: Discriminator\n",
        "    netG: Generator\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim_size: int = 100,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.netD = Discriminator(img_size, img_channels, hidden_channels)\n",
        "        self.netG = Generator(latent_dim_size, img_size, img_channels, hidden_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-_g4GH_6ejx"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Generator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim_size: int = 100,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the generator architecture from the DCGAN paper (the diagram at the top\n",
        "        of page 4). We assume the size of the activations doubles at each layer (so image\n",
        "        size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            latent_dim_size:\n",
        "                the size of the latent dimension, i.e. the input to the generator\n",
        "            img_size:\n",
        "                the size of the image, i.e. the output of the generator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the generator (starting closest\n",
        "                to the middle of the DCGAN and going outward, i.e. in chronological order for\n",
        "                the generator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Reverse hidden channels, so they're in chronological order\n",
        "        hidden_channels = hidden_channels[::-1]\n",
        "\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        # Reverse them, so they're in chronological order for generator\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        # Define the first layer, i.e. latent dim -> (512, 4, 4) and reshape\n",
        "        first_height = img_size // (2**n_layers)\n",
        "        first_size = hidden_channels[0] * (first_height**2)\n",
        "        self.project_and_reshape = Sequential(\n",
        "            Linear(latent_dim_size, first_size, bias=False),\n",
        "            Rearrange(\"b (ic h w) -> b ic h w\", h=first_height, w=first_height),\n",
        "            BatchNorm2d(hidden_channels[0]),\n",
        "            ReLU(),\n",
        "        )\n",
        "\n",
        "        # Equivalent, but using conv rather than linear:\n",
        "        # self.project_and_reshape = Sequential(\n",
        "        #     Rearrange(\"b ic -> b ic 1 1\"),\n",
        "        #     solutions.ConvTranspose2d(latent_dim_size, hidden_channels[0], first_height, 1, 0),\n",
        "        #     BatchNorm2d(hidden_channels[0]),\n",
        "        #     ReLU(),\n",
        "        # )\n",
        "\n",
        "        # Get list of input & output channels for the convolutional blocks\n",
        "        in_channels = hidden_channels\n",
        "        out_channels = hidden_channels[1:] + [img_channels]\n",
        "\n",
        "        # Define all the convolutional blocks (conv_transposed -> batchnorm -> activation)\n",
        "        conv_layer_list = []\n",
        "        for i, (c_in, c_out) in enumerate(zip(in_channels, out_channels)):\n",
        "            conv_layer = [ConvTranspose2d(c_in, c_out, 4, 2, 1), ReLU() if i < n_layers - 1 else Tanh()]\n",
        "            if i < n_layers - 1:\n",
        "                conv_layer.insert(1, BatchNorm2d(c_out))\n",
        "            conv_layer_list.append(Sequential(*conv_layer))\n",
        "\n",
        "        self.hidden_layers = Sequential(*conv_layer_list)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.project_and_reshape(x)\n",
        "        x = self.hidden_layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the discriminator architecture from the DCGAN paper (the mirror image of\n",
        "        the diagram at the top of page 4). We assume the size of the activations doubles at\n",
        "        each layer (so image size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            img_size:\n",
        "                the size of the image, i.e. the input of the discriminator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the discriminator (starting\n",
        "                closest to the middle of the DCGAN and going outward, i.e. in reverse-\n",
        "                chronological order for the discriminator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        # Get list of input & output channels for the convolutional blocks\n",
        "        in_channels = [img_channels] + hidden_channels[:-1]\n",
        "        out_channels = hidden_channels\n",
        "\n",
        "        # Define all the convolutional blocks (conv_transposed -> batchnorm -> activation)\n",
        "        conv_layer_list = []\n",
        "        for i, (c_in, c_out) in enumerate(zip(in_channels, out_channels)):\n",
        "            conv_layer = [\n",
        "                Conv2d(c_in, c_out, 4, 2, 1),\n",
        "                LeakyReLU(0.2),\n",
        "            ]\n",
        "            if i > 0:\n",
        "                conv_layer.insert(1, BatchNorm2d(c_out))\n",
        "            conv_layer_list.append(Sequential(*conv_layer))\n",
        "\n",
        "        self.hidden_layers = Sequential(*conv_layer_list)\n",
        "\n",
        "        # Define the last layer, i.e. reshape and (512, 4, 4) -> real/fake classification\n",
        "        final_height = img_size // (2**n_layers)\n",
        "        final_size = hidden_channels[-1] * (final_height**2)\n",
        "        self.classifier = Sequential(\n",
        "            Rearrange(\"b c h w -> b (c h w)\"),\n",
        "            Linear(final_size, 1, bias=False),\n",
        "            Sigmoid(),\n",
        "        )\n",
        "        # Equivalent, but using conv rather than linear:\n",
        "        # self.classifier = Sequential(\n",
        "        #     Conv2d(out_channels[-1], 1, final_height, 1, 0),\n",
        "        #     Rearrange(\"b c h w -> b (c h w)\"),\n",
        "        #     Sigmoid(),\n",
        "        # )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.hidden_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.squeeze()  # remove dummy `out_channels` dimension\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBXAvRhE6ejy"
      },
      "source": [
        "### Exercise - Weight initialisation\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The paper mentions at the end of page 3 that all weights were initialized from a $N(0, 0.02)$ distribution. This applies to the convolutional and convolutional transpose layers' weights (plus the weights in the linear classifier), but the BatchNorm layers' weights should be initialised from $N(1, 0.02)$ (since 1 is their default value). The BatchNorm biases should all be set to zero.\n",
        "\n",
        "You can fill in the following function to initialise your weights, and call it within the `__init__` method of your DCGAN. (Hint: you can use the functions `nn.init.normal_` and `nn.init.constant_` here.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jqHQU-U6ejy"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(model: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Initializes weights according to the DCGAN paper (details at the end of page 3 of the DCGAN paper), by modifying the\n",
        "    weights of the model in place.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_initialize_weights(initialize_weights, ConvTranspose2d, Conv2d, Linear, BatchNorm2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9x7YOQk6ejy"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def initialize_weights(model: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Initializes weights according to the DCGAN paper (details at the end of page 3 of the DCGAN paper), by modifying the\n",
        "    weights of the model in place.\n",
        "    \"\"\"\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, (ConvTranspose2d, Conv2d, Linear)):\n",
        "            nn.init.normal_(module.weight.data, 0.0, 0.02)\n",
        "        elif isinstance(module, BatchNorm2d):\n",
        "            nn.init.normal_(module.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(module.bias.data, 0.0)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8wxGm5r6ejy"
      },
      "source": [
        "Note - the tests for this aren't maximally strict, but don't worry if you don't get things exactly right, since your model will still probably train successfully. If you think you've got the architecture right but your model still isn't training, you might want to return here and check your initialisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OS76Y3z6ejy"
      },
      "outputs": [],
      "source": [
        "model = DCGAN().to(device)\n",
        "x = t.randn(3, 100).to(device)\n",
        "print(torchinfo.summary(model.netG, input_data=x), end=\"\\n\\n\")\n",
        "print(torchinfo.summary(model.netD, input_data=model.netG(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--NhWG3i6ejy"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Recall, the goal of training the discriminator is to maximize the probability of correctly classifying a given input as real or fake. The goal of the generator is to produce images to fool the discriminator. This is framed as a **minimax game**, where the discriminator and generator try to solve the following:\n",
        "$$\n",
        "\\min_G \\max_D V(D, G)=\\mathbb{E}_x[\\log (D(x))]+\\mathbb{E}_z[\\log (1-D(G(z)))]\n",
        "$$\n",
        "where $D$ is the discriminator function mapping an image to a probability estimate for whether it is real, and $G$ is the generator function which produces an image from latent vector $z$.\n",
        "\n",
        "The literature on minimax games is extensive, so we won't go into it here. It's better to understand this formula on an intuitive level:\n",
        "\n",
        "* Given a fixed $G$ (generator), the goal of the discriminator is to produce high values for $D$ when fed real images $x$, and low values when fed fake images $G(z)$.\n",
        "* The generator $G$ is searching for a strategy where, even if the discriminator $D$ was optimal, it would still find it hard to distinguish between real and fake images with high confidence.\n",
        "\n",
        "Since we can't know the true distribution of $x$, we instead estimate the expression above by calculating it over a batch of real images $x$ (and some random noise $z$). This gives us a loss function to train against (since $D$ wants to maximise this value, and $G$ wants to minimise this value). For each batch, we perform gradient descent on the discriminator and then on the generator.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98mXjxVI6ejy"
      },
      "source": [
        "### Training the discriminator\n",
        "\n",
        "We take the following steps:\n",
        "\n",
        "* Zero the gradients of $D$.\n",
        "    * This is important because if the last thing we did was evaluate $D(G(z))$ (in order to update the parameters of $G$), then $D$ will have stored gradients from that backward pass.\n",
        "* Generate random noise $z$, and compute $D(G(z))$. Take the average of $\\log(1 - D(G(z)))$, and we have the first part of our loss function.\n",
        "    * Note - you can use the same random noise (and even the same fake image) as in the generator step. But make sure you're using the detached version, because we don't want gradients to propagate back through the generator!\n",
        "* Take the real images  $x$ in the current batch, and use that to compute $\\log(D(x))$. This gives us the second part of our loss function.\n",
        "* We now add the two terms together, and perform gradient ascent (since we're trying to maximise this expression).\n",
        "    * You can perform gradient ascent by either flipping the sign of the thing you're doing a backward pass on, or passing the keyword argument `maximize=True` when defining your optimiser (all optimisers have this option).\n",
        "\n",
        "Tip - when calculating $D(G(z))$, for the purpose of training the discriminator, it's best to first calculate $G(z)$ then call `detach` on this tensor before passing it to $D$. This is because you then don't need to worry about gradients accumulating for $G$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZs_8ZXi6ejy"
      },
      "source": [
        "### Training the generator\n",
        "\n",
        "We take the following steps:\n",
        "\n",
        "* Zero the gradients of $G$.\n",
        "* Generate random noise $z$, and compute $D(G(z))$.\n",
        "* We **don't** use $\\log(1 - D(G(z)))$ to calculate our loss function, instead we use $\\log(D(G(z)))$ (and gradient ascent).\n",
        "\n",
        "**Question - can you explain why we use $\\log(D(G(z))$? (The Google reading material mentions this but doesn't really explain it.)**\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "Early in learning, when the generator is really bad at producing realistic images, it will be easy for the discriminator to distinguish between them. So $\\log(1 - D(G(z)))$ will be very close to $\\log(1) = 0$. The gradient of $\\log$ at this point is quite flat, so there won't be a strong gradient with which to train $G$. To put it another way, a marginal improvement in $G$ will have very little effect on the loss function. On the other hand, $\\log(D(G(z)))$ tends to negative infinity as $D(G(z))$ gets very small. So the gradients here are very steep, and a small improvement in $G$ goes a long way.\n",
        "\n",
        "It's worth emphasising that these two functions are both monotonic in opposite directions, so maximising one is equivalent to minimising the other. We haven't changed anything fundamental about how the GAN works; this is just a trick to help with gradient descent.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH7TYu1A6ejy"
      },
      "source": [
        "Note - PyTorch's [`BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html) clamps its log function outputs to be greater than or equal to -100. This is because in principle our loss function could be negative infinity (if we take log of zero). You might find you need to employ a similar trick if you're manually computing the log of probabilities. Aside from the clamping, the following two code snippets are equivalent:\n",
        "\n",
        "```python\n",
        "# Calculating loss manually, without clamping:\n",
        "loss = - t.log(D_G_z)\n",
        "\n",
        "# Calculating loss with clamping behaviour:\n",
        "labels_real = t.ones_like(D_G_z)\n",
        "loss = nn.BCELoss()(D_G_z, labels_real)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjaTGPvz6ejy"
      },
      "source": [
        "### Optimizers\n",
        "\n",
        "The generator and discriminator will have separate optimizers (this makes sense, since we'll have separate training steps for these two, and both are \"trying\" to optimize different things). The [paper](https://arxiv.org/abs/1511.06434v2) describes using an Adam optimizer with learning rate 0.0002, and momentum parameters $\\beta_1 = 0.5, \\beta_2 = 0.999$. This is set up for you already, in the `__init__` block below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z9Nf-Fy6ejy"
      },
      "source": [
        "### Gradient Clipping\n",
        "\n",
        "Gradient clipping is a useful technique for improving the stability of certain training loops, especially those like DCGANs which have potentially unstable loss functions. The idea is that you clip the gradients of your weights to some fixed threshold during backprop, and use these clipped gradients to update the weights. This can be done using [`nn.utils.clip_grad_norm`](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html), which is called between the `loss.backward()` and `optimizer.step()` methods (since it directly modifies the `.grad` attributes of your weights). You shouldn't find this absolutely necessary to train your models, however it might help to clip the gradients to a value like `1.0` for your generator & discriminator. We've given you this as an optional parameter to use in your `DCGANArgs` dataclass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvscr9hZ6ejy"
      },
      "source": [
        "### Exercise - implement GAN training loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 30-45 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should now implement your training loop below. We've filled in the `__init__` method for you, as well as `log_samples` method which determines the core structure of the training loop. Your task is to:\n",
        "\n",
        "* Fill in the two functions `training_step_discriminator` and `training_step_generator`, which perform a single gradient step on the discriminator and generator respectively.\n",
        "    * Note that the discriminator training function takes two arguments: the real and fake image (in the notation above, $x$ and $z$), because it trains to distinguish real and fake. The generator training function only takes the fake image $z$, because it trains to fool the discriminator.\n",
        "    * Also note, you should increment `self.step` only once per (discriminator & generator) step, not for both.\n",
        "* Fill in the `train` method, which should perform the training loop over the number of epochs specified in `args.epochs`. This will be similar to previous training loops, but with a few key differences we'll highlight here:\n",
        "    * You'll need to compute both losses from `training_step_generator` and `training_step_discriminator`. For the former you should pass in just the fake image (you're only training the generator to produce better fake images), for the latter you should pass in the real image and the **detached fake image** i.e. `img.detach()` (because you're training the discriminator to tell real from fake, and you don't want gradients propagating back to the generator).\n",
        "        * The fake image should be created from random noise `t.randn(batch_size, latent_dim_size)` and passing it into your generator.\n",
        "    * Once again the trainloader gives us an iterable of `(img, label)` but we don't need to use the labels (because all these images are real, and that's all we care about).\n",
        "\n",
        "Again, we recommend not using `wandb` until you've got your non-wandb based code working without errors. Once the generator loss is going down (or at least not exploding!) then you can enable it. However, an important note - **generator loss going down is does not imply the model is working, and vice-versa!** For training systems as unstable as GANs, the best you can do is often just inspecting the output. Although it varies depending on details of the hardware and dataset & model you're training with, at least for these exercises if your generator's output doesn't resemble anything like a face after the first epoch, then something's probably going wrong in your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVo-CGE96ejy"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DCGANArgs:\n",
        "    \"\"\"\n",
        "    Class for the arguments to the DCGAN (training and architecture).\n",
        "    Note, we use field(defaultfactory(...)) when our default value is a mutable object.\n",
        "    \"\"\"\n",
        "\n",
        "    # architecture\n",
        "    latent_dim_size: int = 100\n",
        "    hidden_channels: list[int] = field(default_factory=lambda: [128, 256, 512])\n",
        "\n",
        "    # data & training\n",
        "    dataset: Literal[\"MNIST\", \"CELEB\"] = \"CELEB\"\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 3\n",
        "    lr: float = 0.0002\n",
        "    betas: tuple[float, float] = (0.5, 0.999)\n",
        "    clip_grad_norm: float | None = 1.0\n",
        "\n",
        "    # logging\n",
        "    use_wandb: bool = False\n",
        "    wandb_project: str | None = \"day5-gan\"\n",
        "    wandb_name: str | None = None\n",
        "    log_every_n_steps: int = 250\n",
        "\n",
        "\n",
        "class DCGANTrainer:\n",
        "    def __init__(self, args: DCGANArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(self.args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "        batch, img_channels, img_height, img_width = next(iter(self.trainloader))[0].shape\n",
        "        assert img_height == img_width\n",
        "\n",
        "        self.model = DCGAN(args.latent_dim_size, img_height, img_channels, args.hidden_channels).to(device).train()\n",
        "        self.optG = t.optim.Adam(self.model.netG.parameters(), lr=args.lr, betas=args.betas)\n",
        "        self.optD = t.optim.Adam(self.model.netD.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step_discriminator(\n",
        "        self,\n",
        "        img_real: Float[Tensor, \"batch channels height width\"],\n",
        "        img_fake: Float[Tensor, \"batch channels height width\"],\n",
        "    ) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Generates a real and fake image, and performs a gradient step on the discriminator to maximize\n",
        "        log(D(x)) + log(1-D(G(z))). Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def training_step_generator(self, img_fake: Float[Tensor, \"batch channels height width\"]) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Performs a gradient step on the generator to maximize log(D(G(z))). Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Performs evaluation by generating 8 instances of random noise and passing them through the generator, then\n",
        "        optionally logging the results to Weights & Biases.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        self.model.netG.eval()\n",
        "\n",
        "        # Generate random noise\n",
        "        t.manual_seed(42)\n",
        "        noise = t.randn(10, self.model.latent_dim_size).to(device)\n",
        "        # Get generator output\n",
        "        output = self.model.netG(noise)\n",
        "        # Clip values to make the visualization clearer\n",
        "        output = output.clamp(output.quantile(0.01), output.quantile(0.99))\n",
        "        # Log to weights and biases\n",
        "        if self.args.use_wandb:\n",
        "            output = einops.rearrange(output, \"b c h w -> b h w c\").cpu().numpy()\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output]}, step=self.step)\n",
        "        else:\n",
        "            display_data(output, nrows=1, title=\"Generator-produced images\")\n",
        "\n",
        "        self.model.netG.train()\n",
        "\n",
        "    def train(self) -> DCGAN:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            progress_bar = tqdm(self.trainloader, total=len(self.trainloader), ascii=True)\n",
        "\n",
        "            for img_real, label in progress_bar:\n",
        "                # YOUR CODE HERE - fill in the training step for generator & discriminator\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_-7s9ZV6ejy"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def training_step_discriminator(\n",
        "    self,\n",
        "    img_real: Float[Tensor, \"batch channels height width\"],\n",
        "    img_fake: Float[Tensor, \"batch channels height width\"],\n",
        ") -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Generates a real and fake image, and performs a gradient step on the discriminator to maximize\n",
        "    log(D(x)) + log(1-D(G(z))). Logs to wandb if enabled.\n",
        "    \"\"\"\n",
        "    # Zero gradients\n",
        "    self.optD.zero_grad()\n",
        "\n",
        "    # Calculate D(x) and D(G(z)), for use in the objective function\n",
        "    D_x = self.model.netD(img_real)\n",
        "    D_G_z = self.model.netD(img_fake)\n",
        "\n",
        "    # Calculate loss\n",
        "    lossD = -(t.log(D_x).mean() + t.log(1 - D_G_z).mean())\n",
        "\n",
        "    # Gradient descent step (with optional clipping)\n",
        "    lossD.backward()\n",
        "    if self.args.clip_grad_norm is not None:\n",
        "        nn.utils.clip_grad_norm_(self.model.netD.parameters(), self.args.clip_grad_norm)\n",
        "    self.optD.step()\n",
        "\n",
        "    if self.args.use_wandb:\n",
        "        wandb.log(dict(lossD=lossD), step=self.step)\n",
        "    return lossD\n",
        "\n",
        "\n",
        "def training_step_generator(self, img_fake: Float[Tensor, \"batch channels height width\"]) -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Performs a gradient step on the generator to maximize log(D(G(z))). Logs to wandb if enabled.\n",
        "    \"\"\"\n",
        "    # Zero gradients\n",
        "    self.optG.zero_grad()\n",
        "\n",
        "    # Calculate D(G(z)), for use in the objective function\n",
        "    D_G_z = self.model.netD(img_fake)\n",
        "\n",
        "    # Calculate loss\n",
        "    lossG = -(t.log(D_G_z).mean())\n",
        "\n",
        "    # Gradient descent step (with optional clipping)\n",
        "    lossG.backward()\n",
        "    if self.args.clip_grad_norm is not None:\n",
        "        nn.utils.clip_grad_norm_(self.model.netG.parameters(), self.args.clip_grad_norm)\n",
        "    self.optG.step()\n",
        "\n",
        "    if self.args.use_wandb:\n",
        "        wandb.log(dict(lossG=lossG), step=self.step)\n",
        "    return lossG\n",
        "\n",
        "\n",
        "def train(self) -> DCGAN:\n",
        "    \"\"\"Performs a full training run.\"\"\"\n",
        "    self.step = 0\n",
        "    if self.args.use_wandb:\n",
        "        wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "\n",
        "    for epoch in range(self.args.epochs):\n",
        "        progress_bar = tqdm(self.trainloader, total=len(self.trainloader), ascii=True)\n",
        "\n",
        "        for img_real, label in progress_bar:\n",
        "            # Generate random noise & fake image\n",
        "            noise = t.randn(self.args.batch_size, self.args.latent_dim_size).to(device)\n",
        "            img_real = img_real.to(device)\n",
        "            img_fake = self.model.netG(noise)\n",
        "\n",
        "            # Training steps\n",
        "            lossD = self.training_step_discriminator(img_real, img_fake.detach())\n",
        "            lossG = self.training_step_generator(img_fake)\n",
        "\n",
        "            # Update progress bar\n",
        "            self.step += 1\n",
        "            progress_bar.set_description(f\"{epoch=}, {lossD=:.4f}, {lossG=:.4f}, batches={self.step}\")\n",
        "\n",
        "            # Log batch of data\n",
        "            if self.step % self.args.log_every_n_steps == 0:\n",
        "                self.log_samples()\n",
        "\n",
        "    if self.args.use_wandb:\n",
        "        wandb.finish()\n",
        "\n",
        "    return self.model\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oESbBN36ejy"
      },
      "source": [
        "Once you've written your code, here are some default arguments for MNIST and CelebA you can try out.\n",
        "\n",
        "Note that the MNIST model is very small in comparison to CelebA - if you make it any larger, you fall into a very common GAN failure mode where the discriminator becomes perfect (loss goes to zero) and the generator is unable to get a gradient signal to produce better images - see next section for a discussion of this. Larger architectures are generally more likely to fall into this failure mode, and empirically it seems to happen more for MNIST than for CelebA which is why we generally recommend using the CelebA dataset & architecture for this exercise - although this failure mode can happen in both cases!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XJVXvnk6ejy"
      },
      "outputs": [],
      "source": [
        "# Arguments for CelebA\n",
        "args = DCGANArgs(\n",
        "    dataset=\"CELEB\",\n",
        "    hidden_channels=[128, 256, 512],\n",
        "    batch_size=32,  # if you get OOM errors, reduce this!\n",
        "    epochs=5,\n",
        "    use_wandb=False,\n",
        ")\n",
        "trainer = DCGANTrainer(args)\n",
        "dcgan = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbOHf_Bn6ejy"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see an example of the output you should be producing by the end of this CelebA training run.</summary>\n",
        "\n",
        "Here was my output after 250 batches (8000 images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/celeb-gans-1.png\" width=\"700\">\n",
        "\n",
        "After 2000 batches (64000 images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/celeb-gans-2.png\" width=\"700\">\n",
        "\n",
        "And after the end of training (5 epochs, approx 625k images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/celeb-gans-3.png\" width=\"700\">\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-M55VLc6ejy"
      },
      "outputs": [],
      "source": [
        "# Arguments for MNIST\n",
        "args = DCGANArgs(\n",
        "    dataset=\"MNIST\",\n",
        "    hidden_channels=[12, 24],\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    use_wandb=False,\n",
        ")\n",
        "trainer = DCGANTrainer(args)\n",
        "dcgan = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fki-AbOG6ejy"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see an example of the output you should be producing by the end of this MNIST training run.</summary>\n",
        "\n",
        "Here was my output after 250 batches (32k images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mnist-gans-1.png\" width=\"700\">\n",
        "\n",
        "After 2000 batches (256k images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mnist-gans-2.png\" width=\"700\">\n",
        "\n",
        "About 90% of the way through training, it was achieving the best results:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mnist-gans-3.png\" width=\"700\">\n",
        "\n",
        "However after this point it broke, and produced NaNs from both the discriminator and the generator:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mnist-gans-nan.png\" width=\"900\">\n",
        "\n",
        "This is a common problem for training GANs - they're just a pretty cursed architecture! Read on for more on this.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scY9IVU-6ejy"
      },
      "source": [
        "### Fixing bugs\n",
        "\n",
        "GANs are notoriously hard to get exactly right. I ran into quite a few bugs myself building this architecture, and I've tried to mention them somewhere on this page to help participants avoid them. If you run into a bug and are able to fix it, please send it to me and I can add it here, for the benefit of everyone else!\n",
        "\n",
        "* Make sure you apply the layer normalisation (mean 0, std dev 0.02) to your linear layers as well as your convolutional layers.\n",
        "* More generally, in your function to initialise the weights of your network, make sure no layers are being missed out. The easiest way to do this is to inspect your model afterwards (i.e. loop through all the params, printing out their mean and std dev).\n",
        "\n",
        "Also, you might find [this page](https://github.com/soumith/ganhacks) useful. It provides several tips and tricks for how to make your GAN work (many of which we've already mentioned on this page)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdvSiHZx6ejy"
      },
      "source": [
        "## Why so unstable during training?\n",
        "\n",
        "If you try training your GAN on MNIST, you might find that it eventually blows up (with close to zero discriminator loss, and spiking generator loss - possibly even gradients large enough to overflow and lead to `nan` values). This might also happen if you train on CelebA but your architecture is too big, or even if you train with a reasonably-sized architecture but for too long!\n",
        "\n",
        "This is a common problem with GANs, which are notoriously unstable to train. Essentially, the discriminator gets so good at its job that the generator can't latch onto a good gradient for improving its performance. Although the theoretical formulation of GANs as a minimax game is elegant, there are quite a few assumptions that have to go into it in order for there to be one theoretical optimum involving the generator producing perfect images - and in practice this is rarely achieved, even in the limit.\n",
        "\n",
        "Different architectures like diffusion models and VAEs are generally more stable, although many of the most advanced image generation architectures do still take important conceptual ideas from the GAN framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MuGo9ka6ejy"
      },
      "source": [
        "## Bonus - Smooth interpolation\n",
        "\n",
        "Suppose you take two vectors in the latent space. If you use your generator to create output at points along the linear interpolation between these vectors, your image will change continuously (because it is a continuous function of the latent vector), but it might look very different at the start and the end. Can you create any cool animations from this?\n",
        "\n",
        "Instead of linearly interpolating between two vectors, you could try applying a [rotation matrix](https://en.wikipedia.org/wiki/Rotation_matrix) to a vector (this has the advantage of keeping the interpolated vector \"in distribution\", since the rotation between two standard normally distributed vectors is also standard normal, whereas the linear interpolation isn't). Are the results better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_k3ZOhJ6ejy"
      },
      "source": [
        "# 3️⃣ Bonus - Transposed Convolutions\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about & implement the transposed convolution operation.\n",
        "> - Implement GANs and/or VAEs entirely from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1qZAr_G6ejz"
      },
      "source": [
        "## Transposed convolutions\n",
        "\n",
        "In this section, we'll build all the modules required to implement our DCGAN.\n",
        "\n",
        "> Note - this section is similar in flavour to the bonus exercises from the \"CNNs & ResNets\" chapter, i.e. you'll be implementing transposed convolutions using low-level stride and tensor manipulation operations. That section should be considered a prerequisite for this one.\n",
        "\n",
        "Let's start by importing some useful functions from the bonus section of \"CNNs & ResNets\", where we implemented convolutions from scratch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTYCXIAl6ejz"
      },
      "outputs": [],
      "source": [
        "from part2_cnns.solutions import IntOrPair, Pair, conv1d_minimal, conv2d_minimal, force_pair, pad1d, pad2d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gygDKzVZ6ejz"
      },
      "source": [
        "Now, **what are transposed convolutions, and why should we care about them?** One high-level intuition goes something like this: most of the generator's architecture is basically the discriminator architecture in reverse. We need something that performs the reverse of a convolution - not literally the inverse operation, but something reverse in spirit, which uses a kernel of weights to project up to some array of larger size.\n",
        "\n",
        "**Importantly, a transposed convolution isn't literally the inverse of a convolution**. A lot of confusion can come from misunderstanding this!\n",
        "\n",
        "You can describe the difference between convolutions and transposed convolutions as follows:\n",
        "\n",
        "* In convolutions, you slide the kernel around inside the input. At each position of the kernel, you take a sumproduct between the kernel and that section of the input to calculate a single element in the output.\n",
        "* In transposed convolutions, you slide the kernel around what will eventually be your output, and at each position you add some multiple of the kernel to your output.\n",
        "\n",
        "Below is an illustration of both for comparison, in the 1D case (where $*$ stands for the 1D convolution operator, and $*^T$ stands for the transposed convolution operator). Note the difference in size between the output in both cases. With standard convolutions, our output is smaller than our input, because we're having to fit the kernel inside the input in order to produce the output. But in our transposed convolutions, the output is actually larger than the input, because we're fitting the kernel inside the output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-1.png\" width=\"700\">\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Question - what do you think the formula is relating <code>input_size</code>, <code>kernel_size</code> and <code>output_size</code> in the case of 1D convolutions (with no padding or stride)?</summary>\n",
        "\n",
        "The formula is `output_size = input_size + kernel_size - 1`.\n",
        "        \n",
        "Note how this exactly mirrors the equation in the convolutional case; it's identical if we swap around `output_size` and `input_size`.\n",
        "</details>\n",
        "\n",
        "<br>\n",
        "\n",
        "Now, consider the elements in the output of the transposed convolution: `z+4y+3x, 4x+3y-2x`, etc. Note that these look a bit like convolutions, since they're inner products of slices of the input with versions of the kernel. This observation leads nicely into why transposed convolutions are called transposed convolutions - because they can actually be written as convolutions, just with a slightly modified input and kernel.\n",
        "\n",
        "<details>\n",
        "<summary>Question - how can this operation be cast as a convolution? In other words, exactly what arrays <code>input</code> and <code>kernel</code> would produce the same output as the transposed convolution above, if we performed a standard convolution on them?</summary>\n",
        "\n",
        "From looking at the diagram, note that the final output (the blue row at the bottom) looks a bit like sliding the _reversed_ kernel over the input. In other words, we get elements like `z+4y+3x` which are an inner product between the input slice `input[:3] = [1, 4, 3]` and the reversed kernel `[z, y, x]`. This suggests we should be using the reversed kernel in our convolution.\n",
        "\n",
        "Can we just use a reversed kernel on our original input and call it a day? No, because the output size wouldn't be correct. Using a reversed kernel on our original input would give us just the two elements `[z+4y+3x, 4z+3y-2x]`, not the full 6-element output we actually get. The answer is that we need to pad out our input with zeros on the left and right, with the padding amount equal to `kernel_size - 1`.\n",
        "\n",
        "To conclude - with `input_modified = pad(input, kernel_size-1)` and `kernel_modified = kernel[::-1]`, we get:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-2A.png\" width=\"850\">\n",
        "\n",
        "Note - it's also valid to say we use the original kernel and pad & flip the input, but for the exercises below we'll stick to the former interpretation.\n",
        "\n",
        "</details>\n",
        "\n",
        ">\n",
        "\n",
        "<!-- <details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Let `input_mod` and `kernel_mod` be the modified versions of the input and kernel, to be used in the convolution.\n",
        "\n",
        "You should be able to guess what `kernel_mod` is by looking at the diagram.\n",
        "\n",
        "Also, from the formula for transposed convolutions, we must have:\n",
        "\n",
        "```\n",
        "output_size = input_mod_size + kernel_mod_size - 1\n",
        "```\n",
        "\n",
        "But we currently have:\n",
        "\n",
        "```\n",
        "output_size = input_size - kernel_size + 1\n",
        "```\n",
        "\n",
        "which should help you figure out what size `input_mod` needs to be, relative to `input`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "\n",
        "`kernel_mod` should be the same size as kernel (but altered in a particular way). `input_mod` should be formed by padding `input`, so that its size increases by `2 * (kernel_size - 1)`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "If you create `input_mod` by padding `input` with exactly `kernel_size - 1` zeros on either side, and reverse your kernel to create `kernel_mod`, then the convolution of these modified arrays equals your original transposed convolution output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-2A.png\" width=\"850\">\n",
        "\n",
        "</details> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_x9Ustb6ejz"
      },
      "source": [
        "### Exercise - minimal 1D transposed convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Now, you should implement the function `conv_transpose1d_minimal`. You're allowed to call functions like `conv1d_minimal` and `pad1d` which you wrote previously (if you didn't do these exercises, then you can import the solution versions of them - although we do recommend doing the conv from scratch exercises before these ones).\n",
        "\n",
        "One important note - in our convolutions we assumed the kernel had shape `(out_channels, in_channels, kernel_width)`. Here, the order is different: `in_channels` comes before `out_channels`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCQkoWE16ejz"
      },
      "outputs": [],
      "source": [
        "def conv_transpose1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"in_channels out_channels kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"Like torch's conv_transpose1d using bias=False and all other keyword arguments left at their default values.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv_transpose1d_minimal(conv_transpose1d_minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YgLcFRG6ejz"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv_transpose1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"in_channels out_channels kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"Like torch's conv_transpose1d using bias=False and all other keyword arguments left at their default values.\"\"\"\n",
        "    batch, in_channels, width = x.shape\n",
        "    in_channels_2, out_channels, kernel_width = weights.shape\n",
        "    assert in_channels == in_channels_2, \"in_channels for x and weights don't match up\"\n",
        "\n",
        "    x_mod = pad1d(x, left=kernel_width - 1, right=kernel_width - 1, pad_value=0)\n",
        "    weights_mod = einops.rearrange(weights.flip(-1), \"i o w -> o i w\")\n",
        "\n",
        "    return conv1d_minimal(x_mod, weights_mod)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shCi6bLl6ejz"
      },
      "source": [
        "### Exercise - 1D transposed convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴🔴\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 25-40 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Now we add in the extra parameters `padding` and `stride`, just like we did for our convolutions back in week 0.\n",
        "\n",
        "The basic idea is that both parameters mean the inverse of what they did in for convolutions.\n",
        "\n",
        "In convolutions, `padding` tells you how much to pad the input by. But in transposed convolutions, we pad the input by `kernel_size - 1 - padding` (recall that we're already padding by `kernel_size - 1` by default). So padding decreases our output size rather than increasing it.\n",
        "\n",
        "In convolutions, `stride` tells you how much to step the kernel by, as it's being moved around inside the input. In transposed convolutions, stride does something different: you space out all your input elements by an amount equal to `stride` before performing your transposed convolution. This might sound strange, but **it's actually equivalent to performing strides as you're moving the kernel around inside the output.** This diagram should help show why:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-3.png\" width=\"750\">\n",
        "\n",
        "For this reason, transposed convolutions are also referred to as **fractionally strided convolutions**, since a stride of 2 over the output is equivalent to a 1/2 stride over the input (i.e. every time the kernel takes two steps inside the spaced-out version of the input, it moves one stride with reference to the original input).\n",
        "\n",
        "**Question - what is the formula relating output size, input size, kernel size, stride and padding? (note, you shouldn't need to refer to this explicitly in your functions)**\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "Without any padding, we had:\n",
        "\n",
        "```\n",
        "output_size = input_size + kernel_size - 1\n",
        "```\n",
        "\n",
        "Twice the `padding` parameter gets subtracted from the RHS (since we pad by the same amount on each side), so this gives us:\n",
        "\n",
        "```\n",
        "output_size = input_size + kernel_size - 1 - 2 * padding\n",
        "```\n",
        "\n",
        "Finally, consider `stride`. As mentioned above, we can consider stride here to have the same effect as \"spacing out\" elements in the input. Each non-zero element will be `stride - 1` positions apart (for instance, `stride = 2` turns `[1, 2, 3]` into `[1, 0, 2, 0, 3]`). You can check that the number of zeros added between elements equals `(input_size - 1) * (stride - 1)`. When you add this to the right hand side, and simplify, you are left with:\n",
        "\n",
        "```\n",
        "output_size = (input_size - 1) * stride + kernel_size - 2 * padding\n",
        "```\n",
        "</details>\n",
        "\n",
        "Padding should be pretty easy for you to implement on top of what you've already done. For strides, you will need to construct a strided version of the input which is \"spaced out\" in the way described above, before performing the transposed convolution. It might help to write a `fractional_stride` function; we've provided the code for you to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1RGpGml6ejz"
      },
      "outputs": [],
      "source": [
        "def fractional_stride_1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], stride: int = 1\n",
        ") -> Float[Tensor, \"batch in_channels output_width\"]:\n",
        "    \"\"\"Returns a version of x suitable for transposed convolutions, i.e. \"spaced out\" with zeros between its values.\n",
        "    This spacing only happens along the last dimension.\n",
        "    x: shape (batch, in_channels, width)\n",
        "    Example:\n",
        "        x = [[[1, 2, 3], [4, 5, 6]]]\n",
        "        stride = 2\n",
        "        output = [[[1, 0, 2, 0, 3], [4, 0, 5, 0, 6]]]\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_fractional_stride_1d(fractional_stride_1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u-oWkVZ6ejz"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to implement <code>fractional_stride</code>.</summary>\n",
        "\n",
        "The easiest way is to initialise an array of zeros with the appropriate size, then slicing to set its elements from `x`.\n",
        "\n",
        "Warning - if you do it this way, **make sure the output has the same device as `x`**.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def fractional_stride_1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], stride: int = 1\n",
        ") -> Float[Tensor, \"batch in_channels output_width\"]:\n",
        "    \"\"\"Returns a version of x suitable for transposed convolutions, i.e. \"spaced out\" with zeros between its values.\n",
        "    This spacing only happens along the last dimension.\n",
        "    x: shape (batch, in_channels, width)\n",
        "    Example:\n",
        "        x = [[[1, 2, 3], [4, 5, 6]]]\n",
        "        stride = 2\n",
        "        output = [[[1, 0, 2, 0, 3], [4, 0, 5, 0, 6]]]\n",
        "    \"\"\"\n",
        "    batch, in_channels, width = x.shape\n",
        "    width_new = width + (stride - 1) * (\n",
        "        width - 1\n",
        "    )  # the RHS of this sum is the number of zeros we need to add between elements\n",
        "    x_new_shape = (batch, in_channels, width_new)\n",
        "\n",
        "    # Create an empty array to store the spaced version of x in.\n",
        "    x_new = t.zeros(size=x_new_shape, dtype=x.dtype, device=x.device)\n",
        "\n",
        "    x_new[..., ::stride] = x\n",
        "\n",
        "    return x_new\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bChC55DZ6ejz"
      },
      "outputs": [],
      "source": [
        "def conv_transpose1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"in_channels out_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"Like torch's conv_transpose1d using bias=False and all other keyword arguments left at their default values.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv_transpose1d(conv_transpose1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuSyxBEh6ejz"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to implement <code>conv_transpose1d</code>.</summary>\n",
        "\n",
        "There are three things you need to do:\n",
        "\n",
        "* Modify `x` by \"spacing it out\" with `fractional_stride_1d` and padding it the appropriate amount\n",
        "* Modify `weights` (just like you did for `conv_transpose1d_minimal`)\n",
        "* Use `conv1d_minimal` on your modified `x` and `weights` (just like you did for `conv_transpose1d_minimal`)\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv_transpose1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"in_channels out_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"Like torch's conv_transpose1d using bias=False and all other keyword arguments left at their default values.\"\"\"\n",
        "    batch, ic, width = x.shape\n",
        "    ic_2, oc, kernel_width = weights.shape\n",
        "    assert ic == ic_2, f\"in_channels for x and weights don't match up. Shapes are {x.shape}, {weights.shape}.\"\n",
        "\n",
        "    # Apply spacing\n",
        "    x_spaced_out = fractional_stride_1d(x, stride)\n",
        "\n",
        "    # Apply modification (which is controlled by the padding parameter)\n",
        "    padding_amount = kernel_width - 1 - padding\n",
        "    assert padding_amount >= 0, \"total amount padded should be positive\"\n",
        "    x_mod = pad1d(x_spaced_out, left=padding_amount, right=padding_amount, pad_value=0)\n",
        "\n",
        "    # Modify weights, then return the convolution\n",
        "    weights_mod = einops.rearrange(weights.flip(-1), \"i o w -> o i w\")\n",
        "\n",
        "    return conv1d_minimal(x_mod, weights_mod)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpE_-pW76ejz"
      },
      "source": [
        "Another fun fact about transposed convolutions - they are also called **backwards strided convolutions**, because they are equivalent to taking the gradient of Conv2d with respect to its output. As an optional bonus, can you formally prove this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EaH7uif6ejz"
      },
      "source": [
        "### Exercise - 2D transposed convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Finally, we get to 2D transposed convolutions! Since there's no big conceptual difference between this and the 1D case, we'll jump straight to implementing the full version of these convolutions, with padding and strides. A few notes:\n",
        "\n",
        "* You'll need to make `fractional_stride_2d`, which performs spacing along the last two dimensions rather than just the last dimension.\n",
        "* Defining the modified version of your kernel will involve reversing on more than one dimension. You'll still need to perform the same rearrangement flipping the output and input channel dimensions though.\n",
        "* You can use the `force_pair` function from earlier this week (it's been imported for you, as have the `Pair` and `IntOrPair` types)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYoLsk5c6ejz"
      },
      "outputs": [],
      "source": [
        "def fractional_stride_2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"], stride_h: int, stride_w: int\n",
        ") -> Float[Tensor, \"batch in_channels output_height output_width\"]:\n",
        "    \"\"\"\n",
        "    Same as fractional_stride_1d, except we apply it along the last 2 dims of x (height and width).\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def conv_transpose2d(x, weights, stride: IntOrPair = 1, padding: IntOrPair = 0) -> Tensor:\n",
        "    \"\"\"Like torch's conv_transpose2d using bias=False\n",
        "    x: shape (batch, in_channels, height, width)\n",
        "    weights: shape (out_channels, in_channels, kernel_height, kernel_width)\n",
        "    Returns: shape (batch, out_channels, output_height, output_width)\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_fractional_stride_2d(fractional_stride_2d)\n",
        "tests.test_conv_transpose2d(conv_transpose2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1ONhY0A6ejz"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def fractional_stride_2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"], stride_h: int, stride_w: int\n",
        ") -> Float[Tensor, \"batch in_channels output_height output_width\"]:\n",
        "    \"\"\"\n",
        "    Same as fractional_stride_1d, except we apply it along the last 2 dims of x (height and width).\n",
        "    \"\"\"\n",
        "    batch, in_channels, height, width = x.shape\n",
        "    width_new = width + (stride_w - 1) * (width - 1)\n",
        "    height_new = height + (stride_h - 1) * (height - 1)\n",
        "    x_new_shape = (batch, in_channels, height_new, width_new)\n",
        "\n",
        "    # Create an empty array to store the spaced version of x in.\n",
        "    x_new = t.zeros(size=x_new_shape, dtype=x.dtype, device=x.device)\n",
        "\n",
        "    x_new[..., ::stride_h, ::stride_w] = x\n",
        "\n",
        "    return x_new\n",
        "\n",
        "\n",
        "def conv_transpose2d(x, weights, stride: IntOrPair = 1, padding: IntOrPair = 0) -> Tensor:\n",
        "    \"\"\"Like torch's conv_transpose2d using bias=False\n",
        "    x: shape (batch, in_channels, height, width)\n",
        "    weights: shape (out_channels, in_channels, kernel_height, kernel_width)\n",
        "    Returns: shape (batch, out_channels, output_height, output_width)\n",
        "    \"\"\"\n",
        "    stride_h, stride_w = force_pair(stride)\n",
        "    padding_h, padding_w = force_pair(padding)\n",
        "\n",
        "    batch, ic, height, width = x.shape\n",
        "    ic_2, oc, kernel_height, kernel_width = weights.shape\n",
        "    assert ic == ic_2, f\"in_channels for x and weights don't match up. Shapes are {x.shape}, {weights.shape}.\"\n",
        "\n",
        "    # Apply spacing\n",
        "    x_spaced_out = fractional_stride_2d(x, stride_h, stride_w)\n",
        "\n",
        "    # Apply modification (which is controlled by the padding parameter)\n",
        "    pad_h_actual = kernel_height - 1 - padding_h\n",
        "    pad_w_actual = kernel_width - 1 - padding_w\n",
        "    assert min(pad_h_actual, pad_w_actual) >= 0, \"total amount padded should be positive\"\n",
        "    x_mod = pad2d(\n",
        "        x_spaced_out, left=pad_w_actual, right=pad_w_actual, top=pad_h_actual, bottom=pad_h_actual, pad_value=0\n",
        "    )\n",
        "\n",
        "    # Modify weights\n",
        "    weights_mod = einops.rearrange(weights.flip(-1, -2), \"i o h w -> o i h w\")\n",
        "\n",
        "    # Return the convolution\n",
        "    return conv2d_minimal(x_mod, weights_mod)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BenR8gvF6ejz"
      },
      "source": [
        "### Exercise - transposed conv module\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Now that you've written a function to calculate the convolutional transpose, you should implement it as a module just like you've done for `Conv2d` previously. Your weights should be initialised with the uniform distribution `Unif[-sqrt(k), sqrt(k)]` where `k = 1 / (out_channels * kernel_width * kernel_height)` (this is PyTorch's standard behaviour for convolutional transpose layers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cth-Ojp6ejz"
      },
      "outputs": [],
      "source": [
        "class ConvTranspose2d(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, kernel_size: IntOrPair, stride: IntOrPair = 1, padding: IntOrPair = 0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.ConvTranspose2d with bias=False.\n",
        "        Name your weight field `self.weight` for compatibility with the tests.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = force_pair(kernel_size)\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(\n",
        "        self, x: Float[Tensor, \"batch in_channels height width\"]\n",
        "    ) -> Float[Tensor, \"batch out_channels output_height output_width\"]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "\n",
        "\n",
        "tests.test_ConvTranspose2d(ConvTranspose2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaMTOiOg6ejz"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ConvTranspose2d(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, kernel_size: IntOrPair, stride: IntOrPair = 1, padding: IntOrPair = 0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.ConvTranspose2d with bias=False.\n",
        "        Name your weight field `self.weight` for compatibility with the tests.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = force_pair(kernel_size)\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        sf = 1 / (self.out_channels * self.kernel_size[0] * self.kernel_size[1]) ** 0.5\n",
        "        self.weight = nn.Parameter(sf * (2 * t.rand(in_channels, out_channels, *self.kernel_size) - 1))\n",
        "\n",
        "    def forward(\n",
        "        self, x: Float[Tensor, \"batch in_channels height width\"]\n",
        "    ) -> Float[Tensor, \"batch out_channels output_height output_width\"]:\n",
        "        return conv_transpose2d(x, self.weight, self.stride, self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGaQwdA56ejz"
      },
      "source": [
        "Now, you're all done! You can go back and implement GANs or VAEs using the transposed convolution module you've just written."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}