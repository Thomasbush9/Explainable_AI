{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4_UELxj6ejp"
      },
      "source": [
        "# [0.5] - VAEs & GANs (exercises)\n",
        "\n",
        "> **ARENA [Streamlit Page](https://arena-chapter0-fundamentals.streamlit.app/05_[0.5]_VAEs_&_GANs)**\n",
        ">\n",
        "> **Colab: [exercises](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_exercises.ipynb?t=20250316) | [solutions](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_solutions.ipynb?t=20250316)**\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-2zick19fl-6GY1yoGaoUozyM3wObwmnQ), and ask any questions on the dedicated channels for this chapter of material.\n",
        "\n",
        "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n",
        "\n",
        "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etfnZtdU6ejq"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/headers/header-05.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqLChVQP6ejr"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqYP4egj6ejr"
      },
      "source": [
        "Today, we're studying two important classes of generative image models: **Generative Adversarial Networks (GANs)** and **Variational Autoencoders (VAEs)**. Although these generally aren't SOTA any more (thanks in part to the rise of diffusion models), there are some deep conceptual insights which can be gleaned from studying these models (VAEs in particular) which help lay the groundwork for more advanced models.\n",
        "\n",
        "These exercises will also hopefully bring much of this chapter full-circle:\n",
        "\n",
        "* We'll cover transposed convolutions, which will serve as a refresher on some of the ideas behind convolutions **(day 2: CNNs & ResNets)**\n",
        "* We'll be assembling NNet architectures from scratch, like in the ResNets exercises **(day 2: CNNs & ResNets)**\n",
        "* We'll work with different loss functions, and think intuitively about what it means to optimize them **(day 3: Optimization & Hyperparameters)**\n",
        "* We'll be working with `wandb`, and will learn how to log outputs produced by our models **(day 3: Optimization & Hyperparameters)**\n",
        "* We'll have to think carefully about how gradient propagation works between different parts of our model **(day 4: Backpropagation)**\n",
        "\n",
        "Note, many of today's exercises (especially those involving building models & writing forward pass functions) don't have as rigorous unit tests as previous days of content. Part of this is because the design spec for these models is less strict (we're not copying over weights from a pretrained model like last time, all that matters is that our model actually trains correctly, and so small changes to the solution architecture can sometimes be allowed). However, another part is that we're trying to move participants away from being too reliant on unit tests, and towards being able to independently reason through exercises or replications given just a description of the task or a paper implementation to follow. This is an invaluable skill to develop for any aspiring ML practitioner!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzIX6cVj6ejr"
      },
      "source": [
        "## Content & Learning Objectives\n",
        "\n",
        "### 1️⃣ Autoencoders & VAEs\n",
        "\n",
        "Autoencoders are a relatively simple architecture, at least compared to GANs: you learn a compressed representation of your data (mainly using linear layers and convolutions), then reconstruct it back into an image (with linear layers and transposed convolutions).\n",
        "\n",
        "Although autoencoders can learn some interesting low-dimensional representations, they are less good for generating images because their latent spaces aren't generally meaningful. This leads to VAEs, which solve this problem by having their encoders map to a distribution over latent vectors, rather than a single latent vector. This incentivises the latent space to be more meaningful, and we can more easily generate images from sample vectors in this space.\n",
        "\n",
        "We start with some reading material on autoencoders and transposed convolutions (which are often used in parallel with convolutions, to take a latent space and map it back into a full-size image). Then, we actually implement and train VAEs to generate MNIST images, as well as a do a bit of exploring our our autoencoders' latent spaces.\n",
        "\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about the transposed convolution operation\n",
        "> - Understand the basic architecture of autoencoders and VAEs\n",
        "> - Learn about the reparameterization trick for VAEs\n",
        "> - Implement your own autoencoder\n",
        "> - Implement your own VAE, and use it to generate realistic MNIST images\n",
        "> - (optional) Dive deeper into the mathematical underpinnings of VAEs, and learn about the ELBO loss function\n",
        "\n",
        "\n",
        "### 2️⃣ GANs\n",
        "\n",
        "Relative to autoencoders, GANs have a few more moving pieces in their architecture. They're best thought of as two separate networks (the generator and the discriminator) which are learning different goals simultaneously. The goal of the generator is to create images which fool the discriminator, and the goal of the discriminator is to distinguish between real and fake images. The ideal equilibrium point of training is when the generator produces perfect images and the discriminator can't tell the difference between real and fake - however, that's much simpler said than done! GANs are notoriously difficult to train, and we'll have to engage with some of these difficulties during our exercises.\n",
        "\n",
        "By the end of these exercises, you should have built and trained your own GANs, to generate celebrity pictures. By the time you're done, you'll hopefully have produced output like this (below), and you'll have everything you need to set up a competitor to Midjourney (plus or minus a few other foundational ML papers and an investment of a few hundred million dollars).\n",
        "                \n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan-last-output.png\" width=\"1100\">\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand the loss function used in GANs, and why it can be expected to result in the generator producing realistic outputs.\n",
        "> - Implement the DCGAN architecture from the paper, with relatively minimal guidance.\n",
        "> - Learn how to identify and fix bugs in your GAN architecture, to improve convergence properties.\n",
        "\n",
        "\n",
        "### 3️⃣ Bonus - Transposed Convolutions\n",
        "\n",
        "In this section, you'll implement the transposed convolution operation manually. This is similar to a regular convolution, but designed for upsampling rather than downsampling (i.e. producing an image from a latent vector rather producing output from an image). These are very important in many generative algorithms. Once you implement this, you'll be able to build your own GANs and VAEs from scratch, without using any pre-built layers.\n",
        "\n",
        "*Note - the bonus section from the CNNs day is a prerequisite for these bonus exercises. If you haven't completed that section, you'll need to do so before attempting these.*\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about & implement the transposed convolution operation.\n",
        "> - Implement GANs and/or VAEs entirely from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fd8_6de6ejr"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nW8KFYcG6ejr",
        "outputId": "b077e5bb-7217-47b1-84a1-775bab543933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.3.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping)\n",
            "  Downloading wadler_lindig-0.1.4-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading jaxtyping-0.3.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.4-py3-none-any.whl (20 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, wadler-lindig, torchinfo, fsspec, dill, multiprocess, jaxtyping, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 jaxtyping-0.3.0 multiprocess-0.70.16 torchinfo-1.8.0 wadler-lindig-0.1.4 xxhash-3.5.0\n",
            "--2025-03-29 22:37:41--  https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main [following]\n",
            "--2025-03-29 22:37:41--  https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/content/main.zip’\n",
            "\n",
            "main.zip                [        <=>         ]  20.97M  9.53MB/s    in 2.2s    \n",
            "\n",
            "2025-03-29 22:37:43 (9.53 MB/s) - ‘/content/main.zip’ saved [21985499]\n",
            "\n",
            "Archive:  /content/main.zip\n",
            "e79d12f87f6c66d8d79040711b47049b3f9df22a\n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/\n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/0.0_Prerequisites_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/0.0_Prerequisites_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/numbers.npy  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/pikachu.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/pikachu.stl  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/test_with_pytest.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/imagenet_labels.json  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/astronaut.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/chimpanzee.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/dragonfly.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/fireworks.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/frogs.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/golden_retriever.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/goofy.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/hourglass.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/iguana.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/platypus.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/volcano.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/0.3_Optimization_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/0.3_Optimization_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/0.4_Backprop_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/0.4_Backprop_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/utils.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/plotly_utils.py  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "repo = \"ARENA_3.0\"\n",
        "branch = \"main\"\n",
        "\n",
        "# Install dependencies\n",
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    %pip install torchinfo jaxtyping einops datasets\n",
        "\n",
        "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n",
        "root = (\n",
        "    \"/content\"\n",
        "    if IN_COLAB\n",
        "    else \"/root\"\n",
        "    if repo not in os.getcwd()\n",
        "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n",
        ")\n",
        "\n",
        "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n",
        "    if not IN_COLAB:\n",
        "        !sudo apt-get install unzip\n",
        "        %pip install jupyter ipython --upgrade\n",
        "\n",
        "    if not os.path.exists(f\"{root}/{chapter}\"):\n",
        "        !wget -P {root} https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/{branch}.zip\n",
        "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n",
        "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n",
        "        !rm {root}/{branch}.zip\n",
        "        !rmdir {root}/{repo}-{branch}\n",
        "\n",
        "\n",
        "if f\"{root}/{chapter}/exercises\" not in sys.path:\n",
        "    sys.path.append(f\"{root}/{chapter}/exercises\")\n",
        "\n",
        "os.chdir(f\"{root}/{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RS6F-Ml-6ejs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Literal\n",
        "\n",
        "import einops\n",
        "import torch as t\n",
        "import torchinfo\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from einops.layers.torch import Rearrange\n",
        "from jaxtyping import Float, Int\n",
        "from torch import Tensor, nn\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "section = \"part5_vaes_and_gans\"\n",
        "root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
        "exercises_dir = root_dir / chapter / \"exercises\"\n",
        "section_dir = exercises_dir / section\n",
        "if str(exercises_dir) not in sys.path:\n",
        "    sys.path.append(str(exercises_dir))\n",
        "\n",
        "\n",
        "import part5_vaes_and_gans.tests as tests\n",
        "import part5_vaes_and_gans.utils as utils\n",
        "from part2_cnns.utils import print_param_count\n",
        "from plotly_utils import imshow\n",
        "\n",
        "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_IzX4SU6ejs"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get a NumPy-related error</summary>\n",
        "\n",
        "This is an annoying colab-related issue which I haven't been able to find a satisfying fix for. If you restart runtime (but don't delete runtime), and run just the imports cell above again (but not the `%pip install` cell), the problem should go away.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paRsknWR6ejs"
      },
      "source": [
        "# 1️⃣ Autoencoders & VAEs\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about the transposed convolution operation\n",
        "> - Understand the basic architecture of autoencoders and VAEs\n",
        "> - Learn about the reparameterization trick for VAEs\n",
        "> - Implement your own autoencoder\n",
        "> - Implement your own VAE, and use it to generate realistic MNIST images\n",
        "> - (optional) Dive deeper into the mathematical underpinnings of VAEs, and learn about the ELBO loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c-5S6EF6ejs"
      },
      "source": [
        "## Reading\n",
        "\n",
        "**Note** - before you start the reading, you might want to run the first block of code in the \"Loading data\" section, because it can take a few minutes to run.\n",
        "\n",
        "* [Understanding VAEs (Medium)](https://medium.com/towards-data-science/understanding-variational-autoencoders-vaes-f70510919f73)\n",
        "    * A clear and accessible explanation of autoencoders and VAEs.\n",
        "    * You can stop at \"Mathematical details of VAEs\"; we'll (optionally) cover this in more detail later.\n",
        "* [Six (and a half) intuitions for KL divergence](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence)\n",
        "    * Optional reading.\n",
        "    * KL divergence is an important concept in VAEs (and will continue to be a useful concept for the rest of this course).\n",
        "* [From Autoencoder to Beta-VAE](https://lilianweng.github.io/posts/2018-08-12-vae/)\n",
        "    * Optional reading.\n",
        "    * This is a more in-depth look at VAEs, the maths behind them, and different architecture variants.\n",
        "* [Transposed Convolutions explained with… MS Excel!](https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8) (optional)\n",
        "    * Optional reading.\n",
        "    * The first part (up to the highlighted comment) is most valuable, since understanding transposed convolutions at a high level is more important than understanding the exact low-level operations that go into them (that's what the bonus is for!).\n",
        "    * [These visualisations](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md) may also help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq2dTJrD6ejs"
      },
      "source": [
        "## Loading data\n",
        "\n",
        "In these exercises, we'll be using either the Celeb-A dataset or the MNIST dataset. For convenience, we'll include a few functions here to load that data in.\n",
        "\n",
        "You should already be familiar with MNIST. You can read about the Celeb-A dataset [here](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) - essentially it's a large-scale face attributes dataset with more than 200k celebrity images, but we'll only be taking the images from this dataset rather the classifications. Run the code below to download the data from HuggingFace, and save it in your filesystem as images.\n",
        "\n",
        "The code should take 4-15 minutes to run in total, but feel free to move on if it's taking longer (you'll mostly be using MNIST in this section, and only using Celeb-A when you move on to GANs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "39FQLsYb6ejs",
        "outputId": "7f2ce5ec-4266-4ae0-828f-8e130c383117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'section_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9b20a7ce260b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mceleb_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msection_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"data/celeba\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mceleb_image_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mceleb_data_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"img_align_celeba\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceleb_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'section_dir' is not defined"
          ]
        }
      ],
      "source": [
        "celeb_data_dir = section_dir / \"data/celeba\"\n",
        "celeb_image_dir = celeb_data_dir / \"img_align_celeba\"\n",
        "\n",
        "os.makedirs(celeb_image_dir, exist_ok=True)\n",
        "\n",
        "if len(list(celeb_image_dir.glob(\"*.jpg\"))) > 0:\n",
        "    print(\"Dataset already loaded.\")\n",
        "else:\n",
        "    dataset = load_dataset(\"nielsr/CelebA-faces\")\n",
        "    print(\"Dataset loaded.\")\n",
        "\n",
        "    for idx, item in tqdm(enumerate(dataset[\"train\"]), total=len(dataset[\"train\"]), desc=\"Saving imgs...\", ascii=True):\n",
        "        # The image is already a JpegImageFile, so we can directly save it\n",
        "        item[\"image\"].save(celeb_image_dir / f\"{idx:06}.jpg\")\n",
        "\n",
        "    print(\"All images have been saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSl6Nbmh6ejt"
      },
      "source": [
        "<details>\n",
        "<summary>Note on why we double-nest our saving paths, i.e. <code>celeba/img_align_celeba</code></summary>\n",
        "\n",
        "In the code above, each image is saved in the format `'data/celeba/img_align_celeba/000001.jpg'`, etc. The reason for this double nesting (rather than e.g. `data/celeba/000001.jpg`) is that the child folders represent the image classes. If we were training a classifier, we'd have multiple folders within `data/celeba`, with each one being a different class. In this dataset, we only have one class (real celeb images), so we only need one child folder.\n",
        "\n",
        "</details>\n",
        "\n",
        "Now, here's some code to load in either the Celeb-A or MNIST data. It also applies transformations to the data, to get it into the right input format for us.\n",
        "\n",
        "The function below allows you to load in either the Celeb-A or MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gAl8Hdap6ejt"
      },
      "outputs": [],
      "source": [
        "def get_dataset(dataset: Literal[\"MNIST\", \"CELEB\"], train: bool = True) -> Dataset:\n",
        "    assert dataset in [\"MNIST\", \"CELEB\"]\n",
        "\n",
        "    if dataset == \"CELEB\":\n",
        "        image_size = 64\n",
        "        assert train, \"CelebA dataset only has a training set\"\n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(image_size),\n",
        "                transforms.CenterCrop(image_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ]\n",
        "        )\n",
        "        trainset = datasets.ImageFolder(root=exercises_dir / \"part5_vaes_and_gans/data/celeba\", transform=transform)\n",
        "\n",
        "    elif dataset == \"MNIST\":\n",
        "        img_size = 28\n",
        "        transform = transforms.Compose(\n",
        "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "        )\n",
        "        trainset = datasets.MNIST(\n",
        "            root=exercises_dir / \"part5_vaes_and_gans/data\",\n",
        "            transform=transform,\n",
        "            download=True,\n",
        "        )\n",
        "\n",
        "    return trainset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJrHIUpp6ejt"
      },
      "source": [
        "We've also given you some code for visualising your data. You should run this code to make sure your data is correctly loaded in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1CWvzRKC6ejt",
        "outputId": "e2f9391e-2394-45b7-84e4-080e0b190d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 42.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.15MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.2MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.17MB/s]\n"
          ]
        }
      ],
      "source": [
        "def display_data(x: Tensor, nrows: int, title: str):\n",
        "    \"\"\"Displays a batch of data, using plotly.\"\"\"\n",
        "    ncols = x.shape[0] // nrows\n",
        "    # Reshape into the right shape for plotting (make it 2D if image is monochrome)\n",
        "    y = einops.rearrange(x, \"(b1 b2) c h w -> (b1 h) (b2 w) c\", b1=nrows).squeeze()\n",
        "    # Normalize in the 0-1 range, then map to integer type\n",
        "    y = (y - y.min()) / (y.max() - y.min())\n",
        "    y = (y * 255).to(dtype=t.uint8)\n",
        "    # Display data\n",
        "    imshow(\n",
        "        y,\n",
        "        binary_string=(y.ndim == 2),\n",
        "        height=50 * (nrows + 4),\n",
        "        width=50 * (ncols + 5),\n",
        "        title=f\"{title}<br>single input shape = {x[0].shape}\",\n",
        "    )\n",
        "\n",
        "\n",
        "trainset_mnist = get_dataset(\"MNIST\")\n",
        "#trainset_celeb = get_dataset(\"CELEB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E9-Mq-MM6ejt",
        "outputId": "2a7d5171-33e4-4c3b-9ff5-7318bcb3f4a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f4968c37-41bb-41d2-80ec-179c2f95ef34\" class=\"plotly-graph-div\" style=\"height:450px; width:500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f4968c37-41bb-41d2-80ec-179c2f95ef34\")) {                    Plotly.newPlot(                        \"f4968c37-41bb-41d2-80ec-179c2f95ef34\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAAIwAAACMCAAAAACLqx7iAAARE0lEQVR4Xu2ceXBVZZrGH4Y7F0MlVAhJkYJKKsqSIQOSDEIYJRlMgYooKTGhRVIaoS0iFovtgNCAwyoiOCAgq4ALiwEbZRHUJgE1tCBLCB2WsIQGErJQQBbCZXLe973zx13Pd74TFMu2uyq\\u002fv873PLn3vvc73\\u002fp+5wZopplfj17reX2SKv5qtIyIiJj+9ucdNrldb6oekHiDiK6rajBplfGq5GUqu1NVrQliO7+wegszM1\\u002f6jOu+76\\u002f66HOF6WYV9XUGpJRnAtcA8MYum2Cybxmcoor2JN1gL0bW0KHJljcN6XeRmH7MIJ4SEKd\\u002fErgG0GJVkeV1Ht40tMEkLytinjBsWbKiR5xjZuYDu121iuPhEyJiouw83hwQz5uD6Sgfm8p+BlwzTsS2UlUMqyTOKyLiT1Un\\u002fYMxzEdbI2G16gBArxvM+a9xWc90d9ArS83B7JFpprKPfmWG8YIqwtG3jvIfdYTuJn5d9RDWYjU\\u002fr4peEm8Q7QwdPDkK4Hp\\u002fh3qwwRzMAVHr28Ma5jxVA7KJ9oQBWUSXolQPwALOb6FqAICuG7nqeIbnmmmjT35DTMG0r5CY4LKPSDaq01QRc5iWhAE4TZSuegDQOp8fUzUAcO6gmsfbdfQUmL736evlDd8lAHwiZ8KDy17ijrIxXRUxnV1fhACthjTwTNXz0Kn20oevWiunL1FgkDAFE\\u002fjCYZk7XDLCXwwix+Cv2qhieCV9AaDzIaLc1qrp5Zka5knRqnqA8wMFNxf4LtdLJoCeSa8vXl5bX72zlnQdO73G+La9KiKKKDZqUkEtk\\u002fG06vnp8Q3zcu8N8fHUbRofKDEt810u5+uFhYUsjTUHFo3o6KhqDPyVnzhmXq+KQHgFMRFdvkIVqhVEeBbxn81SJl31V5ZzHn8T6ncmbd++ffv2kZ4+9LKc9xsBVhiGoauw5GoueSchej8tUh0Td\\u002fhOf5OQSaW+S+dsuvR4sBdErsxXJSDxgmF8pooBUtw8VtUCPDhrD3OhuQ1n0nveq8SN9CeTFUyu9FUloNowCgI1aeFxJt0YAwCIX1bOzI27zWomX\\u002fJcvHaDbcZ7wCYYNozhqhaMbTDRr11gZj40RNEz6c6SxJjMHZe4dLN+iAUA5LqtQ\\u002f56N3OsKgZhVzPt004yMx94xjLOZBJR+WkiKpilWsHkSrYqJZaxa6F1ggzwijaYiK3nmJm\\u002fTw9RHaDjD0RMVOVrOTbkyipV6m+wrocF6OFmSzDJn11mZr41Vz8YRs8gpne7qLJCrvvnB4OzZLnxbzNz8bw54ar+s8i21kz0t3cLJpvyElTtNyPsK9qivx2\\u002fBWFL6R+nappp5u\\u002fDe+4TTc0yv5C8oLVkgNDoUVOCNrB+4q4z2a1kuibkuJmZeZvmlY5U\\u002fzLVnkUuy4AJ3L\\u002fiOBEtUWUArT+3CyZhwcXLxEREROvCVBeRElgn2vG2qy5T1eJX3iK+eIK0uYTFdsHsIM\\u002fOl4iIHlFdRIokqprKfvKsdB1+pc07vwsDzj3W6nRkVIlf9RHeU1V8\\u002fPlJVK9r4cZ\\u002f\\u002fpfqeLGsSfykTBt+A8Dwf7\\u002fw34qTTURUEoMuRP0UC0CHC0xTtS3YERMTDQBhl4k+szaaSNGtAD2c4X4AUOz2plb+xe9kAn\\u002fbOvAK\\u002fs2vBHN1PTBTu8WhK1cqAeCJtkCZbreCXqrg47b7PgCJsXKf6nSY8XAUAIzS1gzARK+qWhDP5RGRtf0i\\u002fKbY7UZmG8VRQOvNVBBoLAprbYJxM9sHM6LYRURHNOtE7LALJqbSlQpgFV32KeaYxrVu4e6Bv\\u002fxgEr2IW1U8xGUNBPq5gbo3drtUswl6bItc+h3w+ouYq1oAQnrvZHYzl3VSHQC2t6lHqa9rb1ctDzu0+SxHNrv54BRn9KHGdaoHOPpcofqyLXVEFROtfQJNBMPM7GZmHqR6AIAdUqNKALKIuITooHaz7RxCNO0RRBwnIhqmi8bNvEXVACD2jw917969+yIifTATdMEMM1wVjybmETEZV9Q74ZhHtCscUYfZNfNPRF+lJVmyz0zU1AqxjV0wz0qDdXzKvzASQEIBMZF6F1u+TbWvtEXvg3TmUYQ98UktBTb7Pt4nosWqGCDTLph0ud1V1TA+BgBSblJmQoI6HuRQ3XMRg7bcoumerNzwXbss26SxumAcg729eWSdXTA4JctVyUObZXxW1QBUUMPRM0Q0taXqBHGW2a3c3pQ9FAMAEVk3ieofNZs+Ftfa7HAnU4U5L+UZZyqjWvXE7m+3\\u002f41NppmTD0AUaWl3TKoHMPA\\u002f3Ni\\u002fYp\\u002fi+nBrJwnEvuxeXa6KAEKzFk1ur+tCwQwiYqVmjpMXvrrK5usDi2WoKgEAztKHqvTTiT1hCSZpLRERlRQu6WE2grnq0q2PgCmkD\\u002fKecY6ups9GN72U+7TI2rWbaaaZe6NrqTd5+w\\u002fA0mr6QtXuSsLEc5sm6ldWv4D2BUzH26mqlqAd1ugFoQAwQLsH1xE67P96hY3YXw6gcvsR1fXSdeGTLSYf0U5bLTY\\u002f2U03OQFARKWIiNzQnsbpeEcCUNGU+1UfANCXiG0y9iFlMkrV\\u002fOTckosi8q6qm4iNn1ld7TlBOi8i1Xl5eXnL846KyGDlLwEAXUuZtWeQAJAvU1QpQKEUicgDqhzEgOU3hZlPAwA6DerUyTsthV4UaxoYAGbTTuUsLYhntRsHLxnHRES6qbKfDw6JSO3ykdbVwvMirt6qCODA7fOWJWOAGHE1McdGF4nIVlX10m61XDv8bLxmCnauvC1iWcEDSGeaZ18xiHHL6OCyaUc54sHuAOwyTdNHLZ16SxUBIC0rG43jT6kyEJ4C3CgHMD4GatIDAOCG3UASf6pRxK7NhMwsHZJuvT0A0McQEdcgzeY9dJ+bk4HXJpQyuzU1FCNidyr4jEtERESXRcNbvFkfCrDQ87Ifp1lWe08Rl3ZB4jaiulP8g\\u002fX+NhEMxt0WsWszblEP6Pw8\\u002fGW1JxxaaD48Ch1LZbPQdSNXbUhK5VOaYNz2wWDQ8OFZNfpgDvHlgarmJzZp0BoWEdlnSpkNIpqO9juoZpmz++ka\\u002f3F4gKZqBgBazJBzlq+Q7ETEDK617\\u002fMARhwUEZkYLE0iAgqIUtGXaGGw4yVGJFXVgnGKnFKaWvTR6iwgkvlhs67g2C8ipodv5vE2JJbzeHQt5aBnBgLEiJg+S+0Dc4C1yuRV2GbSBmAC9v7VrCvQ0VTAnCZ1uwFx97x838WUWpPRNO22e57jia6xdu3JDSJSIqW6UQ2Inp7puWi5V6QxJdjqS9Q3p4aIq2x24TEiajoEADbI6dTO6DX8mMgCSxd+fWNVVfWueO0+PLpI2gAA2s8XkSKT16vOk6zWtV0Atg24b4FI6a5aET75844MPxVJDAFC3qwVcdcpzXFwHhOtHW\\u002fbSJ3F2mCwMMczVlxTjbvwexE5mp9\\u002fVESkLk1178Zh2aFKAADnxIkbRW7qG4Y992\\u002fyfAmRxneSVfOurBHTstI+sf8TcQ5NK0nHGeSXFKrW3Ynb\\u002fNFKVWummWb+WXggt1Gf1vsNeLjuwqK2qvhLyNpworHxO8+caEfrw+VxqgZgsGuR7lDsnon8gq\\u002fv2lUvmu2Ilw49e8a+KKc1z+R1afjqXof5P0z+mPmkqh65Ni8CiK+j6aoDAD1Wf\\u002f11KfPcz917ramPVvsPqicVASJyrnDwQ+nBpI7ZYhARNSo1MND74PgssZy1AMA4Zr79URmzZKkWsMCl2TB56fsDExFZH0SN3n\\u002f5ci3xj0REpGS9BpV4EgkPSoXmW85o4HXzo5BYxVWWdRmcFXtUyU\\u002fkCapcOWgznVa3lQNKiYgovl38oxeJlDdo5W2A8SI5ZgcAFkhpNNB5i9x6RbWAaYFHzi0U0G4AXarr1acJviGihld7A1hOdD5Scb04inXJm+Ri\\u002fqh1hx18bYLqAPj+K1UJsJdGA+hSXa7cyMfqiEofAQDsINJ8oodCXTDONVyWXsrah2lTjG4A+uuPE\\u002fM4s1XCgvwT6rb4a6Lv0gCg7fM13isNztMyQ9UAvMvMwqtjVB3AyiInsq+La4xqAEAlHTxElKHKePZovidtM5moyDaBEy+SDESmTTUP7uOYWXZaDyIBNGbAWZoROuz2E6oD4GQDMdXpaw0AnnaRS9MMAQDOTiNFjq8tvCS1HwbrLbeKyM5gxU+CpCN5BYCl36oWACRncFMHYEz0sqoBIbFD5x8+XCwiYpSWvvmQOa+5lZlZv8pPk24IbQcggVULANCDSVuhAIC33MyW+TVk\\u002fikRkZqyRpHVlo7a4Y\\u002fChz\\u002fgg6oOAEgT7\\u002fwQpg9muJttg3HuYRpjmUi+FtfOJWn9OuKMnLfOPVksk0OzeJ2qAwAGuL0veLrGpPtI57w4VfMS8jLxJ+GqCrdnl+2Yf6vSUi\\u002fof5OfahV3jrWTlr9mHF8uVRwAQLedlda+5CH0U6JxlnoB5JgDQKud4uqvWsBc2QfHq9Wib\\u002fXR5TkA4PjgpG4YbXOJ\\u002fqBqProRmTMaXs7Iuu2zsk\\u002fSD9Z6AeZwviOTr5nyMkGMuZ0TlvRiSZF2slxFG1TJR\\u002fwa0qTdAGC2686dO1t1IwWwinP3Mz+tyn7G3GaumaXOhACAAQ31ton8jUT6um6S8cxybea9rOTirjfYnmsn7KTlll59d9pOrN83QRV\\u002fCiHLKFfV\\u002fMynC\\u002fcQy73zChdobx4AIE3\\u002fa7Bfiz5lM7WNuplm\\u002fqnYVNpkJrCrd82no\\u002f\\u002fP+6XzT6BAzpqT9KHRwSPoeJqm5vB9ZB81+Oh4O7cpJsvbqgQAiLkjYh6+59CEoFIKUeegYhDZeYbBhqGdwGIXN8omVfQTepVdI1URAHqIbDMvFOZQTdCAl6EPJrx\\u002f6S3DOHFSH8zI2iMvTbcuEr04JjJf0i28HRtEvEcPPuYQ3XjIVwg9QKTZiqd\\u002fabBhGC9k64JxTnbNDUcS242pKXZPoS4RSzAjiehLXzYniXTBZHmfbH0xW\\u002feLu9E8FsAbFaruJe4Y8ze6if33DdZgWk4jIt9TCR3Oam5T1jWj\\u002fnyVYdQP1dVMRHWuA4g9bxfMCeabujPFl1xyxBIM2pwhKvSmVpLIGkw6G8ZeZBvGWGiCcZwujgDwvSxQDB\\u002fCPFeRQh8ZueK6yNhO1mCwlogSATjHjv3OGkx2DdfvTUD2kbEOhBZYgnmOUwE8b9S1Vwwv\\u002f+vmb9RcSbczIjdXdXHEaYIZRUQ5ePj1GUREVKzkny4YPBlA5\\u002fYAkG8JZs8pBxBdZfn2Xt4vl8IoVYSze\\u002fdYAHFi\\u002ffUlNjCzt40ys3lISKwO3oHtszRgmQqEFfD7mjwSgD7lrEvqeGl3VbapGpKIiPw\\u002fOVkTbHW\\u002fYBiBkvU2pUkPPH5RzrYxyz5WipzsoIoBCmRcoGAe28+7v6z5H5MCLDF9eIZlXrt2JzcssrHF+3WqAQAYP8qNgVdVNRhrH0wiouojw71XpprJN4wJ\\u002fkJ8tXFObacvfLt5yOU8tYl6iCnmxvdVMZgCTlUlhK3bv8KTQEoiokvB+ez8oP8wEV\\u002fCFWoCDkCL9+70VjUAQOdTzPNV0UeXPn16dMi4kBEV+\\u002fEQ1fOSREQU\\u002fOX3MXsbcOg25nO6+ac\\u002fz1IlD4OZ2ZOcU3F2e\\u002feWiOuaiFTdlHc8omU9UFMZDbw1mvzC7Nxw7HNvL5nU4l+Tb8\\u002f9XLcD3nTV+24qbYH92qx6+8W\\u002fA1DhPlkEAPjY7AZILiei4MPt1GsGG4ZhsLHXf79MPNRo13cvMmeoGgBggojs7G+pCSu9K4P\\u002fKQWAjjPZMAyj\\u002fFN97211rNTmYD6hmqdr0hoA4or2vKRqep4\\u002fNlt59xeLjRMv6G8+kMNq7tTHSBdPUrVfmVOFttV9qVqXRvk1qbyH5EUzP4\\u002f\\u002fB0a7nGAMXcCjAAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"MNIST data\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":450,\"width\":500},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f4968c37-41bb-41d2-80ec-179c2f95ef34');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Display MNIST\n",
        "x = next(iter(DataLoader(trainset_mnist, batch_size=25)))[0]\n",
        "display_data(x, nrows=5, title=\"MNIST data\")\n",
        "\n",
        "# Display CelebA\n",
        "# x = next(iter(DataLoader(trainset_celeb, batch_size=25)))[0]\n",
        "# display_data(x, nrows=5, title=\"CelebA data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R17t8jDX6ejt"
      },
      "source": [
        "### Holdout data\n",
        "\n",
        "Lastly, we'll also get some **holdout data** that we can use during training. The tensor below has shape `(10, 1, 28, 28)`, and contains a single image from each of the 10 MNIST classes. We do this because we want to monitor our autoencoder's reconstructions for each different image type while it trains. We might find that some images are reconstructed better than others!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C2wapBtK6ejt",
        "outputId": "779ab9e0-4c9a-4803-8bf1-d40fdaa1e76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7f9830ff-4129-4b6d-99e6-2a5ac6c01b7f\" class=\"plotly-graph-div\" style=\"height:250px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7f9830ff-4129-4b6d-99e6-2a5ac6c01b7f\")) {                    Plotly.newPlot(                        \"7f9830ff-4129-4b6d-99e6-2a5ac6c01b7f\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAAcCAAAAACfA\\u002f\\u002fyAAAHg0lEQVR4Xu2Ye0xUVwLGPyPBaMAglkA0EDdVzBKpENdCtmqUNHWND2JbTFtJl7Qx9RFfa1RspVGLoqvGrhpbtcq2rmvBRwVcUbegVkirrgEb62PVMSA+wFR5qBjn++7sHzMwc89cqGu2yW7X319zft\\u002fMZOa7Z845d4BnPOP\\u002fgnhXjameAWBDA\\u002feb7mdlSL7yk035X0d0hVjd27Q\\u002fJ0l3Sf5oWj8fyDPCdACAsJh3F4WaEkB8wlSPJGmfU+oj7fZAU6FrZGRkzsqv+vzV0\\u002fqhmcUXU\\u002fNHmfaJ6XH6Rj\\u002fT\\u002fQQvXhfv1TO1oy+Rdd+t4aYE8KtPqkmuNzUSVl+rpUiS3B7erodPDHgOgIUH7MXE9X97S6EkqWaPmk+MtIUAUkm9acono8\\u002fgwXG\\u002fty6Emb5Tug+7RvHU69QiM\\u002fLxodupmIGf3qeufc\\u002fg615Msq0YvtSuc3YEPAfosvms7ZXJd+XDnfnqqylB7xrvktJNGcAfsr+QfjAtkLjl8GGXtPwrz9fBP8OUjWelOZM2ppgBgB3eb5FVpl1m5OXlO+7v47oZsuen90hejBtADjMizCRv5i7PzS2zF3PFXkxf6wvbOPKyJKnyYGuTzbfxEUv6mq6dEdML3ST5+LyZYJakh5\\u002fXSVamGWHSbarsLKkvzQQYclcqn6u6wekehxTAsDq3+21TIoskL8XCqZiQ2NgYAAivJff4f58uezGl1mLbGOmfTZfO9EDCFrv3UvnwygDTeYk5VlvbRJ0iSQbt5kseaPuqKCTVq968uCGpzSwfFRJ2kJpnRN51tyRsbHYUoBbHjWmrVGY64G\\u002fklV1xwHiHYtrIaCE\\u002fbh+98MBeTKVlzt\\u002fwLlv0luHaSBfznCfMyy6S5MDeA0ddI0vNeLXligH6F1r3p5lRFlkaDmSSNVFmFr9T9dWvex+LO+0hAOA5uRvSTAn0WfLbKAB4t+Ni3igj6V97F1q2YqJvWbGBYwDAapV3MR0AIGKNOB8AZq9ZY0RHSD6YMRTAJvLKc0aKlHP6vEefYt2ZYya54vpwABfIoLUrtJiNo3v7roR4wp4CQL8zcueYMoBtHRUz+VwryX90bxf51sKAGDusixGBYwBAj3K9YjoAQNhRj1KAuXNcksc2c15pJl3ehayYXBsYAQBCt6ou3SXNNIMcte7vDnSb8EBLzQyppP+A4ljMVLcO9TSlj1nZi7JP8Zuupu+3+Pjx4yJ5d0rAd8i3\\u002fBMvPKO41Zrsz9p5vqnmzzMcJs04yjUASfvI5vP6Ni4gOUx+kwYAvd5q9D2ys1aSpS3m9Iy4zf0A+p8kC3oYGVCpcv\\u002fAowr\\u002fwEd6o\\u002ft4tCkBAN2Hlkgeqe55M0l0kd7tuihQ51sZAAYnz\\u002ft4U1NLQ0kTgzZkAJjYKC2IMW3YTNYtQ\\u002fxO1f8leYTOBxbz2ply79OzybNBL4R3V7JK4k0dRcZFLahoEt3jzQzjHnK2fyRu9A+89JOUb0oACHnxOlvqCpvJW\\u002fPNc2GiS5I8kjQmQG\\u002fSj1VVVbIeN1aum9w3pP5xQBZA4hFpk7nMjiFzEF3Mxo2hgy40Bn1MABjfytag5RVA192WZZWYFoi4RZGsvc5bZgRk8GZ7x6F5OhJ0MvzE7XY7XdjQCeTilxBZTZKTzGbi3v\\u002fNoEGDBq0jA4vBgqKioqKid7x70RTrSmAWQEQm9XfDLSCBCnIEUklz9fUicorpAGC3JBWbFkBKgy79MSHmGNeZCZBBV9vD0I9YMzowA4Ckq273HlMCCMkjD0Qg6rRal+4lD6UlO230PY1ibBRYq0zVziM9Gmk3edqHpBuajXiXAuZ4ACs8ksMl7PO+pdOf6TvTtzPcE7wsAxn8k+9R0k7utUUAgAa3uyJoFgFdV7JpWi8M\\u002fY4XRyH8dzua6C84gIzOi0k1lZcXlpVKVcb6m8e9SLrO7bUNJ\\u002fs6fCAgtFSc7rBoZ8rKDsvUdtO3M1oMOsMAGfIdFOfelf187kVut9Nd21Q2vxE5pvA+c7xL\\u002fZsHDvgPpSFjfTv0O81PUczAjTckPT5o6FQydWojqXrnd+w+hdoRYVpg5D2N69bvsjo5cDgXw0frk2Izimvk2mUeQwHke6TADaCNW3xw5iLJD4I2amB4KWMBIDLzHtnS8Z8EBZ7g2wzEzL0qSScnmMGQZu9NqfO6i7AvyVkO8wXLraMImdFgOa3KXjqYMSRvXCBZscyMACTVqXWNeX8BAFUkWTyvf4gZAKgmN6xYsWLFaZFfv2amfgqsLFNFp\\u002f0gSZUTHb7i2DKR22Y7\\u002fyuEX5OXTAcAyFV5SIbuON58eZnmWEzfb0mR9W0rjZ2RbjnvHGGZ67Kjza3IRzV96OZmp1LbKLA220Xk7suSdCLdf1Z+UgZupe1o42ezCo5JwecUP4keORSDmCUU13Zw19phMZ2RvI0kealqfaIZ2Sjw2IpJ2VMrSfeXBx9Cf5qdZAe\\u002fldmSdWdpp1X\\u002fkw6LSOfEHH+KYhD6XgP3vOd0BLWRZZ8xKyWdy8uNCHRPSkIJNzns1ADQa37L0TmmtJPFsgTT\\u002fUJYxasd9PIkhB9i4dNM0\\u002f8B0oL\\u002fNfh3CN\\u002fAX+qU+Q\\u002fyL63HCVafPD22AAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"MNIST holdout data\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":250,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7f9830ff-4129-4b6d-99e6-2a5ac6c01b7f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "testset = get_dataset(\"MNIST\", train=False)\n",
        "HOLDOUT_DATA = dict()\n",
        "for data, target in DataLoader(testset, batch_size=1):\n",
        "    if target.item() not in HOLDOUT_DATA:\n",
        "        HOLDOUT_DATA[target.item()] = data.squeeze()\n",
        "        if len(HOLDOUT_DATA) == 10:\n",
        "            break\n",
        "HOLDOUT_DATA = t.stack([HOLDOUT_DATA[i] for i in range(10)]).to(dtype=t.float, device=device).unsqueeze(1)\n",
        "\n",
        "display_data(HOLDOUT_DATA, nrows=1, title=\"MNIST holdout data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uSRF54F6ejt"
      },
      "source": [
        "You might be wondering why we do this, rather than just e.g. generating some random noise and seeing what the decoder's reconstruction is. The answer is that **our autoencoder's latent space might not be meaningful**. In other words, it's unclear exactly how to sample from it to get output which will look like an MNIST image. We'll return to this idea when we study VAEs later in these exercises.\n",
        "\n",
        "*For the rest of this section (not including the bonus), we'll assume we're working with the MNIST dataset rather than Celeb-A.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO-lEUuo6ejt"
      },
      "source": [
        "## Transposed Convolutions\n",
        "\n",
        "**What are transposed convolutions, and why should we care about them?** One high-level intuition goes something like this: most of the generator's architecture is basically the discriminator architecture in reverse. We need something that performs the reverse of a convolution - not literally the inverse operation, but something reverse in spirit, which uses a kernel of weights to project up to some array of larger size.\n",
        "\n",
        "**Importantly, a transposed convolution isn't literally the inverse of a convolution**. A lot of confusion can come from misunderstanding this!\n",
        "\n",
        "You can describe the difference between convolutions and transposed convolutions as follows:\n",
        "\n",
        "* In convolutions, you slide the kernel around inside the input. At each position of the kernel, you take a sumproduct between the kernel and that section of the input to calculate a single element in the output.\n",
        "* In transposed convolutions, you slide the kernel around what will eventually be your output, and at each position you add some multiple of the kernel to your output.\n",
        "\n",
        "Below is an illustration of both for comparison, in the 1D case (where $*$ stands for the 1D convolution operator, and $*^T$ stands for the transposed convolution operator). Note the difference in size between the output in both cases. With standard convolutions, our output is smaller than our input, because we're having to fit the kernel inside the input in order to produce the output. But in our transposed convolutions, the output is actually larger than the input, because we're fitting the kernel inside the output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-1.png\" width=\"700\">\n",
        "\n",
        "We won't actually have you implement the transposed convolution operation in these exercises; instead we've pushed it to the bonus section. For now, you can just use the `ConvTranspose2d` module which has already been imported for you from today's solutions file, in place of your own implementation. You can use it exactly the same way you use normal convolutional layers: for instance `ConvTranspose2d(32, 16, 4, stride=2, padding=1)` will define a convolution layer that maps a tensor from `(batch_size, in_channels=32, height, width)` up to shape `(batch_size, out_channels=16, height * 2, width * 2)`.\n",
        "\n",
        "[These visualisations](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md) (linked in the reading material) may also help build intuition for the transposed convolution module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUP1vgul6ejt"
      },
      "source": [
        "## Autoencoders\n",
        "\n",
        "We'll start by looking at **Autoencoders**, which are much conceptually simpler than VAEs. These are simply systems which learn a compressed representation of the input, and then reconstruct it. There are two parts to this:\n",
        "\n",
        "* The **encoder** learns to compress the output into a latent space which is lower-dimensional than the original image.\n",
        "* The **decoder** learns to uncompress the encoder's output back into a faithful representation of the original image.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/ae-diagram-l.png\" width=\"700\">\n",
        "                \n",
        "Our loss function is simply some metric of the distance between the input and the reconstructed input, e.g. the $l_2$ loss.\n",
        "\n",
        "You'll start by writing your own autoencoder. We've given some guidance on architecture below, although in general because we're working with a fairly simple dataset (MNIST) and a fairly robust architecture (at least compared to GANs in the next section!), you model is still likely to work well even if it deviates slightly from the specification we'll give below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XqOy_wz6ejt"
      },
      "source": [
        "### Exercise - implement autoencoder\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 15-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "*Note - for the rest of this section (not including the bonus), we'll assume we're working with the MNIST dataset rather than Celeb-A.*\n",
        "\n",
        "Your encoder should consist of two convolutional blocks (i.e. convolution plus ReLU), followed by two fully connected linear layers with a ReLU in between them. Both convolutions will have kernel size 4, stride 2, padding 1 (recall this halves the size of the image). We'll have 16 and 32 output channels respectively.\n",
        "\n",
        "The decoder will be the exact mirror image of the encoder (with convolutions replaced by transposed convolutions).\n",
        "\n",
        "The only free parameters in your implementation will be `latent_dim_size` and `hidden_dim_size`. The former determines the size of the latent space (otherwise called the bottleneck dimension) between the encoder and decoder, and the latter determines the size of the final linear layer we insert just before the end / just after the start of the encoder / decoder's architecture respectively.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/ae-help-10.png\" width=\"1100\">\n",
        "\n",
        "A few extra notes:\n",
        "\n",
        "* You'll need to reshape between the convolutional blocks and linear layers. For this, you might find the `einops` library helpful - they have a function `einops.layers.torch.Rearrange` (imported for you as `Rearrange`) which works like the standard einops function, except that it takes a string and returns a module which performs the corresponding rearrangement. Just like any other module, it can be used inside things like `Sequential` (this way, the logic inside the `forward` method can be very simple!).\n",
        "\n",
        "```python\n",
        ">>> x = t.randn(100, 3, 4, 5)\n",
        ">>> x.shape\n",
        "torch.Size([100, 3, 4, 5])\n",
        "\n",
        ">>> module = Rearrange(\"b c h w -> b (c h w)\")\n",
        ">>> module(x).shape\n",
        "torch.Size([100, 60])\n",
        "```\n",
        "\n",
        "* Note that we don't include a ReLU in the very last layer of the decoder or generator, we only include them ***between successive convolutions or linear layers*** - can you see why it wouldn't make sense to put ReLUs at the end?\n",
        "* The convolutions don't have biases, although we have included biases in the linear layers (this will be important if you want your parameter count to match the solution, but not really that important for good performance).\n",
        "\n",
        "Now, implement your autoencoder below. We recommend you define `encoder` and `decoder` to help make your code run with the functions we've written for you later.\n",
        "\n",
        "<!-- You can test your answer by comparing the architecture to the solution directly. As this course goes on, we won't always include test functions as the exercises get a bit more open-ended and solutions to them are likely to vary more; it's also good practice to find ways to test your answers when you don't have access to black-box tests that you can trust!\n",
        "\n",
        "from part5_vaes_and_gans.solutions import Autoencoder as SolutionAutoencoder\n",
        "\n",
        "soln_Autoencoder = SolutionAutoencoder(latent_dim_size=5, hidden_dim_size=128)\n",
        "my_Autoencoder = Autoencoder(latent_dim_size=5, hidden_dim_size=128)\n",
        "\n",
        "print_param_count(my_Autoencoder, soln_Autoencoder)\n",
        "# print_param_count(my_Autoencoder, soln_Autoencoder, filename=str(section_dir / \"0503.html\"))\n",
        "\n",
        "<iframe src=\"https://info-arena.github.io/ARENA_img/misc/media-05/0503.html\" width=\"920\" height=\"470\"></iframe> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EM5-QkRe6eju",
        "outputId": "9c29e5eb-f7ac-4a9b-c52d-1529c434f649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([1, 5])\n",
            "All tests in `test_autoencoder` passed!\n"
          ]
        }
      ],
      "source": [
        "# Importing all modules you'll need, from previous solutions (you're encouraged to substitute your own implementations instead, if you want to!)\n",
        "from part2_cnns.solutions import BatchNorm2d, Conv2d, Linear, ReLU, Sequential\n",
        "\n",
        "from part5_vaes_and_gans.solutions import ConvTranspose2d\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim_size: int, hidden_dim_size: int):\n",
        "        \"\"\"Creates the encoder & decoder modules.\"\"\"\n",
        "        super().__init__()\n",
        "        self.latent = latent_dim_size\n",
        "        self.hidden = 5\n",
        "        c2l = Rearrange('b c h w -> b (c h w)')\n",
        "        l2c = Rearrange('b (c h w)-> b c h w', c = 32, h=7, w=7)\n",
        "        self.encoder = Sequential(\n",
        "            #convolutional block\n",
        "            Conv2d(in_channels=1, out_channels=16,kernel_size=4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            #BatchNorm2d(num_features=16),\n",
        "            Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            #BatchNorm2d(num_features=32),\n",
        "            c2l,\n",
        "            Linear(in_features=32*7*7, out_features=self.latent),\n",
        "            ReLU(),\n",
        "            Linear(in_features=self.latent, out_features=self.hidden)\n",
        "\n",
        "        )\n",
        "        self.decoder = Sequential(\n",
        "            Linear(self.hidden, self.latent),\n",
        "            ReLU(),\n",
        "            Linear(self.latent, 32*7*7),\n",
        "            ReLU(),\n",
        "            l2c,\n",
        "            ConvTranspose2d(32, 16, 4, 2, 1),\n",
        "            #BatchNorm2d(16),\n",
        "            ReLU(),\n",
        "            ConvTranspose2d(16, 1, 4, 2, 1)\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Returns the reconstruction of the input, after mapping through encoder & decoder.\"\"\"\n",
        "        print(self.hidden)\n",
        "        z = self.encoder(x)\n",
        "        print(z.shape)\n",
        "        x_prime = self.decoder(z)\n",
        "        return x_prime\n",
        "\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_autoencoder(Autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uaj-eZQP6eju"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim_size: int, hidden_dim_size: int):\n",
        "        \"\"\"Creates the encoder & decoder modules.\"\"\"\n",
        "        super().__init__()\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.hidden_dim_size = hidden_dim_size\n",
        "        self.encoder = Sequential(\n",
        "            Conv2d(1, 16, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            Conv2d(16, 32, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            Rearrange(\"b c h w -> b (c h w)\"),\n",
        "            Linear(7 * 7 * 32, hidden_dim_size),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim_size, latent_dim_size),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            Linear(latent_dim_size, hidden_dim_size),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim_size, 7 * 7 * 32),\n",
        "            ReLU(),\n",
        "            Rearrange(\"b (c h w) -> b c h w\", c=32, h=7, w=7),\n",
        "            ConvTranspose2d(32, 16, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            ConvTranspose2d(16, 1, 4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Returns the reconstruction of the input, after mapping through encoder & decoder.\"\"\"\n",
        "        z = self.encoder(x)\n",
        "        x_prime = self.decoder(z)\n",
        "        return x_prime\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRRoq3fq6eju"
      },
      "source": [
        "## Training your Autoencoder\n",
        "\n",
        "Once you've got the architecture right, you should write a training loop which works with [MSE loss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html) between the original and reconstructed data. The standard Adam optimiser with default parameters should suffice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HKTm8Ac6eju"
      },
      "source": [
        "### Logging images to `wandb`\n",
        "\n",
        "Weights and biases provides a nice feature allowing you to log images! This requires you to use the function `wandb.Image`. The first argument is `data_or_path`, which can be any of the following:\n",
        "\n",
        "* A numpy array in shape `(height, width)` or `(height, width, 1)` -> interpreted as monochrome image\n",
        "* A numpy array in shape `(height, width, 3)` -> interpreted as RGB image\n",
        "* A PIL image (can be RGB or monochrome)\n",
        "\n",
        "When it comes to logging, you can log a list of images rather than a single image. Example code, and the output it produces from my GAN (you'll create output like this in the next section!):\n",
        "\n",
        "```python\n",
        "# arr is a numpy array of shape (8, 28, 28, 3), i.e. it's an array of 8 RGB images\n",
        "images = [wandb.Image(a) for a in arr]\n",
        "wandb.log({\"images\": images}, step=self.step)\n",
        "```\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/gan_output_2.png\" width=\"750\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jrt_AOC6eju"
      },
      "source": [
        "### Exercise - write autoencoder training loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 20-35 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should now implement your training loop below. We've filled in some methods for you (and have given you a dataclass to hold arguments), your job is to complete `training_step` and `train`. The former should perform a single training step by optimizing against the reconstruction loss between the image and target (you might find `nn.MSELoss` suitable for this). The latter should be structured like training code you might have seen before, in other words:\n",
        "\n",
        "- Iterate over `self.args.epochs` epochs\n",
        "- For each epoch, you should:\n",
        "    - Iterate over the training data and perform a training step for each batch. We also recommend using & updating a progress bar, and logging to wandb if this is enabled in your training arguments.\n",
        "    - Evaluate the model on the holdout data via `self.log_samples()`, every `args.log_every_n_steps` total steps.\n",
        "\n",
        "Some last tips before we get started:\n",
        "\n",
        "- Don't use wandb until you've ironed out the bugs in your code, and loss seems to be going down based on the in-notebook logging. This is why we've given you the `use_wandb` argument in your dataclass.\n",
        "- Remember to increment `self.step` as you train (this is necessary if you're passing this argument to `wandb.log`). Note we're using `step` here rather than `examples_seen` like in earlier exercises, because it'll prove more useful for our purposes.\n",
        "- Your wandb logging should take place in `training_step` not `train` (this is better practice in general because often there will be variables only defined in the scope of `training_step` that you might want to log - even though that's not the case here, it will be later).\n",
        "- Iterating through `self.trainloader` will give you tuples of `(img, label)`, but you don't need to use the labels - all you need is the image.\n",
        "\n",
        "If you find yourself disconnecting from runtime when you run the training code, then visit https://wandb.ai/authorize and get a `<LOGIN-KEY>` to use in this code: `wandb.login(key=<LOGIN-KEY>)`. If this fails (i.e. you're still getting disconnected), then we recommend either using VSCode instead or some other IDE, or just setting `wandb=False` and displaying / saving your logged output inline. You can take `imshow` and turn it into saved output via code like `imshow(..., return_fig=True).write_html(\"filename.html\")`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "10 % 6"
      ],
      "metadata": {
        "id": "bdaPpMYJDLha",
        "outputId": "f3d0b8a5-b872-4013-e8dd-e546c6117cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RlFjNOrA6eju",
        "outputId": "47da2238-bbb7-4fc3-e467-22d0f3ab402f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=00, loss=1.0293, step=00512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=00, loss=1.0293, step=00512:   1%|          | 1/118 [00:00<00:14,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=1.0026, step=01024:   1%|          | 1/118 [00:00<00:14,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=1.0026, step=01024:   2%|1         | 2/118 [00:00<00:13,  8.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.9671, step=01536:   2%|1         | 2/118 [00:00<00:13,  8.37it/s]\u001b[A\n",
            "epoch=00, loss=0.9671, step=01536:   3%|2         | 3/118 [00:00<00:13,  8.25it/s]\u001b[A\n",
            "epoch=00, loss=0.9917, step=02048:   3%|2         | 3/118 [00:00<00:13,  8.25it/s]\u001b[A\n",
            "epoch=00, loss=0.9917, step=02048:   3%|3         | 4/118 [00:00<00:13,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.9931, step=02560:   3%|3         | 4/118 [00:00<00:13,  8.16it/s]\u001b[A\n",
            "epoch=00, loss=0.9931, step=02560:   4%|4         | 5/118 [00:00<00:13,  8.20it/s]\u001b[A\n",
            "epoch=00, loss=0.9754, step=03072:   4%|4         | 5/118 [00:00<00:13,  8.20it/s]\u001b[A\n",
            "epoch=00, loss=0.9754, step=03072:   5%|5         | 6/118 [00:00<00:13,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.9730, step=03584:   5%|5         | 6/118 [00:00<00:13,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.9730, step=03584:   6%|5         | 7/118 [00:00<00:13,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.9753, step=04096:   6%|5         | 7/118 [00:00<00:13,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.9753, step=04096:   7%|6         | 8/118 [00:00<00:13,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.9831, step=04608:   7%|6         | 8/118 [00:01<00:13,  8.23it/s]\u001b[A\n",
            "epoch=00, loss=0.9831, step=04608:   8%|7         | 9/118 [00:01<00:13,  8.27it/s]\u001b[A\n",
            "epoch=00, loss=0.9794, step=05120:   8%|7         | 9/118 [00:01<00:13,  8.27it/s]\u001b[A\n",
            "epoch=00, loss=0.9794, step=05120:   8%|8         | 10/118 [00:01<00:13,  8.31it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.9511, step=05632:   8%|8         | 10/118 [00:01<00:13,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.9511, step=05632:   9%|9         | 11/118 [00:01<00:12,  8.28it/s]\u001b[A\n",
            "epoch=00, loss=0.9588, step=06144:   9%|9         | 11/118 [00:01<00:12,  8.28it/s]\u001b[A\n",
            "epoch=00, loss=0.9588, step=06144:  10%|#         | 12/118 [00:01<00:12,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.9711, step=06656:  10%|#         | 12/118 [00:01<00:12,  8.28it/s]\u001b[A\n",
            "epoch=00, loss=0.9711, step=06656:  11%|#1        | 13/118 [00:01<00:12,  8.21it/s]\u001b[A\n",
            "epoch=00, loss=0.9576, step=07168:  11%|#1        | 13/118 [00:01<00:12,  8.21it/s]\u001b[A\n",
            "epoch=00, loss=0.9576, step=07168:  12%|#1        | 14/118 [00:01<00:12,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.9507, step=07680:  12%|#1        | 14/118 [00:01<00:12,  8.25it/s]\u001b[A\n",
            "epoch=00, loss=0.9507, step=07680:  13%|#2        | 15/118 [00:01<00:12,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.9315, step=08192:  13%|#2        | 15/118 [00:01<00:12,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.9315, step=08192:  14%|#3        | 16/118 [00:01<00:12,  8.34it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.9101, step=08704:  14%|#3        | 16/118 [00:02<00:12,  8.34it/s]\u001b[A\n",
            "epoch=00, loss=0.9101, step=08704:  14%|#4        | 17/118 [00:02<00:12,  8.33it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=00, loss=0.9237, step=09216:  14%|#4        | 17/118 [00:02<00:12,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.9237, step=09216:  15%|#5        | 18/118 [00:02<00:14,  7.10it/s]\u001b[A\n",
            "epoch=00, loss=0.9077, step=09728:  15%|#5        | 18/118 [00:02<00:14,  7.10it/s]\u001b[A\n",
            "epoch=00, loss=0.9077, step=09728:  16%|#6        | 19/118 [00:02<00:13,  7.42it/s]\u001b[A\n",
            "epoch=00, loss=0.8825, step=10240:  16%|#6        | 19/118 [00:02<00:13,  7.42it/s]\u001b[A\n",
            "epoch=00, loss=0.8825, step=10240:  17%|#6        | 20/118 [00:02<00:12,  7.58it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.8628, step=10752:  17%|#6        | 20/118 [00:02<00:12,  7.58it/s]\u001b[A\n",
            "epoch=00, loss=0.8628, step=10752:  18%|#7        | 21/118 [00:02<00:12,  7.79it/s]\u001b[A\n",
            "epoch=00, loss=0.8628, step=11264:  18%|#7        | 21/118 [00:02<00:12,  7.79it/s]\u001b[A\n",
            "epoch=00, loss=0.8628, step=11264:  19%|#8        | 22/118 [00:02<00:12,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.8439, step=11776:  19%|#8        | 22/118 [00:02<00:12,  7.95it/s]\u001b[A\n",
            "epoch=00, loss=0.8439, step=11776:  19%|#9        | 23/118 [00:02<00:11,  8.07it/s]\u001b[A\n",
            "epoch=00, loss=0.8311, step=12288:  19%|#9        | 23/118 [00:02<00:11,  8.07it/s]\u001b[A\n",
            "epoch=00, loss=0.8311, step=12288:  20%|##        | 24/118 [00:02<00:11,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.8290, step=12800:  20%|##        | 24/118 [00:03<00:11,  8.18it/s]\u001b[A\n",
            "epoch=00, loss=0.8290, step=12800:  21%|##1       | 25/118 [00:03<00:11,  8.15it/s]\u001b[A\n",
            "epoch=00, loss=0.8237, step=13312:  21%|##1       | 25/118 [00:03<00:11,  8.15it/s]\u001b[A\n",
            "epoch=00, loss=0.8237, step=13312:  22%|##2       | 26/118 [00:03<00:11,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7971, step=13824:  22%|##2       | 26/118 [00:03<00:11,  8.16it/s]\u001b[A\n",
            "epoch=00, loss=0.7971, step=13824:  23%|##2       | 27/118 [00:03<00:11,  8.07it/s]\u001b[A\n",
            "epoch=00, loss=0.8003, step=14336:  23%|##2       | 27/118 [00:03<00:11,  8.07it/s]\u001b[A\n",
            "epoch=00, loss=0.8003, step=14336:  24%|##3       | 28/118 [00:03<00:11,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7894, step=14848:  24%|##3       | 28/118 [00:03<00:11,  8.05it/s]\u001b[A\n",
            "epoch=00, loss=0.7894, step=14848:  25%|##4       | 29/118 [00:03<00:10,  8.12it/s]\u001b[A\n",
            "epoch=00, loss=0.7826, step=15360:  25%|##4       | 29/118 [00:03<00:10,  8.12it/s]\u001b[A\n",
            "epoch=00, loss=0.7826, step=15360:  25%|##5       | 30/118 [00:03<00:10,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7667, step=15872:  25%|##5       | 30/118 [00:03<00:10,  8.26it/s]\u001b[A\n",
            "epoch=00, loss=0.7667, step=15872:  26%|##6       | 31/118 [00:03<00:10,  8.32it/s]\u001b[A\n",
            "epoch=00, loss=0.7707, step=16384:  26%|##6       | 31/118 [00:03<00:10,  8.32it/s]\u001b[A\n",
            "epoch=00, loss=0.7707, step=16384:  27%|##7       | 32/118 [00:03<00:10,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7519, step=16896:  27%|##7       | 32/118 [00:04<00:10,  8.36it/s]\u001b[A\n",
            "epoch=00, loss=0.7519, step=16896:  28%|##7       | 33/118 [00:04<00:10,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.7316, step=17408:  28%|##7       | 33/118 [00:04<00:10,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.7316, step=17408:  29%|##8       | 34/118 [00:04<00:10,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7508, step=17920:  29%|##8       | 34/118 [00:04<00:10,  8.17it/s]\u001b[A\n",
            "epoch=00, loss=0.7508, step=17920:  30%|##9       | 35/118 [00:04<00:10,  8.18it/s]\u001b[A\n",
            "epoch=00, loss=0.7340, step=18432:  30%|##9       | 35/118 [00:04<00:10,  8.18it/s]\u001b[A\n",
            "epoch=00, loss=0.7340, step=18432:  31%|###       | 36/118 [00:04<00:09,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7307, step=18944:  31%|###       | 36/118 [00:04<00:09,  8.21it/s]\u001b[A\n",
            "epoch=00, loss=0.7307, step=18944:  31%|###1      | 37/118 [00:04<00:09,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.7452, step=19456:  31%|###1      | 37/118 [00:04<00:09,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.7452, step=19456:  32%|###2      | 38/118 [00:04<00:09,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7380, step=19968:  32%|###2      | 38/118 [00:04<00:09,  8.25it/s]\u001b[A\n",
            "epoch=00, loss=0.7380, step=19968:  33%|###3      | 39/118 [00:04<00:09,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.7365, step=20480:  33%|###3      | 39/118 [00:04<00:09,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.7365, step=20480:  34%|###3      | 40/118 [00:04<00:09,  8.31it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7225, step=20992:  34%|###3      | 40/118 [00:05<00:09,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.7225, step=20992:  35%|###4      | 41/118 [00:05<00:09,  8.30it/s]\u001b[A\n",
            "epoch=00, loss=0.7226, step=21504:  35%|###4      | 41/118 [00:05<00:09,  8.30it/s]\u001b[A\n",
            "epoch=00, loss=0.7226, step=21504:  36%|###5      | 42/118 [00:05<00:09,  8.38it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7183, step=22016:  36%|###5      | 42/118 [00:05<00:09,  8.38it/s]\u001b[A\n",
            "epoch=00, loss=0.7183, step=22016:  36%|###6      | 43/118 [00:05<00:08,  8.43it/s]\u001b[A\n",
            "epoch=00, loss=0.7243, step=22528:  36%|###6      | 43/118 [00:05<00:08,  8.43it/s]\u001b[A\n",
            "epoch=00, loss=0.7243, step=22528:  37%|###7      | 44/118 [00:05<00:09,  7.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7082, step=23040:  37%|###7      | 44/118 [00:05<00:09,  7.86it/s]\u001b[A\n",
            "epoch=00, loss=0.7082, step=23040:  38%|###8      | 45/118 [00:05<00:09,  7.97it/s]\u001b[A\n",
            "epoch=00, loss=0.7230, step=23552:  38%|###8      | 45/118 [00:05<00:09,  7.97it/s]\u001b[A\n",
            "epoch=00, loss=0.7230, step=23552:  39%|###8      | 46/118 [00:05<00:08,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7103, step=24064:  39%|###8      | 46/118 [00:05<00:08,  8.13it/s]\u001b[A\n",
            "epoch=00, loss=0.7103, step=24064:  40%|###9      | 47/118 [00:05<00:08,  8.22it/s]\u001b[A\n",
            "epoch=00, loss=0.7160, step=24576:  40%|###9      | 47/118 [00:05<00:08,  8.22it/s]\u001b[A\n",
            "epoch=00, loss=0.7160, step=24576:  41%|####      | 48/118 [00:05<00:08,  8.33it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6985, step=25088:  41%|####      | 48/118 [00:06<00:08,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.6985, step=25088:  42%|####1     | 49/118 [00:06<00:08,  8.39it/s]\u001b[A\n",
            "epoch=00, loss=0.7115, step=25600:  42%|####1     | 49/118 [00:06<00:08,  8.39it/s]\u001b[A\n",
            "epoch=00, loss=0.7115, step=25600:  42%|####2     | 50/118 [00:06<00:08,  8.42it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7001, step=26112:  42%|####2     | 50/118 [00:06<00:08,  8.42it/s]\u001b[A\n",
            "epoch=00, loss=0.7001, step=26112:  43%|####3     | 51/118 [00:06<00:07,  8.44it/s]\u001b[A\n",
            "epoch=00, loss=0.7032, step=26624:  43%|####3     | 51/118 [00:06<00:07,  8.44it/s]\u001b[A\n",
            "epoch=00, loss=0.7032, step=26624:  44%|####4     | 52/118 [00:06<00:08,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6998, step=27136:  44%|####4     | 52/118 [00:06<00:08,  8.12it/s]\u001b[A\n",
            "epoch=00, loss=0.6998, step=27136:  45%|####4     | 53/118 [00:06<00:07,  8.18it/s]\u001b[A\n",
            "epoch=00, loss=0.6950, step=27648:  45%|####4     | 53/118 [00:06<00:07,  8.18it/s]\u001b[A\n",
            "epoch=00, loss=0.6950, step=27648:  46%|####5     | 54/118 [00:06<00:07,  8.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.7094, step=28160:  46%|####5     | 54/118 [00:06<00:07,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.7094, step=28160:  47%|####6     | 55/118 [00:06<00:07,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6988, step=28672:  47%|####6     | 55/118 [00:06<00:07,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6988, step=28672:  47%|####7     | 56/118 [00:06<00:07,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6950, step=29184:  47%|####7     | 56/118 [00:06<00:07,  8.36it/s]\u001b[A\n",
            "epoch=00, loss=0.6950, step=29184:  48%|####8     | 57/118 [00:06<00:07,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.7008, step=29696:  48%|####8     | 57/118 [00:07<00:07,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.7008, step=29696:  49%|####9     | 58/118 [00:07<00:07,  8.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6918, step=30208:  49%|####9     | 58/118 [00:07<00:07,  8.37it/s]\u001b[A\n",
            "epoch=00, loss=0.6918, step=30208:  50%|#####     | 59/118 [00:07<00:07,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.6964, step=30720:  50%|#####     | 59/118 [00:07<00:07,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.6964, step=30720:  51%|#####     | 60/118 [00:07<00:07,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6937, step=31232:  51%|#####     | 60/118 [00:07<00:07,  8.19it/s]\u001b[A\n",
            "epoch=00, loss=0.6937, step=31232:  52%|#####1    | 61/118 [00:07<00:06,  8.22it/s]\u001b[A\n",
            "epoch=00, loss=0.6973, step=31744:  52%|#####1    | 61/118 [00:07<00:06,  8.22it/s]\u001b[A\n",
            "epoch=00, loss=0.6973, step=31744:  53%|#####2    | 62/118 [00:07<00:06,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6959, step=32256:  53%|#####2    | 62/118 [00:07<00:06,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.6959, step=32256:  53%|#####3    | 63/118 [00:07<00:06,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6755, step=32768:  53%|#####3    | 63/118 [00:07<00:06,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6755, step=32768:  54%|#####4    | 64/118 [00:07<00:06,  8.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6759, step=33280:  54%|#####4    | 64/118 [00:07<00:06,  8.37it/s]\u001b[A\n",
            "epoch=00, loss=0.6759, step=33280:  55%|#####5    | 65/118 [00:07<00:06,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.6895, step=33792:  55%|#####5    | 65/118 [00:08<00:06,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.6895, step=33792:  56%|#####5    | 66/118 [00:08<00:06,  8.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6970, step=34304:  56%|#####5    | 66/118 [00:08<00:06,  8.37it/s]\u001b[A\n",
            "epoch=00, loss=0.6970, step=34304:  57%|#####6    | 67/118 [00:08<00:06,  8.36it/s]\u001b[A\n",
            "epoch=00, loss=0.6795, step=34816:  57%|#####6    | 67/118 [00:08<00:06,  8.36it/s]\u001b[A\n",
            "epoch=00, loss=0.6795, step=34816:  58%|#####7    | 68/118 [00:08<00:05,  8.40it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6804, step=35328:  58%|#####7    | 68/118 [00:08<00:05,  8.40it/s]\u001b[A\n",
            "epoch=00, loss=0.6804, step=35328:  58%|#####8    | 69/118 [00:08<00:05,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6513, step=35840:  58%|#####8    | 69/118 [00:08<00:05,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6513, step=35840:  59%|#####9    | 70/118 [00:08<00:05,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6789, step=36352:  59%|#####9    | 70/118 [00:08<00:05,  8.26it/s]\u001b[A\n",
            "epoch=00, loss=0.6789, step=36352:  60%|######    | 71/118 [00:08<00:05,  8.21it/s]\u001b[A\n",
            "epoch=00, loss=0.6915, step=36864:  60%|######    | 71/118 [00:08<00:05,  8.21it/s]\u001b[A\n",
            "epoch=00, loss=0.6915, step=36864:  61%|######1   | 72/118 [00:08<00:05,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6823, step=37376:  61%|######1   | 72/118 [00:08<00:05,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.6823, step=37376:  62%|######1   | 73/118 [00:08<00:05,  8.26it/s]\u001b[A\n",
            "epoch=00, loss=0.6836, step=37888:  62%|######1   | 73/118 [00:09<00:05,  8.26it/s]\u001b[A\n",
            "epoch=00, loss=0.6836, step=37888:  63%|######2   | 74/118 [00:09<00:05,  8.31it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6724, step=38400:  63%|######2   | 74/118 [00:09<00:05,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6724, step=38400:  64%|######3   | 75/118 [00:09<00:05,  8.28it/s]\u001b[A\n",
            "epoch=00, loss=0.6719, step=38912:  64%|######3   | 75/118 [00:09<00:05,  8.28it/s]\u001b[A\n",
            "epoch=00, loss=0.6719, step=38912:  64%|######4   | 76/118 [00:09<00:05,  8.31it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6815, step=39424:  64%|######4   | 76/118 [00:09<00:05,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6815, step=39424:  65%|######5   | 77/118 [00:09<00:04,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6760, step=39936:  65%|######5   | 77/118 [00:09<00:04,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6760, step=39936:  66%|######6   | 78/118 [00:09<00:04,  8.34it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6555, step=40448:  66%|######6   | 78/118 [00:09<00:04,  8.34it/s]\u001b[A\n",
            "epoch=00, loss=0.6555, step=40448:  67%|######6   | 79/118 [00:09<00:04,  8.34it/s]\u001b[A\n",
            "epoch=00, loss=0.6713, step=40960:  67%|######6   | 79/118 [00:09<00:04,  8.34it/s]\u001b[A\n",
            "epoch=00, loss=0.6713, step=40960:  68%|######7   | 80/118 [00:09<00:04,  8.31it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6708, step=41472:  68%|######7   | 80/118 [00:09<00:04,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6708, step=41472:  69%|######8   | 81/118 [00:09<00:04,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6738, step=41984:  69%|######8   | 81/118 [00:09<00:04,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6738, step=41984:  69%|######9   | 82/118 [00:09<00:04,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6795, step=42496:  69%|######9   | 82/118 [00:10<00:04,  8.28it/s]\u001b[A\n",
            "epoch=00, loss=0.6795, step=42496:  70%|#######   | 83/118 [00:10<00:04,  8.32it/s]\u001b[A\n",
            "epoch=00, loss=0.6455, step=43008:  70%|#######   | 83/118 [00:10<00:04,  8.32it/s]\u001b[A\n",
            "epoch=00, loss=0.6455, step=43008:  71%|#######1  | 84/118 [00:10<00:04,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6495, step=43520:  71%|#######1  | 84/118 [00:10<00:04,  8.36it/s]\u001b[A\n",
            "epoch=00, loss=0.6495, step=43520:  72%|#######2  | 85/118 [00:10<00:03,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6724, step=44032:  72%|#######2  | 85/118 [00:10<00:03,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6724, step=44032:  73%|#######2  | 86/118 [00:10<00:03,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6660, step=44544:  73%|#######2  | 86/118 [00:10<00:03,  8.23it/s]\u001b[A\n",
            "epoch=00, loss=0.6660, step=44544:  74%|#######3  | 87/118 [00:10<00:03,  8.21it/s]\u001b[A\n",
            "epoch=00, loss=0.6751, step=45056:  74%|#######3  | 87/118 [00:10<00:03,  8.21it/s]\u001b[A\n",
            "epoch=00, loss=0.6751, step=45056:  75%|#######4  | 88/118 [00:10<00:03,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6662, step=45568:  75%|#######4  | 88/118 [00:10<00:03,  8.27it/s]\u001b[A\n",
            "epoch=00, loss=0.6662, step=45568:  75%|#######5  | 89/118 [00:10<00:03,  8.35it/s]\u001b[A\n",
            "epoch=00, loss=0.6633, step=46080:  75%|#######5  | 89/118 [00:10<00:03,  8.35it/s]\u001b[A\n",
            "epoch=00, loss=0.6633, step=46080:  76%|#######6  | 90/118 [00:10<00:03,  8.35it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6656, step=46592:  76%|#######6  | 90/118 [00:11<00:03,  8.35it/s]\u001b[A\n",
            "epoch=00, loss=0.6656, step=46592:  77%|#######7  | 91/118 [00:11<00:03,  8.40it/s]\u001b[A\n",
            "epoch=00, loss=0.6574, step=47104:  77%|#######7  | 91/118 [00:11<00:03,  8.40it/s]\u001b[A\n",
            "epoch=00, loss=0.6574, step=47104:  78%|#######7  | 92/118 [00:11<00:03,  8.42it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6685, step=47616:  78%|#######7  | 92/118 [00:11<00:03,  8.42it/s]\u001b[A\n",
            "epoch=00, loss=0.6685, step=47616:  79%|#######8  | 93/118 [00:11<00:02,  8.39it/s]\u001b[A\n",
            "epoch=00, loss=0.6544, step=48128:  79%|#######8  | 93/118 [00:11<00:02,  8.39it/s]\u001b[A\n",
            "epoch=00, loss=0.6544, step=48128:  80%|#######9  | 94/118 [00:11<00:02,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6489, step=48640:  80%|#######9  | 94/118 [00:11<00:02,  8.36it/s]\u001b[A\n",
            "epoch=00, loss=0.6489, step=48640:  81%|########  | 95/118 [00:11<00:02,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6506, step=49152:  81%|########  | 95/118 [00:11<00:02,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6506, step=49152:  81%|########1 | 96/118 [00:11<00:02,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6536, step=49664:  81%|########1 | 96/118 [00:11<00:02,  8.27it/s]\u001b[A\n",
            "epoch=00, loss=0.6536, step=49664:  82%|########2 | 97/118 [00:11<00:02,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6577, step=50176:  82%|########2 | 97/118 [00:11<00:02,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6577, step=50176:  83%|########3 | 98/118 [00:11<00:02,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6518, step=50688:  83%|########3 | 98/118 [00:12<00:02,  8.36it/s]\u001b[A\n",
            "epoch=00, loss=0.6518, step=50688:  84%|########3 | 99/118 [00:12<00:02,  8.35it/s]\u001b[A\n",
            "epoch=00, loss=0.6419, step=51200:  84%|########3 | 99/118 [00:12<00:02,  8.35it/s]\u001b[A\n",
            "epoch=00, loss=0.6419, step=51200:  85%|########4 | 100/118 [00:12<00:02,  8.38it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6635, step=51712:  85%|########4 | 100/118 [00:12<00:02,  8.38it/s]\u001b[A\n",
            "epoch=00, loss=0.6635, step=51712:  86%|########5 | 101/118 [00:12<00:02,  8.41it/s]\u001b[A\n",
            "epoch=00, loss=0.6555, step=52224:  86%|########5 | 101/118 [00:12<00:02,  8.41it/s]\u001b[A\n",
            "epoch=00, loss=0.6555, step=52224:  86%|########6 | 102/118 [00:12<00:01,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6752, step=52736:  86%|########6 | 102/118 [00:12<00:01,  8.19it/s]\u001b[A\n",
            "epoch=00, loss=0.6752, step=52736:  87%|########7 | 103/118 [00:12<00:01,  8.20it/s]\u001b[A\n",
            "epoch=00, loss=0.6755, step=53248:  87%|########7 | 103/118 [00:12<00:01,  8.20it/s]\u001b[A\n",
            "epoch=00, loss=0.6755, step=53248:  88%|########8 | 104/118 [00:12<00:01,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6669, step=53760:  88%|########8 | 104/118 [00:12<00:01,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.6669, step=53760:  89%|########8 | 105/118 [00:12<00:01,  8.27it/s]\u001b[A\n",
            "epoch=00, loss=0.6459, step=54272:  89%|########8 | 105/118 [00:12<00:01,  8.27it/s]\u001b[A\n",
            "epoch=00, loss=0.6459, step=54272:  90%|########9 | 106/118 [00:12<00:01,  8.33it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6438, step=54784:  90%|########9 | 106/118 [00:12<00:01,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.6438, step=54784:  91%|######### | 107/118 [00:12<00:01,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6474, step=55296:  91%|######### | 107/118 [00:13<00:01,  8.29it/s]\u001b[A\n",
            "epoch=00, loss=0.6474, step=55296:  92%|#########1| 108/118 [00:13<00:01,  8.33it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6696, step=55808:  92%|#########1| 108/118 [00:13<00:01,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.6696, step=55808:  92%|#########2| 109/118 [00:13<00:01,  8.34it/s]\u001b[A\n",
            "epoch=00, loss=0.6490, step=56320:  92%|#########2| 109/118 [00:13<00:01,  8.34it/s]\u001b[A\n",
            "epoch=00, loss=0.6490, step=56320:  93%|#########3| 110/118 [00:13<00:00,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6394, step=56832:  93%|#########3| 110/118 [00:13<00:00,  8.09it/s]\u001b[A\n",
            "epoch=00, loss=0.6394, step=56832:  94%|#########4| 111/118 [00:13<00:00,  8.17it/s]\u001b[A\n",
            "epoch=00, loss=0.6476, step=57344:  94%|#########4| 111/118 [00:13<00:00,  8.17it/s]\u001b[A\n",
            "epoch=00, loss=0.6476, step=57344:  95%|#########4| 112/118 [00:13<00:00,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6632, step=57856:  95%|#########4| 112/118 [00:13<00:00,  8.22it/s]\u001b[A\n",
            "epoch=00, loss=0.6632, step=57856:  96%|#########5| 113/118 [00:13<00:00,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.6595, step=58368:  96%|#########5| 113/118 [00:13<00:00,  8.24it/s]\u001b[A\n",
            "epoch=00, loss=0.6595, step=58368:  97%|#########6| 114/118 [00:13<00:00,  8.33it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6372, step=58880:  97%|#########6| 114/118 [00:13<00:00,  8.33it/s]\u001b[A\n",
            "epoch=00, loss=0.6372, step=58880:  97%|#########7| 115/118 [00:13<00:00,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6514, step=59392:  97%|#########7| 115/118 [00:14<00:00,  8.31it/s]\u001b[A\n",
            "epoch=00, loss=0.6514, step=59392:  98%|#########8| 116/118 [00:14<00:00,  8.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=00, loss=0.6318, step=59904:  98%|#########8| 116/118 [00:14<00:00,  8.37it/s]\u001b[A\n",
            "epoch=00, loss=0.6318, step=59904:  99%|#########9| 117/118 [00:14<00:00,  8.39it/s]\u001b[A\n",
            "epoch=00, loss=0.6391, step=60000:  99%|#########9| 117/118 [00:14<00:00,  8.39it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6b94eca8-d6e9-4c2c-ba12-c64c30231c4a\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b94eca8-d6e9-4c2c-ba12-c64c30231c4a\")) {                    Plotly.newPlot(                        \"6b94eca8-d6e9-4c2c-ba12-c64c30231c4a\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAddElEQVR4Xu2YabhlZ1Xn\\u002f2u90977DPfemlIhYQ5iiCFIA50AYgAjGEAUGgIiKKJgG4KIeYAGVAS0CbaISFqNgAwigg00tAQUBGRSBgWBRpkECUVS0x3OtPd+h7X6Q1XduvdUqTz98KHpx\\u002f+Xs9\\u002ff\\u002f95z1ln73Wut99Aq\\u002fl1nEy+Df9cJfccm5oJPf2YZfVv1nZqYl7zr\\u002fM8us2+rlhNzt+uPX3\\u002fJEvt\\u002fTwfe\\u002faS1f7hmmX5btZSYi992lV71tt1sp649vnGfZQYAGB18wjPCMgRwwYU\\u002ftXH8+PHjx1\\u002fvl63T+v4v3GkZwaytrT3zV\\u002f7o3D\\u002fYuPlZy94Fv30PvOA568v4W9XgfZ+\\u002fzTI7Q3bX6j+8dqyzuOden4678LZ+7OkCXYYAbvu0e10InHPGN7jwsT9C54oCwA+99L9MT+F77\\u002fmz038D4Hs\\u002ftWuJ8\\u002f29Ll35YQA49OKHTj\\u002f3kd0usOcK4NCHlum3pHP3YvP77valjWV+hnYmprnrDQeBr7z8Ve\\u002f6tZfuwDt067NtCnzXzz66okPTO\\u002f\\u002fIq7645PzyFaevH\\u002fP6j526vO8ddyWGb3s+7Vzf9e3jk1fya4v\\u002fccvml3aaAC64gfD4G5fgDj3V3flR+OJlyxh3efKtccH5eNmd6Wa37OEeV112IX7plsve9MkT652J+a1HAsAlg4\\u002fc9y476A5d\\u002fmR88TFHl+D4+Y8YAl95pP\\u002fY3j1LFt5\\u002fBY6+gRT33P38PeYTu5YHf+LNuzJ60\\u002foYAD659X3xTTv5KV11\\u002fnue8c1leEr3ufA+DyUo7vg3ly5b3\\u002fd4oH\\u002fz\\u002fZ4O\\u002feMzHsNH\\u002fNe99OG9LwDtedIJsCMxd\\u002ftBwkf+\\u002fAW3fGbzfrtu4LYuvX6M37lpmT70CQC++qOH7rhsAHj1O5EPAxh99Fy889PbeKmw\\u002fTa+smu98csP+sx1+Owj5hc+ZRc\\u002fqT+\\u002f+OvPPXteDr7ythgP6NOXAOBm2X32NXjjsVccu\\u002fgte4+9Y8myd39Z89Hf+Jvw6gfg06fQtnnx20b63p++94tef+xz8oOX\\u002fP02P63HHsSH\\u002f2QZ4uHA1\\u002f\\u002fu+YdwZv0E8qETrw9cBb7Zn6IX7T91dUJjfGA3eOcHZ9\\u002fz+FfM8Q9P380BAFfeQ\\u002f9ntwwBAJf\\u002f9nkAcOnxvQevvxW+sGw39U0vugV3eMa+xXXL\\u002f\\u002f\\u002fol+P9PzXFjz4Ah954Em0n5oJrxscPv3H2F38BAPXVTz7FT2vvj8vWby5D4Ok\\u002f8f5\\u002fOgrgwLJxWo98Qg38+vbyinqHBxy4LZY3wBQTPOGtskQBACuXAVuHAPzsefil3dbTzgP65\\u002f\\u002ftl7D+lFvh6z+72wTe8QN3\\u002fpVrx7\\u002f2gxu\\u002f+aol53m\\u002foK960RT4ReDZx06yU4kJL7xi+p8\\u002ftR3x+acuTus2rwNu+OAyBW5+8YnXe+7Gp\\u002fWoX7i9Az6bt8Gd8A87bLzwwJdnO9cAgOvudp\\u002fL37cMAUDuxvJR4Gp98q3x1It2ZvQB9wC+8ZSPAcB5wI3Hd1gAgM9+4s73u\\u002fzXz8d1NywZz\\u002fyF+L7nt6jufz79t+2afioxl1yBx53RFnfpgRfhr35vGZ7UUxrSu+Dju2sqgNtcdTlwqQLTX31Pu4Ofbs+jH3j0\\u002ffEbWzu8E5r\\u002f\\u002fAde9uFPvfLM2eDel8k31nHxpT+E+Tfv9Jon7Sh5Vzf4+HUfA7D6A5fh4+85bZxUP8XB15G+\\u002fp1LfOVJ+r7HAXe44W54+8u36anEvJA+cjovLGdW34f8Cv7m5ybLFACa737mFWDBLVeXJecuf3xq5\\u002f31a3ZyrAH4Hv7+W7lHcfe3vT1bQfvq1a+46qrBn9yyhEe3xS1v+soF11x5\\u002fAOvGL3jVFsHALx27+RnDgPAE5+Lf3zi4Z3WCd0EAO95xcm6ty2\\u002fF8\\u002fa\\u002f7gHXzhUffN8m55MzIMu1ndtM4h+7vTihG7zOuBrR5YpAHfX1x5sb\\u002fn4AxuYh\\u002f3e8lxIBIAFeNAVO+5gqy99BnAR5cUX3vCpjx753\\u002fXy+AMA+LN\\u002fetH3\\u002f9L5L10qP5f+Ol77kgMvvGL69ufd4aXTD+3ske842Wse\\u002fEzkPzxLXsxlBPzFY5Yx4rF9f6\\u002fAzdODx999mp5MTO2Pbh8EwrPwwV89tTilnxfgZcsQgH\\u002fg63HdBz+29o4Lse+Xv\\u002fHO7c4DAPj8Qx\\u002f9vg7A43eX8mu\\u002fcS8A37jxC58AgJ\\u002fc97Vd7rY+\\u002f8QHX\\u002f\\u002fEO\\u002f7obngR8BK87h543EfudSN+d6n6ntAbFM9+zTIE8KqHKc42t2\\u002f9+J+sffXGN2686uBbd9DtrhRPbdpw7dMOXb9cDS9+AHDj8gQKwD37aXjvDVv73nyX+PILr7zhAy\\u002ffxM5fA2460cVevNTjXrZzcT8sTxWntPWml9t73\\u002ffDu9iYbsTFt6HnfeSCG+h5v7vLOqlfZsFZquW5P\\u002fbD+vefe9y+ZQ7gkxcAwL3vI1\\u002fbAbcTc+pJuviaR9z4hFNwW29dxSevXoaAec418xe8Zevu1931K7\\u002f4odF\\u002ffNSD34pDZzmbP3AZ7Na\\u002fMN1f9PDvtfjCR5eoKiB60Werf77yrBXPXyz67N0DIwDgfs\\u002fBi1555ePOmG62VYueZccQXflsAMDV147\\u002f9IwJANgjeOXyLgLwE9csnvG+e\\u002f7YFdVL3nAI0\\u002fe+95GPwnO3TXf\\u002fD53oRD9+eoT51nWnJz\\u002fkHKDcsjTMvPtpV97roiEeQ8evWx5+AADNo++Pt\\u002fzpmRPQfa\\u002fDY\\u002f\\u002fqwDPx9WVjW3+5e3kyMarnXPdH6\\u002fe86qLzvvGXy+MPgOsZ+PgyBPBMmGuedQfgxb91oiG95S2nvcuecf9LDgFYu+JFDdrlWXOH6A5nvvU5\\u002f+mnbwPgU7+5oyUAAOKieZcCmL79zH4MYPSyh+M5f3BmXnD\\u002f8Uf+3D1oTGdMN9ta2tbbj5J50sOmdwQ+\\u002fqGz3N6LL5f4yqPLFMCRfeF78J6PvvPry40awEsuxM\\u002fPAFx+ieLDr\\u002f5XfiTQpaMTcOC7r\\u002fsuAJ\\u002f8nRvP+Iqf\\u002fumr7wu88fOfOUsZAXCrh+Orv78MAUBV3UNevPm6s9z1k7rd7uXJxHzi7+6Ocw5g\\u002fa0nHqglrRzAzWdtAA+58pKjb9hcbtLb+qkTL0ff\\u002fV\\u002f+lQ0D3POPdy3Xfuvi2wH42PXv2zkTntKJM8u\\u002foO\\u002f6OXz5UcsQALAXx952Ga7e0Y+X9de86y6cTMyhJ\\u002fzktcDv\\u002feFZqta\\u002fpumbzvq7AADg6p95LAB8tf3r135+2dul3cPkPa65+60AtL\\u002f\\u002f0tPD1resax+BPzjj+A8A+CIeThuv\\u002fKtlvEOf\\u002f8rtbn\\u002fqoITTj9ItLz555DmbvvTxS5fRv63PXPt3z1195wduPMuotUvv\\u002fZFdy4c8FPjCu+V3zjwl\\u002fNu6cIzXnOU0BwBv9Nd++l3\\u002ffZnu0ktf\\u002frxn\\u002feP2ilZPO9\\u002fxev5Tb3r0WYatb1GjP7z8fz11e5ueUfi+k\\u002fV+PPf\\u002fPi+YPvHVD7v19ur\\u002fqx3z7RSfw5UEsqa2Rm1GcdGQZ29caNb2L2iChUrFlHkBCinnKnFGFn+OrTWwc4137GEoFMfBBuN9vXaAQvYwXDEl7kvkjuFgjauaPecgZAvnBs7ZoDY0MFyzhyUzPGgbBOPDMARXsQ8NvKldxd6GlYOuocr4MAjeVmxtpd7UrjLeV2sHuRZH3g+99zX7akDONDaQYzc+SFWxcG7gvavgQgPLNXs4tqNzEJJRawfO2SDWNzBU04lY6NyJj8aosHJWFKmhse59IZBxUUw0hpALzGimqpyoii6J0MrMRcMCJhWlIl6QqhiKEqydhN4YVSomQbOMSPq699mATLVAUQfAZFDoITAJhmwPtc2cE1sB2QwySRVUjFpKgKnmNrEpYBYhymqEsk9BhGCqBTKcglwicj0VcAEZjoCpWi2wAGwGu54KcQaziQpTb8eSwL6nHbEYK9J5VaEC+GIyExOjQkkDcTK3turUSLFs5jYuxp3jzJF9SlpyAKAZ5IWJwQQJKFKpldJ6FSEhDcVGy+wNBXAaqdFSPGViSezRs2afTQF6ZREt0VMBJFGlaigZMeIQxRXSkjwrNCsFYXCxgARkCWK0ZE8ZLIlqTQbJFc4OvZpikE98nrYckBjFZy6kvZrMWkrAiVgcxVOxaK8sSvtSKQ1iMTUbT5a41w5SIquxMSxqMTNDKNbWgmI4lz5wyzmNctFKUzYVsWcD7rRXksjKPmVJDcfCtePAhjlioSVnUsPQ3ljJakiMdSosHDMZzVDrcmJfJDsDdoYKJ8RiKKsioGQKpSTrmJ1h4U6TMCIpBZRobBGxrMZaLSZTzGykKDxJZFtEDQtbp8Jl+\\u002fMca2+NZDAJW6dKyinBaoZa65I4McFmXw0H41xRWWz2uRznZIttVTLYlFAC9qTx1HWll7CAeHZJrJL3auumHklA322lUgqEckjZC4eQqno4XMkV62JjEeWw62zxrSJZwzDkzUCriCixgyZrYDpFYWayrvKNhhxjl3JBx6ZUSVmYDVxVVwMN0sVJlixFTQ69ajZkyFpvGw2xpJSi2M5a8b0iWyIy7E2DEDXl1KtmY2Fa1WQNq2FnBqh6OhFLNga0omxFqRqu7BuuNivWHE\\u002fHJke34lamws3MhkmdhhLdeav7XZnN5J\\u002fLlm09xQCyqhoGo73NuBkbPt4fn27N0ixDVdkXNdV45ZzRnmbN2uPl8MbhjX6jp+JsgY\\u002fG1urNWjOytJj2R1Mr0RBAICNwAztyK82QMZnNtro+dwBI2UDFD5o91bgZMa23G9N5GxcCJVa4TK6h2qzWI8Z80m7EvkQGiRH4xLaBt6vNyNB82h+LnUQmku1YrNnTjA0vpvFIaqW3BOu7bIm0qvbvufXeYeirYdsc0XI8aNVRKdqx8wiDgd2zsn+jdof3TKpUAyP0Yom0rvaOz1tdddkO5vW6kS2nLqNLgUlCdXDf7fc31WI47CsveeGlnvmUbWTbYOyG1TlVsxhXG7RZCmeqcxSrxAOz1+8d7LUujbY2q40t0shOYmEmGvi9g3PHq05pMK231qX4aJWimMxmQKt2pdrvq3ZUbfoNFU5UpVRMIjvAih1VB0LdjuoN3hThRHVK2USyDUZuGA5WTTuu1g+ciKWy0QqJqVb3n3fb\\u002fXuVBSGyi22buFWTQjsSeKfW7t1\\u002fB109loYbpVaae0QWUtTDvbc6b22NjYgbwaa+T5w0e4XycO\\u002fB829\\u002f7v5CA6p6cv18ETGTLIxKvGmacT0e7SujzkkMg5kwSVIlo8GNxvubYd1oCUEQyxYxJEGZtK7Wzjk4Hjsn2TRqYkyJM1TBoQQzaNbqwWC11L0XqXVKDMlCVBVvmmalHg73yLDzJVUyJabtWOpm1IxH+2WldSX6wUyIlZskxbqqGg6aYGfd0fXpZAxvHaRwZTX0UZIJo9UmLBBLswEISlPFJkFsqMOgboJvu8kstivGWYOSadDnbGxohuOhN5P2m0fXN1a1ch4iplY2YrxxTTMc+V6FGd5Yo6DSZEMm1K5q6nqImAtL7aw1KkWazGqrOjRVE6rYtb3EsXXWaMnUFMNwlfVNU49cr2rJeWtZVEstbNQG45tmMPZR1bAJxhoFSq1shT37ZjAYhR2xEBU7swbMrh6vrJjDh9b78fkjNA7EhqLJVEdrMRuTrX2u4uxou9EOEMqxemYtQKYZr66440c28\\u002fCcptSugAyXqTdg66uV8dh84+tH+pXbrXLjDDnHrWGwkoCqQWVzX5FykJzEoA9zwyQGvhmPbZy3FJqQLKdCLJgZC1VuxqsrZrKxJc2eKgaXBczaGiJhYT8Yeu6iM9bWE43CmkxnQGKETD0MJi4Ck6k2SyysMXSsrCwGoals7hsUCiUlsbmrrF9YS0KWg9+abd7clNU4aqPMopD6hJYXNtj50GymW3GX\\u002fUzmaYXawK5Va5QMeb+1mBxtdJxDzOgimRTm1pOQNyFsTI8fauJat2\\u002fRp0mXQH5m+rrkyiDQJHOuSSPFpIm8ulYQAMM2tHG+CBRK0QyJDsm3zBZkOIStdrpeY1g4F0rJchsSp0bFMIcyiTk0RjNl0WSD+JmNdSnMFHSSkGuriVLRaLz6memrbAJroEm2pSJ0lKJG8sriPcTVK2O3mHz9y1ubpl5TycqUe7swnLWO8576pHv2Hazmt0y7oZV57oxYp9nWq6u+Xdz8z\\u002fO5rcaSk6jNnZU6ALYejdxs\\u002fcv\\u002fuH6M631FMixKbyKTRMu2cjG34oeGUlpQSpqjLWyQrB+MfSyTzULGWYk5JZuiLcYg2npl1bX9sUNdb6uBlliKy71NRBqtCQMfy6IzFbOWVmLkHG1k0mjZNz5Km21jKKeF9olyNJFJkoWpfMwtwsii346FG6M1Odi65pya1XMPNMgo7CxRaSi7Xq2ZUJnmolsjHps4VyWuS2OkYk+urkzJzcq+vY0KFeOYuDSMSj25uuac6rXzzx1opkLOEueGYJng1CAWV9HIcskdGRFOA1ZnLHlrOZd62Kx4FWR2Ci4NazCOXAimlGa8tqeGkBhHRKVhtcaQZ0O5hMaNPYpGtqImN6zWMDkYisXVZmSplJ6tCOeG1RKRFdZYbMDImpJaGCkm2bbwjMYNhY4pjAb79x7YjFtdtM4mTGpv7cKYcWjC6nm39of0mPrklNH7ReEFjUPxHWmlw30r+7bSPEbnU6S2mKlZHXDomMPKYP+Bc9f79UUy1ihmrFayyZwT6tX946JbhaDkJNoZoZSaeo6UKrO65symFMnsU+8Wqh2NbHQdpOLR3uF4stWnaH3pec7KJdtIkUs92LNKbS9QIaddmJEaKTZz6rVe2buik4UQlJz2dkYwmk3hnKle2z\\u002fOebMQAGt6a5s2AyIV+0yjPWF13HMGk8KIVLqwti5s2TbVCBSZtR2IM8razAuZrEGt0HC1Xhn0yMRclIwMF4WklMaFxKN9ds+4s1lYlZxS3fbZsyWFQRjVFoKSmBOLo2YebQXLomTcYFz5uQiMXag6qheJvZAvrNSsDEaDqJmMFYXVqu01kKcCo340cDRTKcZ0VDzqthdPDqJW\\u002fKixKirZmMjZoW5749kSYCiMKiMnYsmcHbiNKsENrXSJPVG7KJHJODXOUMlBpxINktg9A7OxsXU0quS86LJpM8NQZUrsyRp0PbIBGyVjaN6nVFertnSJK6HpPPZkXA0XLGWtTV8ypbjQQe2QtbdQEShzr8GWrCbnRXHBophioSoEoj5bpmK5pE6NpRy5WAACYkpam5gTpTSXqvYsJllSEQJxRm1iyZTSXJrac6Fo6OTnZa24K5lianVYeWRtDSACZWPrqTHWUgaVXBIXZ3qxjnLue6z28woWonYy6Huv7TrF3JraM3k\\u002fL8Z6zioaJZIYaWEdlxwjDybGGIvEJKX0XPrQZ2M1la7X4SR5F5yoRBM7x\\u002fONqEygQqDhRvLB2yIZxbWcTL+AsaRZ1TRttM6bLEV7U6ioaWEcSyqZxtMUfHCiGRJbG\\u002fNGC2YgAbT9eSVSbG3s1nswKzIp19PoXHAC6U3sO5qtJ2UohInsrMk1D9XPUoypT00p4kyJEgtjwqE44dhXq2uVTifrC6WwhsLFLWJVPKrsZznnLLmpbCGVXkphzAZ56FYQZqnt4nzclCK1l6RdMTITzkZEphg0fZq7eSxFQ0+ckWcMydSvTou1AmpyzLmnAs4oM5+5uN5Pk6oYbZJmzRJVMzBXk1ESplI3bbOoulhysmBKyDM12ZaMqTa+S\\u002fOwiCUXx0yJUimcrYhMqRnENHPzKIIqFkqU2HUwNQbFwEkqidU2Eco5FlVfKJZSD\\u002ffVBqqVWku2byfMzkXXw1ZSRRKWlCIVrhNlyrGIuo54QGMxWknWbMgOesDmvkAdLJtotbbg0kkWYckpkhIVV4yzve0YSrmNJcFlxKyFoK5nF5LvSKCp7zVzyJS1ZBV1aq2NnBwLlzblLCaXmCAMcWqNiaYEAy5tyVm45BQhTOJgmZNFbYhLhyxCJcWelKnY5AIFw8jJIoQ9a3tKnyeTzWisuIXpnTYzcmZYq9\\u002fsJknLwNd2pqXJ1gsTlSRWnVlZHac+TWbTYpy43te2scySrKnd3pVzpM2TzWOtLRp6zSUPohrvilZKollIrCYgRGgrtsTIdXR1qGWRcp8KK8QlY1IgpKguWz8a1zHG6WIhbIuPkpMZJLK2SqZiS0hFhExR+F5yzk2CcaZIBQayQAxlIPSaSxlE5eBU6+KKFmV1SNDK1tNe+9wDYzSxGTubu8Nbs75QUam70sMMow3FjMt4omVr1PLMi13YcYw+a7JmgCYNxp6kOzqZ9wVFSz3rSzuIKquo+2bEvusOb027QhlcT7MToWArGYxtnVOc5iQdkY1axT6I5uAGGJmm4Zjm00WMiVlK1ccgSN4OdFiGI6u5XZ+2sUBRQuyDqFau1mHtKuQ067sclU3K1bT3oqhcrYOBrTXFaYqlIzIpVZPsRDi4SpqxqVNO05KlIzJRbeupil0q1g+siwNuNw8f2dpMpSdTTEDiXLBSjV3XtbekmfaZKw3Z5K6CT0nU+oF3peF288jh6VYphUlaZ+puvojWD9gvRqbbPHJ0czOVhaESg1Ui60fVcOistv2kXY8Lk71wiZVQYecr14xsHUq3tXWknUJYqHS1uiJsvG8qRzV1m8cPz7aKKEyJVYEaF5rQjF1l+25rdrSfcTRCJQYLsPWDMBh5T22\\u002ftTjWz00KhUqsijKZE7EYWXSTdj22NnllsSajC93G2FoT2JXD5mvTzSPdTGCiK1mNMBsaN7Fqu7IRtngQIYWrjkXI9pOhsZYM5eO4aTo52i9UTLbIIoNufW3dGk91vjl8ZbpxuJsqc2+pZJtLyhGmHy\\u002fM1rH5pO9KoUQMlmI1tQvjJVadbs6PbbZbMVFiYtbCSPMZW2espPV883R6vO+RbTEs2UmOna2pbxZpcnxzs5vlQokZJNlJTrEfmH64sFvHplv9IheKzNiOhWw\\u002fXvDWsfkkdlkosYE1iTB30Uz7tTWex8lifXZ8HgnUW+Uy6KpJNkXX5v3e+ZzNytT3sAtDYjvSRTjOs9SttfM4nW9N1+eJFNGpTcoT7uykna7SIm0tjs+OzTtWdJZMayPTQruSxtH1\\u002ffq875KIiRYlRE7KM25zWkm577em862FKBWx4noqebBB8xRXY9vPZ5PZxjxDEZ2azvTEC+pKkUxdXJ\\u002fPF7EIZ7bFdaZnXqCTPE6mi8fnbZtEKRlbXGujoVa7Ese97\\u002fvNWeyzCCcLsQZIujX45nS9aVRS29npoo0WBp2pJqrOKVrfzHQ2NUdmyZQ6J6OGDWnWSXV4Oq0blLzozLSP0YBsJA\\u002f02BjfND0yaERS37nJbBEdvLZmQEmlI1loXB9RzFuxh7IkBchSgc5508atUJXctdIKiha1IjaK6tQdC4sjDZe86HiWSmSoyTqgDFlQMdIeH0rup6UDCEkNYClDWhLS\\u002fvhIU5qk\\u002foRHShZJS0fSalofU8xbfa9qNAMg2ksdjCErtVbUawygWfG9LSKu4+IULg+4J9\\u002fU3RH4wqleiITiqVcmQ6hRIaK3RPNsk4HACLVkHPkSNJhe4kAxK6G3KZeKtFBmm32QAGfLhGxfMgkhCCOrwGbbaK1KObJpswqROmVKQmqVBtpI1gSmRabCJEysBZlsdrXWyibP2XYlkbJ6gRZkttlVWqk1ZUa2K5mENYhq5sw2e68e3pYJXCcnYil0u5kUio0Wq6aEad03MZcA02cZ2k3fZAq52mRWtjJbVGksNisrj2dIlCqRILbYWd3VqYgDp6JNNRNBGmpmNaXZGvSDPuaaTJfyymDCKuKSM2oAsa1SccJRHfNoSlmTy1zBKKJrvSgpZWFyoyklJF9QqVGehz4UUVYqQmE4paLZJRvUKrJtGWoKJTVsBhMWLTZbpwYotgWJLRxh2DSnYmG1SmJb4ewLRzhmutMmqLWcKbKExAbZS\\u002fYgJVrptgJ1oCpJK3loCBMdZmYy4JGbgFpDiswlRGZkp8UpK3iMDfDCcUJvpI7GUAq5BFIlHmPK1EGCahGQAToKhcWAzJDnQAe1VKiYzIRoTTFilHjEU6WOwChcXCLW7FCsshKPMCf0KkFVC4tRRHYn3pNHOmP0qh4iQmqAnkJmZYIZYsroIUE1C9gALYdsTsTyfwDh3dMlJP7W8gAAAABJRU5ErkJggg==\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6b94eca8-d6e9-4c2c-ba12-c64c30231c4a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=00, loss=0.6391, step=60000: 100%|##########| 118/118 [00:14<00:00,  8.28it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6639, step=60512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=01, loss=0.6639, step=60512:   1%|          | 1/118 [00:00<00:15,  7.37it/s]\u001b[A\n",
            "epoch=01, loss=0.6534, step=61024:   1%|          | 1/118 [00:00<00:15,  7.37it/s]\u001b[A\n",
            "epoch=01, loss=0.6534, step=61024:   2%|1         | 2/118 [00:00<00:15,  7.62it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6614, step=61536:   2%|1         | 2/118 [00:00<00:15,  7.62it/s]\u001b[A\n",
            "epoch=01, loss=0.6614, step=61536:   3%|2         | 3/118 [00:00<00:14,  7.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6432, step=62048:   3%|2         | 3/118 [00:00<00:14,  7.68it/s]\u001b[A\n",
            "epoch=01, loss=0.6432, step=62048:   3%|3         | 4/118 [00:00<00:14,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6461, step=62560:   3%|3         | 4/118 [00:00<00:14,  7.87it/s]\u001b[A\n",
            "epoch=01, loss=0.6461, step=62560:   4%|4         | 5/118 [00:00<00:14,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6459, step=63072:   4%|4         | 5/118 [00:00<00:14,  8.03it/s]\u001b[A\n",
            "epoch=01, loss=0.6459, step=63072:   5%|5         | 6/118 [00:00<00:13,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6303, step=63584:   5%|5         | 6/118 [00:00<00:13,  8.12it/s]\u001b[A\n",
            "epoch=01, loss=0.6303, step=63584:   6%|5         | 7/118 [00:00<00:13,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6582, step=64096:   6%|5         | 7/118 [00:01<00:13,  8.09it/s]\u001b[A\n",
            "epoch=01, loss=0.6582, step=64096:   7%|6         | 8/118 [00:01<00:13,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6416, step=64608:   7%|6         | 8/118 [00:01<00:13,  8.14it/s]\u001b[A\n",
            "epoch=01, loss=0.6416, step=64608:   8%|7         | 9/118 [00:01<00:14,  7.64it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6417, step=65120:   8%|7         | 9/118 [00:01<00:14,  7.64it/s]\u001b[A\n",
            "epoch=01, loss=0.6417, step=65120:   8%|8         | 10/118 [00:01<00:14,  7.57it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6386, step=65632:   8%|8         | 10/118 [00:01<00:14,  7.57it/s]\u001b[A\n",
            "epoch=01, loss=0.6386, step=65632:   9%|9         | 11/118 [00:01<00:13,  7.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6508, step=66144:   9%|9         | 11/118 [00:01<00:13,  7.78it/s]\u001b[A\n",
            "epoch=01, loss=0.6508, step=66144:  10%|#         | 12/118 [00:01<00:13,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6558, step=66656:  10%|#         | 12/118 [00:01<00:13,  7.90it/s]\u001b[A\n",
            "epoch=01, loss=0.6558, step=66656:  11%|#1        | 13/118 [00:01<00:13,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6335, step=67168:  11%|#1        | 13/118 [00:01<00:13,  8.04it/s]\u001b[A\n",
            "epoch=01, loss=0.6335, step=67168:  12%|#1        | 14/118 [00:01<00:12,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6304, step=67680:  12%|#1        | 14/118 [00:01<00:12,  8.10it/s]\u001b[A\n",
            "epoch=01, loss=0.6304, step=67680:  13%|#2        | 15/118 [00:01<00:12,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6338, step=68192:  13%|#2        | 15/118 [00:02<00:12,  8.20it/s]\u001b[A\n",
            "epoch=01, loss=0.6338, step=68192:  14%|#3        | 16/118 [00:02<00:12,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6322, step=68704:  14%|#3        | 16/118 [00:02<00:12,  8.25it/s]\u001b[A\n",
            "epoch=01, loss=0.6322, step=68704:  14%|#4        | 17/118 [00:02<00:12,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6528, step=69216:  14%|#4        | 17/118 [00:02<00:12,  8.12it/s]\u001b[A\n",
            "epoch=01, loss=0.6528, step=69216:  15%|#5        | 18/118 [00:02<00:12,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6626, step=69728:  15%|#5        | 18/118 [00:02<00:12,  8.18it/s]\u001b[A\n",
            "epoch=01, loss=0.6626, step=69728:  16%|#6        | 19/118 [00:02<00:12,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6549, step=70240:  16%|#6        | 19/118 [00:02<00:12,  8.23it/s]\u001b[A\n",
            "epoch=01, loss=0.6549, step=70240:  17%|#6        | 20/118 [00:02<00:11,  8.30it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6585, step=70752:  17%|#6        | 20/118 [00:02<00:11,  8.30it/s]\u001b[A\n",
            "epoch=01, loss=0.6585, step=70752:  18%|#7        | 21/118 [00:02<00:11,  8.33it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6341, step=71264:  18%|#7        | 21/118 [00:02<00:11,  8.33it/s]\u001b[A\n",
            "epoch=01, loss=0.6341, step=71264:  19%|#8        | 22/118 [00:02<00:11,  8.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6480, step=71776:  19%|#8        | 22/118 [00:02<00:11,  8.37it/s]\u001b[A\n",
            "epoch=01, loss=0.6480, step=71776:  19%|#9        | 23/118 [00:02<00:11,  8.33it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6368, step=72288:  19%|#9        | 23/118 [00:02<00:11,  8.33it/s]\u001b[A\n",
            "epoch=01, loss=0.6368, step=72288:  20%|##        | 24/118 [00:02<00:11,  8.38it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6545, step=72800:  20%|##        | 24/118 [00:03<00:11,  8.38it/s]\u001b[A\n",
            "epoch=01, loss=0.6545, step=72800:  21%|##1       | 25/118 [00:03<00:11,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6370, step=73312:  21%|##1       | 25/118 [00:03<00:11,  8.25it/s]\u001b[A\n",
            "epoch=01, loss=0.6370, step=73312:  22%|##2       | 26/118 [00:03<00:11,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6311, step=73824:  22%|##2       | 26/118 [00:03<00:11,  8.14it/s]\u001b[A\n",
            "epoch=01, loss=0.6311, step=73824:  23%|##2       | 27/118 [00:03<00:11,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6339, step=74336:  23%|##2       | 27/118 [00:03<00:11,  8.17it/s]\u001b[A\n",
            "epoch=01, loss=0.6339, step=74336:  24%|##3       | 28/118 [00:03<00:10,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6458, step=74848:  24%|##3       | 28/118 [00:03<00:10,  8.18it/s]\u001b[A\n",
            "epoch=01, loss=0.6458, step=74848:  25%|##4       | 29/118 [00:03<00:10,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6341, step=75360:  25%|##4       | 29/118 [00:03<00:10,  8.24it/s]\u001b[A\n",
            "epoch=01, loss=0.6341, step=75360:  25%|##5       | 30/118 [00:03<00:10,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6356, step=75872:  25%|##5       | 30/118 [00:03<00:10,  8.28it/s]\u001b[A\n",
            "epoch=01, loss=0.6356, step=75872:  26%|##6       | 31/118 [00:03<00:10,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6377, step=76384:  26%|##6       | 31/118 [00:03<00:10,  8.27it/s]\u001b[A\n",
            "epoch=01, loss=0.6377, step=76384:  27%|##7       | 32/118 [00:03<00:10,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6309, step=76896:  27%|##7       | 32/118 [00:04<00:10,  8.28it/s]\u001b[A\n",
            "epoch=01, loss=0.6309, step=76896:  28%|##7       | 33/118 [00:04<00:10,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6373, step=77408:  28%|##7       | 33/118 [00:04<00:10,  8.23it/s]\u001b[A\n",
            "epoch=01, loss=0.6373, step=77408:  29%|##8       | 34/118 [00:04<00:10,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6398, step=77920:  29%|##8       | 34/118 [00:04<00:10,  8.08it/s]\u001b[A\n",
            "epoch=01, loss=0.6398, step=77920:  30%|##9       | 35/118 [00:04<00:10,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6290, step=78432:  30%|##9       | 35/118 [00:04<00:10,  8.10it/s]\u001b[A\n",
            "epoch=01, loss=0.6290, step=78432:  31%|###       | 36/118 [00:04<00:10,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6245, step=78944:  31%|###       | 36/118 [00:04<00:10,  8.19it/s]\u001b[A\n",
            "epoch=01, loss=0.6245, step=78944:  31%|###1      | 37/118 [00:04<00:09,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6417, step=79456:  31%|###1      | 37/118 [00:04<00:09,  8.23it/s]\u001b[A\n",
            "epoch=01, loss=0.6417, step=79456:  32%|###2      | 38/118 [00:04<00:09,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6337, step=79968:  32%|###2      | 38/118 [00:04<00:09,  8.27it/s]\u001b[A\n",
            "epoch=01, loss=0.6337, step=79968:  33%|###3      | 39/118 [00:04<00:09,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6482, step=80480:  33%|###3      | 39/118 [00:04<00:09,  8.23it/s]\u001b[A\n",
            "epoch=01, loss=0.6482, step=80480:  34%|###3      | 40/118 [00:04<00:09,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6412, step=80992:  34%|###3      | 40/118 [00:05<00:09,  8.21it/s]\u001b[A\n",
            "epoch=01, loss=0.6412, step=80992:  35%|###4      | 41/118 [00:05<00:09,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6336, step=81504:  35%|###4      | 41/118 [00:05<00:09,  8.26it/s]\u001b[A\n",
            "epoch=01, loss=0.6336, step=81504:  36%|###5      | 42/118 [00:05<00:09,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6293, step=82016:  36%|###5      | 42/118 [00:05<00:09,  8.10it/s]\u001b[A\n",
            "epoch=01, loss=0.6293, step=82016:  36%|###6      | 43/118 [00:05<00:09,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6448, step=82528:  36%|###6      | 43/118 [00:05<00:09,  8.11it/s]\u001b[A\n",
            "epoch=01, loss=0.6448, step=82528:  37%|###7      | 44/118 [00:05<00:09,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6502, step=83040:  37%|###7      | 44/118 [00:05<00:09,  8.15it/s]\u001b[A\n",
            "epoch=01, loss=0.6502, step=83040:  38%|###8      | 45/118 [00:05<00:08,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6331, step=83552:  38%|###8      | 45/118 [00:05<00:08,  8.23it/s]\u001b[A\n",
            "epoch=01, loss=0.6331, step=83552:  39%|###8      | 46/118 [00:05<00:08,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6180, step=84064:  39%|###8      | 46/118 [00:05<00:08,  8.25it/s]\u001b[A\n",
            "epoch=01, loss=0.6180, step=84064:  40%|###9      | 47/118 [00:05<00:08,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6402, step=84576:  40%|###9      | 47/118 [00:05<00:08,  8.10it/s]\u001b[A\n",
            "epoch=01, loss=0.6402, step=84576:  41%|####      | 48/118 [00:05<00:08,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6467, step=85088:  41%|####      | 48/118 [00:06<00:08,  8.14it/s]\u001b[A\n",
            "epoch=01, loss=0.6467, step=85088:  42%|####1     | 49/118 [00:06<00:08,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6331, step=85600:  42%|####1     | 49/118 [00:06<00:08,  8.19it/s]\u001b[A\n",
            "epoch=01, loss=0.6331, step=85600:  42%|####2     | 50/118 [00:06<00:08,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6414, step=86112:  42%|####2     | 50/118 [00:06<00:08,  8.08it/s]\u001b[A\n",
            "epoch=01, loss=0.6414, step=86112:  43%|####3     | 51/118 [00:06<00:08,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6403, step=86624:  43%|####3     | 51/118 [00:06<00:08,  8.14it/s]\u001b[A\n",
            "epoch=01, loss=0.6403, step=86624:  44%|####4     | 52/118 [00:06<00:08,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6268, step=87136:  44%|####4     | 52/118 [00:06<00:08,  8.15it/s]\u001b[A\n",
            "epoch=01, loss=0.6268, step=87136:  45%|####4     | 53/118 [00:06<00:07,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6245, step=87648:  45%|####4     | 53/118 [00:06<00:07,  8.19it/s]\u001b[A\n",
            "epoch=01, loss=0.6245, step=87648:  46%|####5     | 54/118 [00:06<00:07,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6377, step=88160:  46%|####5     | 54/118 [00:06<00:07,  8.20it/s]\u001b[A\n",
            "epoch=01, loss=0.6377, step=88160:  47%|####6     | 55/118 [00:06<00:07,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6547, step=88672:  47%|####6     | 55/118 [00:06<00:07,  8.27it/s]\u001b[A\n",
            "epoch=01, loss=0.6547, step=88672:  47%|####7     | 56/118 [00:06<00:07,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6358, step=89184:  47%|####7     | 56/118 [00:06<00:07,  8.27it/s]\u001b[A\n",
            "epoch=01, loss=0.6358, step=89184:  48%|####8     | 57/118 [00:06<00:07,  8.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6546, step=89696:  48%|####8     | 57/118 [00:07<00:07,  8.29it/s]\u001b[A\n",
            "epoch=01, loss=0.6546, step=89696:  49%|####9     | 58/118 [00:07<00:07,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6407, step=90208:  49%|####9     | 58/118 [00:07<00:07,  8.20it/s]\u001b[A\n",
            "epoch=01, loss=0.6407, step=90208:  50%|#####     | 59/118 [00:07<00:07,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6368, step=90720:  50%|#####     | 59/118 [00:07<00:07,  8.19it/s]\u001b[A\n",
            "epoch=01, loss=0.6368, step=90720:  51%|#####     | 60/118 [00:07<00:07,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6383, step=91232:  51%|#####     | 60/118 [00:07<00:07,  8.21it/s]\u001b[A\n",
            "epoch=01, loss=0.6383, step=91232:  52%|#####1    | 61/118 [00:07<00:06,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6310, step=91744:  52%|#####1    | 61/118 [00:07<00:06,  8.23it/s]\u001b[A\n",
            "epoch=01, loss=0.6310, step=91744:  53%|#####2    | 62/118 [00:07<00:06,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6263, step=92256:  53%|#####2    | 62/118 [00:07<00:06,  8.18it/s]\u001b[A\n",
            "epoch=01, loss=0.6263, step=92256:  53%|#####3    | 63/118 [00:07<00:06,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6254, step=92768:  53%|#####3    | 63/118 [00:07<00:06,  8.19it/s]\u001b[A\n",
            "epoch=01, loss=0.6254, step=92768:  54%|#####4    | 64/118 [00:07<00:06,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6325, step=93280:  54%|#####4    | 64/118 [00:07<00:06,  8.21it/s]\u001b[A\n",
            "epoch=01, loss=0.6325, step=93280:  55%|#####5    | 65/118 [00:07<00:06,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6180, step=93792:  55%|#####5    | 65/118 [00:08<00:06,  8.21it/s]\u001b[A\n",
            "epoch=01, loss=0.6180, step=93792:  56%|#####5    | 66/118 [00:08<00:06,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6168, step=94304:  56%|#####5    | 66/118 [00:08<00:06,  8.13it/s]\u001b[A\n",
            "epoch=01, loss=0.6168, step=94304:  57%|#####6    | 67/118 [00:08<00:06,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6388, step=94816:  57%|#####6    | 67/118 [00:08<00:06,  8.17it/s]\u001b[A\n",
            "epoch=01, loss=0.6388, step=94816:  58%|#####7    | 68/118 [00:08<00:06,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6274, step=95328:  58%|#####7    | 68/118 [00:08<00:06,  8.14it/s]\u001b[A\n",
            "epoch=01, loss=0.6274, step=95328:  58%|#####8    | 69/118 [00:08<00:05,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6374, step=95840:  58%|#####8    | 69/118 [00:08<00:05,  8.17it/s]\u001b[A\n",
            "epoch=01, loss=0.6374, step=95840:  59%|#####9    | 70/118 [00:08<00:05,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6253, step=96352:  59%|#####9    | 70/118 [00:08<00:05,  8.17it/s]\u001b[A\n",
            "epoch=01, loss=0.6253, step=96352:  60%|######    | 71/118 [00:08<00:05,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6293, step=96864:  60%|######    | 71/118 [00:08<00:05,  8.18it/s]\u001b[A\n",
            "epoch=01, loss=0.6293, step=96864:  61%|######1   | 72/118 [00:08<00:05,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6325, step=97376:  61%|######1   | 72/118 [00:08<00:05,  8.22it/s]\u001b[A\n",
            "epoch=01, loss=0.6325, step=97376:  62%|######1   | 73/118 [00:08<00:05,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6305, step=97888:  62%|######1   | 73/118 [00:09<00:05,  8.23it/s]\u001b[A\n",
            "epoch=01, loss=0.6305, step=97888:  63%|######2   | 74/118 [00:09<00:05,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6445, step=98400:  63%|######2   | 74/118 [00:09<00:05,  8.19it/s]\u001b[A\n",
            "epoch=01, loss=0.6445, step=98400:  64%|######3   | 75/118 [00:09<00:05,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6558, step=98912:  64%|######3   | 75/118 [00:09<00:05,  8.23it/s]\u001b[A\n",
            "epoch=01, loss=0.6558, step=98912:  64%|######4   | 76/118 [00:09<00:05,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6297, step=99424:  64%|######4   | 76/118 [00:09<00:05,  8.21it/s]\u001b[A\n",
            "epoch=01, loss=0.6297, step=99424:  65%|######5   | 77/118 [00:09<00:04,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6346, step=99936:  65%|######5   | 77/118 [00:09<00:04,  8.21it/s]\u001b[A\n",
            "epoch=01, loss=0.6346, step=99936:  66%|######6   | 78/118 [00:09<00:04,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6396, step=100448:  66%|######6   | 78/118 [00:09<00:04,  8.18it/s]\u001b[A\n",
            "epoch=01, loss=0.6396, step=100448:  67%|######6   | 79/118 [00:09<00:04,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6478, step=100960:  67%|######6   | 79/118 [00:09<00:04,  8.21it/s]\u001b[A\n",
            "epoch=01, loss=0.6478, step=100960:  68%|######7   | 80/118 [00:09<00:04,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6396, step=101472:  68%|######7   | 80/118 [00:09<00:04,  8.28it/s]\u001b[A\n",
            "epoch=01, loss=0.6396, step=101472:  69%|######8   | 81/118 [00:09<00:04,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6374, step=101984:  69%|######8   | 81/118 [00:10<00:04,  8.28it/s]\u001b[A\n",
            "epoch=01, loss=0.6374, step=101984:  69%|######9   | 82/118 [00:10<00:04,  8.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6432, step=102496:  69%|######9   | 82/118 [00:10<00:04,  8.29it/s]\u001b[A\n",
            "epoch=01, loss=0.6432, step=102496:  70%|#######   | 83/118 [00:10<00:04,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6356, step=103008:  70%|#######   | 83/118 [00:10<00:04,  8.07it/s]\u001b[A\n",
            "epoch=01, loss=0.6356, step=103008:  71%|#######1  | 84/118 [00:10<00:04,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6192, step=103520:  71%|#######1  | 84/118 [00:10<00:04,  8.09it/s]\u001b[A\n",
            "epoch=01, loss=0.6192, step=103520:  72%|#######2  | 85/118 [00:10<00:04,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6381, step=104032:  72%|#######2  | 85/118 [00:10<00:04,  8.16it/s]\u001b[A\n",
            "epoch=01, loss=0.6381, step=104032:  73%|#######2  | 86/118 [00:10<00:03,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6247, step=104544:  73%|#######2  | 86/118 [00:10<00:03,  8.25it/s]\u001b[A\n",
            "epoch=01, loss=0.6247, step=104544:  74%|#######3  | 87/118 [00:10<00:03,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6428, step=105056:  74%|#######3  | 87/118 [00:10<00:03,  8.28it/s]\u001b[A\n",
            "epoch=01, loss=0.6428, step=105056:  75%|#######4  | 88/118 [00:10<00:03,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6217, step=105568:  75%|#######4  | 88/118 [00:10<00:03,  8.13it/s]\u001b[A\n",
            "epoch=01, loss=0.6217, step=105568:  75%|#######5  | 89/118 [00:10<00:03,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6283, step=106080:  75%|#######5  | 89/118 [00:11<00:03,  8.19it/s]\u001b[A\n",
            "epoch=01, loss=0.6283, step=106080:  76%|#######6  | 90/118 [00:11<00:03,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6364, step=106592:  76%|#######6  | 90/118 [00:11<00:03,  8.13it/s]\u001b[A\n",
            "epoch=01, loss=0.6364, step=106592:  77%|#######7  | 91/118 [00:11<00:03,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6356, step=107104:  77%|#######7  | 91/118 [00:11<00:03,  8.14it/s]\u001b[A\n",
            "epoch=01, loss=0.6356, step=107104:  78%|#######7  | 92/118 [00:11<00:03,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6431, step=107616:  78%|#######7  | 92/118 [00:11<00:03,  8.16it/s]\u001b[A\n",
            "epoch=01, loss=0.6431, step=107616:  79%|#######8  | 93/118 [00:11<00:03,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6445, step=108128:  79%|#######8  | 93/118 [00:11<00:03,  8.20it/s]\u001b[A\n",
            "epoch=01, loss=0.6445, step=108128:  80%|#######9  | 94/118 [00:11<00:02,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6319, step=108640:  80%|#######9  | 94/118 [00:11<00:02,  8.18it/s]\u001b[A\n",
            "epoch=01, loss=0.6319, step=108640:  81%|########  | 95/118 [00:11<00:02,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6289, step=109152:  81%|########  | 95/118 [00:11<00:02,  8.03it/s]\u001b[A\n",
            "epoch=01, loss=0.6289, step=109152:  81%|########1 | 96/118 [00:11<00:02,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6337, step=109664:  81%|########1 | 96/118 [00:11<00:02,  8.11it/s]\u001b[A\n",
            "epoch=01, loss=0.6337, step=109664:  82%|########2 | 97/118 [00:11<00:02,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6127, step=110176:  82%|########2 | 97/118 [00:12<00:02,  8.12it/s]\u001b[A\n",
            "epoch=01, loss=0.6127, step=110176:  83%|########3 | 98/118 [00:12<00:02,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6453, step=110688:  83%|########3 | 98/118 [00:12<00:02,  8.20it/s]\u001b[A\n",
            "epoch=01, loss=0.6453, step=110688:  84%|########3 | 99/118 [00:12<00:02,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6356, step=111200:  84%|########3 | 99/118 [00:12<00:02,  8.00it/s]\u001b[A\n",
            "epoch=01, loss=0.6356, step=111200:  85%|########4 | 100/118 [00:12<00:02,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6394, step=111712:  85%|########4 | 100/118 [00:12<00:02,  7.98it/s]\u001b[A\n",
            "epoch=01, loss=0.6394, step=111712:  86%|########5 | 101/118 [00:12<00:02,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6251, step=112224:  86%|########5 | 101/118 [00:12<00:02,  8.08it/s]\u001b[A\n",
            "epoch=01, loss=0.6251, step=112224:  86%|########6 | 102/118 [00:12<00:01,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6140, step=112736:  86%|########6 | 102/118 [00:12<00:01,  8.12it/s]\u001b[A\n",
            "epoch=01, loss=0.6140, step=112736:  87%|########7 | 103/118 [00:12<00:01,  7.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6199, step=113248:  87%|########7 | 103/118 [00:12<00:01,  7.80it/s]\u001b[A\n",
            "epoch=01, loss=0.6199, step=113248:  88%|########8 | 104/118 [00:12<00:01,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6189, step=113760:  88%|########8 | 104/118 [00:12<00:01,  7.90it/s]\u001b[A\n",
            "epoch=01, loss=0.6189, step=113760:  89%|########8 | 105/118 [00:12<00:01,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6464, step=114272:  89%|########8 | 105/118 [00:13<00:01,  7.97it/s]\u001b[A\n",
            "epoch=01, loss=0.6464, step=114272:  90%|########9 | 106/118 [00:13<00:01,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6059, step=114784:  90%|########9 | 106/118 [00:13<00:01,  8.04it/s]\u001b[A\n",
            "epoch=01, loss=0.6059, step=114784:  91%|######### | 107/118 [00:13<00:01,  7.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6182, step=115296:  91%|######### | 107/118 [00:13<00:01,  7.78it/s]\u001b[A\n",
            "epoch=01, loss=0.6182, step=115296:  92%|#########1| 108/118 [00:13<00:01,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6215, step=115808:  92%|#########1| 108/118 [00:13<00:01,  7.87it/s]\u001b[A\n",
            "epoch=01, loss=0.6215, step=115808:  92%|#########2| 109/118 [00:13<00:01,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6298, step=116320:  92%|#########2| 109/118 [00:13<00:01,  7.91it/s]\u001b[A\n",
            "epoch=01, loss=0.6298, step=116320:  93%|#########3| 110/118 [00:13<00:00,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6419, step=116832:  93%|#########3| 110/118 [00:13<00:00,  8.06it/s]\u001b[A\n",
            "epoch=01, loss=0.6419, step=116832:  94%|#########4| 111/118 [00:13<00:00,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6224, step=117344:  94%|#########4| 111/118 [00:13<00:00,  8.08it/s]\u001b[A\n",
            "epoch=01, loss=0.6224, step=117344:  95%|#########4| 112/118 [00:13<00:00,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6318, step=117856:  95%|#########4| 112/118 [00:13<00:00,  8.09it/s]\u001b[A\n",
            "epoch=01, loss=0.6318, step=117856:  96%|#########5| 113/118 [00:13<00:00,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6195, step=118368:  96%|#########5| 113/118 [00:14<00:00,  8.18it/s]\u001b[A\n",
            "epoch=01, loss=0.6195, step=118368:  97%|#########6| 114/118 [00:14<00:00,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6296, step=118880:  97%|#########6| 114/118 [00:14<00:00,  8.20it/s]\u001b[A\n",
            "epoch=01, loss=0.6296, step=118880:  97%|#########7| 115/118 [00:14<00:00,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6120, step=119392:  97%|#########7| 115/118 [00:14<00:00,  7.96it/s]\u001b[A\n",
            "epoch=01, loss=0.6120, step=119392:  98%|#########8| 116/118 [00:14<00:00,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=01, loss=0.6376, step=119904:  98%|#########8| 116/118 [00:14<00:00,  8.07it/s]\u001b[A\n",
            "epoch=01, loss=0.6376, step=119904:  99%|#########9| 117/118 [00:14<00:00,  8.01it/s]\u001b[A\n",
            "epoch=01, loss=0.6115, step=120000:  99%|#########9| 117/118 [00:14<00:00,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"57c7e52e-eb1c-4d2a-b073-dea41f988810\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"57c7e52e-eb1c-4d2a-b073-dea41f988810\")) {                    Plotly.newPlot(                        \"57c7e52e-eb1c-4d2a-b073-dea41f988810\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAcnklEQVR4Xu2YabRtV1Xn\\u002f3POtXZzunvva\\u002fJIQ5MgGAhBJFRIqNBGWhFLQBGwAxsIGjFYoqCANDYpMDgQAYsUKIUaQRRKZRAUJEhPAEG0EGkCyUvy8t67zWn33mvNOevDfc29570qGDX4UNTw9+Wc9fvfc987c68959qXzsK\\u002fczp4Wfw723zbFua8j35iWX1L+XYtzCveefbnl923lOXCXHjNzdfcZ8n9v8e+d\\u002f746hd+cdl+S1kqzAXXPdmffN1ut5Pn3nzwkmUHAOif8dQri2UJ4Lx7\\u002ftjBm2+++eabr43L0Uku+8e7Lyvw6urqVS\\u002f8bwd+\\u002f+CXn7ecnffK++O3fn1jWX+z1O\\u002f+1DnL7hTCrtX93jjyaVq76HNplz7BD\\u002f2cwZclgDs\\u002f56LzgTNetOzv+UPfR3cyB4BH\\u002ffZLpsf1A9fec\\u002fJnAHzXZ3ctcVbxgItH3wsAt738sdN\\u002f+ejuFFi7HLj1I8v2m+LAXmz+x\\u002ft++RsXdWdh6vu89gDw1de9\\u002fp3\\u002f5fd26B2cc7pNgbv\\u002f9JNKunV6j+\\u002f7wy8vJS+4\\u002fOT7H7zuk8ffPujcXYWhu5y9c4n7\\u002fNno2Du7ev6Xh7aWf+t5ryX85HuX5A6eFe\\u002fxRHzp4csa5z\\u002fzHJx3Nl57T7qtmC2H3\\u002f2kS74TLzt08Ts+s73eWZir\\u002fxMAXNj\\u002f6IPO32F38OBn4Es\\u002fdmRJDn\\u002f1CQPgK08rbtizZ\\u002fkrfPByHLmOHBdduks\\u002f+VO7lgee\\u002fo5dH7xlYwQAnx4\\u002fKL1jpz\\u002fOk85+36\\u002fcviyPc8n5lzyW4Dj3Aw9bjh70VKB9x2U\\u002fB3\\u002fbKTvmCS\\u002fbQx\\u002fZ+yLQnudsix2FufBywkf\\u002f7kWHPr95GZ20O\\u002fgPrx7h9QeX7WOfBuCmp9567nIA4C3XIx0GMHj\\u002fnfCek\\u002ffLUmN7Fb66a7358kd+\\u002fuX45x9e3POndvljvOuCm196+rqc8bq7YNSjz10IgHvL6fOeg7etv379gj\\u002fZc\\u002fRvliK53yvrj\\u002f3uJ4o\\u002feCg+d0ydLMwF1w39\\u002fc+59Oo\\u002fWf8X+577nG4W\\u002ftABfOTPlyUeD9z8j79xK75jOQCgt26\\u002fPmwVuK07bu+1\\u002f\\u002fi7bYb44G5x\\u002fYen937qGxb44vN3ewDAo+7vf90sSwDAg195FgA8bH3PgVefiS8ux73qlqvvwN2u3Lu4pl2KnvQqfPDZUzzhobjtbcfUicKcd8Vo\\u002fdDb5+97HwBUz\\u002f654\\u002f4kaz9s49csS+CXnv7Brx4FsG85OMn3P60CXnli+YhqRwbsuwuWN8AUYzztXadr8xg9ENi8DcBPnoWX746ecxbQ\\u002fcanv4yNnzwTN1+5OwT+5hH3eOELRi\\u002f5no3X\\u002fNFS8vwr\\u002fY+ungLPBX5t\\u002fZg7XpjiRZdPf\\u002f5zJ\\u002f7Hu7shAOCca4E3fXjZAoeu2X59wG59kh+48q4R+Od8Qtwd\\u002f7ojxov3f\\u002fnEvDrB79z30gcv7aNt9L5sHwd+xp95Dp590c6KPuT+wMGf\\u002fyQAnAlcf0ob+edP3eOyh7z0bFzz5qXgqiu7G36jQfnQs+l3T\\u002fT044W58HI842PH5Wl5+L3woWuX5TGe2SM\\u002fHzfu7qkAznnyg4GLHZj85vt3bv+T7Wbw8Cc+FL873pFts\\u002fil61\\u002f14c8tfwUAlz7QDm7ggosfhfltd\\u002f+vV+xoec+uceM1nwSw8vBLcOP7TwbH6CY4cC35n16\\u002f5Ec\\u002f7jc8E7jba++Lv37dCXu8MC+mj56sC9up3ffRL8QnnjtZtgBQ3\\u002fOqy8GGQ1fZUnL+m4\\u002fvvI\\u002f\\u002f8a5gFcC9+bIz4xO5+XQXjje8nXztF1795CfXf37Hku7fGYf+\\u002fKvnXfHo9Q\\u002f+weDtx8c6AOCte8Y\\u002fexgAfvT5+NdnHd4ZbXMLALzvDcf63gniHvza3qc86vy++18sTthjhfmeC3zHwcD8lN57zrXA15YnNQCE+7zxQHPoxofXkMddu3wuJALABjzyETuuYOO\\u002ffSVwb8qLL1732Y8d\\u002flS1POUBAO+56SWXveCc1yy1n4tfij9+9b4XXT79q5ede\\u002fX0Qztn5Lvfvf36yKuQ33qauvADCfi7n1jWSEf3ftyB2ycH1v\\u002f2pD1WmKo48j+Oq+IX8eHfPL44zs8a8PvLEkB8+LW45sOfXH3b+dj7goPvOTF5AABfeNKTPtACeOozd+kX3vIAAAff+8VPA8DT935tV3qCLzzrka\\u002f+0XOfulveC3g1rr0\\u002fnvGxi\\u002f4Sb1zqvtu8yfGi3Rt0m9c\\u002fznG6c\\u002fv4mW9Zven6t22+\\u002fsC7dtgTU6k7vmmL515x2xvmx\\u002fUxLngocP1pLmz4z1fg79803vPWe3WvO\\u002f\\u002fRr\\u002f2H121h52Y7uD3Ffmd3YXDyTgZwGY5d6VMYv+NV4ZJLdz8QrND1uODO9NKPnfdaeulpW96vsOE03fLAU77X\\u002f+lfnnK62fmZCwHggZfazit0ojDH76QLrnjC9T99XJ7gT1fwmV9YlgA\\u002f\\u002f9nz33rn+LtecZ+vvOAjgwc88VF\\u002filsvWf4h4GHLYje7ng9Ocq\\u002fvvV\\u002fAF5e\\u002foztgfq9PVF\\u002f\\u002fgVNbNoB4H\\u002fMXf2XZApf9Eq5+82Oecsrp5gSV+Wl2DNFjXgwA+Jnnjv7iuTvyY6wZ3ry8iwD8yLMXv3zD\\u002fZ9yefnqP7sV0w984PufiF8\\u002fEYaHfnh7Ev3wS0+4b567P+OxZwB6x9Lef+8Vj77o3gP8IK1fs3z4AQDUT3wI3vkXp94wl74cP\\u002fEP+6\\u002fabsCn5Ybdy2OFcd\\u002f\\u002f8us27v+kC848+IHl4w+Aaxi4cVkCuApyxfPOBX7n97YH0rt21Pzin3\\u002fIJbcCWH3Ei2s0pz+rAgDo3FPGPPb\\u002fwE\\u002fcGcBnX7P8rNgt6nc6gOlfnTqPAfRf+Xi85M2n1gUPGX3078IjR3T8\\u002fHYqD929PHEryY8\\u002fbnou8KkPvWpnvM0FD7HuD083ku7YW9wb7\\u002fv4e25eHtQAXnE+njMF8JALHR95y\\u002f\\u002fhjwS+9OgE7PvOV3wHgE+\\u002f\\u002fvpTvuI\\u002fPednHgS8\\u002fX9+fvkW2+bMx+OmNy1LAHD38JiXbf7Jaa76Me62e3msMJ\\u002f6x\\u002fvhjP3YeNf2DbXEaD9uP+0AeOJjLjxy3dbykD7Bj22\\u002fHPnbFy8\\u002fnOziouPPJ9usXn3BXQHc+IYbTrfNtp9Z\\u002fjfc\\u002fVn4ytOXJQBgL45e90A8b8c8XubjvOvqHivMbT\\u002f1I78AXPvfv7oz+8bM3nHavwsAAJ73jB8EgJsWn\\u002fjjLyxnu9h9mPzuK+53JoDm2tecPGx901z1BLz5lMd\\u002fAMC\\u002f4fG08Yf\\u002fsKx38IWv3PVuO26047fSHddcc1Iu86UbL15W35jPv+Azv7zyng9ef5qj1i7+\\u002fvt2LR\\u002f7WODf\\u002flbfcNqR8w245wBv\\u002fdCy3Obt8arPvveNy3YXv\\u002feqX\\u002f61fzuxorN2RN\\u002fu\\u002fOqzbvnR0xy2vkkGf\\u002fDgd191Ypue0vi+nbkBv\\u002f5\\u002fXxdMn\\u002fWWx538I\\u002fn\\u002fVzvmW0kYbokWGRY0W0ikVSrgJmSRy3y0yHVLFClnTrWRd1R0BWVQOdySJHBmKLkzkTIBSM5Uhy3JwUAMBZxcNMBB2YSrsCWJAWYY3ESgBDipEfWKTUlMzkxKbsJQIjhlY6qLrWMZDDAWKBFAnRPVYSNkcUBgcAuC7EwqrqA6rMccFRSgjhwZlkVSoAyqyo2YooKYlFyDQI05CxRU0znzknLh0FayZKDvlKAxlZkZpGWyaJxAUiZVlSR1R8iSRgtxZyeP6kQOAwEaXWESFwHOxsYwcngwMkqFkruUDUEFjmhO5GQgNwipO1UNuQmAYE7sMADuxzPe\\u002fvcKdWKHAuQWXd256ECZ4WA4sVMmNhOS7I6oFhORA3CWTApRK1zU4FUCZyIFw5mNlMgsEKsB3KGFZDWrwFRWQ5FQRrIiVXWZsmQhc+airjqzVFksnNSDcEYDMhglI5YggUE5upozZW+JnBSuxDGWQUQ8AkqBMyWIOigZkQuIDMquZkBGR6LulI3ZmZhAWaDmQEYLVhh1xkzMgYly8O2MlIKDoGA2NqdMTp7dCRnk4g4yCpxJVTILXB2ETEbizqQQMjYjZZCpOyEgoitCNu9CWfRqcui85Q6xi0axi22pSJ7cxOraC\\u002fhCSAMU4ibOHsAkgQ1dUlIWSQSKmqODBJFDLOCpSw7nkAjEbAwiAYEZIFVjY6ZMBDFjMAQMFgB5O+NETGImYAQwsZBRl5WMRTomMMydwTCm4DFacDeBGwHSkTLIWQHJsfCKsgdXgYGzOggIBmKL0bc\\u002fZ8wWxHJElrJDvz5jb1EXabq+MWuOFgbWHF2SBSu18hWqs6acTabclRWMACJmruOgiEaTNM6WuWMGHEwuAdwrVwaRedoebXPqFIArwQjMVIQ6RKU2NTmrtMzkSnCCMBexjsFokRY5a2iYyTLBCUxcxV6MStM0VTuWQdwZAipijIVCs+ZknsGcVBzuAeIVF5Hcs+fOk+cY1QVOHpxCGWJhsGy5MzNAQpKiSOY+HBw44+x9B2rfmt1y5OuHaVM7DWXDIZVaIqfV0f7Bopt1G7YoNGhTguDssddb6Q\\u002fqSDoZ96ZNSjE7lISNNPZGa6uro77o5mQ4Hs+5NQMRnJhjVfbqfhEJ7Xg+WahGc3eCI1Coqn6vVwb2xWQ2XWgu9HiGWNWjXq8S0vm4N201F9lhQU0QQsFF3SsrZh2345lqcChJctEowqj7\\u002fUGETdMWWnbyzKwmHkPgUPfqSkQn7Rg5C7kGMgusXPXPPvM77zpabYZHml7peRa0N1Em70iUtVfG4dqdm80jR4pp0UimCkZgKnrVvv7+tVosDQbDzc2JGbPB4Gyx19+\\u002fevb+YZGoP+kfjtaCikTKICrqcqVaG\\u002fWFcjeYVOuLDk6clYlR1sVatbbSE0rteFJtLJCNaTur6mJvb89KLd7N+5Px5hyJQZbJnWMZ6mo4HJXRtD8O3gAZsTOYc+DIVW+wZ2VgaX1syVsoFVnhxjGGohoMV3ql580ttsahiIHKLIsi7j\\u002fjnHt+x516XT2vsMY2nS9k7GXDFpFLtQ4re87bIzfP6\\u002fVK4S0FsJbgWK7uPWOlFzrzXmR0C8mkgORCJfb3HThn\\u002f6hsQlMMDd100XkHYitYYjFY2TMcsGjRq4K12ZzMsZ3F0eqeYZ85S1kG75IaGUO0ZI5xZc\\u002feYS2auF8wui4TjAELEkWqwXA0rIYUcy\\u002fmxgBTJwUHQaAy1qOVs6piGmVRm6saw11CYIn93mhlsBqKrg65NSczD6I6kzwYjc7Y0\\u002feDdnQhfGCzLwXBA5NxS5wilyvVShy06H8FWV2jpJiCxdDv9UajKi6aRmsftUW05CZskqL0+v2VUcUbzaytdDivItRMOAWw1HU1HPQrTcYxDJqtuEhm4BTAoe5Vw2Gvyl3mQgdNLBadG0mKkNDr9YbDqmybDpWOuhhnyY0kCRFVRdEfDPulRQ6xGkyKVh0mClKKCEVv1BtSEbhGNQ2dMUwSk6Moiro\\u002f6vcgImXRnxStgSzkIrqEIq6trXQ3Hfz6ITvn7CIWaxsDcBObWAKBFB7qenXtaDo8m7WkEiaBiOGk0q8rmh7enPcOVEkoKSCcOBgRxeGw50dvPzQuzhppwWAhcSNAg1pR9kLeaLW3ViW3NgOQTARz9bKsQ7e+yL09VSZvMjk4E8GQUVVVaA5P297+Gow2w5kznN0zU9EvecqxqIsi59ZAGk0pOsGTVGVhJErZm0WnJPPocCFoCrFfSONkQWLXtQ5uiuBzKyXLymAUjhz+0hddSxs10k45uSNADYrMFbVbuVtsNetdy2XY4kLJUFIoQsnN1uahELfno1mkDHUUkKqsw\\u002fTooa9L2c5XEnsCU8twLcEhRMrzySyWDvKcNUUyJ\\u002fdIHEOkNJtMQgmwZ9UU2RzuJYUiFNxOJkdDSRAytVyQEkGDEwcCpg2XIbvmtkuJCEwwB6zITnOUkRtddG0y74gdUHGi4E4zrXXglnLTpWwERtEvQ2+0ulZ1G1\\u002f+0u03He2KVPnqXhbjTkQlqlHXpf6e1ZVm49aZEXwWAIAlE4pacre1aej1h0jqRmYMkmAh9ochzY\\u002fc0c5DOSKxGNlVQETZVSJ7ns5N6l7Ms9QlMmOAKLtJIZanM5Ver9RZ7vKxTDIslKx5Mnbp9\\u002fveZM1sxsbkZi1YkOYJZSjzfJwWydQ5iyihdWcki2Ufuj6e5Da1cFIhc2scQqlxriUsJptp0WVz4kgeclUO9w9sY2urd+BOK0VG5NB31igWk1K7EaxFOVReJJ9YyOQll3Awh1iWrIjDtT0rkYOxQM0LAnuI9bBPnfpg3761goQkBIcVIAdIYsHZ69HqWo\\u002fVWyVNbgXBCSQxsnq1sro2EKPOSfN2xiShKFipGq2urQQWJTF1LxymBkKg5L3hcCXYvJllS9u\\u002fk5K5JfaE3qio1eazxlQTe+nwrICLZ\\u002fSGvQFsNp8nSx08OGhaVvuHUVtOqxNeHVWJUFQODl0IVLcufa7L0V3OXoyPbi7QFYFy7gqBdzU5Z6Fytdizf283JSdm15gZ2UPFksGypqMDe2XsxJFhlIKyuhsM1MNo70p0UyMSVkpinAs3GNCrhnvW6i2YgkSyJAGlwpUUVEtv796V2QYZwKwxhSxqBjanenhghabdvO2IgiR0URkGisTc23NWvL3ZmuUuMDipHvucOKFeOWvYzmfTrmWXkDwIMnKQak2OtDX6\\u002fX7JA+uMWVpJniQWOo+Io7U7DZqNxUKxQkxiWbLG4BFOrnXZWx1C1R0OY5dsIh5CDG0qWVZWxIm2nwiJk0ZGNLhRr1gZ9lI2MziMjJNGQTSHUy+MRn3Lag6HsnPWIiK6Al5Xw+EAmt0BGDtSDuzB2D30963VyXLuSImM1DUJm5g4F8MDK5q6pmtDFnYyTikwRNkQBvvXYqddarllNlhIncvqaG0w75qc28X6naqh96RObdHm6IymSMyg+sz9fujIZOJ1EldkUSrINHNOWbSSQEIBwsbkUDCIJeZFy8bWJucgZTCPyV0CVBMnTRR6RS3ZzIg9wMkkkOVEKXfguqjFnZzEApyMA2tKlHPDXsdaBGzEFuCgIJqqTK3moteLsW3nyh6Uick5WltayGqyNqR2Npl6aBkOYhLWVCp3lmnQD5TmcxMLziAO0kYUZW2hbZOa1rxSxlK9yYvW+2EercvUjEy4Td36ZpdjwSi7EmWTQxFYu3lotSsipxmzmCSGxRmFIgbXLs3ajNh1kCCA5oy6U46Bumbq4gCHNGEJLsawslMJgVI7M4ru0uQJcbBgTFZ2SttZpZQ1Km8xBwtZyApNHoVSmkvVLYpua6sxlkxwoESCkFunHWvbztcnbQYbRIWiZRdBTk0xTIvC1seNkiTAgZAGaV9\\u002fX79sZ5uHF0eZiuHgTt2Rrck8CVSKUnKVTUYHBnrwq1tU51ByF9gzSbauzGgKyy33y7r0pjPikIA2atCSQmuT8XRRh7UI85wUytSBPLNy23posoci6UJJXM2pA5lRprbJQrUX7rrIkKAKdISslKhtOmi0MhQ275wFmTwR2I0o5dTMKo\\u002fz1hKH7O6OJELukYlisHZ9Y94FBKgTwRKRwAKrWW4at0ULDdEdcA+u0Qax5mpckhZ1f99wb5LUtg1iZ6CZM5f1cMRhwZO2SxVrdnAcUxIRw7zXoltAAIdZzu5uQkmognRorVukoq4KHnvKWd0pZAEci6ojdCatInsyA1yFs4Aci7p1z5k7ZrWsCndjToHIfFa3glZ4lMUsqwLIzMZG4MwG7WacFylL507uDnJSCHNVlPBFNV\\u002fkXExNCURJnJXAFiCWZ5TmOcfkxu6wIEHqist+Ua8eWBuvDu++X\\u002fMtX\\u002fvaJBqKVi1Q2XEse2veHN7QKueCg6q34vCudIgbdcL90dC1WSQnYpPMZExBnEVG7f4DB3qzvLU1NQ4aDKrCLjA0BUsR5toaBVWQGFQDO7v5Ikgsyya3SiETIAbVyC6u1LJU\\u002fV7KbTJRBSSTO5FHZjFQYnTWkERXh3Ti4MhlEcvourlwp5aEXY1CZgcJFTFEAAsgeUNSeHKEAObxIk322R5BVxbxbE9fmdw+nnRNEGbqYlsj1hVXDemi0SoUObEowVMJ8RhKG1m9WiNPNsazRgnigIpREimwlqrRWs\\u002fmB49szFpTODwXYIpSSC\\u002f2+pzayaLpkhO7wbQAUxGKUIe6H1I7mS\\u002faDsQweC5JqAgFF+gNYu4m41nbGRM7uQanEKUIg2FV56abwVxBko0Bh9VB6lgPuEjztolKnTtlYTd2j5Gr0B8WxXSR5gwoiLMFV+qNbxusjMreSjnucdvefNuh28ZNG9lrIAAp9NYqmXUbR\\u002fuFF1kgEGQqjEESC1RF6PWKxfjo4UUHc4dR8JCaLjENBpH6\\u002ffns1kPr06RK5EIMClLWsRzGYaR2a7KZMxmcXKIQRMoqlP04LHm2Od5ImRUO58IIIZQlF3UY9MJia3O962BwsqDkIlQOevWwqizptJlZZiUTRAUxexwO6h66xZSSdQpWQkBQAgcqR\\u002f3eIErb2rSbm7KSBwQlWVRbXx\\u002fy\\u002fkDtsDlafml8822T9Uwxo40GOMc6ltq1h3xLAg9adk5EKhZyasc05Mgtz7s71sdHu84VTB275cV4A6tlNGknOLh5+NZ2ZsqgLFqkbIsQK5dFnoyPrM8mncKMOYsVndpcpHRZ6HR6eH261SnMhFQspqwzRnRpaL44sj7ZSNkNjE4sJrIuKxst8uzw1qRtE9xUuAsupm5MQb3Zmh9pOqWO3I25Ew+ZLKmxoWnGd8xmKSW4K0soMsKRxdiPrA76mDeHF4cn692EKCp7ROE0F56NZbYex5sDLdRzhEnWfhJ1H+tsZXVYYb3bmm1NGjNydysSow23582VlUHMaT6ZjLfmydmdPbaciRpL2azj1G6NJ7POHRnQouVEtLAumSXO7dZkMk1wUneLiZVoposmq9JW2pqOp50rq5MVjSSiPGOQLtBOtrZmbXKHAhpThLi2U+F24rP1Lrm5E4yhsRNl0kVgSjM0m+Np26kDSqS0zyo2WylXIWUKc22tWcwtimDmCMSxRT\\u002fyKtfYTEcJUV3FUsxBjS06y0rRK9y7lOY2V4cxqWQmlRCqXqwJ2iWb6UyZnNXKrOzROQyrunLr2q7RxhTK4pJVPDjLqKor967tGl2YuVGwkI0tOvFq0a8MXdctbK4GFVZWFTCH2OsVlaV20SbtoGQIUHIW4yIWQ6l01s2SmUHFNZq7MYNjrPqxsqZdtFkTK7lFp72xYxEUtmCqF9lHnTehNy9Nc5j2tFTxUHsiotDMyhzQ1krGKYi5a1AJsWKom1vnSAxj96BGJiAKIahaNOsQWiFzAjvcxSSGkkQ9uSXzTHAxiLu7qBShgqgnaHLbzkjcXUOWItbEahmazDPI2YydnRmBJUDMW\\u002fPs7uQu1kWPJuBIICLKDZnDxGGSTVycGZFJwNDWXB0gdzY6J7mTFsgLCxIXQcqcrM+cGq864tIhgi2UnYhZVzf1IhSSYIMOiTOcS+LgCmWDskJdqOyQKQlcwMEye1BoNM5KoeygouQSiIMb1GFOpkaCqkMWhUskjmaUHW5kpiSoO2TOcK6Ygysy4EbqiuChIwsgEgOLOVkXMjvUmQElFhBJ49EAtq7oiiROgIdEECKIWiADWReyGBmIEHqboLbHLXGRCu2BUnQiSlbSaGtWdomccjnrUg9c6DTOYV1UqmNCkSKEnBIym2c2OIiE+5QQ25JAKilYcMqSCeSIPLAMyUJC7p1qUCjI2ZhAfSQUOXggR2cqCiU4GwPU5+xFih7YvbUkCiN3MWaiQU4clMAGS4SohCROJnD0uxSoI0jHKVkRnLkNmYxIqeeJJBNJhi0gwYhScHKGo\\u002fe\\u002fAJBBdpJMUpT7AAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('57c7e52e-eb1c-4d2a-b073-dea41f988810');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=01, loss=0.6115, step=120000: 100%|##########| 118/118 [00:14<00:00,  8.16it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6345, step=120512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=02, loss=0.6345, step=120512:   1%|          | 1/118 [00:00<00:14,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6319, step=121024:   1%|          | 1/118 [00:00<00:14,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6319, step=121024:   2%|1         | 2/118 [00:00<00:14,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6232, step=121536:   2%|1         | 2/118 [00:00<00:14,  8.26it/s]\u001b[A\n",
            "epoch=02, loss=0.6232, step=121536:   3%|2         | 3/118 [00:00<00:13,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6235, step=122048:   3%|2         | 3/118 [00:00<00:13,  8.25it/s]\u001b[A\n",
            "epoch=02, loss=0.6235, step=122048:   3%|3         | 4/118 [00:00<00:13,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6188, step=122560:   3%|3         | 4/118 [00:00<00:13,  8.18it/s]\u001b[A\n",
            "epoch=02, loss=0.6188, step=122560:   4%|4         | 5/118 [00:00<00:13,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6271, step=123072:   4%|4         | 5/118 [00:00<00:13,  8.19it/s]\u001b[A\n",
            "epoch=02, loss=0.6271, step=123072:   5%|5         | 6/118 [00:00<00:13,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6306, step=123584:   5%|5         | 6/118 [00:00<00:13,  8.21it/s]\u001b[A\n",
            "epoch=02, loss=0.6306, step=123584:   6%|5         | 7/118 [00:00<00:13,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6429, step=124096:   6%|5         | 7/118 [00:00<00:13,  8.15it/s]\u001b[A\n",
            "epoch=02, loss=0.6429, step=124096:   7%|6         | 8/118 [00:00<00:13,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6342, step=124608:   7%|6         | 8/118 [00:01<00:13,  8.23it/s]\u001b[A\n",
            "epoch=02, loss=0.6342, step=124608:   8%|7         | 9/118 [00:01<00:13,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6166, step=125120:   8%|7         | 9/118 [00:01<00:13,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6166, step=125120:   8%|8         | 10/118 [00:01<00:13,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6228, step=125632:   8%|8         | 10/118 [00:01<00:13,  8.15it/s]\u001b[A\n",
            "epoch=02, loss=0.6228, step=125632:   9%|9         | 11/118 [00:01<00:13,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6234, step=126144:   9%|9         | 11/118 [00:01<00:13,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6234, step=126144:  10%|#         | 12/118 [00:01<00:12,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6214, step=126656:  10%|#         | 12/118 [00:01<00:12,  8.22it/s]\u001b[A\n",
            "epoch=02, loss=0.6214, step=126656:  11%|#1        | 13/118 [00:01<00:12,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6231, step=127168:  11%|#1        | 13/118 [00:01<00:12,  8.25it/s]\u001b[A\n",
            "epoch=02, loss=0.6231, step=127168:  12%|#1        | 14/118 [00:01<00:12,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6342, step=127680:  12%|#1        | 14/118 [00:01<00:12,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6342, step=127680:  13%|#2        | 15/118 [00:01<00:12,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6304, step=128192:  13%|#2        | 15/118 [00:01<00:12,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6304, step=128192:  14%|#3        | 16/118 [00:01<00:12,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6190, step=128704:  14%|#3        | 16/118 [00:02<00:12,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6190, step=128704:  14%|#4        | 17/118 [00:02<00:12,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6131, step=129216:  14%|#4        | 17/118 [00:02<00:12,  8.22it/s]\u001b[A\n",
            "epoch=02, loss=0.6131, step=129216:  15%|#5        | 18/118 [00:02<00:12,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6281, step=129728:  15%|#5        | 18/118 [00:02<00:12,  8.15it/s]\u001b[A\n",
            "epoch=02, loss=0.6281, step=129728:  16%|#6        | 19/118 [00:02<00:12,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6351, step=130240:  16%|#6        | 19/118 [00:02<00:12,  8.09it/s]\u001b[A\n",
            "epoch=02, loss=0.6351, step=130240:  17%|#6        | 20/118 [00:02<00:12,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6252, step=130752:  17%|#6        | 20/118 [00:02<00:12,  8.12it/s]\u001b[A\n",
            "epoch=02, loss=0.6252, step=130752:  18%|#7        | 21/118 [00:02<00:11,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6610, step=131264:  18%|#7        | 21/118 [00:02<00:11,  8.19it/s]\u001b[A\n",
            "epoch=02, loss=0.6610, step=131264:  19%|#8        | 22/118 [00:02<00:12,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6916, step=131776:  19%|#8        | 22/118 [00:02<00:12,  7.94it/s]\u001b[A\n",
            "epoch=02, loss=0.6916, step=131776:  19%|#9        | 23/118 [00:02<00:11,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6263, step=132288:  19%|#9        | 23/118 [00:02<00:11,  7.96it/s]\u001b[A\n",
            "epoch=02, loss=0.6263, step=132288:  20%|##        | 24/118 [00:02<00:11,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6296, step=132800:  20%|##        | 24/118 [00:03<00:11,  8.02it/s]\u001b[A\n",
            "epoch=02, loss=0.6296, step=132800:  21%|##1       | 25/118 [00:03<00:11,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6353, step=133312:  21%|##1       | 25/118 [00:03<00:11,  8.11it/s]\u001b[A\n",
            "epoch=02, loss=0.6353, step=133312:  22%|##2       | 26/118 [00:03<00:11,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6264, step=133824:  22%|##2       | 26/118 [00:03<00:11,  8.01it/s]\u001b[A\n",
            "epoch=02, loss=0.6264, step=133824:  23%|##2       | 27/118 [00:03<00:11,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6289, step=134336:  23%|##2       | 27/118 [00:03<00:11,  8.03it/s]\u001b[A\n",
            "epoch=02, loss=0.6289, step=134336:  24%|##3       | 28/118 [00:03<00:11,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6265, step=134848:  24%|##3       | 28/118 [00:03<00:11,  8.11it/s]\u001b[A\n",
            "epoch=02, loss=0.6265, step=134848:  25%|##4       | 29/118 [00:03<00:10,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6142, step=135360:  25%|##4       | 29/118 [00:03<00:10,  8.14it/s]\u001b[A\n",
            "epoch=02, loss=0.6142, step=135360:  25%|##5       | 30/118 [00:03<00:10,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6173, step=135872:  25%|##5       | 30/118 [00:03<00:10,  8.13it/s]\u001b[A\n",
            "epoch=02, loss=0.6173, step=135872:  26%|##6       | 31/118 [00:03<00:10,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6245, step=136384:  26%|##6       | 31/118 [00:03<00:10,  8.19it/s]\u001b[A\n",
            "epoch=02, loss=0.6245, step=136384:  27%|##7       | 32/118 [00:03<00:10,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6226, step=136896:  27%|##7       | 32/118 [00:04<00:10,  8.16it/s]\u001b[A\n",
            "epoch=02, loss=0.6226, step=136896:  28%|##7       | 33/118 [00:04<00:10,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6257, step=137408:  28%|##7       | 33/118 [00:04<00:10,  8.24it/s]\u001b[A\n",
            "epoch=02, loss=0.6257, step=137408:  29%|##8       | 34/118 [00:04<00:10,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6276, step=137920:  29%|##8       | 34/118 [00:04<00:10,  8.24it/s]\u001b[A\n",
            "epoch=02, loss=0.6276, step=137920:  30%|##9       | 35/118 [00:04<00:10,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6301, step=138432:  30%|##9       | 35/118 [00:04<00:10,  8.21it/s]\u001b[A\n",
            "epoch=02, loss=0.6301, step=138432:  31%|###       | 36/118 [00:04<00:09,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6274, step=138944:  31%|###       | 36/118 [00:04<00:09,  8.21it/s]\u001b[A\n",
            "epoch=02, loss=0.6274, step=138944:  31%|###1      | 37/118 [00:04<00:09,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6111, step=139456:  31%|###1      | 37/118 [00:04<00:09,  8.18it/s]\u001b[A\n",
            "epoch=02, loss=0.6111, step=139456:  32%|###2      | 38/118 [00:04<00:09,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6319, step=139968:  32%|###2      | 38/118 [00:04<00:09,  8.07it/s]\u001b[A\n",
            "epoch=02, loss=0.6319, step=139968:  33%|###3      | 39/118 [00:04<00:09,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6282, step=140480:  33%|###3      | 39/118 [00:04<00:09,  8.17it/s]\u001b[A\n",
            "epoch=02, loss=0.6282, step=140480:  34%|###3      | 40/118 [00:04<00:09,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6145, step=140992:  34%|###3      | 40/118 [00:05<00:09,  8.19it/s]\u001b[A\n",
            "epoch=02, loss=0.6145, step=140992:  35%|###4      | 41/118 [00:05<00:09,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6159, step=141504:  35%|###4      | 41/118 [00:05<00:09,  8.17it/s]\u001b[A\n",
            "epoch=02, loss=0.6159, step=141504:  36%|###5      | 42/118 [00:05<00:09,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6262, step=142016:  36%|###5      | 42/118 [00:05<00:09,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6262, step=142016:  36%|###6      | 43/118 [00:05<00:09,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6236, step=142528:  36%|###6      | 43/118 [00:05<00:09,  8.23it/s]\u001b[A\n",
            "epoch=02, loss=0.6236, step=142528:  37%|###7      | 44/118 [00:05<00:09,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6215, step=143040:  37%|###7      | 44/118 [00:05<00:09,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6215, step=143040:  38%|###8      | 45/118 [00:05<00:08,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6141, step=143552:  38%|###8      | 45/118 [00:05<00:08,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6141, step=143552:  39%|###8      | 46/118 [00:05<00:08,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6268, step=144064:  39%|###8      | 46/118 [00:05<00:08,  8.21it/s]\u001b[A\n",
            "epoch=02, loss=0.6268, step=144064:  40%|###9      | 47/118 [00:05<00:08,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6223, step=144576:  40%|###9      | 47/118 [00:05<00:08,  8.11it/s]\u001b[A\n",
            "epoch=02, loss=0.6223, step=144576:  41%|####      | 48/118 [00:05<00:08,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6299, step=145088:  41%|####      | 48/118 [00:06<00:08,  8.14it/s]\u001b[A\n",
            "epoch=02, loss=0.6299, step=145088:  42%|####1     | 49/118 [00:06<00:08,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6162, step=145600:  42%|####1     | 49/118 [00:06<00:08,  8.05it/s]\u001b[A\n",
            "epoch=02, loss=0.6162, step=145600:  42%|####2     | 50/118 [00:06<00:08,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6256, step=146112:  42%|####2     | 50/118 [00:06<00:08,  8.15it/s]\u001b[A\n",
            "epoch=02, loss=0.6256, step=146112:  43%|####3     | 51/118 [00:06<00:08,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6218, step=146624:  43%|####3     | 51/118 [00:06<00:08,  8.19it/s]\u001b[A\n",
            "epoch=02, loss=0.6218, step=146624:  44%|####4     | 52/118 [00:06<00:08,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6317, step=147136:  44%|####4     | 52/118 [00:06<00:08,  8.14it/s]\u001b[A\n",
            "epoch=02, loss=0.6317, step=147136:  45%|####4     | 53/118 [00:06<00:07,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6283, step=147648:  45%|####4     | 53/118 [00:06<00:07,  8.23it/s]\u001b[A\n",
            "epoch=02, loss=0.6283, step=147648:  46%|####5     | 54/118 [00:06<00:07,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6284, step=148160:  46%|####5     | 54/118 [00:06<00:07,  8.19it/s]\u001b[A\n",
            "epoch=02, loss=0.6284, step=148160:  47%|####6     | 55/118 [00:06<00:07,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6183, step=148672:  47%|####6     | 55/118 [00:06<00:07,  8.15it/s]\u001b[A\n",
            "epoch=02, loss=0.6183, step=148672:  47%|####7     | 56/118 [00:06<00:07,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6263, step=149184:  47%|####7     | 56/118 [00:06<00:07,  8.12it/s]\u001b[A\n",
            "epoch=02, loss=0.6263, step=149184:  48%|####8     | 57/118 [00:06<00:07,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6174, step=149696:  48%|####8     | 57/118 [00:07<00:07,  8.17it/s]\u001b[A\n",
            "epoch=02, loss=0.6174, step=149696:  49%|####9     | 58/118 [00:07<00:07,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6149, step=150208:  49%|####9     | 58/118 [00:07<00:07,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6149, step=150208:  50%|#####     | 59/118 [00:07<00:07,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6327, step=150720:  50%|#####     | 59/118 [00:07<00:07,  8.23it/s]\u001b[A\n",
            "epoch=02, loss=0.6327, step=150720:  51%|#####     | 60/118 [00:07<00:07,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6209, step=151232:  51%|#####     | 60/118 [00:07<00:07,  8.22it/s]\u001b[A\n",
            "epoch=02, loss=0.6209, step=151232:  52%|#####1    | 61/118 [00:07<00:06,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6185, step=151744:  52%|#####1    | 61/118 [00:07<00:06,  8.24it/s]\u001b[A\n",
            "epoch=02, loss=0.6185, step=151744:  53%|#####2    | 62/118 [00:07<00:06,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6258, step=152256:  53%|#####2    | 62/118 [00:07<00:06,  8.26it/s]\u001b[A\n",
            "epoch=02, loss=0.6258, step=152256:  53%|#####3    | 63/118 [00:07<00:06,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6232, step=152768:  53%|#####3    | 63/118 [00:07<00:06,  8.14it/s]\u001b[A\n",
            "epoch=02, loss=0.6232, step=152768:  54%|#####4    | 64/118 [00:07<00:06,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6136, step=153280:  54%|#####4    | 64/118 [00:07<00:06,  8.18it/s]\u001b[A\n",
            "epoch=02, loss=0.6136, step=153280:  55%|#####5    | 65/118 [00:07<00:06,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6177, step=153792:  55%|#####5    | 65/118 [00:08<00:06,  8.11it/s]\u001b[A\n",
            "epoch=02, loss=0.6177, step=153792:  56%|#####5    | 66/118 [00:08<00:06,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6333, step=154304:  56%|#####5    | 66/118 [00:08<00:06,  8.15it/s]\u001b[A\n",
            "epoch=02, loss=0.6333, step=154304:  57%|#####6    | 67/118 [00:08<00:06,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6168, step=154816:  57%|#####6    | 67/118 [00:08<00:06,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6168, step=154816:  58%|#####7    | 68/118 [00:08<00:06,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6184, step=155328:  58%|#####7    | 68/118 [00:08<00:06,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6184, step=155328:  58%|#####8    | 69/118 [00:08<00:05,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6106, step=155840:  58%|#####8    | 69/118 [00:08<00:05,  8.17it/s]\u001b[A\n",
            "epoch=02, loss=0.6106, step=155840:  59%|#####9    | 70/118 [00:08<00:05,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6188, step=156352:  59%|#####9    | 70/118 [00:08<00:05,  8.04it/s]\u001b[A\n",
            "epoch=02, loss=0.6188, step=156352:  60%|######    | 71/118 [00:08<00:05,  7.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6320, step=156864:  60%|######    | 71/118 [00:08<00:05,  7.88it/s]\u001b[A\n",
            "epoch=02, loss=0.6320, step=156864:  61%|######1   | 72/118 [00:08<00:05,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6107, step=157376:  61%|######1   | 72/118 [00:08<00:05,  7.94it/s]\u001b[A\n",
            "epoch=02, loss=0.6107, step=157376:  62%|######1   | 73/118 [00:08<00:05,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6329, step=157888:  62%|######1   | 73/118 [00:09<00:05,  7.93it/s]\u001b[A\n",
            "epoch=02, loss=0.6329, step=157888:  63%|######2   | 74/118 [00:09<00:05,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6162, step=158400:  63%|######2   | 74/118 [00:09<00:05,  8.04it/s]\u001b[A\n",
            "epoch=02, loss=0.6162, step=158400:  64%|######3   | 75/118 [00:09<00:05,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6187, step=158912:  64%|######3   | 75/118 [00:09<00:05,  8.07it/s]\u001b[A\n",
            "epoch=02, loss=0.6187, step=158912:  64%|######4   | 76/118 [00:09<00:05,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6166, step=159424:  64%|######4   | 76/118 [00:09<00:05,  8.18it/s]\u001b[A\n",
            "epoch=02, loss=0.6166, step=159424:  65%|######5   | 77/118 [00:09<00:05,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6316, step=159936:  65%|######5   | 77/118 [00:09<00:05,  7.90it/s]\u001b[A\n",
            "epoch=02, loss=0.6316, step=159936:  66%|######6   | 78/118 [00:09<00:05,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6262, step=160448:  66%|######6   | 78/118 [00:09<00:05,  7.98it/s]\u001b[A\n",
            "epoch=02, loss=0.6262, step=160448:  67%|######6   | 79/118 [00:09<00:04,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6151, step=160960:  67%|######6   | 79/118 [00:09<00:04,  7.83it/s]\u001b[A\n",
            "epoch=02, loss=0.6151, step=160960:  68%|######7   | 80/118 [00:09<00:04,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6257, step=161472:  68%|######7   | 80/118 [00:09<00:04,  7.89it/s]\u001b[A\n",
            "epoch=02, loss=0.6257, step=161472:  69%|######8   | 81/118 [00:09<00:04,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6144, step=161984:  69%|######8   | 81/118 [00:10<00:04,  7.95it/s]\u001b[A\n",
            "epoch=02, loss=0.6144, step=161984:  69%|######9   | 82/118 [00:10<00:04,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6297, step=162496:  69%|######9   | 82/118 [00:10<00:04,  8.03it/s]\u001b[A\n",
            "epoch=02, loss=0.6297, step=162496:  70%|#######   | 83/118 [00:10<00:04,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6117, step=163008:  70%|#######   | 83/118 [00:10<00:04,  8.05it/s]\u001b[A\n",
            "epoch=02, loss=0.6117, step=163008:  71%|#######1  | 84/118 [00:10<00:04,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6279, step=163520:  71%|#######1  | 84/118 [00:10<00:04,  8.13it/s]\u001b[A\n",
            "epoch=02, loss=0.6279, step=163520:  72%|#######2  | 85/118 [00:10<00:04,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6313, step=164032:  72%|#######2  | 85/118 [00:10<00:04,  8.17it/s]\u001b[A\n",
            "epoch=02, loss=0.6313, step=164032:  73%|#######2  | 86/118 [00:10<00:03,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6165, step=164544:  73%|#######2  | 86/118 [00:10<00:03,  8.11it/s]\u001b[A\n",
            "epoch=02, loss=0.6165, step=164544:  74%|#######3  | 87/118 [00:10<00:03,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6113, step=165056:  74%|#######3  | 87/118 [00:10<00:03,  8.12it/s]\u001b[A\n",
            "epoch=02, loss=0.6113, step=165056:  75%|#######4  | 88/118 [00:10<00:03,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6315, step=165568:  75%|#######4  | 88/118 [00:10<00:03,  8.05it/s]\u001b[A\n",
            "epoch=02, loss=0.6315, step=165568:  75%|#######5  | 89/118 [00:10<00:03,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6259, step=166080:  75%|#######5  | 89/118 [00:11<00:03,  8.08it/s]\u001b[A\n",
            "epoch=02, loss=0.6259, step=166080:  76%|#######6  | 90/118 [00:11<00:03,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6283, step=166592:  76%|#######6  | 90/118 [00:11<00:03,  8.15it/s]\u001b[A\n",
            "epoch=02, loss=0.6283, step=166592:  77%|#######7  | 91/118 [00:11<00:03,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6082, step=167104:  77%|#######7  | 91/118 [00:11<00:03,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6082, step=167104:  78%|#######7  | 92/118 [00:11<00:03,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6327, step=167616:  78%|#######7  | 92/118 [00:11<00:03,  8.18it/s]\u001b[A\n",
            "epoch=02, loss=0.6327, step=167616:  79%|#######8  | 93/118 [00:11<00:03,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6262, step=168128:  79%|#######8  | 93/118 [00:11<00:03,  8.22it/s]\u001b[A\n",
            "epoch=02, loss=0.6262, step=168128:  80%|#######9  | 94/118 [00:11<00:02,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6307, step=168640:  80%|#######9  | 94/118 [00:11<00:02,  8.19it/s]\u001b[A\n",
            "epoch=02, loss=0.6307, step=168640:  81%|########  | 95/118 [00:11<00:02,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6056, step=169152:  81%|########  | 95/118 [00:11<00:02,  8.12it/s]\u001b[A\n",
            "epoch=02, loss=0.6056, step=169152:  81%|########1 | 96/118 [00:11<00:02,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6127, step=169664:  81%|########1 | 96/118 [00:11<00:02,  8.12it/s]\u001b[A\n",
            "epoch=02, loss=0.6127, step=169664:  82%|########2 | 97/118 [00:11<00:02,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6092, step=170176:  82%|########2 | 97/118 [00:12<00:02,  8.07it/s]\u001b[A\n",
            "epoch=02, loss=0.6092, step=170176:  83%|########3 | 98/118 [00:12<00:02,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6224, step=170688:  83%|########3 | 98/118 [00:12<00:02,  8.16it/s]\u001b[A\n",
            "epoch=02, loss=0.6224, step=170688:  84%|########3 | 99/118 [00:12<00:02,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6170, step=171200:  84%|########3 | 99/118 [00:12<00:02,  8.19it/s]\u001b[A\n",
            "epoch=02, loss=0.6170, step=171200:  85%|########4 | 100/118 [00:12<00:02,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6119, step=171712:  85%|########4 | 100/118 [00:12<00:02,  8.13it/s]\u001b[A\n",
            "epoch=02, loss=0.6119, step=171712:  86%|########5 | 101/118 [00:12<00:02,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6203, step=172224:  86%|########5 | 101/118 [00:12<00:02,  8.16it/s]\u001b[A\n",
            "epoch=02, loss=0.6203, step=172224:  86%|########6 | 102/118 [00:12<00:01,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6207, step=172736:  86%|########6 | 102/118 [00:12<00:01,  8.20it/s]\u001b[A\n",
            "epoch=02, loss=0.6207, step=172736:  87%|########7 | 103/118 [00:12<00:01,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6243, step=173248:  87%|########7 | 103/118 [00:12<00:01,  8.24it/s]\u001b[A\n",
            "epoch=02, loss=0.6243, step=173248:  88%|########8 | 104/118 [00:12<00:01,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6066, step=173760:  88%|########8 | 104/118 [00:12<00:01,  8.17it/s]\u001b[A\n",
            "epoch=02, loss=0.6066, step=173760:  89%|########8 | 105/118 [00:12<00:01,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6225, step=174272:  89%|########8 | 105/118 [00:13<00:01,  8.17it/s]\u001b[A\n",
            "epoch=02, loss=0.6225, step=174272:  90%|########9 | 106/118 [00:13<00:01,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6141, step=174784:  90%|########9 | 106/118 [00:13<00:01,  8.21it/s]\u001b[A\n",
            "epoch=02, loss=0.6141, step=174784:  91%|######### | 107/118 [00:13<00:01,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6021, step=175296:  91%|######### | 107/118 [00:13<00:01,  8.23it/s]\u001b[A\n",
            "epoch=02, loss=0.6021, step=175296:  92%|#########1| 108/118 [00:13<00:01,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6089, step=175808:  92%|#########1| 108/118 [00:13<00:01,  8.26it/s]\u001b[A\n",
            "epoch=02, loss=0.6089, step=175808:  92%|#########2| 109/118 [00:13<00:01,  8.30it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6214, step=176320:  92%|#########2| 109/118 [00:13<00:01,  8.30it/s]\u001b[A\n",
            "epoch=02, loss=0.6214, step=176320:  93%|#########3| 110/118 [00:13<00:00,  8.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6226, step=176832:  93%|#########3| 110/118 [00:13<00:00,  8.29it/s]\u001b[A\n",
            "epoch=02, loss=0.6226, step=176832:  94%|#########4| 111/118 [00:13<00:00,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6109, step=177344:  94%|#########4| 111/118 [00:13<00:00,  8.14it/s]\u001b[A\n",
            "epoch=02, loss=0.6109, step=177344:  95%|#########4| 112/118 [00:13<00:00,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6348, step=177856:  95%|#########4| 112/118 [00:13<00:00,  8.18it/s]\u001b[A\n",
            "epoch=02, loss=0.6348, step=177856:  96%|#########5| 113/118 [00:13<00:00,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6133, step=178368:  96%|#########5| 113/118 [00:13<00:00,  8.25it/s]\u001b[A\n",
            "epoch=02, loss=0.6133, step=178368:  97%|#########6| 114/118 [00:13<00:00,  8.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6231, step=178880:  97%|#########6| 114/118 [00:14<00:00,  8.29it/s]\u001b[A\n",
            "epoch=02, loss=0.6231, step=178880:  97%|#########7| 115/118 [00:14<00:00,  8.32it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6081, step=179392:  97%|#########7| 115/118 [00:14<00:00,  8.32it/s]\u001b[A\n",
            "epoch=02, loss=0.6081, step=179392:  98%|#########8| 116/118 [00:14<00:00,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=02, loss=0.6170, step=179904:  98%|#########8| 116/118 [00:14<00:00,  8.28it/s]\u001b[A\n",
            "epoch=02, loss=0.6170, step=179904:  99%|#########9| 117/118 [00:14<00:00,  8.28it/s]\u001b[A\n",
            "epoch=02, loss=0.6403, step=180000:  99%|#########9| 117/118 [00:14<00:00,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"497c7c8f-f33c-4c95-9137-776b9eaffb3a\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"497c7c8f-f33c-4c95-9137-776b9eaffb3a\")) {                    Plotly.newPlot(                        \"497c7c8f-f33c-4c95-9137-776b9eaffb3a\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAcHUlEQVR4Xu2Za5RtV1Xn\\u002f3POtfbe51WPW\\u002feRJ5grBkhIEIwSoEkiBIUIiEJARBAaUCDIw4jQAh0QBLtDgDgwDFASfGHHKDiMmqCxwyuABBAEB\\u002fKGPO5N7qNunarz2HuvNefsD3WrbtW5t4XRgw+tw9+Xvef\\u002ff\\u002fZZ48y91pprrUO78Z+cCJ4V\\u002fpN1\\u002ft0mZu+nPzsrfV\\u002f595qYN9942hdnte8rs4k59+r9V58zo\\u002f3\\u002fx66\\u002ffu7iv75iVv2+MpOYs2+41C+9Ybu2lVfsv\\u002ffhsxoAoL\\u002f7mS8rZkUAe+\\u002f\\u002fnHv379+\\u002ff\\u002f91cdY6xqO++IOzEnhhYeHy11635133fufXZr29Vz0Ub3rdkVn5e6X7oS+cPqsdR9gWPeTaOR+1O877Qtomb\\u002fL0XzH4rAjgPi857wHA7tfM6vf\\u002fuSfySeYA8JNXvna0IZ+\\u002f42+PfQbAD39hW4hTi\\u002fMeNv8EANj35ktG\\u002f\\u002fKJ7S6w42Jg\\u002f22z6vfEnp1YeeSDv\\u002f7dk7o1MZ1zrtkDfPOd77nxt6\\u002feIm\\u002fh9HJWAYD7\\u002fdJTK7p7dOaTrvv6jPOai4\\u002fdP+39n964feQZ2xJD9zmVtsYP+ou5o3f225MP3LPyja0mgL3XEJ5784y4hRfFM5+Cr10wK+OBzzsde0\\u002fD75xJ+4\\u002fvvg+99PwH4PX3nH\\u002fD59bjrYm58mcB4NzeJx75wC3qFi54Hr72CwdnxMHrntwHvvn0eNvSjhkLH7kYh95PjvMesU1+2u3bwj3P+vNtGb3ryBwAfHb1kemEo\\u002frS02555T2z4gYPf8AjLiE49n7sUbPWI58JNH\\u002f+qJfCrz+ux\\u002fz0m5botqUrQDt+eV3YkphzH0v4xN9fce+Xho\\u002fa9gI3+bHfmcPv3jWrXvILAL596b4zZg0A77sJ+QCA\\u002fkdPwk2f35Rnvv7t+Oa2eOUNj\\u002f3im\\u002fGlp03u\\u002f4Jt+lH++kF3\\u002fvcT52X3u++LuS594VwA3J11X\\u002fliXH\\u002f4msNnX7906MYZSx7yts4n3\\u002faP5e9dhI1RfSwxZ98w8H944cPf8ieH\\u002f8Uee86JauHT9+C241\\u002fhk4A7\\u002f+mN+\\u002fBDswYA3bd+\\u002ffEFYF+7oZ61a+NunQE+sl246WPjs5\\u002f5rgm+cty0C+BxP+J\\u002fVc+KAIALrjoVAP7L8o6Trj4FX521u50733wAZ7x85+StzYz11LfjIy8Y4ckXYd\\u002f1R6XNxOy9bO7wgevHt9wCANWLXryhH2PHz9vwHbMi8KvP\\u002fvC3DgGY+bVbefIvVMD\\u002f2Awf09niAbvui\\u002f3bBGCENTzzgyea5jH3MGBlP4AXnII3bLcuOxVo3vi5b+DIL52COy\\u002fbbgI3PvrM171q8IbHHnnH+2acV7\\u002fMr3vLCHg58JrDR7WNxBSvv3j0ki9URyOctnFzjNOvBd778VkVuPfK9et52+VjPOWlPxCBL+VN4X74yhYbV+z6xma92uTKcx9x4YdnRQCwB7N9CnihP+90vPjBW4fURecBd73k0wBwMnDT8hYLAPClz5z5qAt\\u002f8zS89b0zxuUva299Y43yolPpbZtz+kZizr0Yz\\u002f7khnhCHn0WPvaeWfEoz++SPxC3f2ZWP\\u002f3SC4CHObD2plu2dv\\u002fPb971H\\u002f3Ui\\u002fC21WPWUSaX33LVbZ+\\u002f7vhO8\\u002fDz7a5lnP2wn8Rk3\\u002f3e+8tbprwXdXD7Wz8NYP4xD8ft\\u002f3DMOEq7hj3Xkv\\u002fJTTP63HP81ucAZ1zzYNz4u5vqRmJeT584lhe242ffx78W\\u002f\\u002fgra7MqAHTuf\\u002fnFYMO9L7MZ54F\\u002fsNHzPvVH24wFAGfTBScXT+Hp59ows4wBAHz7pVdfemn3zw7MyP374N4bvrX3sscd\\u002fsi7Bh\\u002fYKOsAgD\\u002fcsfqiAwDwi6\\u002fGv75g9kEAdwHALdccnfc2KZbwmp0\\u002f97gH9Nz\\u002ffLKpHk3MYx\\u002fkH9rUYP6lY8E6p18LfGe2UgNAOOfaPfW9tz+6A7nk92bXhUQA2ICfeMyWN1j7lS8HzqI8\\u002fcr7v\\u002fCJg5+vZpc\\u002fAIC\\u002f\\u002fdbrL3jN6W+fqT8\\u002f9kb80VW7Xn\\u002fx6MYr9l45+vjWGvk3f7N+\\u002fYnLkf\\u002fwBHnh8wn4+2fNymgPL33GgXvW9iz\\u002f3TH1aGKq4tBfbkjFK\\u002fGxN20EG\\u002fyKAb8zKwKIj74Ob\\u002f34pxc+8AAsvfbumzYrDwDgyz\\u002fz1FsbAD\\u002f\\u002f\\u002fG3yq+78UQB33fzVzwLAs3Z+Z5u7yZdf8JNXP\\u002fuMp20XzwKuwnUPxbM\\u002fed5f4d0zs+86f+B4zfYOus57fspxonX76i\\u002f+8eK3b\\u002f5fK+\\u002fe88Et6sZQQrOR4+IVl+1713hDPsrZFwI3z65AAYRfvwz\\u002f+\\u002fdXl97\\u002fwPadD3zcuz76zhVs7Wx3vQMAcOX2xOCdW4NH4a+3hltYveFt4eGP2L4hmKebcfbpdMUn915DV5xwyvsNNhy3iQD2POMJ\\u002fs\\u002f\\u002f8oydszqAz50FAOc\\u002fwra+oc3EbIyksy978s3\\u002fdUPc5M8W8LmXzooAv\\u002frFkzd9cPWH33zON3\\u002f9tv6PPuVxf4a7f3T2Q8CPzwrbmZ0Nj3LWEx4S8NXZiuAOmJ\\u002f1ufKOJ51wxovnmL9m+4IRAHDBq\\u002fCWax\\u002f\\u002fjONWN5tU5n+5JTyaGKLHvxYA8MJXzP3FS7b4R9lhuHa2FwF49ounv\\u002fbhH3nGY6qr\\u002fnQfRrfe+jNPwes2zXDRx9cr0TOOG5jfAz\\u002f4\\u002fEt2A3rvTN\\u002f\\u002f0GWPO+\\u002fsPp5Gh996wtVv56kX4gN\\u002fcfyAecRv4Vkf3X057pw1Nvnw9vBoYtx3\\u002f9b7j\\u002fzIpWefctet123\\u002fBABczcD2\\u002fc06l4Mve+UZwJVXrxekD24ZpQ97+YXn7QOwcPEbOqhPvFYFANAZx5V57P7Z594HwOffsaUkAADaaedGBzC68fh6DKB\\u002f1RPxuvcenxdcOPeJvw+PHdDG+u14Ltoebg4lee4T1vYCn\\u002fnY\\u002f9xqr3P2hdZee6KSdGCpPBu3fOqmO2YLNYC3PAAvGQG48FzHbe\\u002f7Nw4JfPawDLvu\\u002f+YfAvDZa2467if+8y+\\u002f8JHA9V\\u002f+4uwQW+fkJ+Lbvz8rAoC7h8f\\u002f1sofv2\\u002fW2OQHtodHE\\u002fOZf3oIdu\\u002fC8l+uD6gZ5nfhnhMWgJ9+\\u002fDmH\\u002fnRltkhv8pz1y6EPvXZ2c7KN8zb2J+ssvPVB9wVw+7tuPVE3W9+z\\u002fF+43wvxjWfMigCAJRy+4Xy8bEs9nuUfedvbPZqY\\u002fc\\u002f9xVcA7\\u002fmDb231vjujG47fVG7w0uc9HQC+Pf3UH3951tvG9sXkQy97yMkApr939bHF1vfMrz4Z771rVgQAfA1PpCPXfnRW3sKXv3nfH9gy0DaG0oErj255TsTXb3\\u002fYrPTd+dKr\\u002funVCzd95OYTLLW28Q9P2hZecgnw1b\\u002fTa47fJXx37j\\u002fAH31sVlzn+nj55z\\u002f07ll1G+94+3\\u002f7jWNFi\\u002f4j\\u002feH2uhfd+fMnWGx9j\\u002fR\\u002f\\u002f4K\\u002fedlmNz1u4vv3zIdxxf97XjB6\\u002fvt+6tipwn+oHvP9JHQmRJKggdSl9VxqIAeRBaraMXNIToJMroWDWg4qlAlld1WUyJhYWYnZncjJkwk6YVWUYUys5EQEY3L21oJ3ZI2VyRhsZC4MAzmgJt4J\\u002f4YXj7VHRsxuRE5IJujQmphAGWykFsRdBcau7B2MxIMZE2cyDQzPwipQoAojdoESk5K6CEwFxlBCRXtSQW0AeWLzmryrIbGHVCRmhBwTgkoCQkjmRE2oWjhx22sYzuZeGEDk7mA3dodR0QicHB6NnOCkxMhigHLZEozdENyJQA4ncyIjo7Il902PsO4xjIzKht3Z3aM7EbC1vZjBKq5gUjBYGW4MUXILriELGRk5sZIxzAvlzNAyYz1HBAO7KMNMwMpuoUUSSgLv1MYFShMvuNYqdxhTj4mhziKMrO7dJka4sYMVKZKyS2JmIkABDW4wQJEiGRtnosBwECgHwJ1JKQc2IlZiAjsbYMGcjKCUA2164lj3sO6lSCoumYTBDnNo8PXPsEEcDGNxFyMYg5TIiFSCC4GISKCkkMwEAxuzikEcBGOBsWLLc4GiZ+6YYcJRqp6baGq4RkhBBY3kwjyriQEdkmCexL1wJ4EzmAKYOICQW4VBYMQc1JmEIpg5kiO3GQ6hFkTMTi7OAiIBk6qyEci2ekQkLpS3euJEjAAmFhDlpGRgMiKGwp3hYgTRSC5wBCciMJJYABwKRy6ISxgK9QBlmBgRTJSdc0HYfM5oF2diFEjWK5fmu3Psa6uHR+OV0grUQdzh7mXuYBAqQt2mxiacI5HBGczMnaIXxWjcrmk2acmJzcEuwtwtBkUwjJthzpnT0UFHIAEXRSdEo6ad5qShpWMecRE7MRrVWzyDM0iIq6Ibg9GkHWnW0AIEggNgZ8QopbNmyymTOlNiMmewBqs4FsRIyDklt\\u002fXMgEDOKIKUTp49pwx1pqAUOKO1QbF756mnnD7Io+Hd+++6B2vQNoaEmIOSa+7N7VqwdrwytkYoUFMA8IBQ9Qb9XocpTVe6a622RXaYwy2Cu\\u002f35uX43ehoNO2tN20Z1dwLAHIpOp9\\u002ftCHu7MlmrNRVmMAAQCkWn2+92hG3TU9h6e1J1+4Nuh0mnw95aoymqAaTOEA5SdKtuEcTWpuNxzAQ1DsnEhaKg6vQHhWAymYwIWUyZs4kLi4Re2a2iYG06HscEUg1wDTFR1Tn55B86fffOWB2q58rYTotUtQ6mTLAyd2NnYfd9abivSRzMTAsyIqGyqnYOdixU7O10MOwMx5aF3AEKKDvdXfM7d1RBm8lgsDwcqjMUKmAqymqhP7\\u002fQDdB2sFqtTKCAwxhMZVkt9BYWugF5m0ckVJbV0mBxoRJP9dywGo49gxyZHRRDrLr9uflOQboyPOINUQabrk8hkTrdwc7FOWkPDyW5Ql2QCU5RYuz25hb6JeuR1SNeOxQSKGRpC96xtOfMvafvpHI1Tuf38jTts5GRkgp7qUgkO39wT7hrpbdSCmkGgbxgKTs7du6c74ZUSzfA25rFjACPHIrOjl27F3pFnTzOmzUjZlOALXAsOvNLS\\u002fODgJatEywlJzN2ssCxqBaWlub7EU3Z6QRLyWDGTuvfubhz53w35roIkTw16na04ESJnbn5hYVelwodlKZrqbVMDpAEYq\\u002fK\\u002fuLOUzvVqIhND5SmzgonjhziYLC4ODfPZRocMKXQTk0Ck41jHszPn7JrF9\\u002fFK6vgnbyjKEVM2CFt9BzRHfQGnfmWOiOYEQkZeYTETr+3uFDFZjxFN\\u002fSbQnIyd4a4hG6\\u002ftzBfyXhtol3q12XQ5EZsgYQ73e7CfL\\u002fMbRuKoj+JYZrUdd2ret2F+V6VmjYUsT+JYZLVlT1SCJ1+b2G+U7STmjqxX0fJSd0lMxHKsur3F\\u002fqFS6Cy018tWjWYZGazgmLRXez3pVvUHVRjcXM2yUzwIlbd\\u002fkKvQixQlL3VolUjC8pcSKjKPbt3pv0rdxxeHpyWOuXJwxWltSJFiSjIAoKEfjfVh8aTlGuSmoQIBkMnFjw5OJzOxSqTJQOYMxhOxr2ioLWDy6MedU2gDg8wAowMZVGFdnmSBotlAUvmINF1z8uiCs3yOA12lDWsXfew\\u002flxVlDI9tDadi2UiX2\\u002fPCAQypWquwyOSth9LtdYUFtxNiIms7JZBYY1nb5o2Z66Dw5nIzatBJ0xNcxnKpK0qtyF4naqQaWnHYnHkwB13T1YXtZO6uQ4pgwXkZG6oLE0N0+Haam1KofYisyOIxFCgHi4fip0YImk2EzcnQ0FSxJImKwfujVFYyNV8PTseiEMMaMdHVmNHmL1tsrKbAxaIQwjejpdXY4dFvG2zMswYVpCEEFGvLS\\u002fHTggBKamKGwAHiALMxmscgrqmSd1mc2eA3EmDujer\\u002fUKatqmblJDXD8icyIObT+pOMc+W2kndqjqxS6+SuT2nnDSfDn9733e+ds+9K6uV7N7t5FQzZWaFpNQUvbn+ePnekaVsNZOTQ9RNAuV2bWQ8N5jj1lRhYIDECKHk3KyOHIP+XDQnhzkDIDNlEWuHo0y9fmXjnDMZGACbKwe2djg+6mlWMmdyiEElUm5XR8Zzgz41pkrmbAxDbpwit8PxlIqOjg83k9qNKAkrrAEJNQ2o1HTkyOp0mloQVMgo144ozVrdhlC0a8v1pFEjhAAK2ukuntQd3nPgDu\\u002fzYk+94NgnTlXIRU3Utr2cubvTbHWUcgwNWSGWoeLCMTKoLPuLSxpCIk7MiMmdEGJZkiPMdxd30rQwDhlATKRs4BDI0OkOFudq82mmROQxQdmIQ+SMqttfnG8cm56rGHMoGFRW\\u002fcUdWSSBExNihnpwMHuyQTk\\u002fLzYcD6ecnBHNkdk5I+fQ31HhcLs6muZsJhQzzMVB0OyDubmBpiOj1SknEwQiGnf6Jy8GnTQHedwOWlcruqUqFyqsUQ2VC\\u002ff27p4uHxiOOHeZc5oW4pKjGrlwn4udp+2aHCAQiDSmAKSKQBa5s8g7TjsprQkLkXnIbKzRFC65V\\u002fZ2ndQ\\u002frMkIJFkyG+dgBmPul91dJw2WLRuBRDmzS45mZMI9qXaeujRiOIFYYyZlMwWcvFvtWaymo9VpQ6AiIbM7GYKAvFo6Od49Pjysp5EhOTEZuWUnJ6vmTp23leHKpGZQ1XogyZ5DqHbUy8Mid5eoS0uluHCcFHWpFMnqgNhfOm1+cmg0Vuo6s2RwdgQEVoA6ZbVjPrgTmAninD0KAju5d0LcMRdaYicmIoeaCAIZXPrSW+yLqRlAxuseBTJy7nFvcSCuZgRyMlJDQCAFqNfpLs4FdzgRO5ubskCcTKvuzsU5H7X11FJgdcvBSIycDdXC6Yu5rSdNI62www3GjOBk2pk7Zakzbuu6RhvY4MFqk96uXTvW7lkZrrXje+Z8Ny+UsZ0G1tIdmZQ4Ue\\u002fUnXRoZVJzaBmtO7kwWVIzT5Gp6hXisCAe4HAh9mzu1kYtYhmExAtRBgARMjVT1SBFd1DkVk1EgzsgAZ5VVTVI7A4KbdVEcnAnk8Dr7eXoVPVLVtcgLnCQiGowb1Wp3+11R6OVxikwu0AYrgyoIiwNiulkZTXBRBwBEDMV9UaN5rqdcri60jiCkBcIXpdUSi9HXUsK75c7Fhc7rsNm0nrFGYmN28id0vPkyChpIfDYBsSsQQTejDoOy51qskJgD4lIYwuKQtRMJKVUVD2bEDFCIreYHSHA6jHF0KLUdtXBYCX3mI0kwOsxhdCgtLTp2aY3MoJbVfgQYIRMsGjmHMjaUey19dRWR3VmMnF3CmQAO1K2gnIzXpk0mcjBSiQOJyFL0w6lZtocmdTKMIE7Beu3C\\u002f2TBzxdHa2iZumdftKp4cC+Q2MN5hqCa2g9DJb6zT37pqEyBzWVeGbOKVObpnVCi7luNzajBGHOhBxytjJpXVua5MFoEFKdnYgTUSZzp5ymU4uIqLiux07MZr7F04iAStp6YsxsBsqcs1JK0zpTJuuOuRllMJMCiZ2hQZO241CENBk2DQvIAcpCxB6cQySrjyxPpuQkMGH3zGAycXOtp\\u002fUaTYe5pcAEAgWXwrpSRC46lfY7fsrSSVKtDad14LEzpize4f5cVUzlyHTadMUzOXOmLM6gOk3FGgpu2XKb1XH0fCeA6jT16dSDiHNqU3JAmU2cCK3WUAtlbrNao+7wHNY9arV21VjmNqm22QDPgbM4E5o8jZ44mprmNpvDVdjZSNjZoe2k8ok6t3BWGBFRRmCpqirQlEfTpKGGkYN8fdHBCCTQSaETdcnrz3GI4EK87FS7rLK6F+5zSshf+devHylbjuYeKRrFqruAdM+qF0GZSWAGIjP27NoWDbiMkpomG8gd676baUYW73dKtG3TqoOcCWbiCs3WBGGyads4EWcnAczEMzTFJrCw101jxOZOAjIjU9dEiakI1Bz9RkAMTuQehARcJG9HKVMAwZmzOTGHWBVlAR6OmuxGRLD1swoiUBFDZC4abSdZKRDciYMWvDqpl3fTybFHXeQ9lL++dsfhw545JucUUkVlp192Rs14bUIcGApxVkUkkSCBe1TNV5ZGw1HdOoMVhgBGCAF97ywMJI8Or4xrg4ubeSAWkSBlUc2F3K5N66RGRIoNL0oZq0HM7WhSp7zurbcnEqSQcr60tLY6apKzsq6fEYYQqmIwV1RN3TZEcJArwcncY4ydTm+gmI6nmdjdnZQdACHG2Cn7c1KsTtqWyNefC9RyOfxmt3Nmd++0GoWmbu68Y9\\u002fdqzmVbBGGHHKIO\\u002fpFkw8uxyKXOTisVGMGESGwSy8OujwaLi83ydUcYHZ2dyIvqtDpF6PRwQPj2tQdYAKIUUSJg7Jf2GR5OFSFudOGF6PEQdEvbbK8MtR81ON1TxD6cdCh0ZEjyylD3QHJZIG57HW7\\u002fapoJ+O18QTGChKK2QF26cz1e1SvriTNZoA7i4dMRsxlr9cbFDxZm06mDYyzM1NQ5yatfG0Q9hTg3so+\\u002fdbhuw4MD2eRTDmqk3scFDE0fjCPQ0kddQ+tuQaNWWwsUpA0VE8PHVpdSWZGxFmMc2pW2cU5T6ftoUNHDjXJlIhUNCa2aax64EbXVg8eGo+SugGsojGJT2PZBTe2tnbw0Ggt2aaXxSYhlJAG08mhg2vDpK4ESWJByVpVYjT1ysG1cZvMDUZIQcXVEIlF03B0JGkmdacMTsGCkiU3IjSjlYPjaavuDiUJwahYXjuc9u\\u002fuDzBevnf1wMpQx0Ti4oGiURO1Sc2+TloZ9lp4zsFSyF4lyoRpTgrOPEzD8ZFx0gx3spjJYKNc122ukPNwvDJqsoIcHlpOhDSCBMnI9XB1ZZLd3J0tNpzIWwOLJMrNytrKJLu6O3tMlAl1zkac+UheGa2Mk6nD2WIryux5UlUyTfWR4XCS1AEl9qjiAdBpOz1YTFcPaXZkYxi7xyQmDJ3WE5m048Ora7Wqw43YaY4ryu1csRuhcB2mOqdcc4lAI6fSwUqdXrEYYr0yGQLkbuJZLGRnD+5hodctDaltpqnJZiasrM4u8GK+0ynMc2qnqcluzqSsJi6EYq7fKdXatp62ydSNxSk7ewDifK9TqbVtM23bDU9NjrXnKTWT1KiasyjcWEik6g2Koq2n9bRtnAzwQFmcArisqrkQpmvjOlsCbH25AmcBx6o7F4t6Om7q1IAzwwLRfJHF2YUmAZ1RwnzNbVnVAZq57lhUQuhFJc00nVY5WOooObKIOyxkKYuSWN1Mk6kCIIO4wSVLLCOTwj0nt0wA3NkBiMaiiGBFtpzczJ1o0wvlppftqAd2OFhDURYQdbOczBQONmMwSCgWwu6Wc1Z1AozIU\\u002fQAolBGclVPCebuwR0wEwiIuYhCrp6Tqvl6xXLabYCrmE+YhWopqla8A0\\u002fJiqagQkERrZVTsDqFpjvmkrNbNyGLOXEpHs1gbsicYRAvEzKbgwvxYA6HQjmTuSAmqMBZAiOow9TdWN2IEROM4RQ2PLNNr0hQcSMpGMEcZu5KCiUGKyAMDuSEbGSJlckVTDAQC0FETXImJ5UUM4MczgYSBgcHeXLyxFmwfnASumtObcU1FbEuc5\\u002fIysSKbAEDb4Jn8qmWk2kqgohOZereRvMiZEQLEDIkS6KAG5kJGD3KHnOAkHlCZgWg7M7O1HX1wogEZjnkoIA5ubMTulCPx3smTuiSejQRIfO82R5MiKibMwU38gxV8mAkKoAHd3TamjkB7JLMOBIjyfr\\u002foygxpWDGrpwVCE6SA+Dijs7\\u002fAea6aRpFoRvdAAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('497c7c8f-f33c-4c95-9137-776b9eaffb3a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=02, loss=0.6403, step=180000: 100%|##########| 118/118 [00:14<00:00,  8.18it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6322, step=180512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=03, loss=0.6322, step=180512:   1%|          | 1/118 [00:00<00:14,  8.04it/s]\u001b[A\n",
            "epoch=03, loss=0.6286, step=181024:   1%|          | 1/118 [00:00<00:14,  8.04it/s]\u001b[A\n",
            "epoch=03, loss=0.6286, step=181024:   2%|1         | 2/118 [00:00<00:15,  7.63it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6313, step=181536:   2%|1         | 2/118 [00:00<00:15,  7.63it/s]\u001b[A\n",
            "epoch=03, loss=0.6313, step=181536:   3%|2         | 3/118 [00:00<00:14,  7.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6044, step=182048:   3%|2         | 3/118 [00:00<00:14,  7.85it/s]\u001b[A\n",
            "epoch=03, loss=0.6044, step=182048:   3%|3         | 4/118 [00:00<00:14,  7.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6112, step=182560:   3%|3         | 4/118 [00:00<00:14,  7.88it/s]\u001b[A\n",
            "epoch=03, loss=0.6112, step=182560:   4%|4         | 5/118 [00:00<00:14,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6344, step=183072:   4%|4         | 5/118 [00:00<00:14,  8.02it/s]\u001b[A\n",
            "epoch=03, loss=0.6344, step=183072:   5%|5         | 6/118 [00:00<00:13,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6134, step=183584:   5%|5         | 6/118 [00:00<00:13,  8.10it/s]\u001b[A\n",
            "epoch=03, loss=0.6134, step=183584:   6%|5         | 7/118 [00:00<00:13,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6226, step=184096:   6%|5         | 7/118 [00:00<00:13,  8.16it/s]\u001b[A\n",
            "epoch=03, loss=0.6226, step=184096:   7%|6         | 8/118 [00:00<00:13,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6241, step=184608:   7%|6         | 8/118 [00:01<00:13,  8.22it/s]\u001b[A\n",
            "epoch=03, loss=0.6241, step=184608:   8%|7         | 9/118 [00:01<00:13,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6223, step=185120:   8%|7         | 9/118 [00:01<00:13,  8.25it/s]\u001b[A\n",
            "epoch=03, loss=0.6223, step=185120:   8%|8         | 10/118 [00:01<00:13,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6164, step=185632:   8%|8         | 10/118 [00:01<00:13,  8.23it/s]\u001b[A\n",
            "epoch=03, loss=0.6164, step=185632:   9%|9         | 11/118 [00:01<00:13,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6164, step=186144:   9%|9         | 11/118 [00:01<00:13,  8.17it/s]\u001b[A\n",
            "epoch=03, loss=0.6164, step=186144:  10%|#         | 12/118 [00:01<00:12,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6183, step=186656:  10%|#         | 12/118 [00:01<00:12,  8.16it/s]\u001b[A\n",
            "epoch=03, loss=0.6183, step=186656:  11%|#1        | 13/118 [00:01<00:12,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.5993, step=187168:  11%|#1        | 13/118 [00:01<00:12,  8.18it/s]\u001b[A\n",
            "epoch=03, loss=0.5993, step=187168:  12%|#1        | 14/118 [00:01<00:12,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6263, step=187680:  12%|#1        | 14/118 [00:01<00:12,  8.22it/s]\u001b[A\n",
            "epoch=03, loss=0.6263, step=187680:  13%|#2        | 15/118 [00:01<00:12,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6163, step=188192:  13%|#2        | 15/118 [00:01<00:12,  8.26it/s]\u001b[A\n",
            "epoch=03, loss=0.6163, step=188192:  14%|#3        | 16/118 [00:01<00:12,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6140, step=188704:  14%|#3        | 16/118 [00:02<00:12,  8.27it/s]\u001b[A\n",
            "epoch=03, loss=0.6140, step=188704:  14%|#4        | 17/118 [00:02<00:12,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6142, step=189216:  14%|#4        | 17/118 [00:02<00:12,  8.28it/s]\u001b[A\n",
            "epoch=03, loss=0.6142, step=189216:  15%|#5        | 18/118 [00:02<00:12,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6129, step=189728:  15%|#5        | 18/118 [00:02<00:12,  8.28it/s]\u001b[A\n",
            "epoch=03, loss=0.6129, step=189728:  16%|#6        | 19/118 [00:02<00:12,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6142, step=190240:  16%|#6        | 19/118 [00:02<00:12,  8.23it/s]\u001b[A\n",
            "epoch=03, loss=0.6142, step=190240:  17%|#6        | 20/118 [00:02<00:11,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6196, step=190752:  17%|#6        | 20/118 [00:02<00:11,  8.22it/s]\u001b[A\n",
            "epoch=03, loss=0.6196, step=190752:  18%|#7        | 21/118 [00:02<00:11,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6187, step=191264:  18%|#7        | 21/118 [00:02<00:11,  8.19it/s]\u001b[A\n",
            "epoch=03, loss=0.6187, step=191264:  19%|#8        | 22/118 [00:02<00:11,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6098, step=191776:  19%|#8        | 22/118 [00:02<00:11,  8.24it/s]\u001b[A\n",
            "epoch=03, loss=0.6098, step=191776:  19%|#9        | 23/118 [00:02<00:11,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6141, step=192288:  19%|#9        | 23/118 [00:02<00:11,  8.25it/s]\u001b[A\n",
            "epoch=03, loss=0.6141, step=192288:  20%|##        | 24/118 [00:02<00:11,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6298, step=192800:  20%|##        | 24/118 [00:03<00:11,  8.27it/s]\u001b[A\n",
            "epoch=03, loss=0.6298, step=192800:  21%|##1       | 25/118 [00:03<00:11,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6155, step=193312:  21%|##1       | 25/118 [00:03<00:11,  8.25it/s]\u001b[A\n",
            "epoch=03, loss=0.6155, step=193312:  22%|##2       | 26/118 [00:03<00:11,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6263, step=193824:  22%|##2       | 26/118 [00:03<00:11,  8.15it/s]\u001b[A\n",
            "epoch=03, loss=0.6263, step=193824:  23%|##2       | 27/118 [00:03<00:11,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6081, step=194336:  23%|##2       | 27/118 [00:03<00:11,  8.19it/s]\u001b[A\n",
            "epoch=03, loss=0.6081, step=194336:  24%|##3       | 28/118 [00:03<00:10,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6094, step=194848:  24%|##3       | 28/118 [00:03<00:10,  8.25it/s]\u001b[A\n",
            "epoch=03, loss=0.6094, step=194848:  25%|##4       | 29/118 [00:03<00:10,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6382, step=195360:  25%|##4       | 29/118 [00:03<00:10,  8.20it/s]\u001b[A\n",
            "epoch=03, loss=0.6382, step=195360:  25%|##5       | 30/118 [00:03<00:10,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6246, step=195872:  25%|##5       | 30/118 [00:03<00:10,  8.11it/s]\u001b[A\n",
            "epoch=03, loss=0.6246, step=195872:  26%|##6       | 31/118 [00:03<00:10,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6196, step=196384:  26%|##6       | 31/118 [00:03<00:10,  8.01it/s]\u001b[A\n",
            "epoch=03, loss=0.6196, step=196384:  27%|##7       | 32/118 [00:03<00:10,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6069, step=196896:  27%|##7       | 32/118 [00:04<00:10,  8.14it/s]\u001b[A\n",
            "epoch=03, loss=0.6069, step=196896:  28%|##7       | 33/118 [00:04<00:10,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6223, step=197408:  28%|##7       | 33/118 [00:04<00:10,  8.22it/s]\u001b[A\n",
            "epoch=03, loss=0.6223, step=197408:  29%|##8       | 34/118 [00:04<00:10,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6188, step=197920:  29%|##8       | 34/118 [00:04<00:10,  8.20it/s]\u001b[A\n",
            "epoch=03, loss=0.6188, step=197920:  30%|##9       | 35/118 [00:04<00:10,  7.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6226, step=198432:  30%|##9       | 35/118 [00:04<00:10,  7.82it/s]\u001b[A\n",
            "epoch=03, loss=0.6226, step=198432:  31%|###       | 36/118 [00:04<00:10,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6206, step=198944:  31%|###       | 36/118 [00:04<00:10,  7.94it/s]\u001b[A\n",
            "epoch=03, loss=0.6206, step=198944:  31%|###1      | 37/118 [00:04<00:10,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6246, step=199456:  31%|###1      | 37/118 [00:04<00:10,  7.97it/s]\u001b[A\n",
            "epoch=03, loss=0.6246, step=199456:  32%|###2      | 38/118 [00:04<00:09,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6158, step=199968:  32%|###2      | 38/118 [00:04<00:09,  8.07it/s]\u001b[A\n",
            "epoch=03, loss=0.6158, step=199968:  33%|###3      | 39/118 [00:04<00:09,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6001, step=200480:  33%|###3      | 39/118 [00:04<00:09,  8.14it/s]\u001b[A\n",
            "epoch=03, loss=0.6001, step=200480:  34%|###3      | 40/118 [00:04<00:09,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6181, step=200992:  34%|###3      | 40/118 [00:05<00:09,  8.21it/s]\u001b[A\n",
            "epoch=03, loss=0.6181, step=200992:  35%|###4      | 41/118 [00:05<00:09,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6160, step=201504:  35%|###4      | 41/118 [00:05<00:09,  8.23it/s]\u001b[A\n",
            "epoch=03, loss=0.6160, step=201504:  36%|###5      | 42/118 [00:05<00:09,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6326, step=202016:  36%|###5      | 42/118 [00:05<00:09,  8.24it/s]\u001b[A\n",
            "epoch=03, loss=0.6326, step=202016:  36%|###6      | 43/118 [00:05<00:09,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6176, step=202528:  36%|###6      | 43/118 [00:05<00:09,  8.14it/s]\u001b[A\n",
            "epoch=03, loss=0.6176, step=202528:  37%|###7      | 44/118 [00:05<00:09,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6270, step=203040:  37%|###7      | 44/118 [00:05<00:09,  8.18it/s]\u001b[A\n",
            "epoch=03, loss=0.6270, step=203040:  38%|###8      | 45/118 [00:05<00:09,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6233, step=203552:  38%|###8      | 45/118 [00:05<00:09,  8.05it/s]\u001b[A\n",
            "epoch=03, loss=0.6233, step=203552:  39%|###8      | 46/118 [00:05<00:09,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6318, step=204064:  39%|###8      | 46/118 [00:05<00:09,  7.99it/s]\u001b[A\n",
            "epoch=03, loss=0.6318, step=204064:  40%|###9      | 47/118 [00:05<00:08,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6069, step=204576:  40%|###9      | 47/118 [00:05<00:08,  8.09it/s]\u001b[A\n",
            "epoch=03, loss=0.6069, step=204576:  41%|####      | 48/118 [00:05<00:08,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6244, step=205088:  41%|####      | 48/118 [00:06<00:08,  7.87it/s]\u001b[A\n",
            "epoch=03, loss=0.6244, step=205088:  42%|####1     | 49/118 [00:06<00:08,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6152, step=205600:  42%|####1     | 49/118 [00:06<00:08,  7.95it/s]\u001b[A\n",
            "epoch=03, loss=0.6152, step=205600:  42%|####2     | 50/118 [00:06<00:08,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6169, step=206112:  42%|####2     | 50/118 [00:06<00:08,  8.02it/s]\u001b[A\n",
            "epoch=03, loss=0.6169, step=206112:  43%|####3     | 51/118 [00:06<00:08,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6233, step=206624:  43%|####3     | 51/118 [00:06<00:08,  8.00it/s]\u001b[A\n",
            "epoch=03, loss=0.6233, step=206624:  44%|####4     | 52/118 [00:06<00:08,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6226, step=207136:  44%|####4     | 52/118 [00:06<00:08,  7.98it/s]\u001b[A\n",
            "epoch=03, loss=0.6226, step=207136:  45%|####4     | 53/118 [00:06<00:08,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6173, step=207648:  45%|####4     | 53/118 [00:06<00:08,  7.98it/s]\u001b[A\n",
            "epoch=03, loss=0.6173, step=207648:  46%|####5     | 54/118 [00:06<00:08,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6193, step=208160:  46%|####5     | 54/118 [00:06<00:08,  7.87it/s]\u001b[A\n",
            "epoch=03, loss=0.6193, step=208160:  47%|####6     | 55/118 [00:06<00:07,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6199, step=208672:  47%|####6     | 55/118 [00:06<00:07,  8.00it/s]\u001b[A\n",
            "epoch=03, loss=0.6199, step=208672:  47%|####7     | 56/118 [00:06<00:07,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6345, step=209184:  47%|####7     | 56/118 [00:07<00:07,  8.00it/s]\u001b[A\n",
            "epoch=03, loss=0.6345, step=209184:  48%|####8     | 57/118 [00:07<00:07,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6215, step=209696:  48%|####8     | 57/118 [00:07<00:07,  8.04it/s]\u001b[A\n",
            "epoch=03, loss=0.6215, step=209696:  49%|####9     | 58/118 [00:07<00:07,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6180, step=210208:  49%|####9     | 58/118 [00:07<00:07,  8.07it/s]\u001b[A\n",
            "epoch=03, loss=0.6180, step=210208:  50%|#####     | 59/118 [00:07<00:07,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6211, step=210720:  50%|#####     | 59/118 [00:07<00:07,  7.91it/s]\u001b[A\n",
            "epoch=03, loss=0.6211, step=210720:  51%|#####     | 60/118 [00:07<00:07,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6176, step=211232:  51%|#####     | 60/118 [00:07<00:07,  8.00it/s]\u001b[A\n",
            "epoch=03, loss=0.6176, step=211232:  52%|#####1    | 61/118 [00:07<00:07,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.5988, step=211744:  52%|#####1    | 61/118 [00:07<00:07,  8.05it/s]\u001b[A\n",
            "epoch=03, loss=0.5988, step=211744:  53%|#####2    | 62/118 [00:07<00:06,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6123, step=212256:  53%|#####2    | 62/118 [00:07<00:06,  8.10it/s]\u001b[A\n",
            "epoch=03, loss=0.6123, step=212256:  53%|#####3    | 63/118 [00:07<00:06,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6169, step=212768:  53%|#####3    | 63/118 [00:07<00:06,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.6169, step=212768:  54%|#####4    | 64/118 [00:07<00:06,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6230, step=213280:  54%|#####4    | 64/118 [00:08<00:06,  8.15it/s]\u001b[A\n",
            "epoch=03, loss=0.6230, step=213280:  55%|#####5    | 65/118 [00:08<00:06,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6184, step=213792:  55%|#####5    | 65/118 [00:08<00:06,  8.17it/s]\u001b[A\n",
            "epoch=03, loss=0.6184, step=213792:  56%|#####5    | 66/118 [00:08<00:06,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6077, step=214304:  56%|#####5    | 66/118 [00:08<00:06,  8.18it/s]\u001b[A\n",
            "epoch=03, loss=0.6077, step=214304:  57%|#####6    | 67/118 [00:08<00:06,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.5983, step=214816:  57%|#####6    | 67/118 [00:08<00:06,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.5983, step=214816:  58%|#####7    | 68/118 [00:08<00:06,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6238, step=215328:  58%|#####7    | 68/118 [00:08<00:06,  8.09it/s]\u001b[A\n",
            "epoch=03, loss=0.6238, step=215328:  58%|#####8    | 69/118 [00:08<00:05,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6276, step=215840:  58%|#####8    | 69/118 [00:08<00:05,  8.17it/s]\u001b[A\n",
            "epoch=03, loss=0.6276, step=215840:  59%|#####9    | 70/118 [00:08<00:05,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6148, step=216352:  59%|#####9    | 70/118 [00:08<00:05,  8.22it/s]\u001b[A\n",
            "epoch=03, loss=0.6148, step=216352:  60%|######    | 71/118 [00:08<00:05,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6065, step=216864:  60%|######    | 71/118 [00:08<00:05,  8.08it/s]\u001b[A\n",
            "epoch=03, loss=0.6065, step=216864:  61%|######1   | 72/118 [00:08<00:05,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6176, step=217376:  61%|######1   | 72/118 [00:09<00:05,  8.11it/s]\u001b[A\n",
            "epoch=03, loss=0.6176, step=217376:  62%|######1   | 73/118 [00:09<00:05,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6004, step=217888:  62%|######1   | 73/118 [00:09<00:05,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.6004, step=217888:  63%|######2   | 74/118 [00:09<00:05,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6260, step=218400:  63%|######2   | 74/118 [00:09<00:05,  8.17it/s]\u001b[A\n",
            "epoch=03, loss=0.6260, step=218400:  64%|######3   | 75/118 [00:09<00:05,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6224, step=218912:  64%|######3   | 75/118 [00:09<00:05,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.6224, step=218912:  64%|######4   | 76/118 [00:09<00:05,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6092, step=219424:  64%|######4   | 76/118 [00:09<00:05,  8.09it/s]\u001b[A\n",
            "epoch=03, loss=0.6092, step=219424:  65%|######5   | 77/118 [00:09<00:05,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6121, step=219936:  65%|######5   | 77/118 [00:09<00:05,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.6121, step=219936:  66%|######6   | 78/118 [00:09<00:04,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6160, step=220448:  66%|######6   | 78/118 [00:09<00:04,  8.16it/s]\u001b[A\n",
            "epoch=03, loss=0.6160, step=220448:  67%|######6   | 79/118 [00:09<00:04,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6045, step=220960:  67%|######6   | 79/118 [00:09<00:04,  8.19it/s]\u001b[A\n",
            "epoch=03, loss=0.6045, step=220960:  68%|######7   | 80/118 [00:09<00:04,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6273, step=221472:  68%|######7   | 80/118 [00:09<00:04,  8.15it/s]\u001b[A\n",
            "epoch=03, loss=0.6273, step=221472:  69%|######8   | 81/118 [00:09<00:04,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6187, step=221984:  69%|######8   | 81/118 [00:10<00:04,  8.21it/s]\u001b[A\n",
            "epoch=03, loss=0.6187, step=221984:  69%|######9   | 82/118 [00:10<00:04,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6157, step=222496:  69%|######9   | 82/118 [00:10<00:04,  8.27it/s]\u001b[A\n",
            "epoch=03, loss=0.6157, step=222496:  70%|#######   | 83/118 [00:10<00:04,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6080, step=223008:  70%|#######   | 83/118 [00:10<00:04,  8.17it/s]\u001b[A\n",
            "epoch=03, loss=0.6080, step=223008:  71%|#######1  | 84/118 [00:10<00:04,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.5995, step=223520:  71%|#######1  | 84/118 [00:10<00:04,  8.09it/s]\u001b[A\n",
            "epoch=03, loss=0.5995, step=223520:  72%|#######2  | 85/118 [00:10<00:04,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6145, step=224032:  72%|#######2  | 85/118 [00:10<00:04,  8.07it/s]\u001b[A\n",
            "epoch=03, loss=0.6145, step=224032:  73%|#######2  | 86/118 [00:10<00:03,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6163, step=224544:  73%|#######2  | 86/118 [00:10<00:03,  8.09it/s]\u001b[A\n",
            "epoch=03, loss=0.6163, step=224544:  74%|#######3  | 87/118 [00:10<00:03,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6161, step=225056:  74%|#######3  | 87/118 [00:10<00:03,  8.15it/s]\u001b[A\n",
            "epoch=03, loss=0.6161, step=225056:  75%|#######4  | 88/118 [00:10<00:03,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6201, step=225568:  75%|#######4  | 88/118 [00:10<00:03,  8.16it/s]\u001b[A\n",
            "epoch=03, loss=0.6201, step=225568:  75%|#######5  | 89/118 [00:10<00:03,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6180, step=226080:  75%|#######5  | 89/118 [00:11<00:03,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.6180, step=226080:  76%|#######6  | 90/118 [00:11<00:03,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6201, step=226592:  76%|#######6  | 90/118 [00:11<00:03,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.6201, step=226592:  77%|#######7  | 91/118 [00:11<00:03,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6109, step=227104:  77%|#######7  | 91/118 [00:11<00:03,  8.18it/s]\u001b[A\n",
            "epoch=03, loss=0.6109, step=227104:  78%|#######7  | 92/118 [00:11<00:03,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6205, step=227616:  78%|#######7  | 92/118 [00:11<00:03,  8.17it/s]\u001b[A\n",
            "epoch=03, loss=0.6205, step=227616:  79%|#######8  | 93/118 [00:11<00:03,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6238, step=228128:  79%|#######8  | 93/118 [00:11<00:03,  8.20it/s]\u001b[A\n",
            "epoch=03, loss=0.6238, step=228128:  80%|#######9  | 94/118 [00:11<00:02,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6252, step=228640:  80%|#######9  | 94/118 [00:11<00:02,  8.03it/s]\u001b[A\n",
            "epoch=03, loss=0.6252, step=228640:  81%|########  | 95/118 [00:11<00:02,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6025, step=229152:  81%|########  | 95/118 [00:11<00:02,  7.95it/s]\u001b[A\n",
            "epoch=03, loss=0.6025, step=229152:  81%|########1 | 96/118 [00:11<00:02,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6193, step=229664:  81%|########1 | 96/118 [00:11<00:02,  8.03it/s]\u001b[A\n",
            "epoch=03, loss=0.6193, step=229664:  82%|########2 | 97/118 [00:11<00:02,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6151, step=230176:  82%|########2 | 97/118 [00:12<00:02,  8.09it/s]\u001b[A\n",
            "epoch=03, loss=0.6151, step=230176:  83%|########3 | 98/118 [00:12<00:02,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6169, step=230688:  83%|########3 | 98/118 [00:12<00:02,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.6169, step=230688:  84%|########3 | 99/118 [00:12<00:02,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6162, step=231200:  84%|########3 | 99/118 [00:12<00:02,  8.15it/s]\u001b[A\n",
            "epoch=03, loss=0.6162, step=231200:  85%|########4 | 100/118 [00:12<00:02,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6013, step=231712:  85%|########4 | 100/118 [00:12<00:02,  8.08it/s]\u001b[A\n",
            "epoch=03, loss=0.6013, step=231712:  86%|########5 | 101/118 [00:12<00:02,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6147, step=232224:  86%|########5 | 101/118 [00:12<00:02,  8.12it/s]\u001b[A\n",
            "epoch=03, loss=0.6147, step=232224:  86%|########6 | 102/118 [00:12<00:01,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6216, step=232736:  86%|########6 | 102/118 [00:12<00:01,  8.13it/s]\u001b[A\n",
            "epoch=03, loss=0.6216, step=232736:  87%|########7 | 103/118 [00:12<00:01,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6156, step=233248:  87%|########7 | 103/118 [00:12<00:01,  8.19it/s]\u001b[A\n",
            "epoch=03, loss=0.6156, step=233248:  88%|########8 | 104/118 [00:12<00:01,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6256, step=233760:  88%|########8 | 104/118 [00:12<00:01,  8.23it/s]\u001b[A\n",
            "epoch=03, loss=0.6256, step=233760:  89%|########8 | 105/118 [00:12<00:01,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6150, step=234272:  89%|########8 | 105/118 [00:13<00:01,  8.19it/s]\u001b[A\n",
            "epoch=03, loss=0.6150, step=234272:  90%|########9 | 106/118 [00:13<00:01,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6132, step=234784:  90%|########9 | 106/118 [00:13<00:01,  8.21it/s]\u001b[A\n",
            "epoch=03, loss=0.6132, step=234784:  91%|######### | 107/118 [00:13<00:01,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6044, step=235296:  91%|######### | 107/118 [00:13<00:01,  8.14it/s]\u001b[A\n",
            "epoch=03, loss=0.6044, step=235296:  92%|#########1| 108/118 [00:13<00:01,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6181, step=235808:  92%|#########1| 108/118 [00:13<00:01,  7.98it/s]\u001b[A\n",
            "epoch=03, loss=0.6181, step=235808:  92%|#########2| 109/118 [00:13<00:01,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6157, step=236320:  92%|#########2| 109/118 [00:13<00:01,  7.99it/s]\u001b[A\n",
            "epoch=03, loss=0.6157, step=236320:  93%|#########3| 110/118 [00:13<00:01,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6032, step=236832:  93%|#########3| 110/118 [00:13<00:01,  7.98it/s]\u001b[A\n",
            "epoch=03, loss=0.6032, step=236832:  94%|#########4| 111/118 [00:13<00:00,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6125, step=237344:  94%|#########4| 111/118 [00:13<00:00,  8.04it/s]\u001b[A\n",
            "epoch=03, loss=0.6125, step=237344:  95%|#########4| 112/118 [00:13<00:00,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6009, step=237856:  95%|#########4| 112/118 [00:13<00:00,  8.06it/s]\u001b[A\n",
            "epoch=03, loss=0.6009, step=237856:  96%|#########5| 113/118 [00:13<00:00,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6022, step=238368:  96%|#########5| 113/118 [00:14<00:00,  8.04it/s]\u001b[A\n",
            "epoch=03, loss=0.6022, step=238368:  97%|#########6| 114/118 [00:14<00:00,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6192, step=238880:  97%|#########6| 114/118 [00:14<00:00,  8.06it/s]\u001b[A\n",
            "epoch=03, loss=0.6192, step=238880:  97%|#########7| 115/118 [00:14<00:00,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6071, step=239392:  97%|#########7| 115/118 [00:14<00:00,  7.92it/s]\u001b[A\n",
            "epoch=03, loss=0.6071, step=239392:  98%|#########8| 116/118 [00:14<00:00,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=03, loss=0.6131, step=239904:  98%|#########8| 116/118 [00:14<00:00,  7.97it/s]\u001b[A\n",
            "epoch=03, loss=0.6131, step=239904:  99%|#########9| 117/118 [00:14<00:00,  8.05it/s]\u001b[A\n",
            "epoch=03, loss=0.6080, step=240000:  99%|#########9| 117/118 [00:14<00:00,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"caf391f7-6b44-47da-90bf-c8d2db175e42\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"caf391f7-6b44-47da-90bf-c8d2db175e42\")) {                    Plotly.newPlot(                        \"caf391f7-6b44-47da-90bf-c8d2db175e42\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAbNUlEQVR4Xu2YadhlVXXn\\u002f2utvc8599zhHasoqqBQKSUICG0QA0qLRCsqzomIOGHr4yxEiaBNjPhIoji0BgwOOIO0Gu0QFQ3OCkZRWhTFWVGqKKp45\\u002fe+994z7L1Wf3iHet9bJZp+\\u002fND2k\\u002f+Xe\\u002fb\\u002fd88d1tl7rbU3dfCfOph42PhPLeuPNjA7vv\\u002fDYesPqj\\u002fWwLz5+sNvHfb+oBoOzAlXzF1x\\u002fJD3\\u002f542f\\u002f55Yz966bD7B9VQYI679iw76183euv1yrmFhw57AIDWlmednw6bAHYc\\u002fdyFubm5ubmrk2G0Xw\\u002f7+X2HLcjY2NiFF3\\u002fk0Pct7HvVMNtx2Ym4+NWzw\\u002fbvq+ZXfrJ92DtAbsPoT68asW49ftL3qg32mp7+coUNmwCOOO+k+wOHXDDsH332E\\u002flQNQB4zNte1V21HzL+6f3vAfDAWzYMcVjy4D8beQIA3Hnp47o\\u002f\\u002fMZGCozvBPbcMOz+Xjp0AvP\\u002f9b\\u002f8\\u002fHcHdX1g8uPfswX41ds\\u002fcP0lb11nr9PhB5sUuN+LnprR7qWjnvTenw2R1+7cf\\u002f20q761evnQIzcEho84jNaPH\\u002fCpkZUrvaT3z3vnf74eAthxJeEZ1w2Z6\\u002fQyf9SZ+NmDh20c8\\u002fztOPJwvO0o2nPg9D3xrFOOxt\\u002fedcpHb14erw\\u002fM2\\u002f8KAI5v3XjqMevcdTrtBfjZmVNDZud1T24Dv3xS8p2JiSGEr+zE1NVkeNDG9fe0b28YbjnnYxsiumtuBABuXji1+uh6f1VnHf75l+8ZNlf10KMf8jiC4chvnzSMTn0WUH7sYS+HXXPAjHnypRN0w+TrQRPPWTbWBeaEnYQbr3\\u002f93u\\u002fPP2zDA1zTye\\u002fs4LJdw+7jng3g9ifuPnIYAHjfdaj3AWh\\u002f61B8Zv96Gfr4y\\u002fHLDeO51\\u002fzFrW\\u002fCrU\\u002fsHf3CDf6KvnDcHf\\u002f94HHZ8r57odOk7x0PgPNh+upzcc305dPH\\u002fcvE9HAWdQ+8LP\\u002fGm76VfvB0rP7K\\u002fYE57tqOfeG5D3n9h6d\\u002fqDuP\\u002f\\u002f6av19P24Ib\\u002fuewiScCd3z373bjfsMAQNi9\\u002fPrno8CectU9dvPq1bI6+MpG4zNfWzr2We\\u002fo4cfnbfQBAGecaP9SDJsAgNMuOwwATpqZ2HLFNvx0GOeNO16\\u002fF\\u002fc5f7L\\u002fxuH7n3o5vnJOF08+HXdes2KtBWbHeSMze69Zuv56AGi87Hmr\\u002fn5NPFMX3jJsAuee8+VfTQHYNAz26y+f3QD+fm34yMY6Bmw+AndtMIAuFvGsT+qQCwAYORmYvxPAi7bhbzei8w4Dytfe\\u002fHPMvmgb7nj+Rgj86yOPuvj8zj\\u002f8xdxb3jtEXvMKe+\\u002fru8DfABdOr3irgUkv2dl9wS1rv\\u002fiw1Yv92n4V8O6vD7vAXW9Yfj1gSa\\u002fqzFfc2wO3hjXjvvjxOoxLNv9irV6t6Y0nPPS0Lw+bABBPYP134KX2\\u002fO142dHrl9TpDwJ2veBbALAVuG5mHQIA\\u002fODbRz3s4f9wON747iFw4SuqL712gOz0w+jNazl9NTDH78TZN66aB9UjjsXX3jlsruiFOdkxuGljTgWw\\u002fazTgJMNWLz4C4N1\\u002fnfXrtqPeOrpeNPCOras3rlfv+yGW648sDd46Cm6axbH\\u002fdlj0Ntz3w8\\u002fZ13Ke1mOm974LQCjjzwFN31+P1hR2cWWq8g+PFzPRp5nXzobuM97T8C1\\u002f7jmrgbm7+nG\\u002fXFhPTD7PvZifPOFi8MuAOR\\u002fcuFOsGLvi+MQOeaaw1euvvnB9T7GABzLp21NnsLFzaX73ga4rNtf\\u002fE9nnZV\\u002fdO+Q3ToCez\\u002f2yx3nnTHzlcs7n95wNPCB8cXn7QOA\\u002f\\u002fa3+PE5+9ajZe0CgM9fvpL31pRM4IJNT3\\u002fM0S2zj\\u002ffW3JXAPOo4+9yaB7Uf7B8sa\\u002ftVwK\\u002fvHnYB+AdctWWw96ZH5JDHvWu4LyQCwAo8aue6J1jY288HjqXQ\\u002f+nVt3zj7h83htsfAMCnf3XJaa\\u002fd\\u002fpah+nPyG\\u002fDBSzdfsrN77UVHvq379fU18lOfWn599IUIHzhIXORkAq5\\u002f6rCNanryBwbc1d0ysy4GK4HJkqn\\u002ftWqlr8LXLl4drOqvFXjbsAkgecTVeOPXvzX26ftj8uLd161VHgDAbWc89UslgGe+YIP9ijseDGD3Z3\\u002fyHQA4Z\\u002fLXG+iabjvn0Vc85z5P3GgeA1yKq0\\u002fE2Tee9G+4Yij7LusawwUfHDYBvP\\u002fxhoP17Qtnf3zs9uuumXv\\u002flk+uc9eqUrk6adNXnnfnO5ZW7RUddzpw3XAHCsC\\u002f+jx88d0Lk\\u002f98TPWPR5\\u002fx3q++fR7rN727lqvYGzYGBm9fP3gYhruKVS189HL3kFM3tv4jdB2O204X3bjjSrroig1oRX\\u002fHigM2EcChT3+Cfe+HzzhY7bz5PgDwkIfqr9eZa4FZnUXHnffk6565aq7p2lHc\\u002fOJhE5CLzu297hMLD3zz8b98+Q3tB5\\u002f56Gux+wHDbwL+fNjYqOFsuKJjn\\u002fBAh58M\\u002f0czQO2Y27LfPPqgGS85Xu3CjQ0jAOBhF+H173nsM34y7K8pUzvIjCE640IAwEv\\u002fZuTjQ88XAMYVVw7PIgDnnNv\\u002f6y8\\u002f6Ok7s0s\\u002fshvdL37xr87Eq9egP\\u002f3ry5XomSsF\\u002fT+k+77gsYcAcd9QM\\u002fO588446dgWnkYzbzxo95uf+XB84uMHdkCnXoqzvrr5QtwxDNb0pY3DlcCYHfKmq+ZOPOvYbbu+PNz+ALiCgZuGTQAXQs599X2AN\\u002fyP5YL0iU\\u002fsZ6ec\\u002f\\u002fAH7AYwtvOSHIP1xXpIdOQBZR6HPOV5RwC45S2fHQJVP7\\u002feAHSvPbAeA2hd\\u002fgS8+j0HxgUPH7nx3\\u002fyjOnRAd7OmoWm9tpTkeY\\u002fvHgl8++v7O9Q1Hfdwra4c3jwCwL7J9Dh8\\u002ft8\\u002fc8dwoQbwpvvjvC6Ah59guOF9GzPFBtnwYRk2\\u002f8mb7wfg5suuO+Avfu+5LzkVuOZHtx686dr2BNz+rmETAMzMn3Hp\\u002fIcO8tRXdO+Nw5XAfOe7D8QhmzH7yeUFNaTRzbjroAXg0Y89furq+eEivabnLr9Mfe5Vw5uTDXrQRzYMx97+gHsBuOkdXzrYNFves\\u002fwW3e8l+MVfDpsAgAlMX3sKXryuHg\\u002frm7zhKawE5s5nPOeVwDvff5CsdU9a+uhBzwUAAC9+\\u002ftkAcHv\\u002fmx+6bZht0MZm8sRz\\u002f3QrgMG73rq\\u002f2fq9dcGT8Z71rc1+\\u002fQxPpLkrvzpsr9Ntv7zXvVc3Sti\\u002flPa+4R4y5M9uOnnY+t269fz\\u002f\\u002fZrRz3zlswdptTboi0\\u002faMHzs44Cffk4vO3CX8Lt1dBsf\\u002fNqwuaxr\\u002fAW3fO6fht0Neuvlr7lgf9GiDV31H7le97I7nnKQZuv3VPtDp33qJWvT9IDE98esL+Oi\\u002f\\u002fu4oPvs9z1+dW\\u002f3\\u002f9mM+UPKJSULV6i8qEllVaYOBiIVysoKntRApqLqQFY7jkLRLEmXxEDKJkrKDFIikFUmSHlJDDAGK4HIeCNTImWwkhIzFASy2sSy38HWfR8x1j7TMvRk+UiAFREiZspmZEaWWsFEpAQoR3MEC0JBSGGJ9AVEK\\u002feZE1NlLN+aupo8KqG0jkz1gCFKNbPUvuDIjZoD+8iRyXGg6CSiUbGKVQDIAFMhBhmZkljNDIsqBjIyisISYUBksUqILaoD2EBqTEQEM4XTQKKmg9\\u002fBaPkREYPIoHAWSMx0IEKkxJGMlAhQIhjMKbQQrxydi2QCB+MgzqJXMbbKCTg6CaSkECAyQ8lcJCuo4RiqXpH3ImpqVWTiBi4rPVnluCaGOmVCsMhJzcy1wlg5wKtxZJAIEVnNUKNoBlBAoiaBCU4YQM2wwNGMjKM5M45szExECIRIiFAyuWfmTTmysQgRUDMiIZqSyXLQFCDAxEhBkY2hpCQGYyiBySJFYiXjKKZsYCMAChDMxMiMI6tASR15C2hCbdF5a3U0eqoLKlVqV7NVomCoKRmQkjgzdRUSlOzMWIUceWbHQF3XZsZUE9ibEQk58iJOzGJV1aTMFYFhRJHh4BiOCSHUUGIoaB0jOpCBSMjBM3k2qutqmRExlKBMxoAJPCnUIEZExBZZIWRiZBQdyFkkr+S4ZjIyYzI2QMyRkRmcEbFR20cjymKtrWR0tDUhWOzdvdCdb2gSAjsDGOpjIo2EnVYhlnXJwcEAYxNhaaetxJktlfNVrRQAIzKwemEeTTuZgy0VM0UVLQJGRkbGQpKnuXewXtUNtXLFK+vvtzKATISllTa9M1sqF0JQrsgAJoOBwOy8S8F1CKGOHAiITGpMrM4SJ4lKjBbrEA1skcmA5WB6zkAhaqgjIpG56JgCytDyh2zaun3HeOjP7fnVb+7EkkmZciQX2QTsmu3JHKHf7amKMVUCQD37bGR0tJknVi7ON+bKuvLRYAZSz5KPTIx38tzK+fnG9KAsOcAMRuYoSdrtkUbDIfTmm\\u002fNVLNMA3DMDmack7YyM5A2Hcmm+MV+HKg22HDWQkyRpZc1EOHQH3b4FQI0lQlTIeWlmWdM5HQz6S6GKMCVWkJKI960sTx1rd9DraSCoObLg0tKSxqGH79h+6NZmY6qaECmKbJAVpmwKWBLytLVpy4Tr3h1rIR80CkAQJHlr0+T4ROJC2e7M+IXFoCAlmHkkefuQzZs2pUkoW53Mzc+UBo6kAkHayCfGR8YTF6tBZ9Yv9GMkGO6JGUOQ5vmmidFx72LRa88mC72oBEMQAIlkzVZrrJ0xhYUFTyUjGBBIQczeNVsjI53M1XMLEvsOQclqMcBLmrWboyO5cJxfmLGSEYwdsVCR0tjo5iN3HHZIli+6fvsoDmG366sRqTly0bHLJrePyVRZdxMUFI0M5jjJ2mObN4\\u002fmSRGCaxbVgAlQGMwhSVvjm7ZM5Fm\\u002f7KtvjPSEI0WAzbFvtMY2T440XT1wDYmhGBCTHsA81jEyv8JGG74skXTqUPQJUCgbkfNpe2RibDTLgo9j+zR2a2hgZTA5EWl2RsdHJ5O0aDU0GLNGjmwg55JmZ3x8LG+aD2P7TLs1aSBHrq4TbY+Obz90q9\\u002fj5xc0O8QfekfTx+jZINFgnhoTIyP5aHRZ5ciW870JvGs026NtT935QWxy3k8oBDNjMLxkzdZoW2x2rl82NfMZx0gGwJFzWbM1NpK6crGk3Oe9hGNUM9rAusV6xubgXNZsj3Y89xYKy13e91RHXS4CzFmjOT423iIlEW52FnwwJWUVNjiXZc3JTts1Us2T5qKvYKysQkRZ2hwdnWh5Y89odhaSYEbqLLBz3Ghs23povbC0e353sn0wmd97YW6vW2orhJlFG95DnYSqVw9CqKNURiQMAjdEdG5qrmhyIxGLxFEQSZiIJHcSp6en+2loiiMwqVMlZgik4RwtTi+WIy7LRGsDBJGYweB7ZCJYmJovOi5LRQMIAiVicpCsMZLbYmnN0aQBBItkDDKGEGneyagQiUa+jrVGqRlMDAH7fKzJi5EbnTSzlfuclkULUbZs3ZQv7rpram4qLTLbTLUEhUSwgiqJCGU\\u002far\\u002fb61VVDFKrr9nUO0l8gv7M3pnEi3NkpsoUlRXEnKYN6k3tmZL2CDExK5iisakXJ87ZYP7uubThvUMdozGiLn+mOziDJs5559Gb2zeTZs57iqoqFABTJoE4rcvpmryKVd1BHdSMjQjEIYsx9pWsgVAUS2VhtZGZGbGYcAyDWQJH0XJxUIZoxkbNhEa33XvbeLFvz9yvf7H7N7v2iNu2FWQohCNZAKkOouSNpe70XFEGrcAGkAMIbGGwVJK0OqPJSoIhGIsSi7fQ71fErdZolpCQqsryfQqyMFgcQFrtjtQalUC8zAykB2V+hRXdgn17ZMyrmZKBjQisFcBWTM93g8upP1UVFYEpODbREua46A4qUnTnpgZFHcBQZnAsYY6K6YWF4LLYvbscVDAixyJeW+1Nh7mZO3bvCtJyeYiZpKN7EITM1wbTtEqkvUn8YKksIhmiMKJGZ86lKYlLkvbkJhkk5nwFwAUlQZLlDWKW0cbE5oy7kqRBoS5acJHJeRLfyDsTk5a6QBIJWGPJGktkjWn06jhJyfms0ZnYRI1E2dUMk2jKwRubqra4sylb6vbmemlQZqeEQFBY7WxkvJUslrP9bg2Nwi6awtREo2nLdyZ9b647W\\u002figzM45DJqj9zlUwszML7VYIuswpVmmURIz1DAjbw6Nwzdpf6HXL80LoBULcfDRiHw2wjy2fWvoJV6YNEpwRJGYmCRtqba3HiZT85l3HJWjmAtSRyDBiE8mt2\\u002fu7SMmIlIOQ+yITb19vMocuF5ho85NHLGlnHOOiBE5kkmkoAq2Jo1vnsDUYi8IUVJTJCMzdUSMfOywZndmdn6pErIkKsg4UjAlptxvnuwU3bmlWojSGg4SLCRpsnnf7n2xiq0AGWs4AyX9RiUwZxZNkU8ePjrX7Q9q8wq2AIoKR44VTJlz4yPenIMwMYxUzbFzTKauzZ1OQkmC5f0PRYWHUIC4ZiOdHPVMbEIEtmE2sp4FIk\\u002fCAcJ5kkyM+CACR2QMNZgYW9DQyBuj462eDooQiKJpEJCLpLEO7dHDJ6RbDvqFlZ5hZgCzkmmsm62RsTHfrweDEBOKps4WzY1v37pl+rY9d+5Lez2eyNIJ0UFXpExIEQwEEz8x4hZ7\\u002fdIoCIIRjJliFSOTphGOxQXHmUQymJKQRjLS6AhaR3DiGhKMzIyZQxkD2FLWLEsdYIlTVuCgzK8yoVA0A4tloMQnviAs32cQQiSLdSTkeWeEe3MF2Akpm4hpDdZawZ1mXpVzc6XCe6hXMCyIxTKY5c1Ou1iY6SuzIxV1ocosRbuI9UJFMJ+MTh4yEsp9\\u002fX6pxEoGIgW1cg69+bKuPQO+Jk9RxQlJNbC6Kn3StwgweyULroZzwr4ubFAUkHIxYxJyJKo+GpwYlX2B1jFt9xYNTD6wxYMyWWUqIuCyTxrKOu1VfYApqQW1V6g4i8WilxINb91BCQKZKYQMxNB6UAtC0Z8rKnUGJjMSMxOPWHbTrB4MqN8rApMSEOGoXWwa39am\\u002fkJv4DVHevRRO3jm9qle9KWqI4o+ss8baTE7X1NGAVR7VoWLISZ1LIoqLJV5suSq0piFKyD6qLVELaUuFvupFBaMwSQ1IUoMAXUo+kpFaGeLSb+vwk5r0DDr+iFGdSiKqP2ylXbzwUCdSKwIQZQRXQxFj0I78TrTq8WzC2BEIWb15Bh1XXaLsmvGjoxAFgRM0alWgy67JRrMDirxJgoiZ5JaSs438tZ4Sa3ykG1HpPlte+f7zvdBqsyW+Gaeu0JnB4MKYsQA11I5iFFZ9rjoR2anKIsqKhCBmuHBdYW4uBQkzVw6PyiqCFKV2oGJirIXtISoVaEsa1NYJK4dGGvMdD2rPJhQlEu+7psAQYuiUgMCODLAFGOo64HkRQhRSyNTBCEjM2HxznHsJ91eHVkBUhhY2SAwUw1lLx8sBUVthGhRnDdjDb6Z39v\\u002fxtDkbdvz4pbv\\u002f3Qmq8mbAmAvaSNvaJzrK3OAkmkkE6z+Fq5AeSJUllUVTM2EA5Gw1UpEKY+0m42yHvQKU5iwGYCgdYmgkorGQRkNpAah5VOuVcYbmBgIMVZlrCIyR7GoYlSomYBBMBU2iuRRF\\u002fNlcKQGZVYDgX3SSBPHSdEvyghnsBjZVk5InGOGZFYUi5U5MTNlctEn893+1Ca3o7FZ2jFOGn4+94u7p0VDsnygxS5J80Zj0O8uDiKxwZSIg5IHkzjhXBsjI0noTs\\u002f2ikjGqsowMp94NxKy5mRLu3v2LvQqM1JVdsQiwpRRo9PgorvYLWtlUCBlR7SRLa5nzOKI0zQbaUnVnZsvKiVjhTEBIi7zrXajYWVdMMGMo0UyUoEkSdZod2CD3iAwqxpIYcYAxPksbXeStCqqikUDRBVOKnbzt+XJUeOT3ayksrt4x6923dXjInWlV2UVZdfKfN2dXzQFh2iAU2IhhhpplJY021m\\u002fPz29VEQzgwkTW1mHaK7BaavZr++6a3apMlOYCDERPCly12n77sLcXFmrmoFYiIk3smo9A7xF15ROO1nqzc4MyqgwgJWMidMsSVqNPNaL8\\u002f0BjCKIiIMRMUvWzHMJ\\u002fYVeGaIpFETGkUAkaSPLWllW9hYWiwLKAcRwIXqLMz9q2dY0JOnsnf2f7d01M7WIlEsLLhgFQSbCZT3bWyJSjiAJ0aIoopQLBFYfy5lyZnZ6ughBxRDEULmlORprItVBP0wt3L1nUNXKRlGMAyVL5FKTUM70p2cWFiuNysAy87+NUc31ItibhHK2mJ6dnys1RjFENgmIRR4FVKB798JiUQdEM6IgRhqDEoS0WFyYLaoSapHVKAokIJZRBRjU81NL3TIqohnYiYefmt3X3bGl3cJg6q6Z3QuLse9DBKvARTKqeo2lvXnszZma1uqiMmIaWSkuVYNBUed+oV7ozy9VdQ2KZF4JVs2Wi\\u002fMjnYaEcmGw0CvKAA6Ai1wTilBHg4ZePd+bX6pDbTDWZVbG38Ii2SCUVdBm6IX5\\u002fvxSXVdGkdXVEois7mepq1HPz8x1q6AwBasoGxPVvXxJ+kV\\u002f36AoY1S2QBxdkECM0G8suUrLmdn5XqVGppBIvpFYKEaSLbXzUnXr\\u002fkCplNycLppPjEg5aSQd36h6S91IEREMpcARomJwnUbeYNRV1Q9lZRGMmpVYGUjbaZaS1nVdaFEjGmt0EWwClZFmnjNXZTGoq0qjMUVax5q0zMp6jYmJGY\\u002fmec5UV8WgLisLYKphYJBw2mpneax7Ra8sDJEAtuiMhNg1sk6alkvdotQSUMHy6SQTiWR5J8tC2S16dQGKTCpKWRoTo0i8JJQvRbQHvs5dMAqBQgYXAZd4AhSD0hlbTNQiBRIoTAJLlohAVWPQoIBRhJhRlCDInBCUVFU1EMwMTAqTIK6RiDMNGkMMZjCK98SIl79PpJGKIEaNQetlZkQECLkkJTELVaVRCTDAgicGkXjvlaMVdYQqCdRgykQgZu9TE9OqXn5AFAGjDgNQqa3nwK4Wn1aeElSVRh8SdmpkHDWNRgHkysaAHQcLWUAkM5BzltDyhipSEFUxHxFJDRAxDzOjyIGDqAqSmiKbEnmhBNCoikiR1MRcWGbsDmQ+YPU+pDALy9\\u002fHamIcACaQJyIX1bSGEttyoEHMZPAKQTClSMEpAwZlBYSABERSm1oNZUYEkbqsbxRSqiVN+mlsGAdfiWowx62lWjQaEH1ZR\\u002fbEGHChCBzNu6gSBQyzQEGCESKRUmTkiMZRwGZcW+BoRBWrWRTKNZgos5hptCDByCIjShRrWPztDOsYggQDIkMpijVCgJgxBZiyiYIikalEQ1ZXzMGIaglQdgDXYsvrKLFAzpSpIlUyp+DIZCbRLP0\\u002fR3M2JwvGZkEAAAAASUVORK5CYII=\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('caf391f7-6b44-47da-90bf-c8d2db175e42');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=03, loss=0.6080, step=240000: 100%|##########| 118/118 [00:14<00:00,  8.14it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6244, step=240512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=04, loss=0.6244, step=240512:   1%|          | 1/118 [00:00<00:14,  8.26it/s]\u001b[A\n",
            "epoch=04, loss=0.6108, step=241024:   1%|          | 1/118 [00:00<00:14,  8.26it/s]\u001b[A\n",
            "epoch=04, loss=0.6108, step=241024:   2%|1         | 2/118 [00:00<00:14,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6044, step=241536:   2%|1         | 2/118 [00:00<00:14,  8.23it/s]\u001b[A\n",
            "epoch=04, loss=0.6044, step=241536:   3%|2         | 3/118 [00:00<00:14,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6101, step=242048:   3%|2         | 3/118 [00:00<00:14,  8.18it/s]\u001b[A\n",
            "epoch=04, loss=0.6101, step=242048:   3%|3         | 4/118 [00:00<00:14,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6152, step=242560:   3%|3         | 4/118 [00:00<00:14,  8.04it/s]\u001b[A\n",
            "epoch=04, loss=0.6152, step=242560:   4%|4         | 5/118 [00:00<00:13,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6122, step=243072:   4%|4         | 5/118 [00:00<00:13,  8.14it/s]\u001b[A\n",
            "epoch=04, loss=0.6122, step=243072:   5%|5         | 6/118 [00:00<00:13,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6167, step=243584:   5%|5         | 6/118 [00:00<00:13,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6167, step=243584:   6%|5         | 7/118 [00:00<00:13,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6202, step=244096:   6%|5         | 7/118 [00:00<00:13,  8.21it/s]\u001b[A\n",
            "epoch=04, loss=0.6202, step=244096:   7%|6         | 8/118 [00:00<00:13,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6203, step=244608:   7%|6         | 8/118 [00:01<00:13,  8.16it/s]\u001b[A\n",
            "epoch=04, loss=0.6203, step=244608:   8%|7         | 9/118 [00:01<00:13,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6349, step=245120:   8%|7         | 9/118 [00:01<00:13,  8.22it/s]\u001b[A\n",
            "epoch=04, loss=0.6349, step=245120:   8%|8         | 10/118 [00:01<00:13,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6217, step=245632:   8%|8         | 10/118 [00:01<00:13,  8.19it/s]\u001b[A\n",
            "epoch=04, loss=0.6217, step=245632:   9%|9         | 11/118 [00:01<00:13,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6140, step=246144:   9%|9         | 11/118 [00:01<00:13,  8.21it/s]\u001b[A\n",
            "epoch=04, loss=0.6140, step=246144:  10%|#         | 12/118 [00:01<00:12,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6144, step=246656:  10%|#         | 12/118 [00:01<00:12,  8.25it/s]\u001b[A\n",
            "epoch=04, loss=0.6144, step=246656:  11%|#1        | 13/118 [00:01<00:12,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6198, step=247168:  11%|#1        | 13/118 [00:01<00:12,  8.20it/s]\u001b[A\n",
            "epoch=04, loss=0.6198, step=247168:  12%|#1        | 14/118 [00:01<00:12,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6018, step=247680:  12%|#1        | 14/118 [00:01<00:12,  8.08it/s]\u001b[A\n",
            "epoch=04, loss=0.6018, step=247680:  13%|#2        | 15/118 [00:01<00:12,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6134, step=248192:  13%|#2        | 15/118 [00:01<00:12,  8.06it/s]\u001b[A\n",
            "epoch=04, loss=0.6134, step=248192:  14%|#3        | 16/118 [00:01<00:12,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6124, step=248704:  14%|#3        | 16/118 [00:02<00:12,  8.08it/s]\u001b[A\n",
            "epoch=04, loss=0.6124, step=248704:  14%|#4        | 17/118 [00:02<00:12,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6242, step=249216:  14%|#4        | 17/118 [00:02<00:12,  8.09it/s]\u001b[A\n",
            "epoch=04, loss=0.6242, step=249216:  15%|#5        | 18/118 [00:02<00:12,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5995, step=249728:  15%|#5        | 18/118 [00:02<00:12,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.5995, step=249728:  16%|#6        | 19/118 [00:02<00:12,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6091, step=250240:  16%|#6        | 19/118 [00:02<00:12,  8.02it/s]\u001b[A\n",
            "epoch=04, loss=0.6091, step=250240:  17%|#6        | 20/118 [00:02<00:12,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6066, step=250752:  17%|#6        | 20/118 [00:02<00:12,  8.07it/s]\u001b[A\n",
            "epoch=04, loss=0.6066, step=250752:  18%|#7        | 21/118 [00:02<00:12,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6146, step=251264:  18%|#7        | 21/118 [00:02<00:12,  8.05it/s]\u001b[A\n",
            "epoch=04, loss=0.6146, step=251264:  19%|#8        | 22/118 [00:02<00:12,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6091, step=251776:  19%|#8        | 22/118 [00:02<00:12,  7.99it/s]\u001b[A\n",
            "epoch=04, loss=0.6091, step=251776:  19%|#9        | 23/118 [00:02<00:11,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6077, step=252288:  19%|#9        | 23/118 [00:02<00:11,  8.07it/s]\u001b[A\n",
            "epoch=04, loss=0.6077, step=252288:  20%|##        | 24/118 [00:02<00:11,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6185, step=252800:  20%|##        | 24/118 [00:03<00:11,  8.04it/s]\u001b[A\n",
            "epoch=04, loss=0.6185, step=252800:  21%|##1       | 25/118 [00:03<00:11,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6071, step=253312:  21%|##1       | 25/118 [00:03<00:11,  8.08it/s]\u001b[A\n",
            "epoch=04, loss=0.6071, step=253312:  22%|##2       | 26/118 [00:03<00:11,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6129, step=253824:  22%|##2       | 26/118 [00:03<00:11,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6129, step=253824:  23%|##2       | 27/118 [00:03<00:11,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6077, step=254336:  23%|##2       | 27/118 [00:03<00:11,  8.05it/s]\u001b[A\n",
            "epoch=04, loss=0.6077, step=254336:  24%|##3       | 28/118 [00:03<00:11,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5960, step=254848:  24%|##3       | 28/118 [00:03<00:11,  8.05it/s]\u001b[A\n",
            "epoch=04, loss=0.5960, step=254848:  25%|##4       | 29/118 [00:03<00:11,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6145, step=255360:  25%|##4       | 29/118 [00:03<00:11,  8.01it/s]\u001b[A\n",
            "epoch=04, loss=0.6145, step=255360:  25%|##5       | 30/118 [00:03<00:11,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6301, step=255872:  25%|##5       | 30/118 [00:03<00:11,  7.97it/s]\u001b[A\n",
            "epoch=04, loss=0.6301, step=255872:  26%|##6       | 31/118 [00:03<00:10,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6083, step=256384:  26%|##6       | 31/118 [00:03<00:10,  8.04it/s]\u001b[A\n",
            "epoch=04, loss=0.6083, step=256384:  27%|##7       | 32/118 [00:03<00:10,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6039, step=256896:  27%|##7       | 32/118 [00:04<00:10,  7.99it/s]\u001b[A\n",
            "epoch=04, loss=0.6039, step=256896:  28%|##7       | 33/118 [00:04<00:10,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6078, step=257408:  28%|##7       | 33/118 [00:04<00:10,  8.05it/s]\u001b[A\n",
            "epoch=04, loss=0.6078, step=257408:  29%|##8       | 34/118 [00:04<00:10,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6180, step=257920:  29%|##8       | 34/118 [00:04<00:10,  8.04it/s]\u001b[A\n",
            "epoch=04, loss=0.6180, step=257920:  30%|##9       | 35/118 [00:04<00:10,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6095, step=258432:  30%|##9       | 35/118 [00:04<00:10,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6095, step=258432:  31%|###       | 36/118 [00:04<00:10,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6182, step=258944:  31%|###       | 36/118 [00:04<00:10,  8.04it/s]\u001b[A\n",
            "epoch=04, loss=0.6182, step=258944:  31%|###1      | 37/118 [00:04<00:09,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6071, step=259456:  31%|###1      | 37/118 [00:04<00:09,  8.11it/s]\u001b[A\n",
            "epoch=04, loss=0.6071, step=259456:  32%|###2      | 38/118 [00:04<00:09,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5962, step=259968:  32%|###2      | 38/118 [00:04<00:09,  8.10it/s]\u001b[A\n",
            "epoch=04, loss=0.5962, step=259968:  33%|###3      | 39/118 [00:04<00:09,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6183, step=260480:  33%|###3      | 39/118 [00:04<00:09,  8.10it/s]\u001b[A\n",
            "epoch=04, loss=0.6183, step=260480:  34%|###3      | 40/118 [00:04<00:09,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6164, step=260992:  34%|###3      | 40/118 [00:05<00:09,  8.10it/s]\u001b[A\n",
            "epoch=04, loss=0.6164, step=260992:  35%|###4      | 41/118 [00:05<00:09,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6279, step=261504:  35%|###4      | 41/118 [00:05<00:09,  8.13it/s]\u001b[A\n",
            "epoch=04, loss=0.6279, step=261504:  36%|###5      | 42/118 [00:05<00:09,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6113, step=262016:  36%|###5      | 42/118 [00:05<00:09,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6113, step=262016:  36%|###6      | 43/118 [00:05<00:09,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6155, step=262528:  36%|###6      | 43/118 [00:05<00:09,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6155, step=262528:  37%|###7      | 44/118 [00:05<00:09,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6055, step=263040:  37%|###7      | 44/118 [00:05<00:09,  8.13it/s]\u001b[A\n",
            "epoch=04, loss=0.6055, step=263040:  38%|###8      | 45/118 [00:05<00:09,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6144, step=263552:  38%|###8      | 45/118 [00:05<00:09,  8.08it/s]\u001b[A\n",
            "epoch=04, loss=0.6144, step=263552:  39%|###8      | 46/118 [00:05<00:08,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6172, step=264064:  39%|###8      | 46/118 [00:05<00:08,  8.20it/s]\u001b[A\n",
            "epoch=04, loss=0.6172, step=264064:  40%|###9      | 47/118 [00:05<00:08,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6082, step=264576:  40%|###9      | 47/118 [00:05<00:08,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6082, step=264576:  41%|####      | 48/118 [00:05<00:09,  7.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6306, step=265088:  41%|####      | 48/118 [00:06<00:09,  7.36it/s]\u001b[A\n",
            "epoch=04, loss=0.6306, step=265088:  42%|####1     | 49/118 [00:06<00:09,  7.52it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6269, step=265600:  42%|####1     | 49/118 [00:06<00:09,  7.52it/s]\u001b[A\n",
            "epoch=04, loss=0.6269, step=265600:  42%|####2     | 50/118 [00:06<00:08,  7.66it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6163, step=266112:  42%|####2     | 50/118 [00:06<00:08,  7.66it/s]\u001b[A\n",
            "epoch=04, loss=0.6163, step=266112:  43%|####3     | 51/118 [00:06<00:08,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6177, step=266624:  43%|####3     | 51/118 [00:06<00:08,  7.87it/s]\u001b[A\n",
            "epoch=04, loss=0.6177, step=266624:  44%|####4     | 52/118 [00:06<00:08,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6195, step=267136:  44%|####4     | 52/118 [00:06<00:08,  7.91it/s]\u001b[A\n",
            "epoch=04, loss=0.6195, step=267136:  45%|####4     | 53/118 [00:06<00:08,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5963, step=267648:  45%|####4     | 53/118 [00:06<00:08,  8.05it/s]\u001b[A\n",
            "epoch=04, loss=0.5963, step=267648:  46%|####5     | 54/118 [00:06<00:08,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5988, step=268160:  46%|####5     | 54/118 [00:06<00:08,  7.96it/s]\u001b[A\n",
            "epoch=04, loss=0.5988, step=268160:  47%|####6     | 55/118 [00:06<00:07,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6155, step=268672:  47%|####6     | 55/118 [00:06<00:07,  7.99it/s]\u001b[A\n",
            "epoch=04, loss=0.6155, step=268672:  47%|####7     | 56/118 [00:06<00:07,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6144, step=269184:  47%|####7     | 56/118 [00:07<00:07,  7.91it/s]\u001b[A\n",
            "epoch=04, loss=0.6144, step=269184:  48%|####8     | 57/118 [00:07<00:07,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5996, step=269696:  48%|####8     | 57/118 [00:07<00:07,  7.98it/s]\u001b[A\n",
            "epoch=04, loss=0.5996, step=269696:  49%|####9     | 58/118 [00:07<00:07,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6128, step=270208:  49%|####9     | 58/118 [00:07<00:07,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6128, step=270208:  50%|#####     | 59/118 [00:07<00:07,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6098, step=270720:  50%|#####     | 59/118 [00:07<00:07,  8.18it/s]\u001b[A\n",
            "epoch=04, loss=0.6098, step=270720:  51%|#####     | 60/118 [00:07<00:07,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6162, step=271232:  51%|#####     | 60/118 [00:07<00:07,  8.17it/s]\u001b[A\n",
            "epoch=04, loss=0.6162, step=271232:  52%|#####1    | 61/118 [00:07<00:06,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6211, step=271744:  52%|#####1    | 61/118 [00:07<00:06,  8.24it/s]\u001b[A\n",
            "epoch=04, loss=0.6211, step=271744:  53%|#####2    | 62/118 [00:07<00:06,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6167, step=272256:  53%|#####2    | 62/118 [00:07<00:06,  8.18it/s]\u001b[A\n",
            "epoch=04, loss=0.6167, step=272256:  53%|#####3    | 63/118 [00:07<00:06,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6086, step=272768:  53%|#####3    | 63/118 [00:07<00:06,  8.19it/s]\u001b[A\n",
            "epoch=04, loss=0.6086, step=272768:  54%|#####4    | 64/118 [00:07<00:06,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6209, step=273280:  54%|#####4    | 64/118 [00:08<00:06,  8.07it/s]\u001b[A\n",
            "epoch=04, loss=0.6209, step=273280:  55%|#####5    | 65/118 [00:08<00:06,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6258, step=273792:  55%|#####5    | 65/118 [00:08<00:06,  8.13it/s]\u001b[A\n",
            "epoch=04, loss=0.6258, step=273792:  56%|#####5    | 66/118 [00:08<00:06,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6159, step=274304:  56%|#####5    | 66/118 [00:08<00:06,  8.14it/s]\u001b[A\n",
            "epoch=04, loss=0.6159, step=274304:  57%|#####6    | 67/118 [00:08<00:06,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5833, step=274816:  57%|#####6    | 67/118 [00:08<00:06,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.5833, step=274816:  58%|#####7    | 68/118 [00:08<00:06,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6154, step=275328:  58%|#####7    | 68/118 [00:08<00:06,  8.18it/s]\u001b[A\n",
            "epoch=04, loss=0.6154, step=275328:  58%|#####8    | 69/118 [00:08<00:05,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6111, step=275840:  58%|#####8    | 69/118 [00:08<00:05,  8.23it/s]\u001b[A\n",
            "epoch=04, loss=0.6111, step=275840:  59%|#####9    | 70/118 [00:08<00:05,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6148, step=276352:  59%|#####9    | 70/118 [00:08<00:05,  8.25it/s]\u001b[A\n",
            "epoch=04, loss=0.6148, step=276352:  60%|######    | 71/118 [00:08<00:05,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6119, step=276864:  60%|######    | 71/118 [00:08<00:05,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6119, step=276864:  61%|######1   | 72/118 [00:08<00:05,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6212, step=277376:  61%|######1   | 72/118 [00:09<00:05,  8.21it/s]\u001b[A\n",
            "epoch=04, loss=0.6212, step=277376:  62%|######1   | 73/118 [00:09<00:05,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6145, step=277888:  62%|######1   | 73/118 [00:09<00:05,  8.16it/s]\u001b[A\n",
            "epoch=04, loss=0.6145, step=277888:  63%|######2   | 74/118 [00:09<00:05,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6102, step=278400:  63%|######2   | 74/118 [00:09<00:05,  8.19it/s]\u001b[A\n",
            "epoch=04, loss=0.6102, step=278400:  64%|######3   | 75/118 [00:09<00:05,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6092, step=278912:  64%|######3   | 75/118 [00:09<00:05,  8.23it/s]\u001b[A\n",
            "epoch=04, loss=0.6092, step=278912:  64%|######4   | 76/118 [00:09<00:05,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6019, step=279424:  64%|######4   | 76/118 [00:09<00:05,  8.21it/s]\u001b[A\n",
            "epoch=04, loss=0.6019, step=279424:  65%|######5   | 77/118 [00:09<00:05,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6228, step=279936:  65%|######5   | 77/118 [00:09<00:05,  8.19it/s]\u001b[A\n",
            "epoch=04, loss=0.6228, step=279936:  66%|######6   | 78/118 [00:09<00:04,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6228, step=280448:  66%|######6   | 78/118 [00:09<00:04,  8.22it/s]\u001b[A\n",
            "epoch=04, loss=0.6228, step=280448:  67%|######6   | 79/118 [00:09<00:04,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5947, step=280960:  67%|######6   | 79/118 [00:09<00:04,  7.97it/s]\u001b[A\n",
            "epoch=04, loss=0.5947, step=280960:  68%|######7   | 80/118 [00:09<00:04,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6119, step=281472:  68%|######7   | 80/118 [00:10<00:04,  8.09it/s]\u001b[A\n",
            "epoch=04, loss=0.6119, step=281472:  69%|######8   | 81/118 [00:10<00:04,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6098, step=281984:  69%|######8   | 81/118 [00:10<00:04,  8.06it/s]\u001b[A\n",
            "epoch=04, loss=0.6098, step=281984:  69%|######9   | 82/118 [00:10<00:04,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6173, step=282496:  69%|######9   | 82/118 [00:10<00:04,  8.17it/s]\u001b[A\n",
            "epoch=04, loss=0.6173, step=282496:  70%|#######   | 83/118 [00:10<00:04,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6117, step=283008:  70%|#######   | 83/118 [00:10<00:04,  8.08it/s]\u001b[A\n",
            "epoch=04, loss=0.6117, step=283008:  71%|#######1  | 84/118 [00:10<00:04,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6106, step=283520:  71%|#######1  | 84/118 [00:10<00:04,  8.09it/s]\u001b[A\n",
            "epoch=04, loss=0.6106, step=283520:  72%|#######2  | 85/118 [00:10<00:04,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6272, step=284032:  72%|#######2  | 85/118 [00:10<00:04,  8.11it/s]\u001b[A\n",
            "epoch=04, loss=0.6272, step=284032:  73%|#######2  | 86/118 [00:10<00:03,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6180, step=284544:  73%|#######2  | 86/118 [00:10<00:03,  8.20it/s]\u001b[A\n",
            "epoch=04, loss=0.6180, step=284544:  74%|#######3  | 87/118 [00:10<00:03,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6148, step=285056:  74%|#######3  | 87/118 [00:10<00:03,  8.16it/s]\u001b[A\n",
            "epoch=04, loss=0.6148, step=285056:  75%|#######4  | 88/118 [00:10<00:03,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6194, step=285568:  75%|#######4  | 88/118 [00:10<00:03,  8.22it/s]\u001b[A\n",
            "epoch=04, loss=0.6194, step=285568:  75%|#######5  | 89/118 [00:10<00:03,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5856, step=286080:  75%|#######5  | 89/118 [00:11<00:03,  8.25it/s]\u001b[A\n",
            "epoch=04, loss=0.5856, step=286080:  76%|#######6  | 90/118 [00:11<00:03,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6073, step=286592:  76%|#######6  | 90/118 [00:11<00:03,  8.14it/s]\u001b[A\n",
            "epoch=04, loss=0.6073, step=286592:  77%|#######7  | 91/118 [00:11<00:03,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6094, step=287104:  77%|#######7  | 91/118 [00:11<00:03,  8.00it/s]\u001b[A\n",
            "epoch=04, loss=0.6094, step=287104:  78%|#######7  | 92/118 [00:11<00:03,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6178, step=287616:  78%|#######7  | 92/118 [00:11<00:03,  8.01it/s]\u001b[A\n",
            "epoch=04, loss=0.6178, step=287616:  79%|#######8  | 93/118 [00:11<00:03,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6126, step=288128:  79%|#######8  | 93/118 [00:11<00:03,  8.05it/s]\u001b[A\n",
            "epoch=04, loss=0.6126, step=288128:  80%|#######9  | 94/118 [00:11<00:02,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6185, step=288640:  80%|#######9  | 94/118 [00:11<00:02,  8.06it/s]\u001b[A\n",
            "epoch=04, loss=0.6185, step=288640:  81%|########  | 95/118 [00:11<00:02,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6234, step=289152:  81%|########  | 95/118 [00:11<00:02,  7.87it/s]\u001b[A\n",
            "epoch=04, loss=0.6234, step=289152:  81%|########1 | 96/118 [00:11<00:02,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6127, step=289664:  81%|########1 | 96/118 [00:12<00:02,  7.96it/s]\u001b[A\n",
            "epoch=04, loss=0.6127, step=289664:  82%|########2 | 97/118 [00:12<00:02,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6091, step=290176:  82%|########2 | 97/118 [00:12<00:02,  8.09it/s]\u001b[A\n",
            "epoch=04, loss=0.6091, step=290176:  83%|########3 | 98/118 [00:12<00:02,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6182, step=290688:  83%|########3 | 98/118 [00:12<00:02,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6182, step=290688:  84%|########3 | 99/118 [00:12<00:02,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6149, step=291200:  84%|########3 | 99/118 [00:12<00:02,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6149, step=291200:  85%|########4 | 100/118 [00:12<00:02,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6084, step=291712:  85%|########4 | 100/118 [00:12<00:02,  8.11it/s]\u001b[A\n",
            "epoch=04, loss=0.6084, step=291712:  86%|########5 | 101/118 [00:12<00:02,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6006, step=292224:  86%|########5 | 101/118 [00:12<00:02,  8.01it/s]\u001b[A\n",
            "epoch=04, loss=0.6006, step=292224:  86%|########6 | 102/118 [00:12<00:01,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.5966, step=292736:  86%|########6 | 102/118 [00:12<00:01,  8.10it/s]\u001b[A\n",
            "epoch=04, loss=0.5966, step=292736:  87%|########7 | 103/118 [00:12<00:01,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6136, step=293248:  87%|########7 | 103/118 [00:12<00:01,  8.11it/s]\u001b[A\n",
            "epoch=04, loss=0.6136, step=293248:  88%|########8 | 104/118 [00:12<00:01,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6108, step=293760:  88%|########8 | 104/118 [00:12<00:01,  8.10it/s]\u001b[A\n",
            "epoch=04, loss=0.6108, step=293760:  89%|########8 | 105/118 [00:12<00:01,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6148, step=294272:  89%|########8 | 105/118 [00:13<00:01,  8.17it/s]\u001b[A\n",
            "epoch=04, loss=0.6148, step=294272:  90%|########9 | 106/118 [00:13<00:01,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6080, step=294784:  90%|########9 | 106/118 [00:13<00:01,  8.23it/s]\u001b[A\n",
            "epoch=04, loss=0.6080, step=294784:  91%|######### | 107/118 [00:13<00:01,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6004, step=295296:  91%|######### | 107/118 [00:13<00:01,  8.27it/s]\u001b[A\n",
            "epoch=04, loss=0.6004, step=295296:  92%|#########1| 108/118 [00:13<00:01,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6222, step=295808:  92%|#########1| 108/118 [00:13<00:01,  8.17it/s]\u001b[A\n",
            "epoch=04, loss=0.6222, step=295808:  92%|#########2| 109/118 [00:13<00:01,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6204, step=296320:  92%|#########2| 109/118 [00:13<00:01,  8.12it/s]\u001b[A\n",
            "epoch=04, loss=0.6204, step=296320:  93%|#########3| 110/118 [00:13<00:00,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6113, step=296832:  93%|#########3| 110/118 [00:13<00:00,  8.19it/s]\u001b[A\n",
            "epoch=04, loss=0.6113, step=296832:  94%|#########4| 111/118 [00:13<00:00,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6111, step=297344:  94%|#########4| 111/118 [00:13<00:00,  8.15it/s]\u001b[A\n",
            "epoch=04, loss=0.6111, step=297344:  95%|#########4| 112/118 [00:13<00:00,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6284, step=297856:  95%|#########4| 112/118 [00:13<00:00,  7.91it/s]\u001b[A\n",
            "epoch=04, loss=0.6284, step=297856:  96%|#########5| 113/118 [00:13<00:00,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6099, step=298368:  96%|#########5| 113/118 [00:14<00:00,  7.89it/s]\u001b[A\n",
            "epoch=04, loss=0.6099, step=298368:  97%|#########6| 114/118 [00:14<00:00,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6151, step=298880:  97%|#########6| 114/118 [00:14<00:00,  7.97it/s]\u001b[A\n",
            "epoch=04, loss=0.6151, step=298880:  97%|#########7| 115/118 [00:14<00:00,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6199, step=299392:  97%|#########7| 115/118 [00:14<00:00,  8.05it/s]\u001b[A\n",
            "epoch=04, loss=0.6199, step=299392:  98%|#########8| 116/118 [00:14<00:00,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=04, loss=0.6089, step=299904:  98%|#########8| 116/118 [00:14<00:00,  8.10it/s]\u001b[A\n",
            "epoch=04, loss=0.6089, step=299904:  99%|#########9| 117/118 [00:14<00:00,  8.04it/s]\u001b[A\n",
            "epoch=04, loss=0.6123, step=300000:  99%|#########9| 117/118 [00:14<00:00,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"5308c52d-47f8-416c-a131-865a153c8199\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5308c52d-47f8-416c-a131-865a153c8199\")) {                    Plotly.newPlot(                        \"5308c52d-47f8-416c-a131-865a153c8199\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAcL0lEQVR4Xu2YaZglR3Wmv3NORObda+1udWtHYpEsCYFBHhAaEDBtbBkLA0bCYDZjMAxIGAaxmQEMjMTiRcCgMcuAjdgMHoQtgREIswiDsIZFNmZHaEHqrarufjMzIs6ZH7equup22+aZhx\\u002fDPP7+3Iz3u5GReTIyzomkNv5dRxPPgn\\u002fXVD+3gTn1lm\\u002fNop+pfl4D86brj79llv1MNRuY+13VversGfb\\u002fnnZ++ncX\\u002fvk\\u002fz9KfqWYCc9Y1F9vF12xnW3VZt\\u002f+QWQYAaB\\u002fz1P+Sz0IAp572zH632+1235\\u002fNWof1sB\\u002fccxZBFhYWXvqaD+x+d\\u002f\\u002fAS2e9U9\\u002f6ALz6Zauz+KdV83PfPXGWHSG3rfWLV8\\u002fZICye841qG97Uk35fYbMQwEmXnnM6sPOyWX7akx7Du9UA4Ff\\u002f9KX9DXzu4t8c\\u002fg+A+399WxPH+1960NyFAPCTNz568E9f2u4Ci3uBu74wS38q7V5G97z7ff\\u002ffDurWwDTu+85jgB9e+Z7rX\\u002ffmLXiLjj\\u002fapMC9nntRje4c3vux7\\u002frejPPqvYePn\\u002fgXX9k4PO+UbYHhE4+jre37\\u002fvXc+pG+dvyRu7vf32oCOPVdhCddNwO36PnZvZ+A750zi\\u002fELzz4epx6PP74P3eVnPTzg4nNPwyv2PehDN0\\u002fbWwNz5eMB4OzmjeedvoVu0fm\\u002fh+894cAMnHvNY9vAD3\\u002fD37y0NGPhs3tx8H1kOGf7+3fxP2xrHvO0D2+L6O2rcwBwc\\u002fc\\u002fVh\\u002fayjd08fHXv+CuWbihh5x+7qMJhlP+4YGz1nlPAcoPP\\u002fSFsPcfMWMe94Yl+uLy60BLT5+CLYG5317CjX\\u002f7un23dB+67QFu6kFXdXDl7bP0154K4NYL7zxl1gDw7usQ9gPofGU3rj38vswsbG\\u002fFD7e11175qFveiFsuHJ32nG18XZ8587aXHT0ux\\u002fzPk9Bp0tfPBsCNWfdll+IDh95y6KyPLR36+Izl7v+Wxpfe+OX8vY\\u002fAxlUeDsxZ13Ts088497V\\u002ffugf9ZfP\\u002fsYmP6zfOgZf\\u002fOAsxG8At33tVXfiXrMGgHjn9PcR88Bd5QY9Y+fG0VRz+Ox2cO0XBmc85W0jfPuS7RwAcMED7JpiFgIAzn\\u002fLcQDwwJWl3W8\\u002fFt+ZtZv12\\u002f9wH+7xouXxFbP9L3obPvv0Ph77CPzkA+toMzCnXjK3su8Dw099CgDqz3vmBj+spd\\u002fW3lHWnuc\\u002f7bM\\u002fOghg5m636vFPrQOv32zurW\\u002fxgJ0n4u5tAOijj6d8VGcoAGD+wUD3JwCecxxesd269DigfNXN38fqc47Fbc\\u002fabgLX\\u002fKd7v+aFnct\\u002fee1N75xxXvkie+fr+sCLgcsOrbONwOSv3zt49tc2r\\u002fj4jYPDOvF9wJ99fpYCd18+\\u002fT1ysVvXE150sgduCZvgnvj2Fhuv3\\u002fmD4dY2AODysx9y\\u002fg2zEADS2axfAp5nzz4Bz7\\u002fP1lfqEQ8E7njWVwDgWOATK1ssAMA\\u002ffvXeDz3\\u002f8uNx+Z\\u002fNGC99UXXDqyaoPfw4euPmmr4RmPvuxRNv3IBH1SPPwOeumoXr+r0m2em46auz\\u002fMSLHwY8yID+q6+fbOFf2zzqPPKih+MN3cPWukaXfOEtX\\u002fz6O46sDc59sN6xirMe9KsY3XXP9z19y5L3vAZuuuIrAOb3Phg3XX\\u002fYWFc5wDFXk\\u002f3FbD6bf6bd8ETgHu+6H665cpNuBOa\\u002f0Y2H48J65Or7a6\\u002fGl3+vN0sBoHHaS\\u002faCFfuem2acX\\u002fjgxsz78nu2GQsAzuSHHuufwMXNpfvGNnOqHz3n7Rdf3PjgvhncPhH7PvTDUy+5YOWzb2tf29lqvXep\\u002fzv7AeB3\\u002fgDffur+rdZUtwPA9W9ZX\\u002fc25Zdw2Y4n\\u002f+ppLbMPjzbpemAedaZ9YpNB7Yh9yIlXAz+ezdQA4M+6+pjJvpse2YA8+qrZupAIACvwqL1bnuDE\\u002fuRFwBkUx9+9+mtfOvCd+mz5AwD4mx+9\\u002fmGvOv7NM\\u002fnnP1yB916x8\\u002fV7Bx97xSl\\u002fOvj81hz58fVc8ysvQXzPUeIiDybgU0+YxQiHlv\\u002fRgLsHx6x88jBdD0w9O\\u002fi\\u002fNlD+Mnz+1RuNDb1AgT+ehQCyR74fV3z+KwvXno7lV9957WbmAQB864KLbigAPOXZ2\\u002fAL7\\u002fglAHde951\\u002fAICnL9+6zd3Ut572qKueccqF2+EZwBV4\\u002fwPwxBvP+RTePrP6TvVBw2XbJ+hU7\\u002fl1w9Hq9u4TP7Jw63XvX3vPMX+1hW5mpXJj0uYvvvQnb5tdDc96OHDdbAUKwL\\u002f8Unzmz7rLH\\u002f2F6k9Pv+Bdf3dlF9\\u002fcYt\\u002f+JgDA5dsDgz\\u002fZ2ngo\\u002fnprc4u6H3qbO\\u002fe8L25jc3QdzjqBXn7jqe+il799m7WuV7HiKKvl7idfaN\\u002f4pyfvmOUAbj4ZAM59iG59QpuB2ZhFZ13yuOuevAE3dc08bj5KtSV\\u002fcMnoNR\\u002fp\\u002fuKb7vvD3\\u002f9C55yLfuUa3Hnm7J+AR8yC7bp2Fkx1xoX3d\\u002fjO7EbJDFA7459rP37U5t5rq7Kz1F6yvWAEADz0FXjtOy548hHVzabqakeZMUQXXAYAeN6L5\\u002f7yiAoAWFS8c3YWAXj6JeMX3PDAJ++tveHqO9H\\u002fzGd+8wk4vBX2D\\u002f\\u002fCNBP99hWb7KfXPZ\\u002f96F1A2jdTzHzi0gvOObOFJ9LKFUetfhsXPRwf\\u002fcsjK6Dz3oiLPrfrJdMF+Kj6zPbmemDMdr3x6tUHXnzGsXfcMFv+ALiKgZtmIYCXQC552T2Ay\\u002f9ompA+8pHD3oNf9PAz7wSwsPf1DUxma80tolOOSPPY9Zu\\u002feyKAr715S0oAAIRx43oDMPjYkfkYQPstj8FL33FkXHD+3I1\\u002f6x81R0dUN5t65Pbm5qskv3vh4BTgq58\\u002fXKFu6qzztXrn0VLS\\u002fuX8TFz\\u002fpWtvn03UAN50Oi4dAjj\\u002fbMMX3\\u002f2vfCSwma0TsPO0N90LwM1XXnfELX79Gc87D\\u002fjAt245yjICYM9jcOv\\u002fmIUAYGb+197Q\\u002ffOjPPV1nby9uR6Yr37t\\u002fti1E6t\\u002fNX2hZjS3E3cdNQH8ygVnH3xfdzZJb+qZ05+Dn3zJvzJhgHPev625cOWZJwO46a03bK0JNzTds\\u002fwLutfz8IPHzUIAwDIOffzBeM6WfDyrv+dtT2E9MD950tMvA65691FWrX9Ngw8d9bsAAOC5z\\u002fotALh1\\u002fPd\\u002f\\u002fq1Zb5u2F5MPuPQX9wCYXPVHh4utn1qXPQ7vOPoq8l08htbe8blZvEXf+uFJJ29slHD4Vdp3+fqW52j63k0PmkX\\u002ftr75wv\\u002f9yvlr\\u002f+66o5Ra2\\u002fTp39jWfPSjge9+Mr21u43+dDqtg\\u002fd8bhZO9YHssq9\\u002f4r\\u002fP0m1689v+64sPJy1qb7F+3vWHz7\\u002f98Ucptn5Kdd57\\u002fl8\\u002fd3OaHrHw\\u002fTzrs3j5\\u002f31c0H\\u002fau3798FeF\\u002f69mzM9SzgVmjlp5UXPBqlwdzIiVUStVPWAGMzZjY0SWxKRqPh+LgZSVjZSZoCAiVGDLaSwGGBkbGRNICUSoTCynsShYWUVJab0fECCW8YbHRsrEpkQEVLRxzs3xiM1ARBbAlmvJ070qGyKxmCUxZQCWpQQGKWAgMyZYdJSYTC3jaT8yMiRihiVGEgCaOWVvkSWPShQmIE4WHEvwBQFZQGJJLgEEZXOsVK9YvYb1XKIqRswGUjhEMEwnzgDASJ2ykREpHAIRWyoEBgISABDBYCBTCEwLN01RqmJEBCUzsUQC08l6lpiORzAoZGM8YcCIExmMGKbEZmzOYIWImjpJbACbQcXBvHJyWjkGjCQBpEyAEpuJOSUqqe5YjSRycxQQqDVh5Sy4vBLSKEhgS47Y1FTZJ2IOZibKCc6UI4OFGYQgamQJCmM1r8aRiUQYhMBmhgQlFTUxIyUwMRgUWY2QSKFOTTA9JzMRIZIZIZJC3eHxWIhAgU0JCQoVNjIyMyKbTgFARZmMErMZ1ueemSVmI3BkMzaIkhEUIANICUbKKgAlB2eGGnn02Vm9bQ1HqXKVSaQomnhamCbAkDFngGYBbEpiIGLv4IU8g6oQNBGRgpjMCJw5eMeegVCFlIhYQcQGTkwCYThmijFYIoKBiY0Acg6OyTNRCMESiAxMYiCwd3DT8UIVOBHIwGwAGa3fX\\u002fKkbApnBBA0sYF5et9JiIWmV2CJzQBjVlYAyZGJKcTIiJyDEcW8UtdynYXWInNvcqA\\u002f6NXNJTUHgNh8cFLP2VtALEpwEDFACXAi7VrTC2xY9GJMiKIGghGRE5mrtTOBDSdrVZWQXCIzKJEJSz2re08YVcMU1IIoDEhEcOwatYZzZKNyEINi3VMic+yataZzsGHZS0E5ugRlGJERGOIlJ0oJKUQkAivEiMAqcM5lJmacqgpI7CITCMo07WecjFKIpgRxyTFpKkM727m054RTF23UvftHP77TiiRVDWpZIuPErtVeajot+0UPaozIBjLPed6Zn2\\u002fWHEK\\u002f2+iWscyjkZkSMsnqc4vznXpmodttrE6qIotsZiA4yrJWq9NoONJxb9AvYsmRaOpxlrc7c42GUBx2m73Nc4LMc5Z35uYadYc46DZ6ZSzzwAAMlIi8c61ayzunk2IyTNPpBjNRZ0J5vVFr+YyqouqVRYQqYfoCeSfNeiMXj6Is+qkKlswRosuC1mp7Tjj52GOPbdfWqp1eisrGeQkjUgK5WMsbO3ct+2KFLCvzCsYAEVOt0Vre0Vn0YkWnc8D1RymBlMAQylrtHbvml73XotXOuNsPClIYE1Feby4uthZqDqGcW\\u002fG9cUpEAIiI80Zraam9mIlVxdzBqccGEBHljdbScmfRO63mOuseKUUhY8d5vVVfmG8I06C\\u002fSoVYAJmyGRM7NBtzS\\u002fMNj96wW6VME8gSw8hRljcb8\\u002fMtLzQYrNmELIAcwFbkWFjYceJJu3c2aiOOnfuwxrtkklgoQhRBOGstn7jkekRFnkY+KBlBxOftxR1L8zVXBc5akzAByBQGCPu8tbhjcbGWFSFx3miPQDCFEVhc3lrYsTjf8FplmddUFmJkZAThrNZe2LE4X3exypmqOBkTmQIEEV9rL+5cnK\\u002f5Kroayg1PxcDgvNVeWlpqNKym8WBGvUKjsjKByAj11vzy8s5GLS6tUlRYTJzYwCBfby8sLbXaXLdwMAeTRWXHfmwOjXb7uF17ZP\\u002fqcIDmjnzPnS2fBc9GkhjmubW8uDw3b+MsCYGJWMmExNXqjbk22bAXuOlq3llQNRMQnOT1eruF1F2L2qTcOYRkagwhcbVGc76TuWoYs3pWzx1iTGYEgUit3pzrOJoMgmtm9cwhJjXQer\\u002fGXJsx6kVZHy+pmSjBuJY3F5d2tj3BkWsPV7PC1BIbkMQjq7V3zS\\u002fUW3lpWcM5mEFZCcq5b8wt7JzLneQm7WGWTUyRnAUSMe\\u002f37N4Th+N9g59ku07e3bzHyupQRq2kJCC2el7P2EuoimoSQhW4JBATYMhh2l3px4XMZZQqA5wpMU89DYOVXmyzc4wEUmcKIpBRTRyPVgdp0fsMKSiIpwmNjHImG6wM4mLmMkpBAYGCCVDkBOuv9KdeDEYQGBFIIHl7uZMPJ9pezHNC0AgTSkrMxmjNtWsaCiXiEEMKXAkIRGzk2zvn6pMhh\\u002fk8hwWNpOI0jluUZPfuHa3hHQe7h9ao73CsQCiSJGIjrryxVpOUhqPBeFylYMkkCYwcCXsbrx3o1VveO05mxmTKUMfkOMN4dX+vlolnMhgYpgyDCLOzSf\\u002fAIG86z1ZFNTZTJoOwsOike6Bfb7lMEJPZej9yLOxs3N3fr7ecF0pqxqQAoMQq3lJ\\u002ftYpOkSa90SQawJHYmEPNTCelWJJyMhoWhUYjKEM9K4nasIskLVeNe6NJTEbOtMba2XPKiTuq1bXRj1cHods4lo\\u002fd\\u002fX1TK4WUI4tjjkr12v7+oUOTYQxGBBgYSdViqsrAWbuVDzWl6AyAgdVMOaWyUsk6rVolBrVprcvQZKQpjAqVVtNxFUN0RgaASZNCtZxUcO2278UUNz0kTUipKiJn7XY2SCkGB8CI1MWqIY7Cymqo+VoY3j0eBzJGEJgE9ZLnqZIqV1tbOTAYlwBDBeoCtV3u4loXdZdP+neNRhVB4MiR0878zj352u133lWljOqxypB1nEUmk0hKKjFRa5llMhiOgholEagC5tjV2GWN1tzijlhzKj4xIElNzPm8Lj6r1duLO3Ts4bMKMJfUJDHYE7lGc35hoRKrTBIBompOBZKR+EZzfnEpeIrkEm96JBk732jOLS7HGqeN8aCRTdl0Eho2v+yLg6sHR1lUElEgkSpZKHlhsS79yf5ev1RVJkmkkWCiaRLbPLdE1f7VQ2NJidllZFVj8R7Hu2rfbd\\u002fXaoRxncn5XJN4KCIrKIOk\\u002fIQdabLW64WK2NgqYrBqSEJ173K3cNLyZMU5GJlKEGI1mFCNSXju+B1xnOdMpMaRwGpBmXPHeb584nxPjMyAJGF6TmWqecmzpZMWh3cL2\\u002fScm17dS80tnbQ0OuBk6ikZGyITQxu2dMxyvO1gv2RQFshgICV2wqmxcGxjZbL\\u002fwGDCbD4pkZFREhbSuhyzozU+uK83IVAe4DSPlvJWfWH\\u002frXcPk4lmMlfP1DQbN6oMYJgm1ebScYuHBsNhGVmJTI3UiNhL4oyQZYudPDhHPiQ4JVUHcd7ExWzBdVo51XL2wkaAGogdB3hxjfrSXM4g+ArGiqQgdhw5S1yrLc1lwoxM1cSgSiyOE2dEeW2hk5Ui5KPCqSqIIFaF1PD1xR2N1bI\\u002frBIhmkYBWKGxCp35E3bi4HgwHGnwZFBgWhRXoerUO8vz0hv1ByHVkEwd+nCLJx+3Y+0bt\\u002f54pTUpdS6rL1MYjZiLjBLYIGaS7ej44XAwCpocYICxUCpCzDw3y+DYizife5OkMGJoZSljrZlZArk8r7tEpGTMrGUjOi+5pjzPCSAnxslgLJzKGL3nPIbMeccsmTNWWx+vEX3GzRCc807EZX4sSQGBGSyGBGu1Fuerlf2DSN4hiQmZJQBRiRc6zeH44MokmHNQUhBMxVIVTJtzC63e\\u002frt7Ad5REnUh1jXnuSoU3ZJN4Vu79iyG4sBoHAA2MwbMqNFA2V+rQmROwkaO1ZgcubKqilB6NygqmHM+CYJLxuIoC8GFsmAewRGcy0rS5BOIHbiY5IzKsob21cQ5ZUtejcSRlEWtSmX0w9HQVMQpW\\u002fTr41VlWcYy98PJxMw5r2JRlEw80qSfZdV40psMJ6UpDJamdYNAQxkyicVgrSgSWfJExmRQ9khFv9YMk0laHU8iqRGQyHGrXFra3UE5LCaeWuZPP+2ebvXWA4PkKlMiUQFn9cwVq90UWVS5ykktuRRAMVXl0IajHO1mUcCRWAUkF6PWklaVhcHAp3aekggzlzAVjYQYywlzVTW5QeMJBC4GUBINhJDKYkDjos6tbDwhRy4Go+RSAEIqC7HRuIZWfVzAkYsVEMWYkktajrs6P+DqwGDMmbGRUCKQmKPMSQzVYFgNUgSzCgiRjTllSrHs+2yYFwfGY2TTzbwzydSxz2vt1i7ldrV80j2a9bvuWptwNgKgJJTljUadi2p1VCYwyBk4ceXBQlUxCGEUzDTFoogAkECVwImEcuiKYWnCxMUkqBElo+iMmapiaFYaaURVFkpqSKDoQMxlMUxpkkwjhbJIZGaJqPJg4bIYpDCOpimGokgwQwKrgBxDUwoj38iHKVlFhEhp+u3Li8t8JnFM\\u002fUGVyIhYAWNjkBM2WBqP6qmvSpGZIpSdpGgWXPO4++R3wDX8nhNak9u++d1DWVAxA5HlWbPZrGsYj2I0IlUjJfUwEtIUCoshinAqKo1Jk6owwJ4tJU2JkOU1V4RQVBpVWWBgTpoK1kQCrYoSaqRqjmAknDQWSEGFKBSVpWRqxgwjoZRCgRiSMMWysphMVQUwZsDnTCqZjUcrBeVsRCogA5jyvNPIPcmoPx4n9gQzZQOBmThvOIHL03jUrTh3gBnDmeTD\\u002fuTQUv205knSSrRA8QeHvrf\\u002fEEMzIiRm8bV6q1ErR91uMBKyaAyJKo5YWGCcNTtNDv1utwxK4GlsmMSx5NRpzeepd+DgaDLN1CqOSJgJ3tfaNQv90SipMijShmcQyjt1hF6\\u002fH5IRKOn6eAyTLOs0KPR63SoqgROBYWDxtbzdyfMw0eQ9krEmBkiNJK\\u002fVm62Whn4\\u002fKAupggxmYsrssnqtM+fdcBzVJ0kqMbFzSXn4z01\\u002fn2N29\\u002fNg5XDl1h\\u002fccXfBwbvKq0EZvt5pN7i\\u002f2kOCWAJITMmBiOAtaV1qc9m4WFkdT6oENbAQISmZotHy7UYR9x\\u002foDctk6x4zeYbVfbMlw163V5UhwYxYCMTwMG1Ks+1Hw7W1ogjTfg4gQoaUmlLvZOPx6lpRhOl4aiaQWqPRmGvVy2G3W1SUSIkYHNRA7JtznXZedtcmxfTjBzHSer+80WrPt\\u002f241xtUUZQUxOZS9Cke\\u002fHYjHpdr5lfuGnz3ttvXDo1cRhWSizBL7Ly4Iq2MxiyRCcKaTEGaKPSJRcWqXrV2aHWtMlUxS0youOgx2uy0DHFt5eCBcUrGhiTGFdzIZTkoVd3xyoH+IJiamCUBAvkh+8woVb1i9WCvF9bPCUIFPyDxRhZ65drBtcPjQSJSFdUxiqp7cDSuDJaMjKMzJI1G7Fwqe71uSpEMRpYoCThyimpeUI7WDk6KMP2Oq+Solmor3btXTt0z38Rk\\u002f\\u002f6DP17to\\u002fBRwCZwUcBVWU4O+nG3Z2oIxgqymCuUrdSUoja0SIPRyrAqS+VIEAOQhqGYdObqrhcH49VhUVTGgeAiR7ZgAKiRxrE3WB3EEIwiwyWOYpWqqTW1SP3h6iBUlVIiuMSJUWlStYYWqT9aHYSyUo4EFyUwUSrLyShW49XV3iiakUFFnVLyLLEIRVd6aytlESwaA0bJJw6OSKtYjMN4cKA3mEQDjJSVsoZLWrXcrpB7GU\\u002ficJQo5DWwDSA1NWafd+pt4klvNE4IUBWCGiUSMIjnGvWaoxCLUVlWGoktkZKAiFy7XsvFYiwnVVlpIrLE037Mc8163aEKk1FRxZSIsOERzzXqdUchTMZFVR3di5PD44GMiV3WaHfyrBoPilExJk4kBiRvcM7l7WaHedjtl0FLMhVRM2MjFp+1WvPeFYNeOa4mxFFYQVT3KSeL5kbCtXHkxlhSQyxJilBPBEZe96paaaFspCpGgZUZSuaicJ6zh2kKQSsDKxQCJZMolGXkYJRiTNFAhkRMiSDKLs\\u002fYQzWGsO4pESmZKEueiTfTFEIK697meLWct3isUIDAxD73GTilMhYajYnMAJ2uaXkt42RFKlTNlBiIAIjAJFkt80pVLFOpyZjIFERtBpFJZaXAfHKUlQ65hUqSxByszOSQUBmUWcqsBLMi5gmJYQTHcM5UU6JIySUTc5ESmxGETQRqmihNPbgIJTIiETgxSykhkZKBp\\u002f1gRMLwAtWYkCiJmphbH4+E4Rw0TccTNTFSAzNzRmQck1plRs50+iXcmIUogyIGNTYOTglQKJuRMHMOAFVSBCQWKACj5UJZM554daO6ijFRxWSJfGqMkxAUMFexqifhUigwsarLKiUVEzNWlyQaWWKoRKGaTT02k+QSJyMkRpLoUNfKyNjEQBv9lE0lCmqo9F\\u002fwNs+5bTxZ90IFAUgAU5goKBEBlGB5jCRQIkhAggNzYFKGqXlUcDASkKqZGCgx1vv9H3ZMF0n8fGcSAAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5308c52d-47f8-416c-a131-865a153c8199');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=04, loss=0.6123, step=300000: 100%|##########| 118/118 [00:14<00:00,  8.11it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=05, loss=0.6057, step=300512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=05, loss=0.6057, step=300512:   1%|          | 1/118 [00:00<00:15,  7.65it/s]\u001b[A\n",
            "epoch=05, loss=0.6021, step=301024:   1%|          | 1/118 [00:00<00:15,  7.65it/s]\u001b[A\n",
            "epoch=05, loss=0.6021, step=301024:   2%|1         | 2/118 [00:00<00:15,  7.45it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6160, step=301536:   2%|1         | 2/118 [00:00<00:15,  7.45it/s]\u001b[A\n",
            "epoch=05, loss=0.6160, step=301536:   3%|2         | 3/118 [00:00<00:15,  7.63it/s]\u001b[A\n",
            "epoch=05, loss=0.6130, step=302048:   3%|2         | 3/118 [00:00<00:15,  7.63it/s]\u001b[A\n",
            "epoch=05, loss=0.6130, step=302048:   3%|3         | 4/118 [00:00<00:14,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6194, step=302560:   3%|3         | 4/118 [00:00<00:14,  7.87it/s]\u001b[A\n",
            "epoch=05, loss=0.6194, step=302560:   4%|4         | 5/118 [00:00<00:14,  8.03it/s]\u001b[A\n",
            "epoch=05, loss=0.6068, step=303072:   4%|4         | 5/118 [00:00<00:14,  8.03it/s]\u001b[A\n",
            "epoch=05, loss=0.6068, step=303072:   5%|5         | 6/118 [00:00<00:13,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6201, step=303584:   5%|5         | 6/118 [00:00<00:13,  8.18it/s]\u001b[A\n",
            "epoch=05, loss=0.6201, step=303584:   6%|5         | 7/118 [00:00<00:13,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.6140, step=304096:   6%|5         | 7/118 [00:01<00:13,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.6140, step=304096:   7%|6         | 8/118 [00:01<00:13,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5976, step=304608:   7%|6         | 8/118 [00:01<00:13,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.5976, step=304608:   8%|7         | 9/118 [00:01<00:13,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6299, step=305120:   8%|7         | 9/118 [00:01<00:13,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6299, step=305120:   8%|8         | 10/118 [00:01<00:13,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6175, step=305632:   8%|8         | 10/118 [00:01<00:13,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.6175, step=305632:   9%|9         | 11/118 [00:01<00:13,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6106, step=306144:   9%|9         | 11/118 [00:01<00:13,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6106, step=306144:  10%|#         | 12/118 [00:01<00:12,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6102, step=306656:  10%|#         | 12/118 [00:01<00:12,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6102, step=306656:  11%|#1        | 13/118 [00:01<00:12,  8.14it/s]\u001b[A\n",
            "epoch=05, loss=0.6025, step=307168:  11%|#1        | 13/118 [00:01<00:12,  8.14it/s]\u001b[A\n",
            "epoch=05, loss=0.6025, step=307168:  12%|#1        | 14/118 [00:01<00:12,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6034, step=307680:  12%|#1        | 14/118 [00:01<00:12,  8.21it/s]\u001b[A\n",
            "epoch=05, loss=0.6034, step=307680:  13%|#2        | 15/118 [00:01<00:12,  8.15it/s]\u001b[A\n",
            "epoch=05, loss=0.5987, step=308192:  13%|#2        | 15/118 [00:01<00:12,  8.15it/s]\u001b[A\n",
            "epoch=05, loss=0.5987, step=308192:  14%|#3        | 16/118 [00:01<00:12,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6167, step=308704:  14%|#3        | 16/118 [00:02<00:12,  8.14it/s]\u001b[A\n",
            "epoch=05, loss=0.6167, step=308704:  14%|#4        | 17/118 [00:02<00:12,  8.16it/s]\u001b[A\n",
            "epoch=05, loss=0.6065, step=309216:  14%|#4        | 17/118 [00:02<00:12,  8.16it/s]\u001b[A\n",
            "epoch=05, loss=0.6065, step=309216:  15%|#5        | 18/118 [00:02<00:12,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5995, step=309728:  15%|#5        | 18/118 [00:02<00:12,  8.22it/s]\u001b[A\n",
            "epoch=05, loss=0.5995, step=309728:  16%|#6        | 19/118 [00:02<00:12,  8.24it/s]\u001b[A\n",
            "epoch=05, loss=0.6073, step=310240:  16%|#6        | 19/118 [00:02<00:12,  8.24it/s]\u001b[A\n",
            "epoch=05, loss=0.6073, step=310240:  17%|#6        | 20/118 [00:02<00:11,  8.31it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5947, step=310752:  17%|#6        | 20/118 [00:02<00:11,  8.31it/s]\u001b[A\n",
            "epoch=05, loss=0.5947, step=310752:  18%|#7        | 21/118 [00:02<00:11,  8.27it/s]\u001b[A\n",
            "epoch=05, loss=0.6057, step=311264:  18%|#7        | 21/118 [00:02<00:11,  8.27it/s]\u001b[A\n",
            "epoch=05, loss=0.6057, step=311264:  19%|#8        | 22/118 [00:02<00:11,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6004, step=311776:  19%|#8        | 22/118 [00:02<00:11,  8.16it/s]\u001b[A\n",
            "epoch=05, loss=0.6004, step=311776:  19%|#9        | 23/118 [00:02<00:11,  8.18it/s]\u001b[A\n",
            "epoch=05, loss=0.6213, step=312288:  19%|#9        | 23/118 [00:02<00:11,  8.18it/s]\u001b[A\n",
            "epoch=05, loss=0.6213, step=312288:  20%|##        | 24/118 [00:02<00:11,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6197, step=312800:  20%|##        | 24/118 [00:03<00:11,  8.18it/s]\u001b[A\n",
            "epoch=05, loss=0.6197, step=312800:  21%|##1       | 25/118 [00:03<00:11,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.6312, step=313312:  21%|##1       | 25/118 [00:03<00:11,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.6312, step=313312:  22%|##2       | 26/118 [00:03<00:11,  7.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6122, step=313824:  22%|##2       | 26/118 [00:03<00:11,  7.70it/s]\u001b[A\n",
            "epoch=05, loss=0.6122, step=313824:  23%|##2       | 27/118 [00:03<00:11,  7.84it/s]\u001b[A\n",
            "epoch=05, loss=0.6081, step=314336:  23%|##2       | 27/118 [00:03<00:11,  7.84it/s]\u001b[A\n",
            "epoch=05, loss=0.6081, step=314336:  24%|##3       | 28/118 [00:03<00:11,  7.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6068, step=314848:  24%|##3       | 28/118 [00:03<00:11,  7.84it/s]\u001b[A\n",
            "epoch=05, loss=0.6068, step=314848:  25%|##4       | 29/118 [00:03<00:11,  7.89it/s]\u001b[A\n",
            "epoch=05, loss=0.6097, step=315360:  25%|##4       | 29/118 [00:03<00:11,  7.89it/s]\u001b[A\n",
            "epoch=05, loss=0.6097, step=315360:  25%|##5       | 30/118 [00:03<00:10,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6097, step=315872:  25%|##5       | 30/118 [00:03<00:10,  8.04it/s]\u001b[A\n",
            "epoch=05, loss=0.6097, step=315872:  26%|##6       | 31/118 [00:03<00:10,  8.14it/s]\u001b[A\n",
            "epoch=05, loss=0.6134, step=316384:  26%|##6       | 31/118 [00:03<00:10,  8.14it/s]\u001b[A\n",
            "epoch=05, loss=0.6134, step=316384:  27%|##7       | 32/118 [00:03<00:10,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6101, step=316896:  27%|##7       | 32/118 [00:04<00:10,  8.05it/s]\u001b[A\n",
            "epoch=05, loss=0.6101, step=316896:  28%|##7       | 33/118 [00:04<00:10,  8.03it/s]\u001b[A\n",
            "epoch=05, loss=0.6186, step=317408:  28%|##7       | 33/118 [00:04<00:10,  8.03it/s]\u001b[A\n",
            "epoch=05, loss=0.6186, step=317408:  29%|##8       | 34/118 [00:04<00:10,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6085, step=317920:  29%|##8       | 34/118 [00:04<00:10,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.6085, step=317920:  30%|##9       | 35/118 [00:04<00:10,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.5964, step=318432:  30%|##9       | 35/118 [00:04<00:10,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.5964, step=318432:  31%|###       | 36/118 [00:04<00:10,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5921, step=318944:  31%|###       | 36/118 [00:04<00:10,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.5921, step=318944:  31%|###1      | 37/118 [00:04<00:09,  8.20it/s]\u001b[A\n",
            "epoch=05, loss=0.6232, step=319456:  31%|###1      | 37/118 [00:04<00:09,  8.20it/s]\u001b[A\n",
            "epoch=05, loss=0.6232, step=319456:  32%|###2      | 38/118 [00:04<00:09,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5974, step=319968:  32%|###2      | 38/118 [00:04<00:09,  8.09it/s]\u001b[A\n",
            "epoch=05, loss=0.5974, step=319968:  33%|###3      | 39/118 [00:04<00:09,  8.03it/s]\u001b[A\n",
            "epoch=05, loss=0.6008, step=320480:  33%|###3      | 39/118 [00:04<00:09,  8.03it/s]\u001b[A\n",
            "epoch=05, loss=0.6008, step=320480:  34%|###3      | 40/118 [00:04<00:09,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6087, step=320992:  34%|###3      | 40/118 [00:05<00:09,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.6087, step=320992:  35%|###4      | 41/118 [00:05<00:09,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.6050, step=321504:  35%|###4      | 41/118 [00:05<00:09,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.6050, step=321504:  36%|###5      | 42/118 [00:05<00:09,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6241, step=322016:  36%|###5      | 42/118 [00:05<00:09,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6241, step=322016:  36%|###6      | 43/118 [00:05<00:09,  8.04it/s]\u001b[A\n",
            "epoch=05, loss=0.6013, step=322528:  36%|###6      | 43/118 [00:05<00:09,  8.04it/s]\u001b[A\n",
            "epoch=05, loss=0.6013, step=322528:  37%|###7      | 44/118 [00:05<00:09,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6162, step=323040:  37%|###7      | 44/118 [00:05<00:09,  8.15it/s]\u001b[A\n",
            "epoch=05, loss=0.6162, step=323040:  38%|###8      | 45/118 [00:05<00:08,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.6243, step=323552:  38%|###8      | 45/118 [00:05<00:08,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.6243, step=323552:  39%|###8      | 46/118 [00:05<00:08,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6033, step=324064:  39%|###8      | 46/118 [00:05<00:08,  8.16it/s]\u001b[A\n",
            "epoch=05, loss=0.6033, step=324064:  40%|###9      | 47/118 [00:05<00:08,  8.06it/s]\u001b[A\n",
            "epoch=05, loss=0.6072, step=324576:  40%|###9      | 47/118 [00:05<00:08,  8.06it/s]\u001b[A\n",
            "epoch=05, loss=0.6072, step=324576:  41%|####      | 48/118 [00:05<00:08,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6136, step=325088:  41%|####      | 48/118 [00:06<00:08,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.6136, step=325088:  42%|####1     | 49/118 [00:06<00:08,  8.12it/s]\u001b[A\n",
            "epoch=05, loss=0.6056, step=325600:  42%|####1     | 49/118 [00:06<00:08,  8.12it/s]\u001b[A\n",
            "epoch=05, loss=0.6056, step=325600:  42%|####2     | 50/118 [00:06<00:08,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6096, step=326112:  42%|####2     | 50/118 [00:06<00:08,  7.93it/s]\u001b[A\n",
            "epoch=05, loss=0.6096, step=326112:  43%|####3     | 51/118 [00:06<00:08,  8.03it/s]\u001b[A\n",
            "epoch=05, loss=0.6096, step=326624:  43%|####3     | 51/118 [00:06<00:08,  8.03it/s]\u001b[A\n",
            "epoch=05, loss=0.6096, step=326624:  44%|####4     | 52/118 [00:06<00:08,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6161, step=327136:  44%|####4     | 52/118 [00:06<00:08,  8.00it/s]\u001b[A\n",
            "epoch=05, loss=0.6161, step=327136:  45%|####4     | 53/118 [00:06<00:08,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6175, step=327648:  45%|####4     | 53/118 [00:06<00:08,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6175, step=327648:  46%|####5     | 54/118 [00:06<00:07,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6076, step=328160:  46%|####5     | 54/118 [00:06<00:07,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.6076, step=328160:  47%|####6     | 55/118 [00:06<00:07,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6303, step=328672:  47%|####6     | 55/118 [00:06<00:07,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6303, step=328672:  47%|####7     | 56/118 [00:06<00:07,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5926, step=329184:  47%|####7     | 56/118 [00:07<00:07,  8.21it/s]\u001b[A\n",
            "epoch=05, loss=0.5926, step=329184:  48%|####8     | 57/118 [00:07<00:07,  8.23it/s]\u001b[A\n",
            "epoch=05, loss=0.6141, step=329696:  48%|####8     | 57/118 [00:07<00:07,  8.23it/s]\u001b[A\n",
            "epoch=05, loss=0.6141, step=329696:  49%|####9     | 58/118 [00:07<00:07,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6233, step=330208:  49%|####9     | 58/118 [00:07<00:07,  8.22it/s]\u001b[A\n",
            "epoch=05, loss=0.6233, step=330208:  50%|#####     | 59/118 [00:07<00:07,  8.25it/s]\u001b[A\n",
            "epoch=05, loss=0.6004, step=330720:  50%|#####     | 59/118 [00:07<00:07,  8.25it/s]\u001b[A\n",
            "epoch=05, loss=0.6004, step=330720:  51%|#####     | 60/118 [00:07<00:07,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6215, step=331232:  51%|#####     | 60/118 [00:07<00:07,  8.28it/s]\u001b[A\n",
            "epoch=05, loss=0.6215, step=331232:  52%|#####1    | 61/118 [00:07<00:06,  8.27it/s]\u001b[A\n",
            "epoch=05, loss=0.6165, step=331744:  52%|#####1    | 61/118 [00:07<00:06,  8.27it/s]\u001b[A\n",
            "epoch=05, loss=0.6165, step=331744:  53%|#####2    | 62/118 [00:07<00:06,  8.33it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6128, step=332256:  53%|#####2    | 62/118 [00:07<00:06,  8.33it/s]\u001b[A\n",
            "epoch=05, loss=0.6128, step=332256:  53%|#####3    | 63/118 [00:07<00:06,  8.28it/s]\u001b[A\n",
            "epoch=05, loss=0.5944, step=332768:  53%|#####3    | 63/118 [00:07<00:06,  8.28it/s]\u001b[A\n",
            "epoch=05, loss=0.5944, step=332768:  54%|#####4    | 64/118 [00:07<00:06,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6100, step=333280:  54%|#####4    | 64/118 [00:08<00:06,  8.22it/s]\u001b[A\n",
            "epoch=05, loss=0.6100, step=333280:  55%|#####5    | 65/118 [00:08<00:06,  8.19it/s]\u001b[A\n",
            "epoch=05, loss=0.6112, step=333792:  55%|#####5    | 65/118 [00:08<00:06,  8.19it/s]\u001b[A\n",
            "epoch=05, loss=0.6112, step=333792:  56%|#####5    | 66/118 [00:08<00:06,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6020, step=334304:  56%|#####5    | 66/118 [00:08<00:06,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6020, step=334304:  57%|#####6    | 67/118 [00:08<00:06,  7.95it/s]\u001b[A\n",
            "epoch=05, loss=0.5970, step=334816:  57%|#####6    | 67/118 [00:08<00:06,  7.95it/s]\u001b[A\n",
            "epoch=05, loss=0.5970, step=334816:  58%|#####7    | 68/118 [00:08<00:06,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6133, step=335328:  58%|#####7    | 68/118 [00:08<00:06,  7.97it/s]\u001b[A\n",
            "epoch=05, loss=0.6133, step=335328:  58%|#####8    | 69/118 [00:08<00:06,  7.95it/s]\u001b[A\n",
            "epoch=05, loss=0.6211, step=335840:  58%|#####8    | 69/118 [00:08<00:06,  7.95it/s]\u001b[A\n",
            "epoch=05, loss=0.6211, step=335840:  59%|#####9    | 70/118 [00:08<00:05,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6129, step=336352:  59%|#####9    | 70/118 [00:08<00:05,  8.05it/s]\u001b[A\n",
            "epoch=05, loss=0.6129, step=336352:  60%|######    | 71/118 [00:08<00:05,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6041, step=336864:  60%|######    | 71/118 [00:08<00:05,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6041, step=336864:  61%|######1   | 72/118 [00:08<00:05,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6085, step=337376:  61%|######1   | 72/118 [00:09<00:05,  7.99it/s]\u001b[A\n",
            "epoch=05, loss=0.6085, step=337376:  62%|######1   | 73/118 [00:09<00:05,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6054, step=337888:  62%|######1   | 73/118 [00:09<00:05,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6054, step=337888:  63%|######2   | 74/118 [00:09<00:05,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5991, step=338400:  63%|######2   | 74/118 [00:09<00:05,  8.10it/s]\u001b[A\n",
            "epoch=05, loss=0.5991, step=338400:  64%|######3   | 75/118 [00:09<00:05,  7.82it/s]\u001b[A\n",
            "epoch=05, loss=0.6088, step=338912:  64%|######3   | 75/118 [00:09<00:05,  7.82it/s]\u001b[A\n",
            "epoch=05, loss=0.6088, step=338912:  64%|######4   | 76/118 [00:09<00:05,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6097, step=339424:  64%|######4   | 76/118 [00:09<00:05,  7.97it/s]\u001b[A\n",
            "epoch=05, loss=0.6097, step=339424:  65%|######5   | 77/118 [00:09<00:05,  7.94it/s]\u001b[A\n",
            "epoch=05, loss=0.6011, step=339936:  65%|######5   | 77/118 [00:09<00:05,  7.94it/s]\u001b[A\n",
            "epoch=05, loss=0.6011, step=339936:  66%|######6   | 78/118 [00:09<00:04,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5970, step=340448:  66%|######6   | 78/118 [00:09<00:04,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.5970, step=340448:  67%|######6   | 79/118 [00:09<00:04,  8.10it/s]\u001b[A\n",
            "epoch=05, loss=0.6062, step=340960:  67%|######6   | 79/118 [00:09<00:04,  8.10it/s]\u001b[A\n",
            "epoch=05, loss=0.6062, step=340960:  68%|######7   | 80/118 [00:09<00:04,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6176, step=341472:  68%|######7   | 80/118 [00:10<00:04,  8.14it/s]\u001b[A\n",
            "epoch=05, loss=0.6176, step=341472:  69%|######8   | 81/118 [00:10<00:04,  8.15it/s]\u001b[A\n",
            "epoch=05, loss=0.5884, step=341984:  69%|######8   | 81/118 [00:10<00:04,  8.15it/s]\u001b[A\n",
            "epoch=05, loss=0.5884, step=341984:  69%|######9   | 82/118 [00:10<00:04,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6329, step=342496:  69%|######9   | 82/118 [00:10<00:04,  8.05it/s]\u001b[A\n",
            "epoch=05, loss=0.6329, step=342496:  70%|#######   | 83/118 [00:10<00:04,  8.10it/s]\u001b[A\n",
            "epoch=05, loss=0.6056, step=343008:  70%|#######   | 83/118 [00:10<00:04,  8.10it/s]\u001b[A\n",
            "epoch=05, loss=0.6056, step=343008:  71%|#######1  | 84/118 [00:10<00:04,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6166, step=343520:  71%|#######1  | 84/118 [00:10<00:04,  8.05it/s]\u001b[A\n",
            "epoch=05, loss=0.6166, step=343520:  72%|#######2  | 85/118 [00:10<00:04,  8.10it/s]\u001b[A\n",
            "epoch=05, loss=0.6035, step=344032:  72%|#######2  | 85/118 [00:10<00:04,  8.10it/s]\u001b[A\n",
            "epoch=05, loss=0.6035, step=344032:  73%|#######2  | 86/118 [00:10<00:03,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6039, step=344544:  73%|#######2  | 86/118 [00:10<00:03,  8.07it/s]\u001b[A\n",
            "epoch=05, loss=0.6039, step=344544:  74%|#######3  | 87/118 [00:10<00:03,  7.94it/s]\u001b[A\n",
            "epoch=05, loss=0.6036, step=345056:  74%|#######3  | 87/118 [00:10<00:03,  7.94it/s]\u001b[A\n",
            "epoch=05, loss=0.6036, step=345056:  75%|#######4  | 88/118 [00:10<00:03,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6090, step=345568:  75%|#######4  | 88/118 [00:11<00:03,  7.95it/s]\u001b[A\n",
            "epoch=05, loss=0.6090, step=345568:  75%|#######5  | 89/118 [00:11<00:03,  7.87it/s]\u001b[A\n",
            "epoch=05, loss=0.6128, step=346080:  75%|#######5  | 89/118 [00:11<00:03,  7.87it/s]\u001b[A\n",
            "epoch=05, loss=0.6128, step=346080:  76%|#######6  | 90/118 [00:11<00:03,  7.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6115, step=346592:  76%|#######6  | 90/118 [00:11<00:03,  7.86it/s]\u001b[A\n",
            "epoch=05, loss=0.6115, step=346592:  77%|#######7  | 91/118 [00:11<00:03,  7.97it/s]\u001b[A\n",
            "epoch=05, loss=0.6137, step=347104:  77%|#######7  | 91/118 [00:11<00:03,  7.97it/s]\u001b[A\n",
            "epoch=05, loss=0.6137, step=347104:  78%|#######7  | 92/118 [00:11<00:03,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6167, step=347616:  78%|#######7  | 92/118 [00:11<00:03,  8.08it/s]\u001b[A\n",
            "epoch=05, loss=0.6167, step=347616:  79%|#######8  | 93/118 [00:11<00:03,  7.94it/s]\u001b[A\n",
            "epoch=05, loss=0.6182, step=348128:  79%|#######8  | 93/118 [00:11<00:03,  7.94it/s]\u001b[A\n",
            "epoch=05, loss=0.6182, step=348128:  80%|#######9  | 94/118 [00:11<00:03,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6088, step=348640:  80%|#######9  | 94/118 [00:11<00:03,  7.99it/s]\u001b[A\n",
            "epoch=05, loss=0.6088, step=348640:  81%|########  | 95/118 [00:11<00:02,  7.83it/s]\u001b[A\n",
            "epoch=05, loss=0.6065, step=349152:  81%|########  | 95/118 [00:11<00:02,  7.83it/s]\u001b[A\n",
            "epoch=05, loss=0.6065, step=349152:  81%|########1 | 96/118 [00:11<00:02,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6050, step=349664:  81%|########1 | 96/118 [00:12<00:02,  7.94it/s]\u001b[A\n",
            "epoch=05, loss=0.6050, step=349664:  82%|########2 | 97/118 [00:12<00:02,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6037, step=350176:  82%|########2 | 97/118 [00:12<00:02,  8.02it/s]\u001b[A\n",
            "epoch=05, loss=0.6037, step=350176:  83%|########3 | 98/118 [00:12<00:02,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6051, step=350688:  83%|########3 | 98/118 [00:12<00:02,  8.10it/s]\u001b[A\n",
            "epoch=05, loss=0.6051, step=350688:  84%|########3 | 99/118 [00:12<00:02,  8.05it/s]\u001b[A\n",
            "epoch=05, loss=0.6038, step=351200:  84%|########3 | 99/118 [00:12<00:02,  8.05it/s]\u001b[A\n",
            "epoch=05, loss=0.6038, step=351200:  85%|########4 | 100/118 [00:12<00:02,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6053, step=351712:  85%|########4 | 100/118 [00:12<00:02,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.6053, step=351712:  86%|########5 | 101/118 [00:12<00:02,  8.21it/s]\u001b[A\n",
            "epoch=05, loss=0.6056, step=352224:  86%|########5 | 101/118 [00:12<00:02,  8.21it/s]\u001b[A\n",
            "epoch=05, loss=0.6056, step=352224:  86%|########6 | 102/118 [00:12<00:01,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5939, step=352736:  86%|########6 | 102/118 [00:12<00:01,  8.24it/s]\u001b[A\n",
            "epoch=05, loss=0.5939, step=352736:  87%|########7 | 103/118 [00:12<00:01,  8.15it/s]\u001b[A\n",
            "epoch=05, loss=0.6078, step=353248:  87%|########7 | 103/118 [00:12<00:01,  8.15it/s]\u001b[A\n",
            "epoch=05, loss=0.6078, step=353248:  88%|########8 | 104/118 [00:12<00:01,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5962, step=353760:  88%|########8 | 104/118 [00:12<00:01,  8.20it/s]\u001b[A\n",
            "epoch=05, loss=0.5962, step=353760:  89%|########8 | 105/118 [00:12<00:01,  8.23it/s]\u001b[A\n",
            "epoch=05, loss=0.6146, step=354272:  89%|########8 | 105/118 [00:13<00:01,  8.23it/s]\u001b[A\n",
            "epoch=05, loss=0.6146, step=354272:  90%|########9 | 106/118 [00:13<00:01,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6185, step=354784:  90%|########9 | 106/118 [00:13<00:01,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6185, step=354784:  91%|######### | 107/118 [00:13<00:01,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.5993, step=355296:  91%|######### | 107/118 [00:13<00:01,  8.13it/s]\u001b[A\n",
            "epoch=05, loss=0.5993, step=355296:  92%|#########1| 108/118 [00:13<00:01,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6016, step=355808:  92%|#########1| 108/118 [00:13<00:01,  8.18it/s]\u001b[A\n",
            "epoch=05, loss=0.6016, step=355808:  92%|#########2| 109/118 [00:13<00:01,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6254, step=356320:  92%|#########2| 109/118 [00:13<00:01,  8.17it/s]\u001b[A\n",
            "epoch=05, loss=0.6254, step=356320:  93%|#########3| 110/118 [00:13<00:00,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6054, step=356832:  93%|#########3| 110/118 [00:13<00:00,  8.23it/s]\u001b[A\n",
            "epoch=05, loss=0.6054, step=356832:  94%|#########4| 111/118 [00:13<00:00,  8.16it/s]\u001b[A\n",
            "epoch=05, loss=0.6032, step=357344:  94%|#########4| 111/118 [00:13<00:00,  8.16it/s]\u001b[A\n",
            "epoch=05, loss=0.6032, step=357344:  95%|#########4| 112/118 [00:13<00:00,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.5854, step=357856:  95%|#########4| 112/118 [00:13<00:00,  8.21it/s]\u001b[A\n",
            "epoch=05, loss=0.5854, step=357856:  96%|#########5| 113/118 [00:13<00:00,  8.08it/s]\u001b[A\n",
            "epoch=05, loss=0.6111, step=358368:  96%|#########5| 113/118 [00:14<00:00,  8.08it/s]\u001b[A\n",
            "epoch=05, loss=0.6111, step=358368:  97%|#########6| 114/118 [00:14<00:00,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6132, step=358880:  97%|#########6| 114/118 [00:14<00:00,  8.15it/s]\u001b[A\n",
            "epoch=05, loss=0.6132, step=358880:  97%|#########7| 115/118 [00:14<00:00,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.6127, step=359392:  97%|#########7| 115/118 [00:14<00:00,  8.11it/s]\u001b[A\n",
            "epoch=05, loss=0.6127, step=359392:  98%|#########8| 116/118 [00:14<00:00,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=05, loss=0.6019, step=359904:  98%|#########8| 116/118 [00:14<00:00,  8.12it/s]\u001b[A\n",
            "epoch=05, loss=0.6019, step=359904:  99%|#########9| 117/118 [00:14<00:00,  7.89it/s]\u001b[A\n",
            "epoch=05, loss=0.5972, step=360000:  99%|#########9| 117/118 [00:14<00:00,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"90d24222-9318-4013-bbf2-0891fe890ddf\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"90d24222-9318-4013-bbf2-0891fe890ddf\")) {                    Plotly.newPlot(                        \"90d24222-9318-4013-bbf2-0891fe890ddf\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAcYElEQVR4Xu2aebxlV1Xnf2utvc85d3xjpapSlYGkgCSkSBowdhgaghhmGdQkDCICzaBAEIQIooQGDBC1gfAJrUFBw6jYRjoBg0JAgnQwTTANMQFDIEVSw5vufM+w91r+cd979d6tauHTH\\u002f5o+uPvn3P2d911V9119l577fOK2vh3HU88Df5dE\\u002f3EJmbfP31zGv1Y9ZOamCtvPOn2afZj1XRizr167epzptj\\u002fe9rxuZfM3fHKafpj1VRi9l93iV3y19vZVr1+rfuoaQYAaO58weuSaQhg3xkv7q6tra2tfcRPm47qsd954DSCzM3NXXb5R3d9sHv4N6dt+656BC5\\u002f4+o0\\u002flFVv+nOk6fZMXLbRg+\\u002fdsb61fx5t1Xb8Kae++sKm4YATrn0vLOAnW+Y5mc875m8Ww0AnvKe3+xv4EfOX3\\u002f0MwAedtu2IfYm550\\u002f8wwAuO\\u002fdT+9\\u002f8+btVmD+QuD+L0\\u002fTH0m7FtF5zH\\u002f4zg9P6tbE1M65Zhdw93s\\u002fdOPbf38L3qKT02kCAA96xcUZ\\u002fWDw4Gd98NtTlssvPHr\\u002fnD+7ZeP2MadvSwyfspe2jh\\u002f66Zn1O3378C8Odb6z1Qhg3zWE531mCm7RK5MHX4Rv\\u002f\\u002fQ0xlkvOwn7TsIfnEH3Hzu5H3Hxo87Ebx06\\u002f5O3TsZbE\\u002fPeXwCAcxs3P+asLXSLHvcyfPuiI1Ow\\u002fdZnt4C7n5X848L8lAk3XYila8lw3qO34Uv+cdtw5ws\\u002fuS2jB9ZmAODW7mPKT2zlG7r4pM+95uA03NCjznrU0wmG07923rTpP70AKD752NfCPnbMjHn2uxboy4tvBy28aAK2JObcCwk3\\u002f83bD93eeey2B7ip\\u002f\\u002fiBNt57YJo+7ZcB3POM+06fNgD44+tRHQHQ+p+7cf3R9TJV2N6Pu7eN1978pNvfjdufMTrjFdv4uv52\\u002f\\u002fffdPy87PyTU9Fu0G3nAuD6tPWNr8bHlq9a3v9XC8vXTZncw95X\\u002f8q7v5r+6eOx8a88mpj917Xtb1\\u002f06Lf92fI39Ynn\\u002fNMmP6rn7sKXj32EzwK+\\u002f\\u002fW33Idj6ycQ7ptcf2YWuL\\u002fcoA85YeNuojZu2g5u+PvB2S94\\u002fwh3XrqdAwCe8gi7bjwNAQCPe99eADhvZWHX1Xtw17S5Xrv3vxzGaa9bHL2zmDJd9H7c9MI+fv7xuO\\u002fj62gzMfsunVk59LHhjTcCQO1VL9ngR7XwS9r9vWkIvOpXvvDdJQBTv3arfv6Xa8A7NocX1rbYgB2n4P5tAOijhxf8pU5RAMDMI4HO\\u002fQBesQdv3m66dC9QvOXW72D15Xvw\\u002fZduNwJ\\u002f\\u002fbMPfutr27\\u002f7xLUrPzhlefPr7INv6wO\\u002fAbxheZ1tJCZ5+4X9l92WbXx078bNUZ18LfCHfz9NgUNXTK7HLOkNXfTaB3jg9qMb3QPxz1vMeMcJ\\u002fzLYOgYAXHHuox\\u002f3hWkIAPFc1n8Afs1edjJedcbWJfX4nwIOvPQWANgDfGZliwkAcPvXHvzYC644Ce\\u002f8wynDZa8rP\\u002f87OdLH76UrN2v6RmLOvRDP+coGPK6ecDa++IFpuK6X18nOwi3bayqAky95HHC+Ab3LP5dv4V\\u002ffvGs94eLH493dLbaJRq\\u002f++\\u002fd9+bZrju0NHvVIPbCK\\u002fec\\u002fBcP7H3jtr2wpea+s45Z33gJg9mcfiVs+d9SwrrKPXR8h+7PtrQIw8xL7\\u002fHOB0z54Lq57zybdSMw76OajeWE9tvo+9XJ89eW9aQoAtTMvuxCsOPSrccpy1sdPWr\\u002f76oe3cswBOJsfu8dfxPmthfvGNuNE97zi6ksuqX\\u002f88BRunopDn7h736VPXbnpqtb1214NfHih9+IjAPCiN+Off3l68wRwAAA+d9V63dtUsoA37HjeU85smn1ytEnXE\\u002fPE\\u002fbalMVA75hxy8keA7y1NUwDunGt3jQ\\u002fd8oQ65OkfmO4LiQCwAk+6cMsTHNt7XgecTWF010duu\\u002fnInbXp9gcAcP133\\u002fG4t5z0e1P7z\\u002flX4MPv2vH2C\\u002ft\\u002f9Vunv6f\\u002fpa175Kc\\u002fPbk+6TKEDx0nL3I+ATdePI1RLi\\u002f+bwMO9net\\u002fM1Rup6YWrL03zdQ8kZ86fKNwYZeo8B\\u002fnYYA\\u002fBM+ind+6Za5\\u002f3EWFi\\u002f\\u002fwfWbOw8A4I6nXvz5HMALXrYNv+7ATwP4wQ13\\u002fSMAvHDxnm3WTd3xwidf\\u002faLTn7kdPgR4Fz76CDznK+f9Da6eqr4Tfdzwhg9PQwB\\u002f8nOG4\\u002fXt3ef++dw9N3x07UO7\\u002fnIL3dyVio1Jm7z+0vveP9zA69r\\u002feOCG6Q4UgHvTpfi7P+wu\\u002fsVDyvee+dQP3vTeDrZOtgOTXeyK7YnBe7YOHov1J32Mup+4yj3q0TdvYzN0A\\u002fafTG\\u002f6yr5r6E3HLXm\\u002fw4rjVMtdz3+GfeObz98xzQHcehoAPPLR+r0tcDMxn12\\u002f7r\\u002f02Tf80gbc1HWzuPU43Za8+dXDt36q+7Arz7n717\\u002fc+umLnnwdfvDQ6Q8BPzMNtuuGaTDRQ57xcIc7\\u002f2GKmgFqZ38r+\\u002f6Tjlvx\\u002fDlql21vGAEAj\\u002fstvO2Pnvb8O6f5pmpqx5kxRE+9DADwa6+f+fOp5wsA84prpmcRgBe+evSaL\\u002fzU8y7M3vWR+9D\\u002fu7\\u002f7hYvwxk2j+5kvTXai579zk\\u002f3oeuBLn74TiIenmpnPXvrU885u4jm08s6p6jNR7eIL8Kk\\u002fP7YDevS7cPEXd16Ge6cNm\\u002fr89uF6Ysx2vvva1Z+65Ow9Bz4\\u002f3f4AuJqBzSPgFl0GefUbTwOu+IPJhvSpTx21nf8bF+y\\u002fD8Dche+oYzw+apgWnfa1aYQTfvE\\u002fnwLgtis3JvKGylH9RgPQ\\u002f6tj92MAzfc9E2\\u002f8o2Pzggtmbr7RPalNx3Q3m5qa1ptLSV7yc\\u002f3Tga996Xe3mifaf4GW1xynzuPwYrofn\\u002fvKDfdOb9QArjwLr+kDuOBcw5f\\u002f+N94SWBTRydgx5lXPgjAre\\u002f9zDE\\u002f8Rsv\\u002frXHAB\\u002f71u3HKSMATnwm7vlv0xAAzMw97V2dPz3OU1\\u002fXA7YP1xPzta8\\u002fDDtPwOpfThbUlGZOwP3H3QCe\\u002fLRzlq7tTG\\u002fSm3rx5LL02cumDyfbdN7Htg3n3vPQUwHcctXnt\\u002faEG5qcWf4PetAr8S8\\u002fPw0BAItY\\u002futH4hVb9uNp\\u002fQNvewrribn\\u002feS96PfCBPzlO1fq3NPjEsYfKDf3qS58LAPeMvvrhO6Zt27S9mXzEqx9+IoDxB37\\u002faLP1I+sNz8YfHXP8BwDchWfS2jVfnMZbdMfdpz5g46CEo0vp8BVXHIXT+vYt50+jH67bX\\u002fu\\u002ffnv2+ptuON4S3Kq\\u002ffda24dOeDtz12XjVsaeEH64zWvjQl6bhRB9P3nDbZ66eptv0e+\\u002f\\u002f7dfftTmibV31T7je+qp7f\\u002fE4zdaPqNaHL\\u002fj0r25O02MK30+yvoA3\\u002fd\\u002fnBf0X\\u002fvHPbZzt\\u002fj+bMT9OMRvYs44DTCWGYSijaYhQWApSJiKCKQAQUwQbMVmkVAmAkRHImEWI2XkPMKWpEmBGRmBiYWER5z1sw8ZgMJGBhIlIxBkYyRY\\u002fAosc47ceb2I7Gs8bEYSImEkNImRESkQEzzAmJpock4iZFKTEBBU38WNi2vRDBBGZcxBB5LRWGSSMjSVSJY6DFCCIQYVVFAwoR0cMX7nCxVit7ybGKkRGFM1bIIHGnI1grARRF2HMJTkLRKKxYAIBpAYQEYEUAoWDWcGY+Bmr06N+TBoL3hJPyZgq+HVbzgRMTvEEYoISk7J5JS1ZohlLZCUxGEchskRdKVQJAyBROuoHE7jIVFHNUyTiKI1hpRW1+i46H31aMCwyIpiigM1MjdmYECmamCmJGUciFiYwKlYzUgqkpHBqEklIhI01sCKwUqTICjFjBZjJmCiQGpFShPKGHzMLG9umH5SURLEej41RsUIn8ZgAIzIDmxkrR7bIcFBSYjMTigQ2g0UmsFEUVTGwTfkRIpuHcnRwZpaJUY+F0lZ0CaykEhypElUi8GQtmTHYE0yCEAKzESmzI+\\u002fIC1CWZVSACMRsYIg4Thx7MVRFWcHACiIxogh2cIAnoTJWqgCM1v1YHCWOEzYqizLAJulgIzZmR4mwZ1BZlJNpByIYk2Hy2zk6CBsRgYiIojGByaAGBDbyohBlQSQzBhHAZqDgwJPKQQxyTgFSqVQarjXXmGfXHS\\u002f1e4PUXDATBjHUVV58SmKQkBegIGIgJcCLa9ebjln7o7WqNESJIABk7Jybq80kTNYbruS5wiQSDAoyRz5NM+fYRsUwVIaKlTb9\\u002fGytnTBpf7hSFApzkchIiciJb9ebTsh6o7USBpVIRgSQsZF5RwkQjTRECgRWCIHBUcwJJ8rGXosSGkUiEQjKRuY8EiCCY4gUQeKCJ9Eqxqbfsbj7lH2LyFcO\\u002f8v3fiCjyGUNUKekFMXX6zM1kVAMe4YoiARjS1yazizMNTOPvLNWW\\u002fahSAKbwhipS2pzJ8zPphnGa6vZESlLiaxmYHOc+GaznTVYqlF32Cm0SCNIYWyppNncjvmZNLV8bTU74iZ+CmMkkqazC3OtNLGis1pbLkLhA5uBCErwws20yY5QhHwYAxCJCCYqSvBZLa155zWOe3lRTcocSAnOcSNtiDAVoRhoKCySI4VLSkvSXaeetvvkk1pp59SDnouIblaaMZTMpMrSxo4dcxz7wzhip4bJYqGk0VrcNTMv3saNhtP+MCgw2TjgmzOLe+YXXRLHtTpF6VWqUBgTKKnX5xaaM4lHWcwsUT\\u002fXAAKBIEia7cU98wuSxHGtzrHbD6pQAoORNFsLu2fnxeu43nDaGwY1mKmQkUOaNepzrTobD4drXJSxAszYlEBstXp7brbOPM7XyqAxGumGX9Koz7brTDwarnFRxBJwRLA8wezsCXtP3b2YSY\\u002fz9lnOxfuk0CiIxBqj87X2CafMuqLbGedh5KOSEoTTrDW30J71vgyRk1prZDA1GJlwkjba8802ZKjjYL7RM1MYwMTsa62ZhfmZulhIUhdiURDDyEDMSdqYWWi1yY9jrpQ0+2ZqBgDCadacXWzPuKQIgX2tOTQzM5gAbJQ0Wgs7FrJGTDWu1FyXYoykAgMpKGvOLs7vqmUouhSiaVRa9\\u002fO11vyOhXpDM4urh1wXGiI5dgUcZ+3WibtP9Cudfh8zu+onHZw94qMnEzIDOWmdMH\\u002fCwqx1a92EWSIIBCbHSVZrNqwa9KLVOWHRShXGxhDySdLIgnW7MWTRsUdUGMiEnKT15mw7lXIUk1pa8840RigbQdinaaMW0OtoqJknZ2HyXywIjpMsa9atGnRVa+TZaVCFcXQwqiWtxR27Wo5DCsRxJ8ktmoo6KJwltZkTZxbajaRK8rrzDIVyFDLKktbC4oktLzElxNFamls0dVB2pMy7Ttxr\\u002fcGR\\u002fgHZve\\u002fk9pmrh3s8aKqRAIJmvZl5LwFRyzLESkoYEwMGp6WOOwNrCRw0EJFEIxaomg+ljjsDzaIxEBjqgzEzmDh1bIPO0OYSnyJWBgaUWEjNXCziuDPQuhkDgVh9UGYBzHycxGuybcYDAyyU1Od2zSWDYdlaTCqhYCqRCApHEJmZn2mwVnDmQowWXc7EBBZytdndc+lgXLUWk4qpsihBXAzjGUS\\u002fZ+\\u002fO9vjAcu\\u002fgSrUmdJoTR8oSSQAqUhMth2U5Hg4GgzzkFowjkYGJWWy4ujKsZ+yGYgwQoAwlMuEEo5WVUSZIC6EkN1JThkGImHTcWxrVGuIIpaoRLAqUCcIOw9XlUc1TkgtcYWSmNNmQ2dlwbXlUy9iNxGTSZxomjahoVRzJS6cUxp3BOESAgzBIqppB84qrNA2jQW88ipWRGaDMKs5CuVyULqIadwbjqGQOlqo19z74ASdWq53R3auro9Xaie6kPXeYxsKxcYAwU1VYkqwNl470hyEAMJiRWaxUYxkpydotPxDTQGYwM1KDkWpJPk1nWkmRkqlisjTJYlCN5SiYazSEQwyVW\\u002f9OhUbSWMGn2UzL5wksGogm8TRo1DKyz1otP3Tr8ZTJnIWmS6lcXi5SV7PRoXFeCTEqEZNgXlIfC1\\u002f3FteOHBmMKwPbxK+qu5TKleUydTUdHhyPKwbDQSBxdn733nTt3nvvL4aQtCqdJjMegU1dhBKoDKgvuKTod0eFwiILYoSoc0lN0npoted2VE3PSQwEk6jmzGf1lmShrDfm5rQcuKwozFQ0mosM8pC01pibncudBbgIQKIaq0+zplgoG825hZh3XFaVZioxmqjzSV2yEFqt+fV4FcEkwiKZioZYJW5xMRktry4Pk0pN2JQi1DiWOc3ONXg4PNTtlRaVhCIskJloGFVZsrDoh0srS0MfIsSlrFVt8UGnJ+WBO+8p41C7mYAkCUoJYIEjIMQx2btD7u2tdYYlSxCtzDGbGrw0LUtlZu9cMchSItLJmUpJKOF6mng0d87COo2ucAWODNZYqXDdfJbsOHmmmxCbkUWpHImCKeFGlnhq7Z7VaqXeFQ7G0ZGomXluapryzJ65cpRlk3hgI6PAgJprzu\\u002fZSfct9UoG+ZIMSqzE4ig05ve0llYOHunlLOqDEhuBIoNUvVvYswP3Hu4WQpSU5KI306ydzt5z1\\u002fcPRTaIazaybghuUC8TAkhVQ6zvOHGhX3QHo4KUWEkRFWARk6xM5pJ2M0OWuawgiFEkI3apcz5QUxq11BoNlwozKKoReeHAKVy9vjibCBEnBYyVIhmzJOySXNquUctCo+GyIRGRRiJm58ilZTLr280MWU2yglUsGhkbaVFprZEs7m6vjtZ6ucEqi1EIBouhLGfm9+7klX6vO4jBkUKx7ldWsdHMFnc3l4drvdxSqyw69CyZ33fSCQdv+853V2fzYI20uWCj\\u002foDc2FMkJnIRzi3MZkvdfq8MxAAIxoJYasxSruelRZDPavWeESkpMSwiJKJJCMHqjbTeaLhoUDIW1lJjknrRmKWpCLxnIxgZMTQgpN7SGEuuNKnXm2sKmCkLtIwxTblGpQVDktUaPQWUwAQQQhkQWq0di2HtUCeQODUHkBkzuIqC2bnWqL+8NKpIBEpq635FhdCe2TFfLN+\\u002fFpidQsxVoa6Zm62qwepIQmVc27V3Zz48NBhXIDBMyEypUbey1x3lkSx4kAnMHARJFcpYFEzD6Jhd4gEJLqqwUC3Gshznmo38nHM+SSI0OgOTGOVFLlYibcS+mXhRRnRRHQllMZTVuDAdSkucS7zCglP15CgJVRnzgjHURMQlSQmLbCB2CKOeWwjjol92h+MQo9ONw7RTDWWZ+VD2u4NRhJqfnKsBdgjjntsR8qI\\u002f6g7HIQZvquwkKXcs7pyxYpznaVaHe8j+M13nu0d66nJPYFExSVLmqtsrCuKKODgyik6DJVHLnGOvz1XNG8SzxMpMXbQo0KqMZb+DWq0dXOqFWdXMaTAfQj5gyaux1GRcmsCHChRdVLBpWVrV71C91ggu8SKsBnUakKoWBYd+j4t6UpIkzFyZRQFTdCEMEo6Lo6w83BnCm0wO5iBRB8dcBR0Mxn2NYFYiotKZoygxDFNvfpSMDnWHcGBjYmfiVThJs5nmbvIzcX7fvnb2\\u002fQOHx5aYKZkyO59lNRrHtcE4RBiJEkWqnDnmMu9XxbDIQGZFXpkBZlSxJSJWDdxwUCTeJ8lgVCkIMKo8mKwc9WEFKFQhL4pAqoigSiwRieXAjQd56sS54ahSA0wn8agq+mUxzDMCKM9LA2DG6gAhCzGUw1qe98oqFI61YgNAZE4kcd7pUHrdUaVRiCJBWZ2RkEWN5WjYHnfKSksnVrGS4xiqUFD9lLPkADcaye6988N7vnHnsqjypF9xSavZSFV7nSoY+WiBDeZg7EVDUSJodD7zRRnLQqNGZpCknkJgsHdZc66pVTkax2iRhJSZYiiHgDKbVUUOU0DVEeASZzGYQjipzzRiqPJco0USmHixUFYUzFxaT8oyTOIREQiI3msoGyl6vaUxpw4sUYhgRPBJs5E6uOHqcBwlBa0XXhPAJDENkmqvu5xz6olEhZxRc9gbLi22HtY607eDn0V1z+E7Dy4TYjZpqzjJao1mo+p3O6VOEEAxegGLODNOaq0ZX3WWl0dFBCiqOQazT52AW7W5uvUPHuwOKjOOpp6JhMlUfK2eWdEZDaMagQOZY2JxCTtDoz5f0+6hQ71hhQ2\\u002fSTxJaq0ZHzrLS8M8AKQENqgXV0vbM4mvRjH6IAoOkclI2TjJsnqrqUWnUygbGcgmL4ag3k38XD4K0asoOIBdYoEH35pJztizp5uoVb3D3\\u002f3O9w7mvnBcejUycJK12203WO3GAImTl9lmCUBqFCpq1LJWPR8dXuoOCjVVYiJYFWNQrjekUSs79x9eWhtHVQMLMTMJtGr4doP7vW63KIKarZ++gloVuVZ3zXpRHjy00sknfg6AGlWB67W0VS\\u002fGh490++UknqqAJK2ltblWfTRa7ZQVK0cwiIISWJJ6e2YmG6+ujgoFKSsxlFWZSNJ6rTHfyob9lV4VWDkaE1wMXuPSHfXxSQlBlg+t3Pm9e1eX8sSjsigKMyXnvJTFSm8ACgCEVE2NqKCyR9Quk1h2qt7q8tI4xihkkQlVMeyQNlX8eBR6neX7hlWlrIjMGnwciU+VY9Ubri51B5VZEEU0QimjDqxljvKi6q8tHxxWMfLEZlT0iNqlj0WoeqsrR8YhRgYiEwVopZY5yavVw8NRMNKoAKKA1CJYEh\\u002fHnbVO1EAwgilFJp74pSJ5sXpkOA4AosLIoV7VVnsHD+3bO1\\u002fD8MjhQ99bG8TKlWREQqJOpCpi1el3l1eKEBEIkYHolMA6qqp83G6UgzgYrw3yvIpSAWIglGv5oNtq1pyWw3FnNBpVyhWII0WhoIAIoQi9wVo\\u002fVCFKIBMDUdUtRv1Wq+atGuZro9G4ilKCWIlIh2UxHrUbRT8MN+ORuYjITBasyqkaLK\\u002f28giQkrGKcUxEQmGxP1pdWhoXgSKRilJwEYGFLSIW\\u002faK31BnkamRKKpHSpqusbPKOvO5kWGp3pL6oJTAMTTIjZudbzRlv3bXBSDlagBDULIojgKmZZllClRbjoigtAhZYRQhgqSeZdxpiKKqihBppkMgeZIxmo15PqAzjUV5WMRIQaP07pZ5kibMQQ14Vpa37bYnnEbQYlxvxiIgJ3tcbc\\u002fW0GHbyYZ4TRxKFxQTkxPtWYy7B2kqniKhgJqxmymAi7xuN+VqS9zv5sMiJI0sEqOFjHRqVRyRJEZ0fO8sIlddg5onJkKWpWBxVuQooGoMqMgiMzAWyxItjWAwxViDSyRbCKoGjd8RirFG1IiJVJWaFOQWnifNkMVQhViCYKSZ+kdQ7EjGyoFqBKJrSlnjsGNiIFycvdgmS+CQjV8aiGmswJjY1UmFmUJpmSbRBNVYjRGIgAEYENkmSNIOUIa9yjRM\\u002fZWoxC4WkCpXTmMKrL5z5UIW0csEzK9g8E8rKlNmXUhCzIvjISpO\\u002fbJAIq8XIEeaiiomSkoEiyFjIzJQjmVNlSCQDjEHEXkg1RIqkbMqbfrruB1WO2PDbjAdxpKaRI9RHFSMFiIQ9HHGpUUsoOTMABgEzkSXMqHJVgQSevL9S1smb1oSEqNCo1YafgeYrJUvcOFHXz+CMjXICVHyoD01AAWRJxVZ5sJRCFROpsa8imRirsYmRRkYUUwmCzEoldYCpRKeskSkyVIKgFoOSEdiMTZSjkSlDJTClViqZGJmKipEqHfXTo\\u002fF08p3YsGWhMiElMTaDSQTp+h9HkVTKjEhkPsCiA0vFFBmmJggTP7AaVBQUed3P\\u002fyvDIQ2C4DWorQAAAABJRU5ErkJggg==\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('90d24222-9318-4013-bbf2-0891fe890ddf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=05, loss=0.5972, step=360000: 100%|##########| 118/118 [00:14<00:00,  8.11it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6193, step=360512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=06, loss=0.6193, step=360512:   1%|          | 1/118 [00:00<00:14,  7.94it/s]\u001b[A\n",
            "epoch=06, loss=0.6236, step=361024:   1%|          | 1/118 [00:00<00:14,  7.94it/s]\u001b[A\n",
            "epoch=06, loss=0.6236, step=361024:   2%|1         | 2/118 [00:00<00:14,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6163, step=361536:   2%|1         | 2/118 [00:00<00:14,  8.11it/s]\u001b[A\n",
            "epoch=06, loss=0.6163, step=361536:   3%|2         | 3/118 [00:00<00:14,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6027, step=362048:   3%|2         | 3/118 [00:00<00:14,  8.17it/s]\u001b[A\n",
            "epoch=06, loss=0.6027, step=362048:   3%|3         | 4/118 [00:00<00:13,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6157, step=362560:   3%|3         | 4/118 [00:00<00:13,  8.15it/s]\u001b[A\n",
            "epoch=06, loss=0.6157, step=362560:   4%|4         | 5/118 [00:00<00:14,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6041, step=363072:   4%|4         | 5/118 [00:00<00:14,  8.06it/s]\u001b[A\n",
            "epoch=06, loss=0.6041, step=363072:   5%|5         | 6/118 [00:00<00:13,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5884, step=363584:   5%|5         | 6/118 [00:00<00:13,  8.09it/s]\u001b[A\n",
            "epoch=06, loss=0.5884, step=363584:   6%|5         | 7/118 [00:00<00:13,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5916, step=364096:   6%|5         | 7/118 [00:00<00:13,  7.96it/s]\u001b[A\n",
            "epoch=06, loss=0.5916, step=364096:   7%|6         | 8/118 [00:00<00:13,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5965, step=364608:   7%|6         | 8/118 [00:01<00:13,  8.01it/s]\u001b[A\n",
            "epoch=06, loss=0.5965, step=364608:   8%|7         | 9/118 [00:01<00:13,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6012, step=365120:   8%|7         | 9/118 [00:01<00:13,  8.04it/s]\u001b[A\n",
            "epoch=06, loss=0.6012, step=365120:   8%|8         | 10/118 [00:01<00:13,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6314, step=365632:   8%|8         | 10/118 [00:01<00:13,  8.01it/s]\u001b[A\n",
            "epoch=06, loss=0.6314, step=365632:   9%|9         | 11/118 [00:01<00:13,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6166, step=366144:   9%|9         | 11/118 [00:01<00:13,  8.03it/s]\u001b[A\n",
            "epoch=06, loss=0.6166, step=366144:  10%|#         | 12/118 [00:01<00:13,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5959, step=366656:  10%|#         | 12/118 [00:01<00:13,  8.11it/s]\u001b[A\n",
            "epoch=06, loss=0.5959, step=366656:  11%|#1        | 13/118 [00:01<00:12,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6161, step=367168:  11%|#1        | 13/118 [00:01<00:12,  8.15it/s]\u001b[A\n",
            "epoch=06, loss=0.6161, step=367168:  12%|#1        | 14/118 [00:01<00:12,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6056, step=367680:  12%|#1        | 14/118 [00:01<00:12,  8.20it/s]\u001b[A\n",
            "epoch=06, loss=0.6056, step=367680:  13%|#2        | 15/118 [00:01<00:12,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6145, step=368192:  13%|#2        | 15/118 [00:01<00:12,  8.14it/s]\u001b[A\n",
            "epoch=06, loss=0.6145, step=368192:  14%|#3        | 16/118 [00:01<00:12,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6080, step=368704:  14%|#3        | 16/118 [00:02<00:12,  8.21it/s]\u001b[A\n",
            "epoch=06, loss=0.6080, step=368704:  14%|#4        | 17/118 [00:02<00:12,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6029, step=369216:  14%|#4        | 17/118 [00:02<00:12,  8.11it/s]\u001b[A\n",
            "epoch=06, loss=0.6029, step=369216:  15%|#5        | 18/118 [00:02<00:12,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5953, step=369728:  15%|#5        | 18/118 [00:02<00:12,  8.18it/s]\u001b[A\n",
            "epoch=06, loss=0.5953, step=369728:  16%|#6        | 19/118 [00:02<00:12,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6123, step=370240:  16%|#6        | 19/118 [00:02<00:12,  8.19it/s]\u001b[A\n",
            "epoch=06, loss=0.6123, step=370240:  17%|#6        | 20/118 [00:02<00:11,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6093, step=370752:  17%|#6        | 20/118 [00:02<00:11,  8.17it/s]\u001b[A\n",
            "epoch=06, loss=0.6093, step=370752:  18%|#7        | 21/118 [00:02<00:11,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6144, step=371264:  18%|#7        | 21/118 [00:02<00:11,  8.09it/s]\u001b[A\n",
            "epoch=06, loss=0.6144, step=371264:  19%|#8        | 22/118 [00:02<00:12,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6002, step=371776:  19%|#8        | 22/118 [00:02<00:12,  8.00it/s]\u001b[A\n",
            "epoch=06, loss=0.6002, step=371776:  19%|#9        | 23/118 [00:02<00:11,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6139, step=372288:  19%|#9        | 23/118 [00:02<00:11,  8.09it/s]\u001b[A\n",
            "epoch=06, loss=0.6139, step=372288:  20%|##        | 24/118 [00:02<00:11,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6167, step=372800:  20%|##        | 24/118 [00:03<00:11,  8.12it/s]\u001b[A\n",
            "epoch=06, loss=0.6167, step=372800:  21%|##1       | 25/118 [00:03<00:11,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5911, step=373312:  21%|##1       | 25/118 [00:03<00:11,  8.03it/s]\u001b[A\n",
            "epoch=06, loss=0.5911, step=373312:  22%|##2       | 26/118 [00:03<00:11,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5989, step=373824:  22%|##2       | 26/118 [00:03<00:11,  7.93it/s]\u001b[A\n",
            "epoch=06, loss=0.5989, step=373824:  23%|##2       | 27/118 [00:03<00:11,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6206, step=374336:  23%|##2       | 27/118 [00:03<00:11,  8.02it/s]\u001b[A\n",
            "epoch=06, loss=0.6206, step=374336:  24%|##3       | 28/118 [00:03<00:11,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5858, step=374848:  24%|##3       | 28/118 [00:03<00:11,  8.08it/s]\u001b[A\n",
            "epoch=06, loss=0.5858, step=374848:  25%|##4       | 29/118 [00:03<00:10,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6037, step=375360:  25%|##4       | 29/118 [00:03<00:10,  8.12it/s]\u001b[A\n",
            "epoch=06, loss=0.6037, step=375360:  25%|##5       | 30/118 [00:03<00:11,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6034, step=375872:  25%|##5       | 30/118 [00:03<00:11,  7.98it/s]\u001b[A\n",
            "epoch=06, loss=0.6034, step=375872:  26%|##6       | 31/118 [00:03<00:10,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6020, step=376384:  26%|##6       | 31/118 [00:03<00:10,  7.97it/s]\u001b[A\n",
            "epoch=06, loss=0.6020, step=376384:  27%|##7       | 32/118 [00:03<00:10,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6020, step=376896:  27%|##7       | 32/118 [00:04<00:10,  8.06it/s]\u001b[A\n",
            "epoch=06, loss=0.6020, step=376896:  28%|##7       | 33/118 [00:04<00:10,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6077, step=377408:  28%|##7       | 33/118 [00:04<00:10,  7.99it/s]\u001b[A\n",
            "epoch=06, loss=0.6077, step=377408:  29%|##8       | 34/118 [00:04<00:10,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6082, step=377920:  29%|##8       | 34/118 [00:04<00:10,  8.12it/s]\u001b[A\n",
            "epoch=06, loss=0.6082, step=377920:  30%|##9       | 35/118 [00:04<00:10,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6074, step=378432:  30%|##9       | 35/118 [00:04<00:10,  8.17it/s]\u001b[A\n",
            "epoch=06, loss=0.6074, step=378432:  31%|###       | 36/118 [00:04<00:10,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6031, step=378944:  31%|###       | 36/118 [00:04<00:10,  8.06it/s]\u001b[A\n",
            "epoch=06, loss=0.6031, step=378944:  31%|###1      | 37/118 [00:04<00:10,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6015, step=379456:  31%|###1      | 37/118 [00:04<00:10,  7.99it/s]\u001b[A\n",
            "epoch=06, loss=0.6015, step=379456:  32%|###2      | 38/118 [00:04<00:10,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5977, step=379968:  32%|###2      | 38/118 [00:04<00:10,  7.94it/s]\u001b[A\n",
            "epoch=06, loss=0.5977, step=379968:  33%|###3      | 39/118 [00:04<00:09,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5967, step=380480:  33%|###3      | 39/118 [00:04<00:09,  8.04it/s]\u001b[A\n",
            "epoch=06, loss=0.5967, step=380480:  34%|###3      | 40/118 [00:04<00:09,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5923, step=380992:  34%|###3      | 40/118 [00:05<00:09,  8.04it/s]\u001b[A\n",
            "epoch=06, loss=0.5923, step=380992:  35%|###4      | 41/118 [00:05<00:09,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6020, step=381504:  35%|###4      | 41/118 [00:05<00:09,  8.06it/s]\u001b[A\n",
            "epoch=06, loss=0.6020, step=381504:  36%|###5      | 42/118 [00:05<00:09,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5979, step=382016:  36%|###5      | 42/118 [00:05<00:09,  8.07it/s]\u001b[A\n",
            "epoch=06, loss=0.5979, step=382016:  36%|###6      | 43/118 [00:05<00:09,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5930, step=382528:  36%|###6      | 43/118 [00:05<00:09,  7.90it/s]\u001b[A\n",
            "epoch=06, loss=0.5930, step=382528:  37%|###7      | 44/118 [00:05<00:09,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5971, step=383040:  37%|###7      | 44/118 [00:05<00:09,  7.95it/s]\u001b[A\n",
            "epoch=06, loss=0.5971, step=383040:  38%|###8      | 45/118 [00:05<00:09,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6373, step=383552:  38%|###8      | 45/118 [00:05<00:09,  7.93it/s]\u001b[A\n",
            "epoch=06, loss=0.6373, step=383552:  39%|###8      | 46/118 [00:05<00:09,  7.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6093, step=384064:  39%|###8      | 46/118 [00:05<00:09,  7.85it/s]\u001b[A\n",
            "epoch=06, loss=0.6093, step=384064:  40%|###9      | 47/118 [00:05<00:08,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5889, step=384576:  40%|###9      | 47/118 [00:05<00:08,  7.91it/s]\u001b[A\n",
            "epoch=06, loss=0.5889, step=384576:  41%|####      | 48/118 [00:05<00:08,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6141, step=385088:  41%|####      | 48/118 [00:06<00:08,  7.90it/s]\u001b[A\n",
            "epoch=06, loss=0.6141, step=385088:  42%|####1     | 49/118 [00:06<00:08,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5944, step=385600:  42%|####1     | 49/118 [00:06<00:08,  7.96it/s]\u001b[A\n",
            "epoch=06, loss=0.5944, step=385600:  42%|####2     | 50/118 [00:06<00:08,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6159, step=386112:  42%|####2     | 50/118 [00:06<00:08,  7.99it/s]\u001b[A\n",
            "epoch=06, loss=0.6159, step=386112:  43%|####3     | 51/118 [00:06<00:08,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6069, step=386624:  43%|####3     | 51/118 [00:06<00:08,  8.04it/s]\u001b[A\n",
            "epoch=06, loss=0.6069, step=386624:  44%|####4     | 52/118 [00:06<00:08,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6001, step=387136:  44%|####4     | 52/118 [00:06<00:08,  8.05it/s]\u001b[A\n",
            "epoch=06, loss=0.6001, step=387136:  45%|####4     | 53/118 [00:06<00:08,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6115, step=387648:  45%|####4     | 53/118 [00:06<00:08,  7.99it/s]\u001b[A\n",
            "epoch=06, loss=0.6115, step=387648:  46%|####5     | 54/118 [00:06<00:08,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6224, step=388160:  46%|####5     | 54/118 [00:06<00:08,  7.98it/s]\u001b[A\n",
            "epoch=06, loss=0.6224, step=388160:  47%|####6     | 55/118 [00:06<00:07,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5963, step=388672:  47%|####6     | 55/118 [00:06<00:07,  8.06it/s]\u001b[A\n",
            "epoch=06, loss=0.5963, step=388672:  47%|####7     | 56/118 [00:06<00:07,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6123, step=389184:  47%|####7     | 56/118 [00:07<00:07,  8.09it/s]\u001b[A\n",
            "epoch=06, loss=0.6123, step=389184:  48%|####8     | 57/118 [00:07<00:07,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5862, step=389696:  48%|####8     | 57/118 [00:07<00:07,  8.14it/s]\u001b[A\n",
            "epoch=06, loss=0.5862, step=389696:  49%|####9     | 58/118 [00:07<00:07,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5773, step=390208:  49%|####9     | 58/118 [00:07<00:07,  8.17it/s]\u001b[A\n",
            "epoch=06, loss=0.5773, step=390208:  50%|#####     | 59/118 [00:07<00:07,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6127, step=390720:  50%|#####     | 59/118 [00:07<00:07,  8.12it/s]\u001b[A\n",
            "epoch=06, loss=0.6127, step=390720:  51%|#####     | 60/118 [00:07<00:07,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6146, step=391232:  51%|#####     | 60/118 [00:07<00:07,  8.04it/s]\u001b[A\n",
            "epoch=06, loss=0.6146, step=391232:  52%|#####1    | 61/118 [00:07<00:07,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5932, step=391744:  52%|#####1    | 61/118 [00:07<00:07,  7.99it/s]\u001b[A\n",
            "epoch=06, loss=0.5932, step=391744:  53%|#####2    | 62/118 [00:07<00:07,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6045, step=392256:  53%|#####2    | 62/118 [00:07<00:07,  7.89it/s]\u001b[A\n",
            "epoch=06, loss=0.6045, step=392256:  53%|#####3    | 63/118 [00:07<00:06,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6019, step=392768:  53%|#####3    | 63/118 [00:07<00:06,  7.95it/s]\u001b[A\n",
            "epoch=06, loss=0.6019, step=392768:  54%|#####4    | 64/118 [00:07<00:06,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5909, step=393280:  54%|#####4    | 64/118 [00:08<00:06,  8.01it/s]\u001b[A\n",
            "epoch=06, loss=0.5909, step=393280:  55%|#####5    | 65/118 [00:08<00:06,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6004, step=393792:  55%|#####5    | 65/118 [00:08<00:06,  8.02it/s]\u001b[A\n",
            "epoch=06, loss=0.6004, step=393792:  56%|#####5    | 66/118 [00:08<00:06,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6001, step=394304:  56%|#####5    | 66/118 [00:08<00:06,  7.96it/s]\u001b[A\n",
            "epoch=06, loss=0.6001, step=394304:  57%|#####6    | 67/118 [00:08<00:06,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6041, step=394816:  57%|#####6    | 67/118 [00:08<00:06,  7.99it/s]\u001b[A\n",
            "epoch=06, loss=0.6041, step=394816:  58%|#####7    | 68/118 [00:08<00:06,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6240, step=395328:  58%|#####7    | 68/118 [00:08<00:06,  8.02it/s]\u001b[A\n",
            "epoch=06, loss=0.6240, step=395328:  58%|#####8    | 69/118 [00:08<00:06,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5904, step=395840:  58%|#####8    | 69/118 [00:08<00:06,  8.00it/s]\u001b[A\n",
            "epoch=06, loss=0.5904, step=395840:  59%|#####9    | 70/118 [00:08<00:06,  7.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6189, step=396352:  59%|#####9    | 70/118 [00:08<00:06,  7.70it/s]\u001b[A\n",
            "epoch=06, loss=0.6189, step=396352:  60%|######    | 71/118 [00:08<00:06,  7.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6078, step=396864:  60%|######    | 71/118 [00:08<00:06,  7.80it/s]\u001b[A\n",
            "epoch=06, loss=0.6078, step=396864:  61%|######1   | 72/118 [00:08<00:05,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6131, step=397376:  61%|######1   | 72/118 [00:09<00:05,  7.89it/s]\u001b[A\n",
            "epoch=06, loss=0.6131, step=397376:  62%|######1   | 73/118 [00:09<00:05,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6043, step=397888:  62%|######1   | 73/118 [00:09<00:05,  7.99it/s]\u001b[A\n",
            "epoch=06, loss=0.6043, step=397888:  63%|######2   | 74/118 [00:09<00:05,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6044, step=398400:  63%|######2   | 74/118 [00:09<00:05,  8.07it/s]\u001b[A\n",
            "epoch=06, loss=0.6044, step=398400:  64%|######3   | 75/118 [00:09<00:05,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6029, step=398912:  64%|######3   | 75/118 [00:09<00:05,  8.11it/s]\u001b[A\n",
            "epoch=06, loss=0.6029, step=398912:  64%|######4   | 76/118 [00:09<00:05,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6077, step=399424:  64%|######4   | 76/118 [00:09<00:05,  8.18it/s]\u001b[A\n",
            "epoch=06, loss=0.6077, step=399424:  65%|######5   | 77/118 [00:09<00:05,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6081, step=399936:  65%|######5   | 77/118 [00:09<00:05,  8.09it/s]\u001b[A\n",
            "epoch=06, loss=0.6081, step=399936:  66%|######6   | 78/118 [00:09<00:05,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6145, step=400448:  66%|######6   | 78/118 [00:09<00:05,  7.97it/s]\u001b[A\n",
            "epoch=06, loss=0.6145, step=400448:  67%|######6   | 79/118 [00:09<00:04,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6054, step=400960:  67%|######6   | 79/118 [00:09<00:04,  8.01it/s]\u001b[A\n",
            "epoch=06, loss=0.6054, step=400960:  68%|######7   | 80/118 [00:09<00:04,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6124, step=401472:  68%|######7   | 80/118 [00:10<00:04,  8.12it/s]\u001b[A\n",
            "epoch=06, loss=0.6124, step=401472:  69%|######8   | 81/118 [00:10<00:04,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6123, step=401984:  69%|######8   | 81/118 [00:10<00:04,  8.10it/s]\u001b[A\n",
            "epoch=06, loss=0.6123, step=401984:  69%|######9   | 82/118 [00:10<00:04,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6083, step=402496:  69%|######9   | 82/118 [00:10<00:04,  8.07it/s]\u001b[A\n",
            "epoch=06, loss=0.6083, step=402496:  70%|#######   | 83/118 [00:10<00:04,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6122, step=403008:  70%|#######   | 83/118 [00:10<00:04,  8.02it/s]\u001b[A\n",
            "epoch=06, loss=0.6122, step=403008:  71%|#######1  | 84/118 [00:10<00:04,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6088, step=403520:  71%|#######1  | 84/118 [00:10<00:04,  8.10it/s]\u001b[A\n",
            "epoch=06, loss=0.6088, step=403520:  72%|#######2  | 85/118 [00:10<00:04,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6212, step=404032:  72%|#######2  | 85/118 [00:10<00:04,  7.83it/s]\u001b[A\n",
            "epoch=06, loss=0.6212, step=404032:  73%|#######2  | 86/118 [00:10<00:04,  7.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6069, step=404544:  73%|#######2  | 86/118 [00:10<00:04,  7.82it/s]\u001b[A\n",
            "epoch=06, loss=0.6069, step=404544:  74%|#######3  | 87/118 [00:10<00:03,  7.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5909, step=405056:  74%|#######3  | 87/118 [00:10<00:03,  7.80it/s]\u001b[A\n",
            "epoch=06, loss=0.5909, step=405056:  75%|#######4  | 88/118 [00:10<00:03,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6120, step=405568:  75%|#######4  | 88/118 [00:11<00:03,  7.91it/s]\u001b[A\n",
            "epoch=06, loss=0.6120, step=405568:  75%|#######5  | 89/118 [00:11<00:03,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6053, step=406080:  75%|#######5  | 89/118 [00:11<00:03,  8.00it/s]\u001b[A\n",
            "epoch=06, loss=0.6053, step=406080:  76%|#######6  | 90/118 [00:11<00:03,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6127, step=406592:  76%|#######6  | 90/118 [00:11<00:03,  8.04it/s]\u001b[A\n",
            "epoch=06, loss=0.6127, step=406592:  77%|#######7  | 91/118 [00:11<00:03,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6127, step=407104:  77%|#######7  | 91/118 [00:11<00:03,  8.09it/s]\u001b[A\n",
            "epoch=06, loss=0.6127, step=407104:  78%|#######7  | 92/118 [00:11<00:03,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6055, step=407616:  78%|#######7  | 92/118 [00:11<00:03,  8.01it/s]\u001b[A\n",
            "epoch=06, loss=0.6055, step=407616:  79%|#######8  | 93/118 [00:11<00:03,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6054, step=408128:  79%|#######8  | 93/118 [00:11<00:03,  7.99it/s]\u001b[A\n",
            "epoch=06, loss=0.6054, step=408128:  80%|#######9  | 94/118 [00:11<00:03,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6317, step=408640:  80%|#######9  | 94/118 [00:11<00:03,  7.89it/s]\u001b[A\n",
            "epoch=06, loss=0.6317, step=408640:  81%|########  | 95/118 [00:11<00:02,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6035, step=409152:  81%|########  | 95/118 [00:11<00:02,  7.95it/s]\u001b[A\n",
            "epoch=06, loss=0.6035, step=409152:  81%|########1 | 96/118 [00:11<00:02,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6142, step=409664:  81%|########1 | 96/118 [00:12<00:02,  7.92it/s]\u001b[A\n",
            "epoch=06, loss=0.6142, step=409664:  82%|########2 | 97/118 [00:12<00:02,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6020, step=410176:  82%|########2 | 97/118 [00:12<00:02,  7.93it/s]\u001b[A\n",
            "epoch=06, loss=0.6020, step=410176:  83%|########3 | 98/118 [00:12<00:02,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5941, step=410688:  83%|########3 | 98/118 [00:12<00:02,  8.03it/s]\u001b[A\n",
            "epoch=06, loss=0.5941, step=410688:  84%|########3 | 99/118 [00:12<00:02,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5989, step=411200:  84%|########3 | 99/118 [00:12<00:02,  8.13it/s]\u001b[A\n",
            "epoch=06, loss=0.5989, step=411200:  85%|########4 | 100/118 [00:12<00:02,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6143, step=411712:  85%|########4 | 100/118 [00:12<00:02,  8.06it/s]\u001b[A\n",
            "epoch=06, loss=0.6143, step=411712:  86%|########5 | 101/118 [00:12<00:02,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6015, step=412224:  86%|########5 | 101/118 [00:12<00:02,  7.98it/s]\u001b[A\n",
            "epoch=06, loss=0.6015, step=412224:  86%|########6 | 102/118 [00:12<00:01,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6000, step=412736:  86%|########6 | 102/118 [00:12<00:01,  8.01it/s]\u001b[A\n",
            "epoch=06, loss=0.6000, step=412736:  87%|########7 | 103/118 [00:12<00:01,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6070, step=413248:  87%|########7 | 103/118 [00:12<00:01,  8.02it/s]\u001b[A\n",
            "epoch=06, loss=0.6070, step=413248:  88%|########8 | 104/118 [00:12<00:01,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5985, step=413760:  88%|########8 | 104/118 [00:13<00:01,  8.06it/s]\u001b[A\n",
            "epoch=06, loss=0.5985, step=413760:  89%|########8 | 105/118 [00:13<00:01,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6041, step=414272:  89%|########8 | 105/118 [00:13<00:01,  8.02it/s]\u001b[A\n",
            "epoch=06, loss=0.6041, step=414272:  90%|########9 | 106/118 [00:13<00:01,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6034, step=414784:  90%|########9 | 106/118 [00:13<00:01,  8.07it/s]\u001b[A\n",
            "epoch=06, loss=0.6034, step=414784:  91%|######### | 107/118 [00:13<00:01,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6036, step=415296:  91%|######### | 107/118 [00:13<00:01,  8.12it/s]\u001b[A\n",
            "epoch=06, loss=0.6036, step=415296:  92%|#########1| 108/118 [00:13<00:01,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5915, step=415808:  92%|#########1| 108/118 [00:13<00:01,  8.21it/s]\u001b[A\n",
            "epoch=06, loss=0.5915, step=415808:  92%|#########2| 109/118 [00:13<00:01,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5912, step=416320:  92%|#########2| 109/118 [00:13<00:01,  8.22it/s]\u001b[A\n",
            "epoch=06, loss=0.5912, step=416320:  93%|#########3| 110/118 [00:13<00:00,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6018, step=416832:  93%|#########3| 110/118 [00:13<00:00,  8.19it/s]\u001b[A\n",
            "epoch=06, loss=0.6018, step=416832:  94%|#########4| 111/118 [00:13<00:00,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6135, step=417344:  94%|#########4| 111/118 [00:13<00:00,  8.19it/s]\u001b[A\n",
            "epoch=06, loss=0.6135, step=417344:  95%|#########4| 112/118 [00:13<00:00,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5982, step=417856:  95%|#########4| 112/118 [00:14<00:00,  8.19it/s]\u001b[A\n",
            "epoch=06, loss=0.5982, step=417856:  96%|#########5| 113/118 [00:14<00:00,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6019, step=418368:  96%|#########5| 113/118 [00:14<00:00,  8.14it/s]\u001b[A\n",
            "epoch=06, loss=0.6019, step=418368:  97%|#########6| 114/118 [00:14<00:00,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6016, step=418880:  97%|#########6| 114/118 [00:14<00:00,  8.22it/s]\u001b[A\n",
            "epoch=06, loss=0.6016, step=418880:  97%|#########7| 115/118 [00:14<00:00,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.5951, step=419392:  97%|#########7| 115/118 [00:14<00:00,  8.23it/s]\u001b[A\n",
            "epoch=06, loss=0.5951, step=419392:  98%|#########8| 116/118 [00:14<00:00,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=06, loss=0.6113, step=419904:  98%|#########8| 116/118 [00:14<00:00,  8.22it/s]\u001b[A\n",
            "epoch=06, loss=0.6113, step=419904:  99%|#########9| 117/118 [00:14<00:00,  8.23it/s]\u001b[A\n",
            "epoch=06, loss=0.6296, step=420000:  99%|#########9| 117/118 [00:14<00:00,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e89d0664-5cae-443d-a297-4be58796f32a\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e89d0664-5cae-443d-a297-4be58796f32a\")) {                    Plotly.newPlot(                        \"e89d0664-5cae-443d-a297-4be58796f32a\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAa2klEQVR4Xu2ZabRlVXXv\\u002f3OutZvT3f5WFVBVECgbwBKeik8QB4KKDaLEKCJBY\\u002fswovjECCoadIgRiD5EbBJRQwA1JNGgASP4sEHQAU\\u002fFoANbGquo\\u002fjbn3tPtZs0534dzm3NPVdCR4YfnG\\u002fl\\u002fOXv95\\u002fmdddY8a6+51j40iv\\u002fSgcTDxn+prz\\u002fYxGz58U+Grd+r\\u002flATc8XXN9037P1eNZyYYz8x94ljhrz\\u002f9zR96+vH73\\u002fLsPt71VBitt50lp1101pvUH8x13z6sAcAqK9\\u002f1QXxsAlgy+Nf25ybm5ubuz4aDq3qpF9uGbbgxsfHL3zfDRs+09x90XBsy8eegve\\u002fe27Y\\u002fl1V\\u002fdbPNg97+8mvaT35uhFrlRPH\\u002fbhcY6\\u002fo7LcpbNgEcOhbjzsKWL\\u002ffCB5\\u002f9hl8kBoAvODKd7WW7RMmbl59D4An3bumiY3xU48ffREA7Lj89NZP71obBcZPBXZ8d9j9nbRhCs1nHPur357UwcRUjvn0BuDBqz5366X\\u002fa8Ae0KZk2AGAx7zpzJQeaT\\u002fujz\\u002fzq6HIJaeuXr\\u002fi+ruXL088Yk1i+NCNNNh+4ldHlq700u4\\u002f72r+ejAIYMs1hHO+NmQO6M3xY8\\u002fEL582bOOoczfhiE248nG0a\\u002f\\u002fJ\\u002feSzTjgS79l9\\u002fD\\u002f8sN8eTMxHXwoAx9TufMbRA+6AnnkufvnyvUPmyPv\\u002fuAE88JL4nsnJ4cR861Tsu4EMx524xn7FPWua6\\u002f\\u002fsxjXg9rkRAPjBwjOKGwf9Zb18021v2zVsLuvpR574QoLhiLv\\u002f+3DoGa8E8htPehvs8\\u002fvNmJdcNknfnfoAaPK1fWMgMcc+l3DnrR\\u002fYfV\\u002fzpDU\\u002f4Iqe9skRfGz7sPvCVwF46IwdRwwHAHzuFpR7ATS+fxBuXr1fhj7+ajywpj3\\u002f3ufedwXuO6P7+D9f4y\\u002fptq3bLj5wXtZ\\u002f9jCM1OjHxwDg6nD0nefjC7NXz2z98uTMV4ZC\\u002fr9dVb3rr7+fXHsKlr\\u002flamK23tSwb7zu6ZdeN\\u002fNTPfWYf1\\u002fxV\\u002fWKDfjuPwybOAPY9qNLduAxwwEAYUf\\u002f9VljwM5i2T163fJVXyP41lrjljvaW1\\u002f58S5+\\u002fta1PgDgBU+xm3rDJgDgmVdtBICnzk0c9IlD8IvhcLWy7QN7cPjbp7qX5UOhM6\\u002fGt17TwktOwY4vLlkridly\\u002fsjs7i92brsNACpvfsOyv6rJV+rCR4ZN4PxXf\\u002fPBGQBDox3Un7yqAvzVSvPUykAMmD4UwxOghQW86ss65AIARo8HmjsBvPEQvHdt6K0bgfySH\\u002f4ac39+CLaduzYIfOU5j3vf20c++Nz5D392KPKeC+wzl7aAvwAumlnylhMTf+DU1hvvTZffunH5YlWbrwP+9o5hF9h9Wf\\u002f1uLX2ql52wR9FwE9WC90W\\u002fHwgjEvX\\u002fbo92AYAXHbsic\\u002f85rAJAHIs613AefY\\u002fNuMtRw5m9JSnANvPvRsADgZumR0IAQB+cs\\u002fjTjr5rzbhsk8PBS68oLj9kgzJKRvpr1fW9OXEHHMqzt6vLK7Rs5+A7\\u002fzNsLmkc2vA0bj7\\u002fwz7m1\\u002f+TOB4A1rvuy0b8H+0ctV49pmn4IqFgVhf3bd+56rv3vuZ\\u002ffcGTz9Bt89j69NegM7Ox1z32oEl781V3H353QDGnn0C7v7GamBJRQsbrie7\\u002fpYhf\\u002fT1dvufAodfcyy+ctWKu5yYD9Kdq3lh3X\\u002f1Pe0SfP+Ni8MuAFSOvPBUsGL3eTIUOeoLm5auvnftoI9xAE\\u002fgkw6OX8bZD3L\\u002f4zXBvh560yfOOqv2xT1Ddv1Q7L7xgS3nnzb7rY83\\u002fnW5rAMArp1YfP1eAHjtxfjZq4eLJ4DtAHDb1Uvr3oqiSVw0dc7zj6yb3dhdcZcS89yt9m8rHtT2O6Btvh54eN+wC8Afc92G3u57nlWFO\\u002f1Tw\\u002ftCIgCswPOeM\\u002fALZnblBcATKHR\\u002fccO9d+39WWW4ygMAbn7wgyf95aYPDy0\\u002fT\\u002fsQrr1i+gOntm66+IgrW3cM1sivfrX\\u002f+rwLEf7uAHlxJxBw61nDNsqZqfsM2NXaMPv1VXcpMZV435eXrfhduON9y41l\\u002fU8Frhw2AUTPvgGX3XH3+FePwtQlj9y8UnkAAPe\\u002f8MxvZgBeuXYhfPv2pwJ45Gs\\u002f\\u002fwEAvHrq4TXRFd3\\u002f6ud98jVHnLHWfAJwBW54Cs6+67iv45NDq29fXzBcdO2wCeBzpxsOtG9fOPsfxx\\u002f62ufnP7fhSwPuSlXKlydt\\u002fI7zd3y8s2wvaespwC3DO1AA\\u002ft3n439\\u002femHqn44urjrytGu+fVUTg4fe7f0qdtlQhfjoYOMkLP3S+2nhxqv9CSfeucYbpVuwdTNdfNeWa+jiT60JLekvWbGWAQBs+NMX2b\\u002f\\u002f5JzpYR\\u002fAD48AgBNO1IcHzJXELN9JW89\\u002fyS2vWjZX9C9j+MGbhk3Avectnfd\\u002faeFJVzzxgQu+2\\u002fj7M5\\u002f\\u002fL3jkAGfzZw0ba3XzsNHX0S9+ksfPvzfkmgFqR\\u002f80\\u002fc3zD7jiRU9Uu+jBYRc46WJc+unTzllTD9eoorZy02AlMUSnvRMAcN47Rv7xjQPxJU0orhmeRQD+7C3dt33zKec8J7388zvQuv32PzkT714J+lPu6Feicz604v3u2nLuC9cDsmdoM\\u002fO18087bmsdr6DZy4Y3PwCAystPxj\\u002f\\u002f0\\u002f47oBMvx1nfXn8Rtg0HVnT72uZSYszWX37D3HEvf8Ih22\\u002f\\u002fzNp3AMAnGFh7vunrIri3vPNw4ENX9gvSlwbu0uPffvITdwAYf86lVfQGi\\u002fWQ6Ij9yjzWvewNmwHc++GBkgAAKLvVWw1A66b96zGA+sdejHdds39ecPLonbf6547QfrubFQ1N65Vbyb3+Ra0jgHvuWN2hrmjryVpcc4B1Hnumkq247Xu3bBsu1ACuOApvbQM4+RjDnZ99lIcENvywDNNHXvFYAD\\u002f42Nf2G+KPX3feM4Av3H\\u002ffgTddB78YD\\u002f3tsAkAZuZfeHnzuuFN76oOW9tcSsw9P3oS1q\\u002fD3Jf6N9SQRtdh1wELwAtOO2bm+uZwkV7R6\\u002fov+75+0fDhZI2e+oU1zfGPbj0MwN0fv\\u002f1A06x\\u002fZvkP9Jjz8OuXDpsAgCnM3nQC3jRQj4f1fV7zKywlZuc5r3kH8Km\\u002fe2Aw9tvVvvGAzwUAAOe94WwAeKj7\\u002fb+\\u002ffzi2Rms3k08+\\u002f8kHA+j9zUdWN1u\\u002fsy58CT693\\u002fEfAPALvJjmr\\u002fn2sD2g+x847LDlgxJWb6U9ly0deQ6kX959\\u002fLD123Xf23\\u002f0nrGbv33LgW7BQX3jjDXN008HfvF1uXr\\u002fU8Jv1+MbuPY7w2ZfX4zfce+\\u002ffXLYXaOPXP3eC1eP5DQ6EPpD1\\u002fvfvP2lB9hs\\u002fY5qXPvMf33TyjTdb+H7Q9Y38e7\\u002ffF7QevVnT18+2\\u002f1\\u002fNmN+n2I2g2MrgpmRWaFiBFEINDYSMpiJBDVTNRIjBUwDYoEpg8FEosYwMzJSI0SxAEZGCoNYf1YyOzNCHCmgZAQmUjUmGKAw\\u002fBZuuT+jgf7AaoTIAWQEUgPEjIgUFgyAOvTHABUxNTWDYmkM9GgcGzkWcikbWPLMnFIuQEl5KIxIxEg9OccMM\\u002fbMkXFglpLMGBBTmIEC1EihTKZFSQQCtP\\u002fHCZRU2FSITPMAGIEUSmagoEYwGAP2qFxJABvEzAxL\\u002fZkJk2khgBixwkBMZApn5sBKXBpIxFiYmB3BzHnmGC4wh7Uc1nBUJ1JiCFXyAKDadUJOnS+ZzEgVZOKJoBaMI3OAmLJXqDkYGUAEJSYlMYaxQp3Cq5Ea2BGIKXAAQTnAHIzNiJSIVAmsLOpApKSscGakRrQ\\u002ft9IfnCkTC4d+f2aOFcYwJYJBjYhMSSMYG8gUbMJEUBNjDw8EEnjDo3DeYjWLyCxDZHHFYi+h8KWRcnCiZHAgMjUzhvNOlczYjNkIamAms5gjCrI0JYnIGVjATJ4pdkxFAVEyAYiMiMSM2AQMT9af2WYgckYkxkzOIRniVvsDUo4QBGqAKhHEmIxBLAYLzthxcMpGBBMjGINIVSFsLorEuJ+L\\u002f4hjwEcGglGAryYjk5U6u\\u002fnF2VanGxmg5liJvLrSU5KwZ\\u002fii11MuHcMgIGVzHMc+iiwvshCUC1YmNQHMU5xWK5Hz2u4thKC+ZGEAClJShyjiyENLlSBcki1xcBRVqmk8xPX7c3A+jqMosizvLfcHEMwZDOqYakbMkUhpakTB2PUnmDjnE3jv0iLrKQfHemAOYkw+xCAuPVWqk1MbNm4eRXd+16+377RSncRGIRKnbB7V+ljNx1q0mlYom\\u002faXisi7alpPRymSfLG3UEgRm3mBsnkf+5HR0WqdXdaar8wFLWIzJwQyY3aRr8Xjlph2ynYeSiDwCtcYHa3VmfNBDspGsfPVSiMdZR+yxW6zlDw2eAEZCytTkqYV530CLRfKMrfADAqRspJ5Tqv1NKqxtOcpC85gA1xS8d4nsGKJ86QGB0tq6zdv3rB5XRx1exNk3ZK6jg3GSmJc+rS2bv0UWbdTeIpKGJkyG8dppTFWH6lHFMrFOdfKKA9spMzmklp1YnpkLPGWdep70MlQCinEsbD3abVeGx2J2NBenGvlbIHQ5+J6dWJ6ZDTxlo3W9q5w\\u002fVhaGRlvjNQihGJxhtsZikAGAykTRVypjY7VYq7keRPdXArAgP7yVyZpY3pyjJM8104vUgGtcFRd4op8fonzMKUicSOjE1MHrauUWIxs9PBe1p2hYMIQdqbBubg6fegESTNqpllOAIsDcZTWRybGJ+oRhaisspZBXAApE1NSHRmdHhtPohCiivTynEAKMkdwFKf1scnJ8TgKaSj2OTPxgWBMTEltZHRqfDyJQhmbZCscE3GUNkYmx8drEYIPKaQsuV\\u002fTYWRgXx+fnmqMcC2mhZ1+lkIIUDKBMxWf1MfXbxqJo95ip55bCEYrXG1iaro+uobzxCU7ipN4YnIcM6GbpSOjlQ27G00NjsSxmZrj+tTUhvVjRStVR0z9guvIubTemByrJyELaRW1xJuIQMmYvIsr1UaDtNVSV4ti56QsBUTqQJzWR9dPTFZVRKtx1m6SiRhWuJEGWaulvtrngoBImZxLa43xsWpc9iSpaXWpP2NhMoq5Oja1aSyNUfee2nNp14KSEweomfP1DRMHTTc4uHbiHGyVo+rY1KaxylrOG5yjMtKx8QnpLc72mtWpQ+r1Q\\u002fbOllykanDkBGmcevbOik7W65ZF7gsGkZFjV00S15tv00QapxRKNQdSIoCIYgRbaHZpPPExylzJsRlBvXfxyMhkDQstGU+SKodS1AkPcFhodnks8TGVucKxKRHIsavEMXXmOzSRxgmFQvtFE+aIXGVi43Qla2p5UFJCi1C6kkjUPMxQb9RTB4jmZa9TloUviPucTycPma7kTRvkvElRM\\u002fjpddOj5d75hdmCejw+knLECheImFWdi6wsgnQ6C4vtosxQGgz9XS+zdlt7O5UavGkRFDBSJiJnZiTZ\\u002fGy30XDsWACQQWGkRHBe886eRU6VtOzlQgZby\\u002fXqdfaOBAAMykRwBGbpLezrVmrkYeXSVtDIacRKMVt3rih9EfVa8wsdCWYO5Ii18Oys7OZxkFar1ct7Vqpb5jhidOeL4Arfa80vtCWYeUNsmk5u2rge3Tzft9iljm9gfOo3AuQgogDHhiK3eqU7t3PfYstUHZkBYFJRC2GhV1ajCiMvc2GQmRmThbwsfZapTyo1diplcP31jhyrcxxk72yvzqkPi3kmTIQBLs\\u002fUDXCAKTNDRDSEVhY4Th3yIg8OMCVSV6IWV2OZmZEUUXd2W7OTKzwKYnCwiJ0L3XoUtXq7du+bF1GGySoXZmc0he\\u002fObmt2CoWHJzZYY3z9hmpvZmavhCQkJh6uyig9WRRcSezymKrTFOWtVi8ArOyDKBBMQQZfqUxPjHRRZMEJAU6ESBgUU1KFm5iY6KUcyKmDspi4MhbTIOpr6yZqWdZu9eLS1nBxFW5iYrKbLHNOFD5AjUFRtTY1PtqlkAcODLDAAoCoLDSv8MQ0ujtnZltcgiLAvHLJDnni6lNJttiabWWiCvY6yFV5fBrdnfuWOB+bmWsccnBazjy8K5PSijqJukQNEcEKDixkHNzh06E312wVwcUlW1AmNglKLtHRNF23aXQGQaFE4kvn2KTUyDeQ9pKxjaPtvewNBGV1YEAAIkrGqwdvbuzodUtWojJa5rxv2DAXmNikVHaJoZJObR6Z42AwIvEgA5F5F0nwyUHrG+XOHfMdB4pKIljgACOisrHxIL+ruXe+W7IPbMJLHEea+fSg9bVy1yPNDhNFJXnxRpw20lrz4Z2zxsKeRurVOYXLkyIGwYlBpbr+4PHZ3ly3CGzqlAIpwJHjgJgTq62f9E7VRWLGCgWZ8yyuYlEjHR+rFFEUpRnQX0AocijMJwlGN64T7WaqbEqyzOkSN56uciufSQnHqE1PRA7wcYCxLu02LRT5SGVs3SRtm9\\u002fXzDWhgBAiEFjUQqiu2zjVk7l2J4OQM8gKV2Yj1bH1E\\u002fSb+ZllzlMGnx60bqL3qwcebjVyowZxFXnW46iMKTABPkScTI9Gc3u6nSDmoAAZsdOg4rx3MdUrKUgi5xRqPjBTsETT1HtRT95HURJ7YlU2YjK1UpSpGk2MVdvdrpEHlFiGOOcjP8CxlCI+8i5GNU3ZSeSYoHAGIzi2LKsVUxPrqrt3bpvJEEcCowhKBPjSfDw1Vp3d02wWgSMWENEqV9Ympqu7d\\u002f1mJrM+50UTqUTjTrsLOeelRtHEIdOtYiEvlQ2sFJkRonqDivZiLxOFRACYrD\\u002fEXt6Loa5dLTshsCuVWL3BGYHzUEoInmpFz8gnmTKLM2NHGtqdqEoh78bz3XZPhcQMSxxlS1y96AFLnDcwsVkvzyIIt2uho+Ki0oiMjMR7DVkrqltRthcXWllBpTdTBrHCm7JSrWbF4kKrWwafVdA\\u002f0Ir3GvKWr1tZthearayg4M2UPaWh3pga9Si0xy6l6mFbDvbdPe1APosBePHGaSWJ8uZsXpgJc3BOSJ0G0hCyBYoKyqPUOplCHIlx8FZYVErRibnV46l0rFB4cxCBOFNTXxRNZFSPR3yz2QXBkcItcVp0Im73eKoymssyp84CNIRskX1uPZdyN1OIFwWVbI6CF83Ldm2sy5097RY8yClxAMwHZ1FacVw053qZCuDEkfAqF9r18R519q5yHuw09km126isDzriJg7fPGb7ZuZLOABK5in21WotyvKFXqFKZl7FxIszIi17Pc+lc3khnTwzJ0KqHBwcWdFpsfbyShFCluWBYFCwMsAmWdEToFp0u52sZ6TBCS1z3RbZEpcXy5w4Y9Ky13VUEhcFdYrcuFQoERgU9R+mFb0eNbPCgieUzgxQsoh9Wq1UXVYutjNRA5wSQp\\u002fzvMSh2VvlPKSMxHxy0GPdI+Jr9XWHNxZ3\\u002fOqRLpySAWZaieqN0UoounNFIQxYyQDYlIhMyjacxqahk3VJlUg1Ihg7Rsh7TFmZOB+KzLQ0E4lIjUAG61IUV5HJvlbpzTGUeJhzoeyZLHGmTAwp22D1ppplXYgSVD0bmOHiehIxx3lrZi6PEDGo\\u002f+TUYEkyMjqaFKG1r5cFx0QBDCIDMzipJxFzlC\\u002fOzhXLHDw07XWz5sHpUbU\\u002f0ppV6klv2\\u002fYH984rNEb\\u002fqWxSTWuNer6wsKBOHJsBRCKOAWaCUZJW4zJrlpmRAggkkQM550IgSqsVy+c7i4UqwELiiZSZvU9qlQr1ii6MSAETiHcg53iZy+Y7i+UKx2T9\\u002fqK0Gpf5QtHr9ycAmxnHSbU2Os7aXijVw5uRgtmgRpzWKvVGo2g1m0IgBmCA9bkoqdZGx1hazVI9HIwU7KMg6D04Xnvs9LoWBKEz8\\u002fCD2\\u002fblThyLCwYzF6ejYzWd29cksVj73RE8yDE5htTj0RTtZqstZVAoiCICM3kpe3VfbcRZOT+fZYVAjYmN2bGPHddrY8ja870MCiNjtj7ntOzVfXUkzsr5+d4y5wF25MjKajRSoc7CYkvKst9fMDZycW1kbLJms3ubHYU3H4wYEIOxT6tjYw1q7pkLAd7AwsSGYa6r8HBixPBBWcvZX1bzQxNmNz8z+9DDj8w3s9hZIPElAHVREkdFOdcunFeGRbCCjWFFpFmUV+FNWu3Z2U6ugDgjcQqJtUNRJA7WLlv7mq3STJ2SMBAsyisS+UhCNtNczMXMhGF9TrocReJI22Vr70J7lbMi8r0oS81ZaHfmZto9AcQZxBuriMBVIs5azbkg4iEwFqc+ACrwUeTKztxij1iYzAGBdYmjZa4U8VAYi\\u002fPwpW929+zdvHmyKt3ZfXt3zHdEfIAyOXMBzhV5mc\\u002fY4sxcZhQVDDFPEgUWhqDrIsdUyMLCQk8lCCmbC6wOpZiZ1t2CdTrzi0URhJXgghMitTzJM2+tbG6+qzANrG6ZUzXTupMhrt9fm71jLnVxsdnVEISU4AOXjgBhFMXs3l3trjgDKRurEy7Zu5CFfC7M7J3NhaKSSeFIosClJ0AcimJ2z+52b5Wjasy5IHGjVIvRy3Sxp76sOBLkRLEaR1HSqFelbM\\u002f3ehSpCtjY2AI7sDmuVSvVlIuy0+4VQYQIxiV7YmPU0rRacUF63V6Wq4BMWciBEUXVRrXmtZu12j2xYEQAleyJ1R2QC+zB6qhWrVRTV4ROu1eEoCAY2IhdnI6NTXhd2Ddb5FYwiSM1lkjNR0k6MlKVvDnbzdiLqTqQsQ5yzX1zgxw1SCKFCYlzrhTmwiEGF44USiBylCaRhSIvSknhFKakzsAkgDNyURTFbKEoSympv6oxCcELKIp84kylLKQgwKBEpIBjjhKXOJMiK0sxkJGyPRq31B9cFEUJWyjLQgL6\\u002fYGMiWqVelKglfdEYMoEBPNKADuqpgmKolsUmhD1x8DUfzS2ygVd5WjUwBBngYiE4cUXTmMpQ0VdcGBjZxFECjF450sXDGwwL1AiZSJzsSPREGCkgDGckBIpGxn7mAQhkJCyqTMWGJGxI7gEJlKKgdXI2LyQEok7EOeW+gPBRZ5EQyAlJTMGmZIDU82xhW4Q1x+2khqDjeEYMYvkhSFyvuSlMfAy50lliKPJQlljV3jznYjYQCgIpt5LpQNnLIBFhbPSk3MFc+GVoexLZQCsIHPGotz\\u002fuykwEpTCxur634u0PzR1gZFK\\u002fwERG8HYWIwVZGABYnoUTh+lvxDgSMjBq6oyiIODMsQsCsZgASEqWYIn9iVT6ZSgDoOcuDXc\\u002fwWKgk0rKNPugAAAAABJRU5ErkJggg==\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e89d0664-5cae-443d-a297-4be58796f32a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=06, loss=0.6296, step=420000: 100%|##########| 118/118 [00:14<00:00,  8.07it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6019, step=420512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=07, loss=0.6019, step=420512:   1%|          | 1/118 [00:00<00:14,  7.86it/s]\u001b[A\n",
            "epoch=07, loss=0.6040, step=421024:   1%|          | 1/118 [00:00<00:14,  7.86it/s]\u001b[A\n",
            "epoch=07, loss=0.6040, step=421024:   2%|1         | 2/118 [00:00<00:14,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6030, step=421536:   2%|1         | 2/118 [00:00<00:14,  8.14it/s]\u001b[A\n",
            "epoch=07, loss=0.6030, step=421536:   3%|2         | 3/118 [00:00<00:14,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6020, step=422048:   3%|2         | 3/118 [00:00<00:14,  7.99it/s]\u001b[A\n",
            "epoch=07, loss=0.6020, step=422048:   3%|3         | 4/118 [00:00<00:14,  7.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5973, step=422560:   3%|3         | 4/118 [00:00<00:14,  7.88it/s]\u001b[A\n",
            "epoch=07, loss=0.5973, step=422560:   4%|4         | 5/118 [00:00<00:14,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5962, step=423072:   4%|4         | 5/118 [00:00<00:14,  7.97it/s]\u001b[A\n",
            "epoch=07, loss=0.5962, step=423072:   5%|5         | 6/118 [00:00<00:13,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5967, step=423584:   5%|5         | 6/118 [00:00<00:13,  8.08it/s]\u001b[A\n",
            "epoch=07, loss=0.5967, step=423584:   6%|5         | 7/118 [00:00<00:13,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6013, step=424096:   6%|5         | 7/118 [00:00<00:13,  8.15it/s]\u001b[A\n",
            "epoch=07, loss=0.6013, step=424096:   7%|6         | 8/118 [00:00<00:13,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6167, step=424608:   7%|6         | 8/118 [00:01<00:13,  8.09it/s]\u001b[A\n",
            "epoch=07, loss=0.6167, step=424608:   8%|7         | 9/118 [00:01<00:13,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6026, step=425120:   8%|7         | 9/118 [00:01<00:13,  8.06it/s]\u001b[A\n",
            "epoch=07, loss=0.6026, step=425120:   8%|8         | 10/118 [00:01<00:13,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6064, step=425632:   8%|8         | 10/118 [00:01<00:13,  8.09it/s]\u001b[A\n",
            "epoch=07, loss=0.6064, step=425632:   9%|9         | 11/118 [00:01<00:13,  7.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6270, step=426144:   9%|9         | 11/118 [00:01<00:13,  7.86it/s]\u001b[A\n",
            "epoch=07, loss=0.6270, step=426144:  10%|#         | 12/118 [00:01<00:13,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5853, step=426656:  10%|#         | 12/118 [00:01<00:13,  7.96it/s]\u001b[A\n",
            "epoch=07, loss=0.5853, step=426656:  11%|#1        | 13/118 [00:01<00:13,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6001, step=427168:  11%|#1        | 13/118 [00:01<00:13,  8.00it/s]\u001b[A\n",
            "epoch=07, loss=0.6001, step=427168:  12%|#1        | 14/118 [00:01<00:12,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6076, step=427680:  12%|#1        | 14/118 [00:01<00:12,  8.11it/s]\u001b[A\n",
            "epoch=07, loss=0.6076, step=427680:  13%|#2        | 15/118 [00:01<00:12,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5922, step=428192:  13%|#2        | 15/118 [00:01<00:12,  8.16it/s]\u001b[A\n",
            "epoch=07, loss=0.5922, step=428192:  14%|#3        | 16/118 [00:01<00:12,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6179, step=428704:  14%|#3        | 16/118 [00:02<00:12,  8.07it/s]\u001b[A\n",
            "epoch=07, loss=0.6179, step=428704:  14%|#4        | 17/118 [00:02<00:12,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6046, step=429216:  14%|#4        | 17/118 [00:02<00:12,  8.05it/s]\u001b[A\n",
            "epoch=07, loss=0.6046, step=429216:  15%|#5        | 18/118 [00:02<00:12,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6121, step=429728:  15%|#5        | 18/118 [00:02<00:12,  7.99it/s]\u001b[A\n",
            "epoch=07, loss=0.6121, step=429728:  16%|#6        | 19/118 [00:02<00:12,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6018, step=430240:  16%|#6        | 19/118 [00:02<00:12,  8.12it/s]\u001b[A\n",
            "epoch=07, loss=0.6018, step=430240:  17%|#6        | 20/118 [00:02<00:12,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5937, step=430752:  17%|#6        | 20/118 [00:02<00:12,  8.11it/s]\u001b[A\n",
            "epoch=07, loss=0.5937, step=430752:  18%|#7        | 21/118 [00:02<00:11,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5929, step=431264:  18%|#7        | 21/118 [00:02<00:11,  8.12it/s]\u001b[A\n",
            "epoch=07, loss=0.5929, step=431264:  19%|#8        | 22/118 [00:02<00:12,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5958, step=431776:  19%|#8        | 22/118 [00:02<00:12,  7.92it/s]\u001b[A\n",
            "epoch=07, loss=0.5958, step=431776:  19%|#9        | 23/118 [00:02<00:12,  7.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6001, step=432288:  19%|#9        | 23/118 [00:02<00:12,  7.85it/s]\u001b[A\n",
            "epoch=07, loss=0.6001, step=432288:  20%|##        | 24/118 [00:02<00:11,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5978, step=432800:  20%|##        | 24/118 [00:03<00:11,  7.94it/s]\u001b[A\n",
            "epoch=07, loss=0.5978, step=432800:  21%|##1       | 25/118 [00:03<00:11,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6099, step=433312:  21%|##1       | 25/118 [00:03<00:11,  8.04it/s]\u001b[A\n",
            "epoch=07, loss=0.6099, step=433312:  22%|##2       | 26/118 [00:03<00:11,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6132, step=433824:  22%|##2       | 26/118 [00:03<00:11,  8.14it/s]\u001b[A\n",
            "epoch=07, loss=0.6132, step=433824:  23%|##2       | 27/118 [00:03<00:11,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6055, step=434336:  23%|##2       | 27/118 [00:03<00:11,  8.07it/s]\u001b[A\n",
            "epoch=07, loss=0.6055, step=434336:  24%|##3       | 28/118 [00:03<00:11,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6115, step=434848:  24%|##3       | 28/118 [00:03<00:11,  8.11it/s]\u001b[A\n",
            "epoch=07, loss=0.6115, step=434848:  25%|##4       | 29/118 [00:03<00:10,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6246, step=435360:  25%|##4       | 29/118 [00:03<00:10,  8.10it/s]\u001b[A\n",
            "epoch=07, loss=0.6246, step=435360:  25%|##5       | 30/118 [00:03<00:10,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5938, step=435872:  25%|##5       | 30/118 [00:03<00:10,  8.01it/s]\u001b[A\n",
            "epoch=07, loss=0.5938, step=435872:  26%|##6       | 31/118 [00:03<00:10,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6010, step=436384:  26%|##6       | 31/118 [00:03<00:10,  7.97it/s]\u001b[A\n",
            "epoch=07, loss=0.6010, step=436384:  27%|##7       | 32/118 [00:03<00:10,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6001, step=436896:  27%|##7       | 32/118 [00:04<00:10,  7.87it/s]\u001b[A\n",
            "epoch=07, loss=0.6001, step=436896:  28%|##7       | 33/118 [00:04<00:10,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6029, step=437408:  28%|##7       | 33/118 [00:04<00:10,  7.92it/s]\u001b[A\n",
            "epoch=07, loss=0.6029, step=437408:  29%|##8       | 34/118 [00:04<00:10,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5979, step=437920:  29%|##8       | 34/118 [00:04<00:10,  7.94it/s]\u001b[A\n",
            "epoch=07, loss=0.5979, step=437920:  30%|##9       | 35/118 [00:04<00:10,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5901, step=438432:  30%|##9       | 35/118 [00:04<00:10,  8.01it/s]\u001b[A\n",
            "epoch=07, loss=0.5901, step=438432:  31%|###       | 36/118 [00:04<00:10,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6066, step=438944:  31%|###       | 36/118 [00:04<00:10,  7.90it/s]\u001b[A\n",
            "epoch=07, loss=0.6066, step=438944:  31%|###1      | 37/118 [00:04<00:10,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6025, step=439456:  31%|###1      | 37/118 [00:04<00:10,  7.96it/s]\u001b[A\n",
            "epoch=07, loss=0.6025, step=439456:  32%|###2      | 38/118 [00:04<00:10,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5952, step=439968:  32%|###2      | 38/118 [00:04<00:10,  7.97it/s]\u001b[A\n",
            "epoch=07, loss=0.5952, step=439968:  33%|###3      | 39/118 [00:04<00:09,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5821, step=440480:  33%|###3      | 39/118 [00:04<00:09,  8.04it/s]\u001b[A\n",
            "epoch=07, loss=0.5821, step=440480:  34%|###3      | 40/118 [00:04<00:09,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6057, step=440992:  34%|###3      | 40/118 [00:05<00:09,  8.05it/s]\u001b[A\n",
            "epoch=07, loss=0.6057, step=440992:  35%|###4      | 41/118 [00:05<00:09,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6079, step=441504:  35%|###4      | 41/118 [00:05<00:09,  8.02it/s]\u001b[A\n",
            "epoch=07, loss=0.6079, step=441504:  36%|###5      | 42/118 [00:05<00:09,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6112, step=442016:  36%|###5      | 42/118 [00:05<00:09,  8.04it/s]\u001b[A\n",
            "epoch=07, loss=0.6112, step=442016:  36%|###6      | 43/118 [00:05<00:09,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5960, step=442528:  36%|###6      | 43/118 [00:05<00:09,  7.92it/s]\u001b[A\n",
            "epoch=07, loss=0.5960, step=442528:  37%|###7      | 44/118 [00:05<00:09,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6129, step=443040:  37%|###7      | 44/118 [00:05<00:09,  7.97it/s]\u001b[A\n",
            "epoch=07, loss=0.6129, step=443040:  38%|###8      | 45/118 [00:05<00:09,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6215, step=443552:  38%|###8      | 45/118 [00:05<00:09,  8.02it/s]\u001b[A\n",
            "epoch=07, loss=0.6215, step=443552:  39%|###8      | 46/118 [00:05<00:09,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6042, step=444064:  39%|###8      | 46/118 [00:05<00:09,  7.87it/s]\u001b[A\n",
            "epoch=07, loss=0.6042, step=444064:  40%|###9      | 47/118 [00:05<00:09,  7.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5964, step=444576:  40%|###9      | 47/118 [00:06<00:09,  7.74it/s]\u001b[A\n",
            "epoch=07, loss=0.5964, step=444576:  41%|####      | 48/118 [00:06<00:08,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6003, step=445088:  41%|####      | 48/118 [00:06<00:08,  7.83it/s]\u001b[A\n",
            "epoch=07, loss=0.6003, step=445088:  42%|####1     | 49/118 [00:06<00:08,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6004, step=445600:  42%|####1     | 49/118 [00:06<00:08,  7.90it/s]\u001b[A\n",
            "epoch=07, loss=0.6004, step=445600:  42%|####2     | 50/118 [00:06<00:08,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5986, step=446112:  42%|####2     | 50/118 [00:06<00:08,  8.03it/s]\u001b[A\n",
            "epoch=07, loss=0.5986, step=446112:  43%|####3     | 51/118 [00:06<00:08,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5933, step=446624:  43%|####3     | 51/118 [00:06<00:08,  8.06it/s]\u001b[A\n",
            "epoch=07, loss=0.5933, step=446624:  44%|####4     | 52/118 [00:06<00:08,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5906, step=447136:  44%|####4     | 52/118 [00:06<00:08,  7.92it/s]\u001b[A\n",
            "epoch=07, loss=0.5906, step=447136:  45%|####4     | 53/118 [00:06<00:08,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5996, step=447648:  45%|####4     | 53/118 [00:06<00:08,  8.01it/s]\u001b[A\n",
            "epoch=07, loss=0.5996, step=447648:  46%|####5     | 54/118 [00:06<00:08,  7.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5861, step=448160:  46%|####5     | 54/118 [00:06<00:08,  7.84it/s]\u001b[A\n",
            "epoch=07, loss=0.5861, step=448160:  47%|####6     | 55/118 [00:06<00:07,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6306, step=448672:  47%|####6     | 55/118 [00:07<00:07,  7.92it/s]\u001b[A\n",
            "epoch=07, loss=0.6306, step=448672:  47%|####7     | 56/118 [00:07<00:07,  7.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5907, step=449184:  47%|####7     | 56/118 [00:07<00:07,  7.78it/s]\u001b[A\n",
            "epoch=07, loss=0.5907, step=449184:  48%|####8     | 57/118 [00:07<00:07,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6011, step=449696:  48%|####8     | 57/118 [00:07<00:07,  7.90it/s]\u001b[A\n",
            "epoch=07, loss=0.6011, step=449696:  49%|####9     | 58/118 [00:07<00:07,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6082, step=450208:  49%|####9     | 58/118 [00:07<00:07,  8.04it/s]\u001b[A\n",
            "epoch=07, loss=0.6082, step=450208:  50%|#####     | 59/118 [00:07<00:07,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6077, step=450720:  50%|#####     | 59/118 [00:07<00:07,  8.01it/s]\u001b[A\n",
            "epoch=07, loss=0.6077, step=450720:  51%|#####     | 60/118 [00:07<00:07,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6067, step=451232:  51%|#####     | 60/118 [00:07<00:07,  8.13it/s]\u001b[A\n",
            "epoch=07, loss=0.6067, step=451232:  52%|#####1    | 61/118 [00:07<00:07,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6073, step=451744:  52%|#####1    | 61/118 [00:07<00:07,  8.00it/s]\u001b[A\n",
            "epoch=07, loss=0.6073, step=451744:  53%|#####2    | 62/118 [00:07<00:06,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5984, step=452256:  53%|#####2    | 62/118 [00:07<00:06,  8.06it/s]\u001b[A\n",
            "epoch=07, loss=0.5984, step=452256:  53%|#####3    | 63/118 [00:07<00:06,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6132, step=452768:  53%|#####3    | 63/118 [00:08<00:06,  7.96it/s]\u001b[A\n",
            "epoch=07, loss=0.6132, step=452768:  54%|#####4    | 64/118 [00:08<00:06,  7.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5829, step=453280:  54%|#####4    | 64/118 [00:08<00:06,  7.78it/s]\u001b[A\n",
            "epoch=07, loss=0.5829, step=453280:  55%|#####5    | 65/118 [00:08<00:06,  7.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6004, step=453792:  55%|#####5    | 65/118 [00:08<00:06,  7.81it/s]\u001b[A\n",
            "epoch=07, loss=0.6004, step=453792:  56%|#####5    | 66/118 [00:08<00:06,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5976, step=454304:  56%|#####5    | 66/118 [00:08<00:06,  7.93it/s]\u001b[A\n",
            "epoch=07, loss=0.5976, step=454304:  57%|#####6    | 67/118 [00:08<00:06,  7.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6079, step=454816:  57%|#####6    | 67/118 [00:08<00:06,  7.88it/s]\u001b[A\n",
            "epoch=07, loss=0.6079, step=454816:  58%|#####7    | 68/118 [00:08<00:06,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6025, step=455328:  58%|#####7    | 68/118 [00:08<00:06,  7.96it/s]\u001b[A\n",
            "epoch=07, loss=0.6025, step=455328:  58%|#####8    | 69/118 [00:08<00:06,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5877, step=455840:  58%|#####8    | 69/118 [00:08<00:06,  8.00it/s]\u001b[A\n",
            "epoch=07, loss=0.5877, step=455840:  59%|#####9    | 70/118 [00:08<00:06,  7.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5803, step=456352:  59%|#####9    | 70/118 [00:08<00:06,  7.88it/s]\u001b[A\n",
            "epoch=07, loss=0.5803, step=456352:  60%|######    | 71/118 [00:08<00:06,  7.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5916, step=456864:  60%|######    | 71/118 [00:09<00:06,  7.81it/s]\u001b[A\n",
            "epoch=07, loss=0.5916, step=456864:  61%|######1   | 72/118 [00:09<00:05,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5862, step=457376:  61%|######1   | 72/118 [00:09<00:05,  7.93it/s]\u001b[A\n",
            "epoch=07, loss=0.5862, step=457376:  62%|######1   | 73/118 [00:09<00:05,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5904, step=457888:  62%|######1   | 73/118 [00:09<00:05,  7.91it/s]\u001b[A\n",
            "epoch=07, loss=0.5904, step=457888:  63%|######2   | 74/118 [00:09<00:05,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5992, step=458400:  63%|######2   | 74/118 [00:09<00:05,  7.96it/s]\u001b[A\n",
            "epoch=07, loss=0.5992, step=458400:  64%|######3   | 75/118 [00:09<00:05,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6004, step=458912:  64%|######3   | 75/118 [00:09<00:05,  8.08it/s]\u001b[A\n",
            "epoch=07, loss=0.6004, step=458912:  64%|######4   | 76/118 [00:09<00:05,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6116, step=459424:  64%|######4   | 76/118 [00:09<00:05,  8.07it/s]\u001b[A\n",
            "epoch=07, loss=0.6116, step=459424:  65%|######5   | 77/118 [00:09<00:05,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6131, step=459936:  65%|######5   | 77/118 [00:09<00:05,  8.02it/s]\u001b[A\n",
            "epoch=07, loss=0.6131, step=459936:  66%|######6   | 78/118 [00:09<00:05,  7.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5904, step=460448:  66%|######6   | 78/118 [00:09<00:05,  7.79it/s]\u001b[A\n",
            "epoch=07, loss=0.5904, step=460448:  67%|######6   | 79/118 [00:09<00:05,  7.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5915, step=460960:  67%|######6   | 79/118 [00:10<00:05,  7.70it/s]\u001b[A\n",
            "epoch=07, loss=0.5915, step=460960:  68%|######7   | 80/118 [00:10<00:04,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5949, step=461472:  68%|######7   | 80/118 [00:10<00:04,  7.87it/s]\u001b[A\n",
            "epoch=07, loss=0.5949, step=461472:  69%|######8   | 81/118 [00:10<00:04,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6032, step=461984:  69%|######8   | 81/118 [00:10<00:04,  7.89it/s]\u001b[A\n",
            "epoch=07, loss=0.6032, step=461984:  69%|######9   | 82/118 [00:10<00:04,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5931, step=462496:  69%|######9   | 82/118 [00:10<00:04,  7.97it/s]\u001b[A\n",
            "epoch=07, loss=0.5931, step=462496:  70%|#######   | 83/118 [00:10<00:04,  7.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5933, step=463008:  70%|#######   | 83/118 [00:10<00:04,  7.84it/s]\u001b[A\n",
            "epoch=07, loss=0.5933, step=463008:  71%|#######1  | 84/118 [00:10<00:04,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6012, step=463520:  71%|#######1  | 84/118 [00:10<00:04,  7.92it/s]\u001b[A\n",
            "epoch=07, loss=0.6012, step=463520:  72%|#######2  | 85/118 [00:10<00:04,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6005, step=464032:  72%|#######2  | 85/118 [00:10<00:04,  7.90it/s]\u001b[A\n",
            "epoch=07, loss=0.6005, step=464032:  73%|#######2  | 86/118 [00:10<00:03,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5859, step=464544:  73%|#######2  | 86/118 [00:10<00:03,  8.03it/s]\u001b[A\n",
            "epoch=07, loss=0.5859, step=464544:  74%|#######3  | 87/118 [00:10<00:03,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5979, step=465056:  74%|#######3  | 87/118 [00:11<00:03,  8.03it/s]\u001b[A\n",
            "epoch=07, loss=0.5979, step=465056:  75%|#######4  | 88/118 [00:11<00:03,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6047, step=465568:  75%|#######4  | 88/118 [00:11<00:03,  8.08it/s]\u001b[A\n",
            "epoch=07, loss=0.6047, step=465568:  75%|#######5  | 89/118 [00:11<00:03,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6094, step=466080:  75%|#######5  | 89/118 [00:11<00:03,  8.10it/s]\u001b[A\n",
            "epoch=07, loss=0.6094, step=466080:  76%|#######6  | 90/118 [00:11<00:03,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6092, step=466592:  76%|#######6  | 90/118 [00:11<00:03,  8.09it/s]\u001b[A\n",
            "epoch=07, loss=0.6092, step=466592:  77%|#######7  | 91/118 [00:11<00:03,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6213, step=467104:  77%|#######7  | 91/118 [00:11<00:03,  8.09it/s]\u001b[A\n",
            "epoch=07, loss=0.6213, step=467104:  78%|#######7  | 92/118 [00:11<00:03,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6083, step=467616:  78%|#######7  | 92/118 [00:11<00:03,  8.10it/s]\u001b[A\n",
            "epoch=07, loss=0.6083, step=467616:  79%|#######8  | 93/118 [00:11<00:03,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6128, step=468128:  79%|#######8  | 93/118 [00:11<00:03,  8.09it/s]\u001b[A\n",
            "epoch=07, loss=0.6128, step=468128:  80%|#######9  | 94/118 [00:11<00:02,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6061, step=468640:  80%|#######9  | 94/118 [00:11<00:02,  8.13it/s]\u001b[A\n",
            "epoch=07, loss=0.6061, step=468640:  81%|########  | 95/118 [00:11<00:02,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6028, step=469152:  81%|########  | 95/118 [00:12<00:02,  8.16it/s]\u001b[A\n",
            "epoch=07, loss=0.6028, step=469152:  81%|########1 | 96/118 [00:12<00:02,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5880, step=469664:  81%|########1 | 96/118 [00:12<00:02,  8.01it/s]\u001b[A\n",
            "epoch=07, loss=0.5880, step=469664:  82%|########2 | 97/118 [00:12<00:02,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5992, step=470176:  82%|########2 | 97/118 [00:12<00:02,  7.94it/s]\u001b[A\n",
            "epoch=07, loss=0.5992, step=470176:  83%|########3 | 98/118 [00:12<00:02,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6004, step=470688:  83%|########3 | 98/118 [00:12<00:02,  8.00it/s]\u001b[A\n",
            "epoch=07, loss=0.6004, step=470688:  84%|########3 | 99/118 [00:12<00:02,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5894, step=471200:  84%|########3 | 99/118 [00:12<00:02,  7.94it/s]\u001b[A\n",
            "epoch=07, loss=0.5894, step=471200:  85%|########4 | 100/118 [00:12<00:02,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5891, step=471712:  85%|########4 | 100/118 [00:12<00:02,  7.94it/s]\u001b[A\n",
            "epoch=07, loss=0.5891, step=471712:  86%|########5 | 101/118 [00:12<00:02,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5972, step=472224:  86%|########5 | 101/118 [00:12<00:02,  7.96it/s]\u001b[A\n",
            "epoch=07, loss=0.5972, step=472224:  86%|########6 | 102/118 [00:12<00:02,  7.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6020, step=472736:  86%|########6 | 102/118 [00:12<00:02,  7.86it/s]\u001b[A\n",
            "epoch=07, loss=0.6020, step=472736:  87%|########7 | 103/118 [00:12<00:01,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6001, step=473248:  87%|########7 | 103/118 [00:13<00:01,  7.89it/s]\u001b[A\n",
            "epoch=07, loss=0.6001, step=473248:  88%|########8 | 104/118 [00:13<00:01,  7.67it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5964, step=473760:  88%|########8 | 104/118 [00:13<00:01,  7.67it/s]\u001b[A\n",
            "epoch=07, loss=0.5964, step=473760:  89%|########8 | 105/118 [00:13<00:01,  7.56it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6187, step=474272:  89%|########8 | 105/118 [00:13<00:01,  7.56it/s]\u001b[A\n",
            "epoch=07, loss=0.6187, step=474272:  90%|########9 | 106/118 [00:13<00:01,  7.64it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5918, step=474784:  90%|########9 | 106/118 [00:13<00:01,  7.64it/s]\u001b[A\n",
            "epoch=07, loss=0.5918, step=474784:  91%|######### | 107/118 [00:13<00:01,  7.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6179, step=475296:  91%|######### | 107/118 [00:13<00:01,  7.72it/s]\u001b[A\n",
            "epoch=07, loss=0.6179, step=475296:  92%|#########1| 108/118 [00:13<00:01,  7.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5955, step=475808:  92%|#########1| 108/118 [00:13<00:01,  7.74it/s]\u001b[A\n",
            "epoch=07, loss=0.5955, step=475808:  92%|#########2| 109/118 [00:13<00:01,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5927, step=476320:  92%|#########2| 109/118 [00:13<00:01,  7.92it/s]\u001b[A\n",
            "epoch=07, loss=0.5927, step=476320:  93%|#########3| 110/118 [00:13<00:01,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5944, step=476832:  93%|#########3| 110/118 [00:13<00:01,  7.96it/s]\u001b[A\n",
            "epoch=07, loss=0.5944, step=476832:  94%|#########4| 111/118 [00:13<00:00,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5876, step=477344:  94%|#########4| 111/118 [00:14<00:00,  8.00it/s]\u001b[A\n",
            "epoch=07, loss=0.5876, step=477344:  95%|#########4| 112/118 [00:14<00:00,  7.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5869, step=477856:  95%|#########4| 112/118 [00:14<00:00,  7.82it/s]\u001b[A\n",
            "epoch=07, loss=0.5869, step=477856:  96%|#########5| 113/118 [00:14<00:00,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.5975, step=478368:  96%|#########5| 113/118 [00:14<00:00,  7.89it/s]\u001b[A\n",
            "epoch=07, loss=0.5975, step=478368:  97%|#########6| 114/118 [00:14<00:00,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6040, step=478880:  97%|#########6| 114/118 [00:14<00:00,  7.95it/s]\u001b[A\n",
            "epoch=07, loss=0.6040, step=478880:  97%|#########7| 115/118 [00:14<00:00,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6157, step=479392:  97%|#########7| 115/118 [00:14<00:00,  8.04it/s]\u001b[A\n",
            "epoch=07, loss=0.6157, step=479392:  98%|#########8| 116/118 [00:14<00:00,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=07, loss=0.6036, step=479904:  98%|#########8| 116/118 [00:14<00:00,  8.09it/s]\u001b[A\n",
            "epoch=07, loss=0.6036, step=479904:  99%|#########9| 117/118 [00:14<00:00,  8.14it/s]\u001b[A\n",
            "epoch=07, loss=0.6223, step=480000:  99%|#########9| 117/118 [00:14<00:00,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f083fe96-84fc-4900-a6de-0fd4c5f43a14\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f083fe96-84fc-4900-a6de-0fd4c5f43a14\")) {                    Plotly.newPlot(                        \"f083fe96-84fc-4900-a6de-0fd4c5f43a14\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAbx0lEQVR4Xu15aZilVXXuu9ba33TOqbm6q+kBCI0EECTEkCvig2gkXsAhxgDROF2NyRUh0RiS4PiI0YhGxYi5EkfURINDphswzorEqJeIQxyC2tFuurq7hlOnzvBNe691f5yq6qrTddXnPv643ifvn\\u002fPt9633WXXWt7+11v4OTeM\\u002fsR14lPhPDPFTm5j9\\u002f\\u002fqVUeonip\\u002fWxLz6jr1fHeV+ohhNzHm3LNxy3gj3\\u002fx523PmsqW\\u002f+7ij7E8VIYs798FV21Ye2cpvxgoWli0Y5AEBr7qnPT0ZJAPvP\\u002fG9LCwsLCwu3xaPScVz8zdNHKcjU1NT1L333rr9Yuv8PRrX9Nz8Yr3jR8ij946Lx8a+fPMqdALdl9fO3jVuvmr7gK9UWegNP+l2FjZIATrnugrOAnTeM8mc+6fG8Sw0ALnvdC7vr9EOn\\u002fvH43wA4\\u002f94tS+yNL3jIxGMB4PCrr+j+291bVWD6UuDw50bZHwu7ZrHysJ+770cndXNisvPeMgd8901vu+NVb9hEb8K+7TYFHvDfr0zp\\u002ft4Zv\\u002fKO+0aUl1x6\\u002fPrq935h\\u002ffKi07Ykhk\\u002fZS5vXD\\u002fqb8bUrfeXgg0dWvrNZBLD\\u002fVsLT7hwhN+G50RlX4r6HjtI4+9n7sH8vbv5Zmj9x+z74qoeeiZceecjt9wzXmxPz+icCwHnNux929iZ2Ex7+bNz3pIURcvxlT2gB370y+peZmdHEfPpSLPwVgF\\u002fY+vxd\\u002faUty7mn3b7FeHB5HADu6Tysvn0zv46r937sBfOj5DouOvOiKwiG0z5\\u002f4aj0sKcA5e0XPw\\u002f2vhN2zBNeNUOfm305aOY3h8SmxJz3y4S7P\\u002fryI19buXjLDdzAQ24Zx5sOjrJXPBXAgSfef9qoAOCdd6A+BmDs7l24494NeqSwvRHf27Juv+zRX301vvargzN\\u002fewu\\u002fho+c84MXb5+XubeeivEG3XseAG6Mqn94Ld6\\u002f+ObFcz8ws\\u002fgPI5I7\\u002fw2Nf\\u002f7TL8TveATuXac2xHM\\u002fPGYff\\u002fZFr3zv4tf10vO2GxJ+fRc+99ejJB4P\\u002fODLL78fZ4wKAPz9w89HTgCHy3X2gTvWr4YYx6e3Enfc1TvnKX8+wLeev5UHAFz2YPu7YpQEADz85j0AcOHy9K5bduPbo3IjO\\u002fjHR3Ha82cHrxn1X\\u002flGfPpZXfzKI3D4\\u002fWvURmL2Xzu+dPT9\\u002fY9+FACya7a5VzO\\u002foZ3Xj5LA857+qQMLAEa+7Wb86lMz4E82lo\\u002fKNmnAjpMxugG6WMVTPqwjLABg4kKgcxjAb+\\u002fBS7dKv7MHKF9+z3ew\\u002fNu78YPnbBWBv3\\u002fUGS+9fvwVv9x+\\u002fTtGlBc9z97+qi7we8AfLa5x64lJbry0d8296fqf7l2\\u002fOI6T3wW89a5RFjhy0\\u002fDzgq30cVz5vFMj4Gt+g3gAvrVJxo07v9PbvAYA3HTeRQ\\u002f\\u002f1CgJAOE81n8GrrFn78Nzz9mc0Uc8GDj0nC8AwG7gzqVNEgDg61864+JLXrkXr3nriHD986pP3pgjvWQvvW6jpq8n5kGX4ikntMUt+KUH4rO3jpJr+K0G2Vn44taaCuDkqx4OPMSA7o0fyzfxX964GvulKx+B13U2aUMMnv+pm++69+0nzgYXXaiHlnHuf7kM\\u002ffnT3\\u002fWbm0recxv44mu+AGDyUQ\\u002fFFz92XFhD2cWu28jee8cIP\\u002fFM++RTgdPe8nP4+z\\u002fbYNcT8wq6+3heWE+svpe\\u002fFP9yzeooCwDZmddfClYcuS6MKGe\\u002fd33nff62LcIUgHP44t3RlVTcU7l7t4hDHHjuLVdf3fjroyN062Qcuf17+6+9fOnTfz72t+ttHQBw2\\u002fTqbx0DgGe8EN965rHN0hAHAeBjt6zVvQ3EM7hhx5MuO6tp9oHBBruWmEefYx\\u002fZ4KD2teOLIU6+Dfj+aKcGgOjc2+byI196ZAPymFtH50IiAKzAoy\\u002fddAdze93zgQeSz7\\u002f9l\\u002ffevfC1dLTLAwD+8cArLn7JvtePlJ+HvBLvfu2OGy\\u002ft\\u002fd1LT\\u002fvT3mc398h\\u002fWOs1\\u002f\\u002fV6+Hdtkxe5kICPPnmURrU4+2UDjnTnljblYC0xabzwN+tU8ge468b1xTp+R4GbR0kA8SPfjdfc9YWpvz0Lsy85dMdG5wEAfONxV36yBPCUZ2+hrz\\u002f4iwAO3fnt\\u002fwUAT5\\u002f9jy3qBr7xzEff8ozTnriVPBt4Ld79YDzl7gv+EW8Zqb5DvMdww9YNOsTbHmPYbm7vPPV9UwfufF\\u002f7bXMbKcCmrlStb9rkBdcdfnN\\u002fnV7DuY8A7hydQAFEf3gdPvHWzuz7z67edNZlt37mzzrYfOg9OOxiN21NDI4\\u002fyQAuxuhUsY7O7W90D71oa+WboDtw7j56yd37b6WXvGWLtIYXs2KbarnryY+1r\\u002fzbk7frnfecAQAPvUj\\u002fYxO5kZj1XXTutU+48+nr5AY+OIl7njtKAnLDtYMbP9w5\\u002f6YHfff3Pzf2i7922Ydw\\u002f\\u002fmjfwQ8cpTYitFquIYHPu58h29\\u002ffoQ1AGYP\\u002fGry\\u002fSu2rXjxg9Ru2DowAgAuvgGvfNvlTz5hutlAqrbNjiG6\\u002fAYAwDUvGP\\u002fANZv0NUwr3j66iwA87drB733qF578qPS1f3U\\u002fup\\u002f4xBN\\u002fDS\\u002faEKNH3DXsRL\\u002fxyg3ux8fpz75iDghHR4aZj1x32QXntHA1Lb12dPgBAGRXXYIPffDECeiiV+M3PrPzevxgVNjAJ7cu1xJjtvNP\\u002fmr5F646Z\\u002fehT46OPwBuYeCLoySA6yHX\\u002fsFpwE03DxvShza9sbjw+Zecfz+AqUe9ooF8c7MeAZ12QpvHzl971skAvvz6TeUQAFANGncYgN7fndiPAbRufhxe9LYT84JLxu\\u002f+p+iXx+mE6WYDI9t641GSZz22ux\\u002f40l3HJ9QNnPtwrd6+XUs6Npucg499\\u002fo4fjDZqAK8+C9f1AFxynuFz7\\u002fzcqHwcNvqyDDvOvOkBAO55050nfMWv\\u002fNZzHga8\\u002fxtf26aMANj9OBz4i1ESAGAWXf4nK+\\u002fZ5q6v4dSty7XEfOnL52NuJ5b\\u002fZvhAjWB8J+a3bQCPufy8hb\\u002fsjDbpDTxz+LHwTy8cPZxswQXv27Kcev05pwL44ps\\u002ftd02G55Z\\u002fg94wDX47lWjJABgBksfuhDXjW7ATfgX3nIX1hJz+GnPeAFw6zu3qVo\\u002fDL3bt30vAAC47jd\\u002fHQAO5J9\\u002fzzdGtS3YOkw++LqfPwlAfusbjg9bPzZ+\\u002fwl46wnHfwDAv+Nx1H77Z0bpTfjGd089df2ghOOP0tGb1o482+G+Lz5klPrR+Or1\\u002f\\u002frCyTs+fcc2o9YWfPzxW5ZXXAH8+0f0lhNPCT8aZ47hts+OkkO8P37BvR\\u002f5H6PsFrzhjS\\u002f6o+NNi6Y3ST\\u002fteNlzD169zbD1Y2LsHQ\\u002f\\u002fn9dubNMTCt9PMz6FF\\u002f\\u002ff5wXdZ77jMfs2Vv9f7ZifJJhgJk6LymBiWgWvjKCs0Mg4kJpB1atBATKDAhY84gBTGCvMghqbwYjYlBBFClMzVoAMRDAi3qwRGMykagwzQGFG9kN9cYApbYqnx+MJACUjBUjNmMhgHjCogJTUjFSDKpSIDGREpp5+mM+xEilHrlawL5TikgdOrEJFDIM3Ji+BGQSFE2UOVDsKNZEREAIAYwoU4MwIpFaywQBTg8HYSLwxAoyDGQFGZgolM+aajKEwguFEX61iaz4mAmxTPPXR8XikBjaoEDEUYFUyMqKaAG\\u002fCngOLESlEjESpdhxs6NPtfK5kqoURuNmviKXRjUpm46SKQAYOgJoJzOCJAsRMCebUEMSMVEBCBCFPAURBPMwQ2IyUiDh25jSYmbJRYCVSMSMygCkYS+Cgsrb1tvrEHMyMlQOrURBsjedpLR7YWGEAwcgMZDAl70gZDDKCmjGpIYABVlIiE6z5yLbxOY3VhYSMVgMjGgtjDr52FXsW74IC6sBmw2+WOBc8zDHArAQzZkTCcUQoqzoEWDAicqbGJCwudklkVhd1wWZmRAQCqYEJAYIIDFLAPIjJmYJImKMoOu6DGhFtxHNCSUQoawSFeSOCGbEyiNWAwEYixgYjkAUjmABQMwT2SeyCkgmT\\u002fTCfiwKpmZWgVjS+qznBSXtlubfalSBmyhwcnEkQihM4kbjI+7V4x6RWE0EobjQbiYh2+ys1NKpYSUyNmZ1LJlpTDWHrdhZkoBZYCTAFBQ6RRU6cM\\u002fUhhMCe1G32TTZEdJOP1WoiE44azSwWp91+x\\u002fthPJgZxBAQhDkzI3ZBawtGrCakDqJsQi5W51xalYNKgrBu57PKghE7nxCs58JYOjW7Z\\u002f\\u002fpU1F+7Mj3DhykgcFHQt4FpwSHZjaRZKlUq0uBvRg8lEyiKJ6cnphoOCuXl6K21zICJJiCJI6bM7tm5rKWlscWk8NUFGwyLOHK7GLXSCctMu3VvbqulfwW386spcXCQjyPsmCTtXguiiemx8cbDkV7OW4HrYbxyMiTCnOWNRwiZyGs+iqnQBAKEiSQOW4kLZc1o9BfMq5hsDUfb\\u002fZ16yqnQI6USBzF2dy+00\\u002f62d1Z1ttzJLHCc9dFILBRAPkobe2YnXZROfCr7MwbkzJIorGxmV1Tk7FonqVsgxLVWuknltbUjj27diRRKMVVBUIdAIWReI6k0RxrToxFpLa6GvcK1kDY5Jsb+qQuSesAKBmDOG61ZucmJ2KneTMTy4fxAJAyIXZZc3oyY0qLYjXq931tBAKMglGIG+OzkxOS+WqhP9CgoOO+RnN6IhNKyw2fIwRUjqemTjrltD2T5I\\u002fENnOGcnmYvQWymsWgLmqM7zx52kW9leVGHx5ESgSKmxPTczNTUVx6i7PWoDBFAAADXJw1J1ut2vWtW1QuJbMgBjAZc9yYmJ6dnnKujqt8gVW9BN7GV7sUBmUDiAhJc3JqbnoqiqtASaOVlzAEAGxGKlE6PjM312hqxlg9eoSt9oDBvLCZxY2JHTv3jCWNarXIB1Z7ENiMgkTZ2MyuoY86x+aHPkdSE8fpWGvX7p1u+Wi7F83sbOydHz9KFbtaCGZw0tqxc25uHHW2FBGbKYECk0jSaIw1AnqdgJSY2FfBjFkNMCZyPOCltpZJCRILpkYcmFiy8eldM1MNX9Xc4EHmTEMADVuEMEec09JKKNPCyJlXGFEQiCSN1nhTfX81IBMh9pVXsNQMUBqN75g7ecpxmYpzxUpi6oO4msmU4OLxk3bsnG3GFA8SdqZh6DPO3Pjs3MnTImXGkRQraUd9EAeFQyA+ae++aHXlUGchPen0fRNnHpnvU53AmyMETdLUMSFUvUG\\u002f6+va1WREABPHocCg3acJkYjqykCRKYgoBKO6XxXtgSYtH4yCApEaTKMoakxOTmdhqeOnozQTXwcTYwUY6o3qflm0c02aQQ1egUiVYBCWWMuq3+7TpHMx1aUSC4hNnUg8tvPUHUlnpZjc3UAEH7wEIqs1Zii1xscSVo+oqop+XdeuNh76ktbOU3cmnYVicndmkdXBSyCnqBNDsm\\u002fvrvF8fuHI93NqOzolimMmFoIQm7FzXJdlmlerq92qKswbjNnAZkBVLi8Pmk1hJ0YgKBmTBqckkQ2W20UaaVSyRAoLZEQEZjj2g+7hFUlniEJZG6uZMWmIjMRZvrSSp5FFBUvcgwUyZiM2M6vK5aW82RJ2okRGRgYSdWQcQ1cPd6ooaNVfaQ80wISGw6mI47oXQ9J+t9MfDFQVAInKiK899DlQbDa29+x9e6ul+xcPdJZpuTGDPXu\\u002fCdLK2BAgMKootFory4fm222YMpkpMyOURaF5oUmzNYYOgg\\u002fEMAQyAzGZ1pJGyVRmVey9agQYiETgCIUeXhxMSBphUFcBRIZAMAPBQiWJS6cyK2NfD33KTAhFUeggD1GzOUYdhFqZYEZQCX4sySQ\\u002ffChPJcPg0Eq\\u002fNIjVRiBPjkSqiqMkr44enl+qVUksDH2tJJPB\\u002fKEikQz9Q52hz0EYmNy5Y05W7ztwtByIxWUt3rUizo0ggT0zl3Hc3BGndbfd92YwjusQ4JQMEScNcdOzM\\u002f1EVExhxh6BVZJGK2YTbkxGVeGiJA6kxMGAWmtfUe2luXOqVZaDQeU8EXjYk5OsFbEJNyfjMo\\u002fWfarESoqI1uPFrAIVGAcEIzMu88Eg4l27XDF\\u002fbGmZK4YLBFJSFivzuDnT5OXV+ZWBNyWOwtAHqYp8EPOuXS4\\u002fcmypTRXDuVRVoul9p8SrB+89VpinQYq6EqdGMUGVa\\u002fJRoDrZvxv3LS+0Cy9RLfAqLAghRG4MrSqZ2N3sLrpkwCBjE7BHREnU1LR2jYmo9t0sSQsjMgEZfFAQN9N0z8+Mz5d5YGMzUQF7i5C4pma1a0zEx31BhOF9cDKGVpVM7ml2j0ncZ5AykRIJOabKu\\u002fHZfXvcDw61e1EQ8UQwJc\\u002fKhGps376k2zl0rFcLebGw5hOmyruxHft2y\\u002fcPLvdcYOfJeQfm5qQkh756qK2xOeeareYxVddPaxGYBAL87K69M91qsVfUFFiAADViYjHXsESSiYmkjJM46zOIVZUocmnsxHOLE0nQHEuTyHtIbSADo7IozTC+b1fQvDSQGSmpMsUujSNXScqJS6w5liTOeUhQc8Yk6hpIJZmcSIoojrOcwRQMMCN4XzfGs9m9E\\u002fPLR5bzEEHJK5EZG5nWM3Mnz3ksdro5eWGDZwPMQHVdN8azHXsmDg99pOTZ+oU2Ttm9t\\u002fvN7y8s0yDva9Rs+H6voKhyFBQEF5CN75rJVu7vrPpaZe21AKOugqbNqNVMBUpxmiVOBABIYEaUuTpC3W8v96iZpWKABQOzaqiMoqg1NTvddFUJCEGNATELRJnzaz5uZpkAQDAw6lI1bcatVuqYJE6zxLHAABBTRL7Ioa0de3eW8wfm+xbHQsxCauTYBcsaczPjxf1Ly5U350BEABFFPPTt3LuzmD9wZN3nQmhoFs\\u002fmg5WFQVYFi+Jde+by\\u002fmK\\u002frMnAgZ0GB9cc88VKuzcoPRcRDHDDE6GU3mttqF1VGcVZHpiUvRqzS0KwPLfKCtqRJEnmWALEjAXBdwdRFuqsn7Z7q7mZBoOKBmORDV\\u002fJM\\u002fG6z5kxyLj0Xr1RcEVhFDUKZVYyqONQ91ZlLpR1r7PY7g64apmaEdiLmJpao+GLlZV2r6zIpzCADCYc6v6qm9Oi6nYW292cq5aamaPMT07ONNhCnduko3j\\u002f2aclywcWByr9DAb2RC5Lmcqlo4NBUBiUxbOKhcBVXfZj7vXChMwGSGSsChhDLSaod3WxUtmOaZZmJMK1mYmpquT9RZ9Yi1pRp91XCgKYKEMtIlPvfLFSQqc4bqz5IOY1qeqiF3O\\u002fr5My440jFVMlzyrwruDVKKJW7rr3L7UtVgaZ1KRgT5AkMa3bi71+7QlsJF42fN044max7iMxEwcBxDXidKK1m2U8mXzAz+yQQ\\u002fNHc3NMCASHKM3ShvR63V6hBpBTj+ACW8Ra97ts+SAqg1W+DkwgBRRI48RZ7Yu8RpKOZ3UFJhEzVlaG+kHZq0yTYtBfLUol9aw69MWilc\\u002fzCkk6ltb1ui+wOQpVb5VpUERF0KKqA8FIjcEgx6TmQ9Ebk+V+Yd4IQdQIIEQUZUmcopevrg5UDZAQENZ9Zj4U\\u002fQG3e8d9Dr6u6sKPnXKWHcJ4q7Vz3\\u002fTK4X\\u002f73oqKGikBmiaTU9Nxr+ofy0sfGThgWA3EEao8j7gsOG2QVQiVavARAUnqHChj1spN7J52g7osTVVJghLI1K94FyXk+wv9moyIFWxAkjgHSoW1dOMnTUeDuiwt6PAuClDlg0iKnNPUrEKoVX2IJEDI4FLmgMQvzB\\u002fNY46EYEKsRhQa6dTUVJSH3pHuoI6NJBixDX3kUpaAxB+bP1bEHDHDhByh2e\\u002f0l3ZO\\u002feJUlyas2ZDBwUMHji0baUZEasxpM200m\\u002flKp2NOmYenWW\\u002fC4EikrtmysSZVK91O6dXAgSBAJGkrjWNuydik9I4e7fTKAEIIQlAGmKJmlnGR9wxsAYRgEFDk0mYax9RwYxPcO3q00y8VBG\\u002fCxE64rkSTZoZypb9aBQVxYBMlRBJn2fiUWK9TaswOygohSFCRrJU1W62y026rBBKYKViHPhc1sokptt5KpdG6z8VBKf\\u002fWZHrmyXt7gPrewe995\\u002ftHc1exq0nVjKO0NTnZpPZCm40iBQUmJjAMgATfb8bZeFoVS+1BXtZQFQZMK\\u002fXBuTjTiEN7fuHIUq\\u002fWoAwBEZFEjEZryhVFpygsmJGCCLBQaQgicaoxh5X5hSPLQx\\u002fxcGjWut+KG+NJmS+387z0UBWyQEQcN8cmZyei9tHlHObMeSUimBokysampsZk5diiBjgFeyIhDH1Ra2xi6BsAzlxtROSCMvyxbzbz\\u002fZHj0F6c\\u002f9b3DnU7ReTUmw47LLvYxfVgsVeKeWJ1Bu9UzIzCQPriGaG\\u002f2ltY7pQKz0BgJV90UueaDlzXRX9x+Uh3UCsAZYNnLTMfR4n5\\u002ftJKp1YyBDYEVgpDX2TifdFfWjrSHdRKQBAzhQ5kEHmBDrq9YyurtcEzSAWkMM\\u002fSSONydXWxChj+BmFmYgT1kDiOQ2+x12fxzMog72zoCyzNNCpXO0uVB1MwYzOHqHLLg6Pzp566I6v7xxYOHuoUHlxCI+LAHi4Keag7eXuhU4PiSqEg9pFngtWqoQ4t9joYtLtFUXkORGTG9SBUqyvNMYfQ7w46g37uAykRew7ERnXiQ13W9VK7CKTBI4jx8JeKerXTHHMUBt3BSt7LfaBAxJ6J4K1ranCrNhi0V8thPIhnzwxnSSyDzrH5XhEYSspGKp4Cx5EV6ruDo0fatSLyRkrEIRr6xOKY85VjR3qFbvhoLJWBWUMnbYyR17pccuSb8EEqYheUoziZmMzCYGWlykVCMGUSFdQsRHDWiJNGg0Mo8ryogwdgHJgI7KTpYhIfal9XJcyUzFwgBplzzVZrLEVedFZzryEQgXDcF7EE731dVgZVMovW4mkzThtN8SHP86IaxiOCEcXp1MxsQzuLi4Oirpk9iRmbBHVRmk5ON31\\u002fcXlQkgu69h10zTc9vSPTzuJCvslHUwiJUqgpkGOthLyTJCB3kZoBBqE0S0NVlqWGzCSQKhsTiAIQBUCcJALTug4VEYZvDwDigCBsLGALaoEJUDAoQIU4iaI0hpZ5VQUFGRlj3afMJgxRDRs+ogA4BVzEqUC1rjbiGSmMWo3JVNEt+nWtUFGGqTMD4NBoZFaWgzKEGMNfY4wJRgrjVjaVqPXyQeUVKkYwdTRtRFy7oGLwEeIy8YArvLaq4clUyBLydaXKkXMVh+ENkgAlUhegzAnM1LOaOQ0CVigB7M3MHAjwYgRREHGAEoyZ4RJG8LU3wAAwJGz1kXkxggsgkkCBSEVhLDGpqeewFo9UwWBuJIwwqGsKNPwnlYgMBCFLxddVrRSJ86RmbDTiqzwFMlr\\u002fZWvWK2niqthcV8QpGSoYNEqKLDcxrgGSWtQ7FvbMVRSIAjsfyNg4GBOBVBkqauKJEquCmMBMRQkELxQYxgakwQeBQZQAAgcjBSuxJ8So\\u002fbY+JaTqA4GM1eiEeN6DuWaHSFUDG1EQmMDDXFAxrsFwNYfgmMUzV244n5\\u002fgU173\\u002fW+z80xxZ+0dBAAAAABJRU5ErkJggg==\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f083fe96-84fc-4900-a6de-0fd4c5f43a14');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=07, loss=0.6223, step=480000: 100%|##########| 118/118 [00:14<00:00,  8.00it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5960, step=480512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=08, loss=0.5960, step=480512:   1%|          | 1/118 [00:00<00:14,  8.28it/s]\u001b[A\n",
            "epoch=08, loss=0.6027, step=481024:   1%|          | 1/118 [00:00<00:14,  8.28it/s]\u001b[A\n",
            "epoch=08, loss=0.6027, step=481024:   2%|1         | 2/118 [00:00<00:14,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5901, step=481536:   2%|1         | 2/118 [00:00<00:14,  8.28it/s]\u001b[A\n",
            "epoch=08, loss=0.5901, step=481536:   3%|2         | 3/118 [00:00<00:14,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5997, step=482048:   3%|2         | 3/118 [00:00<00:14,  8.05it/s]\u001b[A\n",
            "epoch=08, loss=0.5997, step=482048:   3%|3         | 4/118 [00:00<00:14,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6122, step=482560:   3%|3         | 4/118 [00:00<00:14,  8.04it/s]\u001b[A\n",
            "epoch=08, loss=0.6122, step=482560:   4%|4         | 5/118 [00:00<00:14,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6040, step=483072:   4%|4         | 5/118 [00:00<00:14,  8.05it/s]\u001b[A\n",
            "epoch=08, loss=0.6040, step=483072:   5%|5         | 6/118 [00:00<00:13,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6078, step=483584:   5%|5         | 6/118 [00:00<00:13,  8.03it/s]\u001b[A\n",
            "epoch=08, loss=0.6078, step=483584:   6%|5         | 7/118 [00:00<00:13,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6110, step=484096:   6%|5         | 7/118 [00:00<00:13,  8.07it/s]\u001b[A\n",
            "epoch=08, loss=0.6110, step=484096:   7%|6         | 8/118 [00:00<00:13,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6106, step=484608:   7%|6         | 8/118 [00:01<00:13,  8.08it/s]\u001b[A\n",
            "epoch=08, loss=0.6106, step=484608:   8%|7         | 9/118 [00:01<00:13,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5943, step=485120:   8%|7         | 9/118 [00:01<00:13,  8.15it/s]\u001b[A\n",
            "epoch=08, loss=0.5943, step=485120:   8%|8         | 10/118 [00:01<00:13,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6115, step=485632:   8%|8         | 10/118 [00:01<00:13,  8.11it/s]\u001b[A\n",
            "epoch=08, loss=0.6115, step=485632:   9%|9         | 11/118 [00:01<00:13,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5903, step=486144:   9%|9         | 11/118 [00:01<00:13,  7.98it/s]\u001b[A\n",
            "epoch=08, loss=0.5903, step=486144:  10%|#         | 12/118 [00:01<00:13,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5884, step=486656:  10%|#         | 12/118 [00:01<00:13,  7.91it/s]\u001b[A\n",
            "epoch=08, loss=0.5884, step=486656:  11%|#1        | 13/118 [00:01<00:13,  7.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6048, step=487168:  11%|#1        | 13/118 [00:01<00:13,  7.84it/s]\u001b[A\n",
            "epoch=08, loss=0.6048, step=487168:  12%|#1        | 14/118 [00:01<00:13,  7.64it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5965, step=487680:  12%|#1        | 14/118 [00:01<00:13,  7.64it/s]\u001b[A\n",
            "epoch=08, loss=0.5965, step=487680:  13%|#2        | 15/118 [00:01<00:13,  7.59it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5957, step=488192:  13%|#2        | 15/118 [00:02<00:13,  7.59it/s]\u001b[A\n",
            "epoch=08, loss=0.5957, step=488192:  14%|#3        | 16/118 [00:02<00:13,  7.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6137, step=488704:  14%|#3        | 16/118 [00:02<00:13,  7.73it/s]\u001b[A\n",
            "epoch=08, loss=0.6137, step=488704:  14%|#4        | 17/118 [00:02<00:13,  7.69it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6051, step=489216:  14%|#4        | 17/118 [00:02<00:13,  7.69it/s]\u001b[A\n",
            "epoch=08, loss=0.6051, step=489216:  15%|#5        | 18/118 [00:02<00:12,  7.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6032, step=489728:  15%|#5        | 18/118 [00:02<00:12,  7.84it/s]\u001b[A\n",
            "epoch=08, loss=0.6032, step=489728:  16%|#6        | 19/118 [00:02<00:12,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5893, step=490240:  16%|#6        | 19/118 [00:02<00:12,  7.91it/s]\u001b[A\n",
            "epoch=08, loss=0.5893, step=490240:  17%|#6        | 20/118 [00:02<00:12,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5959, step=490752:  17%|#6        | 20/118 [00:02<00:12,  7.89it/s]\u001b[A\n",
            "epoch=08, loss=0.5959, step=490752:  18%|#7        | 21/118 [00:02<00:12,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6008, step=491264:  18%|#7        | 21/118 [00:02<00:12,  7.83it/s]\u001b[A\n",
            "epoch=08, loss=0.6008, step=491264:  19%|#8        | 22/118 [00:02<00:12,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5984, step=491776:  19%|#8        | 22/118 [00:02<00:12,  7.94it/s]\u001b[A\n",
            "epoch=08, loss=0.5984, step=491776:  19%|#9        | 23/118 [00:02<00:11,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6019, step=492288:  19%|#9        | 23/118 [00:03<00:11,  7.99it/s]\u001b[A\n",
            "epoch=08, loss=0.6019, step=492288:  20%|##        | 24/118 [00:03<00:11,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5825, step=492800:  20%|##        | 24/118 [00:03<00:11,  8.09it/s]\u001b[A\n",
            "epoch=08, loss=0.5825, step=492800:  21%|##1       | 25/118 [00:03<00:11,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6144, step=493312:  21%|##1       | 25/118 [00:03<00:11,  8.10it/s]\u001b[A\n",
            "epoch=08, loss=0.6144, step=493312:  22%|##2       | 26/118 [00:03<00:11,  7.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5979, step=493824:  22%|##2       | 26/118 [00:03<00:11,  7.81it/s]\u001b[A\n",
            "epoch=08, loss=0.5979, step=493824:  23%|##2       | 27/118 [00:03<00:11,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5959, step=494336:  23%|##2       | 27/118 [00:03<00:11,  7.89it/s]\u001b[A\n",
            "epoch=08, loss=0.5959, step=494336:  24%|##3       | 28/118 [00:03<00:11,  8.01it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5883, step=494848:  24%|##3       | 28/118 [00:03<00:11,  8.01it/s]\u001b[A\n",
            "epoch=08, loss=0.5883, step=494848:  25%|##4       | 29/118 [00:03<00:11,  7.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6022, step=495360:  25%|##4       | 29/118 [00:03<00:11,  7.82it/s]\u001b[A\n",
            "epoch=08, loss=0.6022, step=495360:  25%|##5       | 30/118 [00:03<00:11,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5962, step=495872:  25%|##5       | 30/118 [00:03<00:11,  7.83it/s]\u001b[A\n",
            "epoch=08, loss=0.5962, step=495872:  26%|##6       | 31/118 [00:03<00:10,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5924, step=496384:  26%|##6       | 31/118 [00:04<00:10,  7.95it/s]\u001b[A\n",
            "epoch=08, loss=0.5924, step=496384:  27%|##7       | 32/118 [00:04<00:10,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5975, step=496896:  27%|##7       | 32/118 [00:04<00:10,  7.94it/s]\u001b[A\n",
            "epoch=08, loss=0.5975, step=496896:  28%|##7       | 33/118 [00:04<00:10,  7.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6055, step=497408:  28%|##7       | 33/118 [00:04<00:10,  7.86it/s]\u001b[A\n",
            "epoch=08, loss=0.6055, step=497408:  29%|##8       | 34/118 [00:04<00:10,  7.69it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5972, step=497920:  29%|##8       | 34/118 [00:04<00:10,  7.69it/s]\u001b[A\n",
            "epoch=08, loss=0.5972, step=497920:  30%|##9       | 35/118 [00:04<00:10,  7.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6150, step=498432:  30%|##9       | 35/118 [00:04<00:10,  7.88it/s]\u001b[A\n",
            "epoch=08, loss=0.6150, step=498432:  31%|###       | 36/118 [00:04<00:15,  5.29it/s]\u001b[A\n",
            "epoch=08, loss=0.5924, step=498944:  31%|###       | 36/118 [00:04<00:15,  5.29it/s]\u001b[A\n",
            "epoch=08, loss=0.5924, step=498944:  31%|###1      | 37/118 [00:04<00:13,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6084, step=499456:  31%|###1      | 37/118 [00:05<00:13,  5.89it/s]\u001b[A\n",
            "epoch=08, loss=0.6084, step=499456:  32%|###2      | 38/118 [00:05<00:12,  6.38it/s]\u001b[A\n",
            "epoch=08, loss=0.6004, step=499968:  32%|###2      | 38/118 [00:05<00:12,  6.38it/s]\u001b[A\n",
            "epoch=08, loss=0.6004, step=499968:  33%|###3      | 39/118 [00:05<00:11,  6.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5969, step=500480:  33%|###3      | 39/118 [00:05<00:11,  6.74it/s]\u001b[A\n",
            "epoch=08, loss=0.5969, step=500480:  34%|###3      | 40/118 [00:05<00:10,  7.10it/s]\u001b[A\n",
            "epoch=08, loss=0.6030, step=500992:  34%|###3      | 40/118 [00:05<00:10,  7.10it/s]\u001b[A\n",
            "epoch=08, loss=0.6030, step=500992:  35%|###4      | 41/118 [00:05<00:10,  7.41it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5996, step=501504:  35%|###4      | 41/118 [00:05<00:10,  7.41it/s]\u001b[A\n",
            "epoch=08, loss=0.5996, step=501504:  36%|###5      | 42/118 [00:05<00:10,  7.55it/s]\u001b[A\n",
            "epoch=08, loss=0.5785, step=502016:  36%|###5      | 42/118 [00:05<00:10,  7.55it/s]\u001b[A\n",
            "epoch=08, loss=0.5785, step=502016:  36%|###6      | 43/118 [00:05<00:09,  7.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5845, step=502528:  36%|###6      | 43/118 [00:05<00:09,  7.74it/s]\u001b[A\n",
            "epoch=08, loss=0.5845, step=502528:  37%|###7      | 44/118 [00:05<00:09,  7.84it/s]\u001b[A\n",
            "epoch=08, loss=0.5982, step=503040:  37%|###7      | 44/118 [00:05<00:09,  7.84it/s]\u001b[A\n",
            "epoch=08, loss=0.5982, step=503040:  38%|###8      | 45/118 [00:05<00:09,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5950, step=503552:  38%|###8      | 45/118 [00:06<00:09,  7.91it/s]\u001b[A\n",
            "epoch=08, loss=0.5950, step=503552:  39%|###8      | 46/118 [00:06<00:09,  7.95it/s]\u001b[A\n",
            "epoch=08, loss=0.5951, step=504064:  39%|###8      | 46/118 [00:06<00:09,  7.95it/s]\u001b[A\n",
            "epoch=08, loss=0.5951, step=504064:  40%|###9      | 47/118 [00:06<00:08,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6106, step=504576:  40%|###9      | 47/118 [00:06<00:08,  8.04it/s]\u001b[A\n",
            "epoch=08, loss=0.6106, step=504576:  41%|####      | 48/118 [00:06<00:08,  8.05it/s]\u001b[A\n",
            "epoch=08, loss=0.6006, step=505088:  41%|####      | 48/118 [00:06<00:08,  8.05it/s]\u001b[A\n",
            "epoch=08, loss=0.6006, step=505088:  42%|####1     | 49/118 [00:06<00:08,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5999, step=505600:  42%|####1     | 49/118 [00:06<00:08,  7.98it/s]\u001b[A\n",
            "epoch=08, loss=0.5999, step=505600:  42%|####2     | 50/118 [00:06<00:08,  7.84it/s]\u001b[A\n",
            "epoch=08, loss=0.5991, step=506112:  42%|####2     | 50/118 [00:06<00:08,  7.84it/s]\u001b[A\n",
            "epoch=08, loss=0.5991, step=506112:  43%|####3     | 51/118 [00:06<00:08,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6118, step=506624:  43%|####3     | 51/118 [00:06<00:08,  7.96it/s]\u001b[A\n",
            "epoch=08, loss=0.6118, step=506624:  44%|####4     | 52/118 [00:06<00:08,  8.04it/s]\u001b[A\n",
            "epoch=08, loss=0.6125, step=507136:  44%|####4     | 52/118 [00:06<00:08,  8.04it/s]\u001b[A\n",
            "epoch=08, loss=0.6125, step=507136:  45%|####4     | 53/118 [00:06<00:08,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6026, step=507648:  45%|####4     | 53/118 [00:07<00:08,  7.94it/s]\u001b[A\n",
            "epoch=08, loss=0.6026, step=507648:  46%|####5     | 54/118 [00:07<00:08,  7.95it/s]\u001b[A\n",
            "epoch=08, loss=0.6012, step=508160:  46%|####5     | 54/118 [00:07<00:08,  7.95it/s]\u001b[A\n",
            "epoch=08, loss=0.6012, step=508160:  47%|####6     | 55/118 [00:07<00:07,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5831, step=508672:  47%|####6     | 55/118 [00:07<00:07,  7.94it/s]\u001b[A\n",
            "epoch=08, loss=0.5831, step=508672:  47%|####7     | 56/118 [00:07<00:07,  7.93it/s]\u001b[A\n",
            "epoch=08, loss=0.6059, step=509184:  47%|####7     | 56/118 [00:07<00:07,  7.93it/s]\u001b[A\n",
            "epoch=08, loss=0.6059, step=509184:  48%|####8     | 57/118 [00:07<00:07,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5922, step=509696:  48%|####8     | 57/118 [00:07<00:07,  7.93it/s]\u001b[A\n",
            "epoch=08, loss=0.5922, step=509696:  49%|####9     | 58/118 [00:07<00:07,  7.88it/s]\u001b[A\n",
            "epoch=08, loss=0.5842, step=510208:  49%|####9     | 58/118 [00:07<00:07,  7.88it/s]\u001b[A\n",
            "epoch=08, loss=0.5842, step=510208:  50%|#####     | 59/118 [00:07<00:07,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6017, step=510720:  50%|#####     | 59/118 [00:07<00:07,  7.97it/s]\u001b[A\n",
            "epoch=08, loss=0.6017, step=510720:  51%|#####     | 60/118 [00:07<00:07,  7.96it/s]\u001b[A\n",
            "epoch=08, loss=0.6126, step=511232:  51%|#####     | 60/118 [00:07<00:07,  7.96it/s]\u001b[A\n",
            "epoch=08, loss=0.6126, step=511232:  52%|#####1    | 61/118 [00:07<00:07,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5807, step=511744:  52%|#####1    | 61/118 [00:08<00:07,  7.99it/s]\u001b[A\n",
            "epoch=08, loss=0.5807, step=511744:  53%|#####2    | 62/118 [00:08<00:06,  8.03it/s]\u001b[A\n",
            "epoch=08, loss=0.5979, step=512256:  53%|#####2    | 62/118 [00:08<00:06,  8.03it/s]\u001b[A\n",
            "epoch=08, loss=0.5979, step=512256:  53%|#####3    | 63/118 [00:08<00:06,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5872, step=512768:  53%|#####3    | 63/118 [00:08<00:06,  7.96it/s]\u001b[A\n",
            "epoch=08, loss=0.5872, step=512768:  54%|#####4    | 64/118 [00:08<00:06,  7.75it/s]\u001b[A\n",
            "epoch=08, loss=0.6045, step=513280:  54%|#####4    | 64/118 [00:08<00:06,  7.75it/s]\u001b[A\n",
            "epoch=08, loss=0.6045, step=513280:  55%|#####5    | 65/118 [00:08<00:06,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5994, step=513792:  55%|#####5    | 65/118 [00:08<00:06,  7.91it/s]\u001b[A\n",
            "epoch=08, loss=0.5994, step=513792:  56%|#####5    | 66/118 [00:08<00:06,  7.90it/s]\u001b[A\n",
            "epoch=08, loss=0.6110, step=514304:  56%|#####5    | 66/118 [00:08<00:06,  7.90it/s]\u001b[A\n",
            "epoch=08, loss=0.6110, step=514304:  57%|#####6    | 67/118 [00:08<00:06,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5896, step=514816:  57%|#####6    | 67/118 [00:08<00:06,  7.91it/s]\u001b[A\n",
            "epoch=08, loss=0.5896, step=514816:  58%|#####7    | 68/118 [00:08<00:06,  7.93it/s]\u001b[A\n",
            "epoch=08, loss=0.6132, step=515328:  58%|#####7    | 68/118 [00:08<00:06,  7.93it/s]\u001b[A\n",
            "epoch=08, loss=0.6132, step=515328:  58%|#####8    | 69/118 [00:08<00:06,  7.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6006, step=515840:  58%|#####8    | 69/118 [00:09<00:06,  7.20it/s]\u001b[A\n",
            "epoch=08, loss=0.6006, step=515840:  59%|#####9    | 70/118 [00:09<00:06,  7.35it/s]\u001b[A\n",
            "epoch=08, loss=0.5840, step=516352:  59%|#####9    | 70/118 [00:09<00:06,  7.35it/s]\u001b[A\n",
            "epoch=08, loss=0.5840, step=516352:  60%|######    | 71/118 [00:09<00:06,  7.48it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6045, step=516864:  60%|######    | 71/118 [00:09<00:06,  7.48it/s]\u001b[A\n",
            "epoch=08, loss=0.6045, step=516864:  61%|######1   | 72/118 [00:09<00:06,  7.59it/s]\u001b[A\n",
            "epoch=08, loss=0.5857, step=517376:  61%|######1   | 72/118 [00:09<00:06,  7.59it/s]\u001b[A\n",
            "epoch=08, loss=0.5857, step=517376:  62%|######1   | 73/118 [00:09<00:05,  7.64it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6044, step=517888:  62%|######1   | 73/118 [00:09<00:05,  7.64it/s]\u001b[A\n",
            "epoch=08, loss=0.6044, step=517888:  63%|######2   | 74/118 [00:09<00:05,  7.75it/s]\u001b[A\n",
            "epoch=08, loss=0.5938, step=518400:  63%|######2   | 74/118 [00:09<00:05,  7.75it/s]\u001b[A\n",
            "epoch=08, loss=0.5938, step=518400:  64%|######3   | 75/118 [00:09<00:05,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6041, step=518912:  64%|######3   | 75/118 [00:09<00:05,  7.93it/s]\u001b[A\n",
            "epoch=08, loss=0.6041, step=518912:  64%|######4   | 76/118 [00:09<00:05,  7.99it/s]\u001b[A\n",
            "epoch=08, loss=0.5817, step=519424:  64%|######4   | 76/118 [00:09<00:05,  7.99it/s]\u001b[A\n",
            "epoch=08, loss=0.5817, step=519424:  65%|######5   | 77/118 [00:09<00:05,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6022, step=519936:  65%|######5   | 77/118 [00:10<00:05,  7.93it/s]\u001b[A\n",
            "epoch=08, loss=0.6022, step=519936:  66%|######6   | 78/118 [00:10<00:04,  8.00it/s]\u001b[A\n",
            "epoch=08, loss=0.6045, step=520448:  66%|######6   | 78/118 [00:10<00:04,  8.00it/s]\u001b[A\n",
            "epoch=08, loss=0.6045, step=520448:  67%|######6   | 79/118 [00:10<00:04,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5991, step=520960:  67%|######6   | 79/118 [00:10<00:04,  7.97it/s]\u001b[A\n",
            "epoch=08, loss=0.5991, step=520960:  68%|######7   | 80/118 [00:10<00:04,  7.92it/s]\u001b[A\n",
            "epoch=08, loss=0.5978, step=521472:  68%|######7   | 80/118 [00:10<00:04,  7.92it/s]\u001b[A\n",
            "epoch=08, loss=0.5978, step=521472:  69%|######8   | 81/118 [00:10<00:04,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5982, step=521984:  69%|######8   | 81/118 [00:10<00:04,  8.03it/s]\u001b[A\n",
            "epoch=08, loss=0.5982, step=521984:  69%|######9   | 82/118 [00:10<00:04,  7.99it/s]\u001b[A\n",
            "epoch=08, loss=0.6092, step=522496:  69%|######9   | 82/118 [00:10<00:04,  7.99it/s]\u001b[A\n",
            "epoch=08, loss=0.6092, step=522496:  70%|#######   | 83/118 [00:10<00:04,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6061, step=523008:  70%|#######   | 83/118 [00:10<00:04,  7.97it/s]\u001b[A\n",
            "epoch=08, loss=0.6061, step=523008:  71%|#######1  | 84/118 [00:10<00:04,  7.90it/s]\u001b[A\n",
            "epoch=08, loss=0.5960, step=523520:  71%|#######1  | 84/118 [00:10<00:04,  7.90it/s]\u001b[A\n",
            "epoch=08, loss=0.5960, step=523520:  72%|#######2  | 85/118 [00:10<00:04,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5957, step=524032:  72%|#######2  | 85/118 [00:11<00:04,  8.02it/s]\u001b[A\n",
            "epoch=08, loss=0.5957, step=524032:  73%|#######2  | 86/118 [00:11<00:03,  8.07it/s]\u001b[A\n",
            "epoch=08, loss=0.6003, step=524544:  73%|#######2  | 86/118 [00:11<00:03,  8.07it/s]\u001b[A\n",
            "epoch=08, loss=0.6003, step=524544:  74%|#######3  | 87/118 [00:11<00:03,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5811, step=525056:  74%|#######3  | 87/118 [00:11<00:03,  8.11it/s]\u001b[A\n",
            "epoch=08, loss=0.5811, step=525056:  75%|#######4  | 88/118 [00:11<00:03,  7.80it/s]\u001b[A\n",
            "epoch=08, loss=0.5864, step=525568:  75%|#######4  | 88/118 [00:11<00:03,  7.80it/s]\u001b[A\n",
            "epoch=08, loss=0.5864, step=525568:  75%|#######5  | 89/118 [00:11<00:03,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5966, step=526080:  75%|#######5  | 89/118 [00:11<00:03,  7.95it/s]\u001b[A\n",
            "epoch=08, loss=0.5966, step=526080:  76%|#######6  | 90/118 [00:11<00:03,  7.90it/s]\u001b[A\n",
            "epoch=08, loss=0.5900, step=526592:  76%|#######6  | 90/118 [00:11<00:03,  7.90it/s]\u001b[A\n",
            "epoch=08, loss=0.5900, step=526592:  77%|#######7  | 91/118 [00:11<00:03,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5866, step=527104:  77%|#######7  | 91/118 [00:11<00:03,  8.04it/s]\u001b[A\n",
            "epoch=08, loss=0.5866, step=527104:  78%|#######7  | 92/118 [00:11<00:03,  8.02it/s]\u001b[A\n",
            "epoch=08, loss=0.5871, step=527616:  78%|#######7  | 92/118 [00:11<00:03,  8.02it/s]\u001b[A\n",
            "epoch=08, loss=0.5871, step=527616:  79%|#######8  | 93/118 [00:11<00:03,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5912, step=528128:  79%|#######8  | 93/118 [00:12<00:03,  8.02it/s]\u001b[A\n",
            "epoch=08, loss=0.5912, step=528128:  80%|#######9  | 94/118 [00:12<00:02,  8.03it/s]\u001b[A\n",
            "epoch=08, loss=0.6005, step=528640:  80%|#######9  | 94/118 [00:12<00:02,  8.03it/s]\u001b[A\n",
            "epoch=08, loss=0.6005, step=528640:  81%|########  | 95/118 [00:12<00:02,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5843, step=529152:  81%|########  | 95/118 [00:12<00:02,  7.96it/s]\u001b[A\n",
            "epoch=08, loss=0.5843, step=529152:  81%|########1 | 96/118 [00:12<00:02,  7.82it/s]\u001b[A\n",
            "epoch=08, loss=0.5943, step=529664:  81%|########1 | 96/118 [00:12<00:02,  7.82it/s]\u001b[A\n",
            "epoch=08, loss=0.5943, step=529664:  82%|########2 | 97/118 [00:12<00:02,  7.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5893, step=530176:  82%|########2 | 97/118 [00:12<00:02,  7.68it/s]\u001b[A\n",
            "epoch=08, loss=0.5893, step=530176:  83%|########3 | 98/118 [00:12<00:02,  7.74it/s]\u001b[A\n",
            "epoch=08, loss=0.5979, step=530688:  83%|########3 | 98/118 [00:12<00:02,  7.74it/s]\u001b[A\n",
            "epoch=08, loss=0.5979, step=530688:  84%|########3 | 99/118 [00:12<00:02,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5909, step=531200:  84%|########3 | 99/118 [00:12<00:02,  7.87it/s]\u001b[A\n",
            "epoch=08, loss=0.5909, step=531200:  85%|########4 | 100/118 [00:12<00:02,  7.73it/s]\u001b[A\n",
            "epoch=08, loss=0.5917, step=531712:  85%|########4 | 100/118 [00:12<00:02,  7.73it/s]\u001b[A\n",
            "epoch=08, loss=0.5917, step=531712:  86%|########5 | 101/118 [00:12<00:02,  7.65it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5826, step=532224:  86%|########5 | 101/118 [00:13<00:02,  7.65it/s]\u001b[A\n",
            "epoch=08, loss=0.5826, step=532224:  86%|########6 | 102/118 [00:13<00:02,  7.69it/s]\u001b[A\n",
            "epoch=08, loss=0.5922, step=532736:  86%|########6 | 102/118 [00:13<00:02,  7.69it/s]\u001b[A\n",
            "epoch=08, loss=0.5922, step=532736:  87%|########7 | 103/118 [00:13<00:01,  7.62it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5849, step=533248:  87%|########7 | 103/118 [00:13<00:01,  7.62it/s]\u001b[A\n",
            "epoch=08, loss=0.5849, step=533248:  88%|########8 | 104/118 [00:13<00:01,  7.57it/s]\u001b[A\n",
            "epoch=08, loss=0.5847, step=533760:  88%|########8 | 104/118 [00:13<00:01,  7.57it/s]\u001b[A\n",
            "epoch=08, loss=0.5847, step=533760:  89%|########8 | 105/118 [00:13<00:01,  7.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5860, step=534272:  89%|########8 | 105/118 [00:13<00:01,  7.68it/s]\u001b[A\n",
            "epoch=08, loss=0.5860, step=534272:  90%|########9 | 106/118 [00:13<00:01,  7.78it/s]\u001b[A\n",
            "epoch=08, loss=0.5934, step=534784:  90%|########9 | 106/118 [00:13<00:01,  7.78it/s]\u001b[A\n",
            "epoch=08, loss=0.5934, step=534784:  91%|######### | 107/118 [00:13<00:01,  7.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5925, step=535296:  91%|######### | 107/118 [00:13<00:01,  7.78it/s]\u001b[A\n",
            "epoch=08, loss=0.5925, step=535296:  92%|#########1| 108/118 [00:13<00:01,  7.78it/s]\u001b[A\n",
            "epoch=08, loss=0.5988, step=535808:  92%|#########1| 108/118 [00:14<00:01,  7.78it/s]\u001b[A\n",
            "epoch=08, loss=0.5988, step=535808:  92%|#########2| 109/118 [00:14<00:01,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.5890, step=536320:  92%|#########2| 109/118 [00:14<00:01,  7.83it/s]\u001b[A\n",
            "epoch=08, loss=0.5890, step=536320:  93%|#########3| 110/118 [00:14<00:01,  7.92it/s]\u001b[A\n",
            "epoch=08, loss=0.5859, step=536832:  93%|#########3| 110/118 [00:14<00:01,  7.92it/s]\u001b[A\n",
            "epoch=08, loss=0.5859, step=536832:  94%|#########4| 111/118 [00:14<00:00,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6056, step=537344:  94%|#########4| 111/118 [00:14<00:00,  7.97it/s]\u001b[A\n",
            "epoch=08, loss=0.6056, step=537344:  95%|#########4| 112/118 [00:14<00:00,  8.00it/s]\u001b[A\n",
            "epoch=08, loss=0.6034, step=537856:  95%|#########4| 112/118 [00:14<00:00,  8.00it/s]\u001b[A\n",
            "epoch=08, loss=0.6034, step=537856:  96%|#########5| 113/118 [00:14<00:00,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6007, step=538368:  96%|#########5| 113/118 [00:14<00:00,  8.06it/s]\u001b[A\n",
            "epoch=08, loss=0.6007, step=538368:  97%|#########6| 114/118 [00:14<00:00,  8.05it/s]\u001b[A\n",
            "epoch=08, loss=0.5951, step=538880:  97%|#########6| 114/118 [00:14<00:00,  8.05it/s]\u001b[A\n",
            "epoch=08, loss=0.5951, step=538880:  97%|#########7| 115/118 [00:14<00:00,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=08, loss=0.6323, step=539392:  97%|#########7| 115/118 [00:14<00:00,  7.98it/s]\u001b[A\n",
            "epoch=08, loss=0.6323, step=539392:  98%|#########8| 116/118 [00:14<00:00,  7.83it/s]\u001b[A\n",
            "epoch=08, loss=0.6124, step=539904:  98%|#########8| 116/118 [00:15<00:00,  7.83it/s]\u001b[A\n",
            "epoch=08, loss=0.6124, step=539904:  99%|#########9| 117/118 [00:15<00:00,  7.80it/s]\u001b[A\n",
            "epoch=08, loss=0.5663, step=540000:  99%|#########9| 117/118 [00:15<00:00,  7.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d52eb174-d23d-4757-be13-2a9a41b4e1ec\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d52eb174-d23d-4757-be13-2a9a41b4e1ec\")) {                    Plotly.newPlot(                        \"d52eb174-d23d-4757-be13-2a9a41b4e1ec\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAdFklEQVR4Xu2ZabguV1Xn\\u002f2utvavqnc5877lzAkkIJsQkNB3zmBA7EDFGwozMiKJo09ghSRNGW9REwCFoQ4cQm5bJANqNmhhBGYxBOoiAhEYNEGLuzR3P+J53rtp7r9Ufzr3nnvPeq\\u002fL0w4emH39fqvb\\u002fX\\u002ft5q1btvdfab1GOf+V08Ljwr6zzPRuYcx785rj0XeV7NTDv\\u002fOzeB8a17yrjgXniHYM7Lh7T\\u002ft9j\\u002fi9+dubvfm5c\\u002fa4yFpgL73mJveSerdpm3jAYPXlcAwC0dvzk60+3jp9z3qtGg8FgMPhYNm6d5Mr9jxuXIDMzM2+6+fd3fmDUfvO4d85tl+AXXrc8Ln+nND7\\u002f8Bnj2im4La1\\u002f+5FJ61azl36l2iJv8LLXKWxcBHDmjT9wPjB\\u002fw7h+3suew7vUAODp73pd54R8+ewfn7wGwJO+sqWJvdmll00+GwAO3vrM7tc+t9UFZq8GDv3luPodsXMbVn\\u002foid9cGddPYXNg6hf97k7goVs\\u002f9NlfescmeRP7TjcocO7Pv6igR3uPf+57vzHm\\u002fMrVJ89f+v77T5xecfaWwPCZe2lz+6JPTB4\\u002f07cOPnZkdXyVPef9hBfcPSZu4rXZuS\\u002fCN05dEJ7w6n04ex9+\\u002ffvo8KnD95IXX34e3nDksju\\u002fuN7eHJh3vwAALm587orzN6mbeMqr8Y1nL4yJk7c8rwU89PTsgbnZMQufuRoLHyDDpVvn30u\\u002fsKW546fu3BLRAyuTAPDFtR+q7tysn+DFez\\u002f5msPj4gmefP6Tn0kwnP3Vi8atH3oFUN555etgHzxlGj7\\u002fN+bovrm3gWZfti5sCswTf5Rw3yfeduSB9r\\u002fb8gI3+MHfmcStB8bVZ\\u002fwkgIevOXj2uAHgjrsQjwKY+PIu3HVyvowtbLfjoS3tlTde89Vb8cCP9c97zRb9OPdeuP+m08dlxwcfg8kGfeViAFwfd99yAz609FuLF949t\\u002fiHY5Z70m31z73tf+W\\u002fdxVO3OXJwFx4z4T92cuf\\u002fNbfXfya\\u002fujFf7uhn+RlO3Hf742LeC6w\\u002f0tvPohzxw0A8eD68YengUPlCfWC7SfO1pnAZ7cKd93b\\u002ff5X\\u002fHYff\\u002f\\u002fqrToA4NpL7H8Ox0UAwFNu2wsAFy3P7rxjDx4ctxu1\\u002fb94FGfdtG1wy2jMetHt+MxLO3jeVTj44ePSRmDOuX5y6eiHe5\\u002f4BADUrnvFCf0kcz+h7bePi8C\\u002ff+WnH14AMPa0m\\u002fnxn6oBv7zRvLq2yQPmz8ShLQLQwRpe8fs6pgIApi4D2ocAvGYP3rDVunEvUL75b76J5dfswf6f2moCf\\u002fgjj7\\u002f5uolf+9GVd7x3zHnrTfbet3aANwA3Lh7XTgQmf\\u002fvV3Vd+pThx6d4TJyc546PAbfeOq8CRm9ePP7BVPskLb3qsBx4IG8I5+IdNNt42\\u002f63e5jYA4OaLr3jKp8dFAEgXs\\u002f4VcJ29eh9e+9jNU+qqS4BHf\\u002fJ+ANgN3L20yQIAPPDXj7\\u002fyqb+2D7fcNma86abqU28eorhqL71tY00\\u002fEZiLr8bzTkmLW3jaBfiL\\u002fzouHuc\\u002fNMiegPv\\u002felw\\u002f48VPAS4zoPOWT24e\\u002fl\\u002faOJt42ouuwq+2T1rH6b\\u002f6C7f95VduP7U2ePLlemAZF\\u002f7g09E\\u002f9LiPvGzTkvfaOu6\\u002f5X4A0z9yOe7\\u002f5EnjOGUHOz9K9v67xvSpn7VPPR846\\u002f1PxMdv3VBPBObtdN\\u002fJuLCeuvo+42Z8\\u002fqfXxlUAqJ\\u002f3pqvBiiOvSmPOE\\u002f7HiZH3+fdtMWYAfD9fuTt7IQ\\u002f\\u002fpnSnW9Ae\\u002fpk7XvKSxoePjsmtM3HkzofOuf7apc\\u002f8duvPTqR1AMD7ZtdecRQAfuYX8fcvHe8I4AAAfPKdx9e9DbI53LD95T92ftPsI\\u002f0N9XhgrrnQNtW7al872VjnjI8C\\u002f3hsXAXgL\\u002frIzuGRLzytDnnWu0+pCwkAK3DN1Zve4MjedRNwAcXBP3zgy59b+HZtvPwBAPzxt99x5S\\u002fve\\u002ftY\\u002fvnBX8f7fnX+7Vd3P\\u002f76s9\\u002fdvXdzjvzD47nmx96E+N9OExe5jIBPPGdcRrW47RsGHO7sXNoUg+OBqWULf3BCyt+Ce99yonGC\\u002f6TAb4yLALKnfQw333v\\u002fzCfPx7ZfefSujcwDAPj60178qRGAV2zNLv\\u002fxwKUAHr37wb8GgFdu+8ct7gZff8k1v\\u002fPTZ1+zVbwA+FV89BI873OXfgbvGlt91\\u002fkDww1bB+g6H3qW4XR1e\\u002fvHPz7z8N0fWv3gzo0QYFNWKk\\u002fEOH\\u002fDDQd\\u002fa3w1vPAq4O7xChSA\\u002f4Ub8OfvaW\\u002f7oydUv3n+te\\u002f\\u002f7G+28dVN9oH1LHbzWNrdEuErMV5VnKB95+3u8ivu26JN0t248Ax6\\u002fefOeT+9\\u002fl1brOP8MitOs1ru\\u002fIln29\\u002f+75dvG9cBfHEPAFx+hW5+QxuBOTGKLrz++Xe\\u002f8IS4wZ9M44s\\u002fMy4C8ovX93\\u002fh99tPuvWih37+LycufeHT78Gjjx+\\u002fCPjhcWEr\\u002f0R1f8Gzn+TwD381ppoBak\\u002f4VvHIUzb2XpvJLlK7cWvBCAC48j\\u002fjre+59uVb8uEWamqnGTFE194IALjuDZMfeeUm\\u002fziziveOjyIAr7x+8JpPX\\u002fLyq4tbPngQnT\\u002f\\u002f8xe8EK\\u002fbMP1V965nop843Rz8l3jcq5+xA0hHx4qZe2649tILWngpLd1y2uq3\\u002fqKn4mMfPbUCuuJWPPez82\\u002fG\\u002fnFjg09tbR4PjNmOWz+w\\u002fAMvvmDPgU\\u002fdsfUKALiDgY0t4CbeBLn+LWcBv\\u002fLr6wnpYx876V32+qeeexDAzI+8o47h6WtVAACd9YVxCTte8HNnAPjyO\\u002f5kzKgG9c8agO7HT83HAFq3PQeve8+pccFTJ+\\u002f7U3\\u002fNBJ2ySdpgbFhvTCX52Wd1zwa+cO\\u002fJCnWDC5+q1e3jm0cAOLYt\\u002f3588q\\u002fu2j+eqAG883zc2AXw1IsN993xz\\u002fxJYGNbJ2D++955LoAvvvPuUx7xKy+\\u002f7grgQ3\\u002f31dMsIwB2PwcPn7bYMjP\\u002fjN9c\\u002fd3xovckj93aPB6YL3zpSdgxj+U\\u002fWJ9QY0zO4\\u002fBpE8BV1168+IHVU5L0CV61flj40xtHW42tXPqhLc2Zd1\\u002f4GAD3\\u002f\\u002fanTjfM1vcs\\u002fwTnXodvPWNcBABsw9I9l+NVm\\u002fLxOJ\\u002fnLW\\u002fheGAOveCn3wi8+3dOs2r9c3TvPO3\\u002fAgCAV\\u002f3cywDg4cHn\\u002f\\u002fvXx70tbC0mL7n+SbsBDN\\u002f9ayeLre+YNz4f79lc2pzkQTyHVm4f26xu4esPPeaxJzZKODmVjt5880lxnG\\u002fef9m49C\\u002fz1eu+9Nbpuz7zJ6cptbbwZ8\\u002fd0nzGM4EH70m\\u002f1d6ifmecN4H3\\u002fcW4uM6Hszd++Z7\\u002fMq5u4R23\\u002f9L1J5MW5Zus73Vuee2BZ56m2PoOmfi9p\\u002fzRqzaG6SkL3\\u002fcyn8ZN\\u002f\\u002fdxQecldzxr30br\\u002f6sR893EMcwyKivxMB8tiolYhI+csiDqlAxqRkQqBAUpkamyL8UAcGRAiViNTYySiXqrRBnGiUEAGVRACjVRj1IMrGxslkAuGYhUlDg5VKIEcGKQEWDGIDveb+QMZBzZoAxJxmBQAqvXxDBWSkxIBAaMTMUIySU2MeDkM5gRlAiahNP6XSqN91OhlhIbAYHMY5ioXvogkoBkzhzIiIIkEaUkcAoylaGosjozGCUxUmdMEd4SjFUhySmgbGKirMKBnAaAVYmMsX5nMGVOAJGBGKrKKmYAqxirKHMgZ4GMVcHqzEgpiZI5IyR4MxipGpMoBKoQSmIAkakxKWkiIZhQoOQkcRKIwUhlxJaIRCFmBj61XyYcHChJfRQ5cTZwyTJjiQQzoUSEIERQKDkiVlJLkMpAZOBETOQEQhEJkZMLFgkEEFQcwTuwJSiNRDkigiBQBojMlNUnjhAyjhaJABCpCMg5iCVTKkU5UASBzVhBxMIQihQprf8er7\\u002fAZEIwgwk4KoFJEVlIIQgMNoNBmKCslEDBhMiIVIWhBnPGUcmYFdFpLflUCGSk3qQRJgQhcSAoR1YVgpiYGVQdikw0hiSqYFFSIu\\u002fYZy7PgHJYBQMZgeFVweTF+yzz3jiMwtArGQHMRmRGTDA4yknAANRgxE4VzF6cy7LMG1ejMHS23s8lNiMn5L3knmg0qhKO\\u002fx5AbOSMFErKIPaJjEBGUBM2B8AAVQefsaWorEpGIDYSXu8nRuTW79LI+UgGaErSkMm5Zkvy9nK73et4ZcCcA4NACkFda3mWVYOuulIUMGWwz\\u002fKJialC2NprC+VQfeIEB4OQk7w22ZorPEu\\u002ffayzFtVICbBEMFJvTtg5SikhKgeAZb2fy4vJ5mzNM\\u002fXax3wnmZIRm0UGvMtazVYuYu3ucijNJ04gmBIbKasTODAzqwY1MBROICBDEkZNC59lYdQvpXJmMCUyKKsTK8DEpBZMicjFGkGGnhr51OyuMx87XRsePfrQw49alVDVweojmyij7lqNuVp9NDiiHKBqDCKf583pnTPzWd1GR4\\u002fxAkIpSZDYjF2eTczs3La7mOJ0bKl2IPaCU0kKsBGL8y6rTVhO2guDKgRTlcQG9nk2MbNzblc+hXhsMT+YBkOnrImNzOd5fXJ+ajYrMFpYkGVOpSRGUgErlMkVjcK5QjRYJ45KRCJizSInNuGGa9Rmi6IcLbAESmrKRAZjcrV6XSRnDdaJZRkTHCUmp+Lrc\\u002fv27TpnV63Z23XIx37lOi4zgSqZafJ5a3p2e72O\\u002fkIuTsnYiCDiJ2fm9s3N+iyNQMOSBinBlIiNmVuz2\\u002fbNzxc1JHbDQRUqAwwqYuR9o9aqTTZywDqra92KVQlMYswyMbtt7\\u002fz2vLAIHgxCrAxmBAG7bGJ6ds\\u002f0jM\\u002fSyEmMvZEFwMyMway51OuzE3XnfNXv+gFSABlDE5lB89rU1PRsrY7+UnfklYijgYhYC6nX5yZq4lzZ77ohpQh2gKLybnp2fn7vvhbFBWdzjxvpaMklJdZEpKY+a07N790+WS9Xuq1OClBSJnBRb7Sm8mJEfeqPKsk0qZqBYFCf5XnDZT3ruW7V5ZyMIhvgmJjzxvTU7OSsy2Jt0CsoaCWBARjMZ3nR8FkfPemWPcqQEFmNmIiLxuT0XLOlPEBplGWmampGAsDM15pzO3cVTW1FbS8dWY2hTABSIlIgr09tn9s1PVULq2E0TBEKEhApskZzbufuvBGbIbUXD7djKAFHXIkras363Pw0lhe6lZueqO06PNlGxc6ckkI9N+fnt8\\u002fPNSGrmYmZgkiJGSLsqctLHYq+MqUYjcxIDaSUIrRHSz2uipGSkAGJKDGzq0\\u002fNbZueqseYtKn1gmNKdjznKKWI1KOlLlfZQMFQQAmJRdhnWeEGbq0LcwqjUBnMJHliq\\u002fupuR1nzJmr8gwSVhw0mTn1IGN12eSu+em5qQn4XgExVSOJHiT1bHpuxxmzJsPMg8sVZymZOoAzhNzm5nfX+t2jnTW\\u002f\\u002fcxdM49fWOxTWcSgYCOtt1pF7hGs32v3UoySNDkmizGlPsmoG7ieJ5hVSuqhYmyl1HXUD6lbwddSSM4SkgsghFx8bWJipggrPZtp5TVK0UCkKiZWjWpx2K1iNyArQlBRRXJBhWGqhiHTsFtJq4BYqgzmwVBiJ\\u002fnEjrO3ZyuLw+n5OhyllDiBLSYhELdmpuse1cCHUXeQUpJoDFN2rpjaedZ2t3J0ML29pg5JVRROY2Ig37V7x\\u002fRwcfnYoZA6zPNFXogyGXky0sznufaGeZBOu90dDJOSGdiU1Iitv9aNjRrn7CgbGhLMyJSMfeFipxsyCX5IvmgDCmUIiOAk9bpHulnREmgZiUlhxmps7DKpOt2Y++QHJHkXZDBiGJkapVG7E5p1KdjBBSOFGokZwRUUB\\u002fvXQpas6rVXR8lgpOQBMpcXWVxzSRuDTrvdHcQEMyM2I\\u002fIFld1HVoOfRRistUeqgIOworXj3DP2pt7i0v61DneKbW7Xnm8nS5WxQU04K+KwVWv21g4cOLaqSgSFJZClGKNpVqf6dBG6BWIihpmZqSPvndMJSjyF5OuLUZMIDDASY8IoHlkeTCFzXGpUIlOzZOYgIoImzM1Q8DWLqs5gqmQUy1BJgM+aE61YZIiJoWZCyVnM603pH9rfq7u6lMe6\\u002fQGMtAIZKbwrarHKKdfekUcPrsQIIjUhdYh50UD\\u002f0Ue6dam7sNgfjAykDsTKE9u3zfvlRw4eG40cssoociOPfWVjpeQ8V6VrbmvGY0uH10ZqZpyPksEndvmEz0LDNad9r55xHsgscYISfL01WUNJyCdDSGWW5xo1kSbH0WKKXBo3tk+1RqEcRVHiRAolk1prsobKU20yjcqBzzMkU9YoLjFLwzlf9xOzjW7Nm08AkigpkJGEUTWQ2t75rFxYXF7laJBEBjVwhpJldnYiLa0caPcjVCmrlBQpA4eyHFCxZz6vlpdX1zgB7ApT76Z27M06Bx9Y6pvxsE4hOB8DvCgSB1bHLjUes08OLx9eLoNIIIsmTKqUCj\\u002fltCpq01QfrDb6eYAyGBws4zwv4LwvGilZKIragMDGDLUYY\\u002fTSyGo7z24ei5VCYYlAkGgeeV5nrbJaM1VxVMtrIwKpiFiymMmkS1XR2M61dl4f+GTGbACEhXU4osmZM870f39otesiOLAkI0kC5yRO7j6z9sja\\u002foVeJZTIIhsIQkJxMLSpqTMfUzx4pN1zicjIxQxEjRnJD339YNuK5Iu81Wr0LLkyj47JmBgaZnedtWtNF7t9g0VSSqQqxJy7rKbS9FnutNmqNUqJzAkGLvJGXTCyQljz0CrrNe+iuUoJRkKBcqrR5M4dirIip6acCEaUZfWakwoNEcu0OVGv92IyV6mBiDxnDaPJvGhIqteLZpsTUwLDjLmK2pgo5nZvP7p6ZHmYhBIncwQjIovVth3n7C3dYqcdkQyGBJCZMZUJjWY+u3fH4tqxlVEUKCWHARe1vTv2HvnWIwvdqT4sQ57HbrckGXhJzJwy4+bUnqmss395DcqiSuubYouwvGb1SodVavpmMydi1vX6D45q6EoZzLJGo17LkBIQjYlTSiMFZ05mZluVJceiZsYwNjLmmgx9qYqsXmt2M1IFIsCIbJY3qJ4Qw6ieN1s5MZkamIQyqka9urUmdu2uFv\\u002fxyAA5JTUGKVNmXlFr7phudA4srKiys8QRYAJnVJa9Gk00d+3B2qNH+5ZRgrGLllk92x5H7aVho2JCvmPP9kFveRCiqLGyQKGYbKTR0vLacIS8IjGCmDIT56apO6Kgk9rKi1qzF5SgUHM+b7Gl3khSym3a1V3mJCYSNnYWY3eYqadRf3K1PyiZ1YwMpOpc3iDT4ZBTLGZarp4VzqXIBGUGuZjSoIJSCuKyWmugylEB85TKTi7btYr9cml1rc8hh6oSszpR0yo0anG02l7tjywrhRMBMBKksp3xbKrSUJfbq32qclNTJ5KmWrN1JqbSJurU2HHuXll4ZGWYuFdXECtB6k2i0bGFwSAx1CQhsrJYcinFULNqZQRtUJZ7kqApEbFR4YkCNK2lco58lnthGCITkrIb9hZiZnVrdPrd0iywspGBGbkAUTR2QrVt2knuWUwtMbMFX4VyULPBWplz7nyemSRVVTbRxAPxIpaXo97Bhbb5JInBUUGsnOBzTWF5udcPYDMyUo4M1igDWSELu8uyPHisrT6xSnLOxFS4URTNxnbxk82ZM86etUNHjg3hGARiEtfIixp3UrczlCTw0ORKVkbuhKqBK\\u002ftlcr6RjwI88\\u002frnGSvyepOBFBmTk3PTVVQjH2FsbGyh6ja6glSMRr213jBRSqQwsNbyoqCEsjRqtmYmRxFETsxIxTI2HfTyOByYkIdW6pkIxmAwE8WUwrBfDlY6w5S8WCIyIhA75+tZnqEj3c6AEoujpFKu9zNUKVajXjVc6\\u002fRDELFIBIcUfChHzT3fZ4fRak3u3DPd3v+NAx3lYMzKrL4+v31HvdtaWxzFUBBgrAY2yjKhmBzVYsdNzbckIZUpxQCCZXmWU97Uen9Vmnt3un5VRSjM2JRNLIXVkGUZbLjSq5ASUVQms6zwDm6Ki9qyNPfNuxhDMDVVD3jPqCqtHAXXnM41QcuUYiAHMJFxzkhc16VDR\\u002fuZ5WBSTkLKbL62bXauNpzpHuuVVUHExgoSgEGGzFJAXZePHuo4ziFJWR201uv0Vnc1\\u002f81Ul6ao2UL\\u002fwP6HF1ZhqJGxGrnGZKNZrw9WV9qJTUgVZhRFiJzPcgjcjJ+oobOw0B0GZVYVUXNUn2z5sr9d69Oue\\u002fjoUnuYAE5YnypJjYtaHcPuWkwkiRjJnJh5qU80iyqbRH1GukeOrXRHCcSJhUm8k6jJGrVJl9aWl\\u002ftlNBZVEqVYsK8VE1MOndV+zMyZiSYjEzWSxkSz1WiM2kvLQVRYDWZQYuWYsyvy1pTj7movZCqmksxcpsbDb87Wztu7exQJsf\\u002fot7\\u002f1yNGBBIL6BNYsb07NzDRkZWExJiM1AUCSyDQlIFhVNJuFC2tHFhZXe8GigmGURtUwNmoIJVej\\u002fqHFR5d6UaMBZEIgdmJFcyYPw85wqDGBgzFglEapirVavVm5UI4OLx5Y6kaNarS+VaIY+4280SzKeGSx3R1ERAU0icF8ozm1bTZrHz3aR3LJBQMrR2P1vj41M9vK2scWyqhkSRJAokoCg6vXJ7fN1jpLR3uITiUABJdgFJe+0azOKcTpytKhB799sLNWsSRFIgZUiYrMhe5Sb8hIYCOTaElUuRp2fQ2Js2q4OlhePtIbaSLWJIrUX2xk+SSZVe3u2rHlhW5P1WDqYJEtIBa+RtrvLK9Wydii0xS9WhquNPLaBBuV3X53YeVop5cSyJKYGcW+7zrJJPa7g6XlxUG0JJRUmJQospuo51VnbbFKBFJVUagQYEZUq3ntLXV6JAly\\u002fBkcUyJEdq1aEbprC6NAgJmKJWd58J3R0pGzztheoHPs2OGD7WEgDhQdMcEoZxvFYegdOLymZKwAOFlc34D2NVSLU3Wx4WDQ7nUGIbESmOCqtapaWW5NIQxW1tbWRsMqKSmRMzZhcEKAxU5cXR0FQwqUyASQ2I+x025OShq1O932cDBa7yeJHLQ00\\u002f50q+yF4XC10x2ExBEQQInhqciysHbsyKBMICWVtP7hhjK2UksdPHqkvV4XABIRHaBM8Ch8FvsLRwelAqZJEqkLWV5iRF87ZBOa9WLZLtmnukLzEFGoc5bauS2Ug4MLgyQuipkxk09JDCHFQdf73GmwMgzX78eUVZSqVK4e8Z7TsAyVhsTESpqcqSMb+ZRMQ437YaUziElVyEiVlasU2se8FxtVsYohEHEiTU4FiJpGpV+qZwg0KvtlMFIyUwdmi6PeSjbk1WNHRqWpUlQxpZjDO6S1Gq2EwcGjnUQSxNSI1ScHJguj\\u002foqvfGf56HCUEiMaIRHV2HKFVS44J7E0CRnngYY5WSBHLMSNiRzD0B4F5MbGqlySmmD9T\\u002fUoYuJUVINFIQoWhY1BlDh6UaXkkq1\\u002fLEoaRThRchCfF0XGMfTLkUYiqBqxMYgTR8dmnJyqURKs9yMF+0RJHDlnklKlgYmCJsdsHLnZnGowrw66cZTM2IiCMhyTMLVaNR6FlVFpXsVYjUoyMCsHadSnGiLdYS8MooJAFJSpEGaqsgQBBTFf+WRMVUAtwBw5kNMGh6oaGmXiAhuAgMRGRkQuKEw9GWsUM3Ya1z9AkpFEgykbQ1VMiJNBxQgAiJldLkihCmYAIUkUIyOQRIOuf5dTMSY53s+IyEU1wLORRlYjp0ESA8TqpF5znDpVhQhjIuVISsJC5LThUlX1FRn5wDAgUCKASB3Xap6tF0oLUOb1nSDVVVkzFzK4jrBLACoyaOaHxYgFUoFYAmnlWFgh0SWDwsXEEJgaGxmZCpIYyAwZgoo5SjCJbGRp\\u002fRMbyDRPqgIDGwEEjkYKVuIEOIpJzEHNJG30MwKZ5hYTQwxqRACpClTUWIEsKkQCefKWUuTElJjMWTKTRExcEbGLSMGRsBJHHw0KKIQDO\\u002fKWLLASJSYTJDP5PyPyeuDf3spIAAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d52eb174-d23d-4757-be13-2a9a41b4e1ec');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=08, loss=0.5663, step=540000: 100%|##########| 118/118 [00:15<00:00,  7.82it/s]\n",
            "\n",
            "  0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=09, loss=0.5962, step=540512:   0%|          | 0/118 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=09, loss=0.5962, step=540512:   1%|          | 1/118 [00:00<00:15,  7.34it/s]\u001b[A\n",
            "epoch=09, loss=0.5788, step=541024:   1%|          | 1/118 [00:00<00:15,  7.34it/s]\u001b[A\n",
            "epoch=09, loss=0.5788, step=541024:   2%|1         | 2/118 [00:00<00:15,  7.61it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6062, step=541536:   2%|1         | 2/118 [00:00<00:15,  7.61it/s]\u001b[A\n",
            "epoch=09, loss=0.6062, step=541536:   3%|2         | 3/118 [00:00<00:14,  7.86it/s]\u001b[A\n",
            "epoch=09, loss=0.6050, step=542048:   3%|2         | 3/118 [00:00<00:14,  7.86it/s]\u001b[A\n",
            "epoch=09, loss=0.6050, step=542048:   3%|3         | 4/118 [00:00<00:14,  7.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5863, step=542560:   3%|3         | 4/118 [00:00<00:14,  7.95it/s]\u001b[A\n",
            "epoch=09, loss=0.5863, step=542560:   4%|4         | 5/118 [00:00<00:14,  8.05it/s]\u001b[A\n",
            "epoch=09, loss=0.5820, step=543072:   4%|4         | 5/118 [00:00<00:14,  8.05it/s]\u001b[A\n",
            "epoch=09, loss=0.5820, step=543072:   5%|5         | 6/118 [00:00<00:13,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5932, step=543584:   5%|5         | 6/118 [00:00<00:13,  8.12it/s]\u001b[A\n",
            "epoch=09, loss=0.5932, step=543584:   6%|5         | 7/118 [00:00<00:13,  8.13it/s]\u001b[A\n",
            "epoch=09, loss=0.5924, step=544096:   6%|5         | 7/118 [00:01<00:13,  8.13it/s]\u001b[A\n",
            "epoch=09, loss=0.5924, step=544096:   7%|6         | 8/118 [00:01<00:13,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5911, step=544608:   7%|6         | 8/118 [00:01<00:13,  7.98it/s]\u001b[A\n",
            "epoch=09, loss=0.5911, step=544608:   8%|7         | 9/118 [00:01<00:14,  7.75it/s]\u001b[A\n",
            "epoch=09, loss=0.6084, step=545120:   8%|7         | 9/118 [00:01<00:14,  7.75it/s]\u001b[A\n",
            "epoch=09, loss=0.6084, step=545120:   8%|8         | 10/118 [00:01<00:14,  7.66it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5905, step=545632:   8%|8         | 10/118 [00:01<00:14,  7.66it/s]\u001b[A\n",
            "epoch=09, loss=0.5905, step=545632:   9%|9         | 11/118 [00:01<00:13,  7.79it/s]\u001b[A\n",
            "epoch=09, loss=0.5897, step=546144:   9%|9         | 11/118 [00:01<00:13,  7.79it/s]\u001b[A\n",
            "epoch=09, loss=0.5897, step=546144:  10%|#         | 12/118 [00:01<00:13,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5934, step=546656:  10%|#         | 12/118 [00:01<00:13,  7.87it/s]\u001b[A\n",
            "epoch=09, loss=0.5934, step=546656:  11%|#1        | 13/118 [00:01<00:13,  7.97it/s]\u001b[A\n",
            "epoch=09, loss=0.5978, step=547168:  11%|#1        | 13/118 [00:01<00:13,  7.97it/s]\u001b[A\n",
            "epoch=09, loss=0.5978, step=547168:  12%|#1        | 14/118 [00:01<00:13,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5855, step=547680:  12%|#1        | 14/118 [00:01<00:13,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5855, step=547680:  13%|#2        | 15/118 [00:01<00:12,  7.99it/s]\u001b[A\n",
            "epoch=09, loss=0.6000, step=548192:  13%|#2        | 15/118 [00:02<00:12,  7.99it/s]\u001b[A\n",
            "epoch=09, loss=0.6000, step=548192:  14%|#3        | 16/118 [00:02<00:12,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6012, step=548704:  14%|#3        | 16/118 [00:02<00:12,  7.94it/s]\u001b[A\n",
            "epoch=09, loss=0.6012, step=548704:  14%|#4        | 17/118 [00:02<00:12,  8.00it/s]\u001b[A\n",
            "epoch=09, loss=0.5986, step=549216:  14%|#4        | 17/118 [00:02<00:12,  8.00it/s]\u001b[A\n",
            "epoch=09, loss=0.5986, step=549216:  15%|#5        | 18/118 [00:02<00:12,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5984, step=549728:  15%|#5        | 18/118 [00:02<00:12,  8.10it/s]\u001b[A\n",
            "epoch=09, loss=0.5984, step=549728:  16%|#6        | 19/118 [00:02<00:12,  8.01it/s]\u001b[A\n",
            "epoch=09, loss=0.5869, step=550240:  16%|#6        | 19/118 [00:02<00:12,  8.01it/s]\u001b[A\n",
            "epoch=09, loss=0.5869, step=550240:  17%|#6        | 20/118 [00:02<00:12,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5961, step=550752:  17%|#6        | 20/118 [00:02<00:12,  7.97it/s]\u001b[A\n",
            "epoch=09, loss=0.5961, step=550752:  18%|#7        | 21/118 [00:02<00:12,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.5921, step=551264:  18%|#7        | 21/118 [00:02<00:12,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.5921, step=551264:  19%|#8        | 22/118 [00:02<00:12,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5920, step=551776:  19%|#8        | 22/118 [00:02<00:12,  7.94it/s]\u001b[A\n",
            "epoch=09, loss=0.5920, step=551776:  19%|#9        | 23/118 [00:02<00:12,  7.88it/s]\u001b[A\n",
            "epoch=09, loss=0.5796, step=552288:  19%|#9        | 23/118 [00:03<00:12,  7.88it/s]\u001b[A\n",
            "epoch=09, loss=0.5796, step=552288:  20%|##        | 24/118 [00:03<00:12,  7.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5993, step=552800:  20%|##        | 24/118 [00:03<00:12,  7.82it/s]\u001b[A\n",
            "epoch=09, loss=0.5993, step=552800:  21%|##1       | 25/118 [00:03<00:11,  7.91it/s]\u001b[A\n",
            "epoch=09, loss=0.5849, step=553312:  21%|##1       | 25/118 [00:03<00:11,  7.91it/s]\u001b[A\n",
            "epoch=09, loss=0.5849, step=553312:  22%|##2       | 26/118 [00:03<00:11,  7.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6034, step=553824:  22%|##2       | 26/118 [00:03<00:11,  7.77it/s]\u001b[A\n",
            "epoch=09, loss=0.6034, step=553824:  23%|##2       | 27/118 [00:03<00:11,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5899, step=554336:  23%|##2       | 27/118 [00:03<00:11,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5899, step=554336:  24%|##3       | 28/118 [00:03<00:11,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5992, step=554848:  24%|##3       | 28/118 [00:03<00:11,  7.90it/s]\u001b[A\n",
            "epoch=09, loss=0.5992, step=554848:  25%|##4       | 29/118 [00:03<00:11,  7.97it/s]\u001b[A\n",
            "epoch=09, loss=0.6007, step=555360:  25%|##4       | 29/118 [00:03<00:11,  7.97it/s]\u001b[A\n",
            "epoch=09, loss=0.6007, step=555360:  25%|##5       | 30/118 [00:03<00:10,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6028, step=555872:  25%|##5       | 30/118 [00:03<00:10,  8.06it/s]\u001b[A\n",
            "epoch=09, loss=0.6028, step=555872:  26%|##6       | 31/118 [00:03<00:10,  8.08it/s]\u001b[A\n",
            "epoch=09, loss=0.5817, step=556384:  26%|##6       | 31/118 [00:04<00:10,  8.08it/s]\u001b[A\n",
            "epoch=09, loss=0.5817, step=556384:  27%|##7       | 32/118 [00:04<00:10,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5974, step=556896:  27%|##7       | 32/118 [00:04<00:10,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.5974, step=556896:  28%|##7       | 33/118 [00:04<00:10,  7.91it/s]\u001b[A\n",
            "epoch=09, loss=0.5837, step=557408:  28%|##7       | 33/118 [00:04<00:10,  7.91it/s]\u001b[A\n",
            "epoch=09, loss=0.5837, step=557408:  29%|##8       | 34/118 [00:04<00:10,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5921, step=557920:  29%|##8       | 34/118 [00:04<00:10,  7.83it/s]\u001b[A\n",
            "epoch=09, loss=0.5921, step=557920:  30%|##9       | 35/118 [00:04<00:10,  7.81it/s]\u001b[A\n",
            "epoch=09, loss=0.5974, step=558432:  30%|##9       | 35/118 [00:04<00:10,  7.81it/s]\u001b[A\n",
            "epoch=09, loss=0.5974, step=558432:  31%|###       | 36/118 [00:04<00:10,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6003, step=558944:  31%|###       | 36/118 [00:04<00:10,  7.90it/s]\u001b[A\n",
            "epoch=09, loss=0.6003, step=558944:  31%|###1      | 37/118 [00:04<00:10,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5880, step=559456:  31%|###1      | 37/118 [00:04<00:10,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5880, step=559456:  32%|###2      | 38/118 [00:04<00:10,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5942, step=559968:  32%|###2      | 38/118 [00:04<00:10,  7.87it/s]\u001b[A\n",
            "epoch=09, loss=0.5942, step=559968:  33%|###3      | 39/118 [00:04<00:09,  7.96it/s]\u001b[A\n",
            "epoch=09, loss=0.5939, step=560480:  33%|###3      | 39/118 [00:05<00:09,  7.96it/s]\u001b[A\n",
            "epoch=09, loss=0.5939, step=560480:  34%|###3      | 40/118 [00:05<00:09,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5964, step=560992:  34%|###3      | 40/118 [00:05<00:09,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5964, step=560992:  35%|###4      | 41/118 [00:05<00:09,  7.98it/s]\u001b[A\n",
            "epoch=09, loss=0.5940, step=561504:  35%|###4      | 41/118 [00:05<00:09,  7.98it/s]\u001b[A\n",
            "epoch=09, loss=0.5940, step=561504:  36%|###5      | 42/118 [00:05<00:09,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6002, step=562016:  36%|###5      | 42/118 [00:05<00:09,  7.83it/s]\u001b[A\n",
            "epoch=09, loss=0.6002, step=562016:  36%|###6      | 43/118 [00:05<00:09,  7.91it/s]\u001b[A\n",
            "epoch=09, loss=0.5984, step=562528:  36%|###6      | 43/118 [00:05<00:09,  7.91it/s]\u001b[A\n",
            "epoch=09, loss=0.5984, step=562528:  37%|###7      | 44/118 [00:05<00:09,  7.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5940, step=563040:  37%|###7      | 44/118 [00:05<00:09,  7.83it/s]\u001b[A\n",
            "epoch=09, loss=0.5940, step=563040:  38%|###8      | 45/118 [00:05<00:09,  7.75it/s]\u001b[A\n",
            "epoch=09, loss=0.5962, step=563552:  38%|###8      | 45/118 [00:05<00:09,  7.75it/s]\u001b[A\n",
            "epoch=09, loss=0.5962, step=563552:  39%|###8      | 46/118 [00:05<00:09,  7.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5822, step=564064:  39%|###8      | 46/118 [00:05<00:09,  7.86it/s]\u001b[A\n",
            "epoch=09, loss=0.5822, step=564064:  40%|###9      | 47/118 [00:05<00:08,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.5977, step=564576:  40%|###9      | 47/118 [00:06<00:08,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.5977, step=564576:  41%|####      | 48/118 [00:06<00:08,  7.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5976, step=565088:  41%|####      | 48/118 [00:06<00:08,  7.86it/s]\u001b[A\n",
            "epoch=09, loss=0.5976, step=565088:  42%|####1     | 49/118 [00:06<00:08,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.5923, step=565600:  42%|####1     | 49/118 [00:06<00:08,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.5923, step=565600:  42%|####2     | 50/118 [00:06<00:08,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5771, step=566112:  42%|####2     | 50/118 [00:06<00:08,  7.98it/s]\u001b[A\n",
            "epoch=09, loss=0.5771, step=566112:  43%|####3     | 51/118 [00:06<00:08,  8.06it/s]\u001b[A\n",
            "epoch=09, loss=0.5777, step=566624:  43%|####3     | 51/118 [00:06<00:08,  8.06it/s]\u001b[A\n",
            "epoch=09, loss=0.5777, step=566624:  44%|####4     | 52/118 [00:06<00:08,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5956, step=567136:  44%|####4     | 52/118 [00:06<00:08,  8.02it/s]\u001b[A\n",
            "epoch=09, loss=0.5956, step=567136:  45%|####4     | 53/118 [00:06<00:08,  8.11it/s]\u001b[A\n",
            "epoch=09, loss=0.5862, step=567648:  45%|####4     | 53/118 [00:06<00:08,  8.11it/s]\u001b[A\n",
            "epoch=09, loss=0.5862, step=567648:  46%|####5     | 54/118 [00:06<00:07,  8.14it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6048, step=568160:  46%|####5     | 54/118 [00:06<00:07,  8.14it/s]\u001b[A\n",
            "epoch=09, loss=0.6048, step=568160:  47%|####6     | 55/118 [00:06<00:07,  8.09it/s]\u001b[A\n",
            "epoch=09, loss=0.5904, step=568672:  47%|####6     | 55/118 [00:07<00:07,  8.09it/s]\u001b[A\n",
            "epoch=09, loss=0.5904, step=568672:  47%|####7     | 56/118 [00:07<00:07,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5957, step=569184:  47%|####7     | 56/118 [00:07<00:07,  8.03it/s]\u001b[A\n",
            "epoch=09, loss=0.5957, step=569184:  48%|####8     | 57/118 [00:07<00:07,  7.98it/s]\u001b[A\n",
            "epoch=09, loss=0.5936, step=569696:  48%|####8     | 57/118 [00:07<00:07,  7.98it/s]\u001b[A\n",
            "epoch=09, loss=0.5936, step=569696:  49%|####9     | 58/118 [00:07<00:07,  7.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5821, step=570208:  49%|####9     | 58/118 [00:07<00:07,  7.96it/s]\u001b[A\n",
            "epoch=09, loss=0.5821, step=570208:  50%|#####     | 59/118 [00:07<00:07,  8.00it/s]\u001b[A\n",
            "epoch=09, loss=0.6045, step=570720:  50%|#####     | 59/118 [00:07<00:07,  8.00it/s]\u001b[A\n",
            "epoch=09, loss=0.6045, step=570720:  51%|#####     | 60/118 [00:07<00:07,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5889, step=571232:  51%|#####     | 60/118 [00:07<00:07,  8.11it/s]\u001b[A\n",
            "epoch=09, loss=0.5889, step=571232:  52%|#####1    | 61/118 [00:07<00:07,  8.03it/s]\u001b[A\n",
            "epoch=09, loss=0.5929, step=571744:  52%|#####1    | 61/118 [00:07<00:07,  8.03it/s]\u001b[A\n",
            "epoch=09, loss=0.5929, step=571744:  53%|#####2    | 62/118 [00:07<00:07,  7.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5887, step=572256:  53%|#####2    | 62/118 [00:07<00:07,  7.90it/s]\u001b[A\n",
            "epoch=09, loss=0.5887, step=572256:  53%|#####3    | 63/118 [00:07<00:06,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5984, step=572768:  53%|#####3    | 63/118 [00:08<00:06,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5984, step=572768:  54%|#####4    | 64/118 [00:08<00:06,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5833, step=573280:  54%|#####4    | 64/118 [00:08<00:06,  8.02it/s]\u001b[A\n",
            "epoch=09, loss=0.5833, step=573280:  55%|#####5    | 65/118 [00:08<00:06,  8.01it/s]\u001b[A\n",
            "epoch=09, loss=0.5987, step=573792:  55%|#####5    | 65/118 [00:08<00:06,  8.01it/s]\u001b[A\n",
            "epoch=09, loss=0.5987, step=573792:  56%|#####5    | 66/118 [00:08<00:06,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5876, step=574304:  56%|#####5    | 66/118 [00:08<00:06,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5876, step=574304:  57%|#####6    | 67/118 [00:08<00:06,  8.00it/s]\u001b[A\n",
            "epoch=09, loss=0.6057, step=574816:  57%|#####6    | 67/118 [00:08<00:06,  8.00it/s]\u001b[A\n",
            "epoch=09, loss=0.6057, step=574816:  58%|#####7    | 68/118 [00:08<00:06,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6192, step=575328:  58%|#####7    | 68/118 [00:08<00:06,  7.91it/s]\u001b[A\n",
            "epoch=09, loss=0.6192, step=575328:  58%|#####8    | 69/118 [00:08<00:06,  7.95it/s]\u001b[A\n",
            "epoch=09, loss=0.5946, step=575840:  58%|#####8    | 69/118 [00:08<00:06,  7.95it/s]\u001b[A\n",
            "epoch=09, loss=0.5946, step=575840:  59%|#####9    | 70/118 [00:08<00:06,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5975, step=576352:  59%|#####9    | 70/118 [00:08<00:06,  7.97it/s]\u001b[A\n",
            "epoch=09, loss=0.5975, step=576352:  60%|######    | 71/118 [00:08<00:05,  8.04it/s]\u001b[A\n",
            "epoch=09, loss=0.5951, step=576864:  60%|######    | 71/118 [00:09<00:05,  8.04it/s]\u001b[A\n",
            "epoch=09, loss=0.5951, step=576864:  61%|######1   | 72/118 [00:09<00:05,  7.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5883, step=577376:  61%|######1   | 72/118 [00:09<00:05,  7.86it/s]\u001b[A\n",
            "epoch=09, loss=0.5883, step=577376:  62%|######1   | 73/118 [00:09<00:05,  7.88it/s]\u001b[A\n",
            "epoch=09, loss=0.5887, step=577888:  62%|######1   | 73/118 [00:09<00:05,  7.88it/s]\u001b[A\n",
            "epoch=09, loss=0.5887, step=577888:  63%|######2   | 74/118 [00:09<00:05,  7.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6031, step=578400:  63%|######2   | 74/118 [00:09<00:05,  7.82it/s]\u001b[A\n",
            "epoch=09, loss=0.6031, step=578400:  64%|######3   | 75/118 [00:09<00:05,  7.80it/s]\u001b[A\n",
            "epoch=09, loss=0.5955, step=578912:  64%|######3   | 75/118 [00:09<00:05,  7.80it/s]\u001b[A\n",
            "epoch=09, loss=0.5955, step=578912:  64%|######4   | 76/118 [00:09<00:05,  7.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6154, step=579424:  64%|######4   | 76/118 [00:09<00:05,  7.85it/s]\u001b[A\n",
            "epoch=09, loss=0.6154, step=579424:  65%|######5   | 77/118 [00:09<00:05,  7.82it/s]\u001b[A\n",
            "epoch=09, loss=0.6180, step=579936:  65%|######5   | 77/118 [00:09<00:05,  7.82it/s]\u001b[A\n",
            "epoch=09, loss=0.6180, step=579936:  66%|######6   | 78/118 [00:09<00:05,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6124, step=580448:  66%|######6   | 78/118 [00:09<00:05,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.6124, step=580448:  67%|######6   | 79/118 [00:09<00:04,  7.88it/s]\u001b[A\n",
            "epoch=09, loss=0.5882, step=580960:  67%|######6   | 79/118 [00:10<00:04,  7.88it/s]\u001b[A\n",
            "epoch=09, loss=0.5882, step=580960:  68%|######7   | 80/118 [00:10<00:04,  7.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5839, step=581472:  68%|######7   | 80/118 [00:10<00:04,  7.97it/s]\u001b[A\n",
            "epoch=09, loss=0.5839, step=581472:  69%|######8   | 81/118 [00:10<00:04,  7.99it/s]\u001b[A\n",
            "epoch=09, loss=0.5846, step=581984:  69%|######8   | 81/118 [00:10<00:04,  7.99it/s]\u001b[A\n",
            "epoch=09, loss=0.5846, step=581984:  69%|######9   | 82/118 [00:10<00:04,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5998, step=582496:  69%|######9   | 82/118 [00:10<00:04,  8.05it/s]\u001b[A\n",
            "epoch=09, loss=0.5998, step=582496:  70%|#######   | 83/118 [00:10<00:04,  7.98it/s]\u001b[A\n",
            "epoch=09, loss=0.5837, step=583008:  70%|#######   | 83/118 [00:10<00:04,  7.98it/s]\u001b[A\n",
            "epoch=09, loss=0.5837, step=583008:  71%|#######1  | 84/118 [00:10<00:04,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5675, step=583520:  71%|#######1  | 84/118 [00:10<00:04,  7.87it/s]\u001b[A\n",
            "epoch=09, loss=0.5675, step=583520:  72%|#######2  | 85/118 [00:10<00:04,  7.76it/s]\u001b[A\n",
            "epoch=09, loss=0.6014, step=584032:  72%|#######2  | 85/118 [00:10<00:04,  7.76it/s]\u001b[A\n",
            "epoch=09, loss=0.6014, step=584032:  73%|#######2  | 86/118 [00:10<00:04,  7.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6080, step=584544:  73%|#######2  | 86/118 [00:10<00:04,  7.89it/s]\u001b[A\n",
            "epoch=09, loss=0.6080, step=584544:  74%|#######3  | 87/118 [00:10<00:03,  7.79it/s]\u001b[A\n",
            "epoch=09, loss=0.6148, step=585056:  74%|#######3  | 87/118 [00:11<00:03,  7.79it/s]\u001b[A\n",
            "epoch=09, loss=0.6148, step=585056:  75%|#######4  | 88/118 [00:11<00:03,  7.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5926, step=585568:  75%|#######4  | 88/118 [00:11<00:03,  7.91it/s]\u001b[A\n",
            "epoch=09, loss=0.5926, step=585568:  75%|#######5  | 89/118 [00:11<00:03,  7.70it/s]\u001b[A\n",
            "epoch=09, loss=0.5797, step=586080:  75%|#######5  | 89/118 [00:11<00:03,  7.70it/s]\u001b[A\n",
            "epoch=09, loss=0.5797, step=586080:  76%|#######6  | 90/118 [00:11<00:03,  7.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5946, step=586592:  76%|#######6  | 90/118 [00:11<00:03,  7.68it/s]\u001b[A\n",
            "epoch=09, loss=0.5946, step=586592:  77%|#######7  | 91/118 [00:11<00:03,  7.76it/s]\u001b[A\n",
            "epoch=09, loss=0.5788, step=587104:  77%|#######7  | 91/118 [00:11<00:03,  7.76it/s]\u001b[A\n",
            "epoch=09, loss=0.5788, step=587104:  78%|#######7  | 92/118 [00:11<00:03,  7.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6061, step=587616:  78%|#######7  | 92/118 [00:11<00:03,  7.72it/s]\u001b[A\n",
            "epoch=09, loss=0.6061, step=587616:  79%|#######8  | 93/118 [00:11<00:03,  7.80it/s]\u001b[A\n",
            "epoch=09, loss=0.5707, step=588128:  79%|#######8  | 93/118 [00:11<00:03,  7.80it/s]\u001b[A\n",
            "epoch=09, loss=0.5707, step=588128:  80%|#######9  | 94/118 [00:11<00:03,  7.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5962, step=588640:  80%|#######9  | 94/118 [00:11<00:03,  7.93it/s]\u001b[A\n",
            "epoch=09, loss=0.5962, step=588640:  81%|########  | 95/118 [00:11<00:02,  8.03it/s]\u001b[A\n",
            "epoch=09, loss=0.5881, step=589152:  81%|########  | 95/118 [00:12<00:02,  8.03it/s]\u001b[A\n",
            "epoch=09, loss=0.5881, step=589152:  81%|########1 | 96/118 [00:12<00:02,  7.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5906, step=589664:  81%|########1 | 96/118 [00:12<00:02,  7.81it/s]\u001b[A\n",
            "epoch=09, loss=0.5906, step=589664:  82%|########2 | 97/118 [00:12<00:02,  7.87it/s]\u001b[A\n",
            "epoch=09, loss=0.5916, step=590176:  82%|########2 | 97/118 [00:12<00:02,  7.87it/s]\u001b[A\n",
            "epoch=09, loss=0.5916, step=590176:  83%|########3 | 98/118 [00:12<00:02,  7.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5954, step=590688:  83%|########3 | 98/118 [00:12<00:02,  7.70it/s]\u001b[A\n",
            "epoch=09, loss=0.5954, step=590688:  84%|########3 | 99/118 [00:12<00:02,  7.84it/s]\u001b[A\n",
            "epoch=09, loss=0.6130, step=591200:  84%|########3 | 99/118 [00:12<00:02,  7.84it/s]\u001b[A\n",
            "epoch=09, loss=0.6130, step=591200:  85%|########4 | 100/118 [00:12<00:02,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.6003, step=591712:  85%|########4 | 100/118 [00:12<00:02,  7.94it/s]\u001b[A\n",
            "epoch=09, loss=0.6003, step=591712:  86%|########5 | 101/118 [00:12<00:02,  8.04it/s]\u001b[A\n",
            "epoch=09, loss=0.6033, step=592224:  86%|########5 | 101/118 [00:12<00:02,  8.04it/s]\u001b[A\n",
            "epoch=09, loss=0.6033, step=592224:  86%|########6 | 102/118 [00:12<00:01,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5893, step=592736:  86%|########6 | 102/118 [00:13<00:01,  8.05it/s]\u001b[A\n",
            "epoch=09, loss=0.5893, step=592736:  87%|########7 | 103/118 [00:13<00:01,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5849, step=593248:  87%|########7 | 103/118 [00:13<00:01,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.5849, step=593248:  88%|########8 | 104/118 [00:13<00:01,  7.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5922, step=593760:  88%|########8 | 104/118 [00:13<00:01,  7.87it/s]\u001b[A\n",
            "epoch=09, loss=0.5922, step=593760:  89%|########8 | 105/118 [00:13<00:01,  7.71it/s]\u001b[A\n",
            "epoch=09, loss=0.5885, step=594272:  89%|########8 | 105/118 [00:13<00:01,  7.71it/s]\u001b[A\n",
            "epoch=09, loss=0.5885, step=594272:  90%|########9 | 106/118 [00:13<00:01,  7.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5897, step=594784:  90%|########9 | 106/118 [00:13<00:01,  7.85it/s]\u001b[A\n",
            "epoch=09, loss=0.5897, step=594784:  91%|######### | 107/118 [00:13<00:01,  7.94it/s]\u001b[A\n",
            "epoch=09, loss=0.5961, step=595296:  91%|######### | 107/118 [00:13<00:01,  7.94it/s]\u001b[A\n",
            "epoch=09, loss=0.5961, step=595296:  92%|#########1| 108/118 [00:13<00:01,  7.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5962, step=595808:  92%|#########1| 108/118 [00:13<00:01,  7.82it/s]\u001b[A\n",
            "epoch=09, loss=0.5962, step=595808:  92%|#########2| 109/118 [00:13<00:01,  7.74it/s]\u001b[A\n",
            "epoch=09, loss=0.5865, step=596320:  92%|#########2| 109/118 [00:13<00:01,  7.74it/s]\u001b[A\n",
            "epoch=09, loss=0.5865, step=596320:  93%|#########3| 110/118 [00:13<00:01,  7.67it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5896, step=596832:  93%|#########3| 110/118 [00:14<00:01,  7.67it/s]\u001b[A\n",
            "epoch=09, loss=0.5896, step=596832:  94%|#########4| 111/118 [00:14<00:00,  7.81it/s]\u001b[A\n",
            "epoch=09, loss=0.5837, step=597344:  94%|#########4| 111/118 [00:14<00:00,  7.81it/s]\u001b[A\n",
            "epoch=09, loss=0.5837, step=597344:  95%|#########4| 112/118 [00:14<00:00,  7.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5968, step=597856:  95%|#########4| 112/118 [00:14<00:00,  7.70it/s]\u001b[A\n",
            "epoch=09, loss=0.5968, step=597856:  96%|#########5| 113/118 [00:14<00:00,  7.68it/s]\u001b[A\n",
            "epoch=09, loss=0.5907, step=598368:  96%|#########5| 113/118 [00:14<00:00,  7.68it/s]\u001b[A\n",
            "epoch=09, loss=0.5907, step=598368:  97%|#########6| 114/118 [00:14<00:00,  7.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5776, step=598880:  97%|#########6| 114/118 [00:14<00:00,  7.85it/s]\u001b[A\n",
            "epoch=09, loss=0.5776, step=598880:  97%|#########7| 115/118 [00:14<00:00,  7.99it/s]\u001b[A\n",
            "epoch=09, loss=0.5887, step=599392:  97%|#########7| 115/118 [00:14<00:00,  7.99it/s]\u001b[A\n",
            "epoch=09, loss=0.5887, step=599392:  98%|#########8| 116/118 [00:14<00:00,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([512, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch=09, loss=0.5800, step=599904:  98%|#########8| 116/118 [00:14<00:00,  8.12it/s]\u001b[A\n",
            "epoch=09, loss=0.5800, step=599904:  99%|#########9| 117/118 [00:14<00:00,  7.92it/s]\u001b[A\n",
            "epoch=09, loss=0.6177, step=600000:  99%|#########9| 117/118 [00:14<00:00,  7.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "torch.Size([512, 5])\n",
            "5\n",
            "torch.Size([96, 5])\n",
            "5\n",
            "torch.Size([10, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ca0e423b-a559-4314-9a6e-7864e9702265\" class=\"plotly-graph-div\" style=\"height:300px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ca0e423b-a559-4314-9a6e-7864e9702265\")) {                    Plotly.newPlot(                        \"ca0e423b-a559-4314-9a6e-7864e9702265\",                        [{\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAA4CAAAAAADPrjSAAAc+0lEQVR4Xu2ae7wlV1Xnf2vtvavqPO+77+1XOiENhEBDEBMmEDUmSpC3oCQB5DUi4ABBHgHj8BDB8HIGDIJCFJSAUfEjMAlKFBAJSIAxwgcxIHl0Ot3pvs9zz7NO1V5rzR\\u002fn3tv3nu5RPvPhj9GPv3+q9nedferUqr3XWnvXoQb+U6cTj4P\\u002f1Ej\\u002fbh1z8Fv\\u002fNI5+qPr36ph33bL\\u002fW+Psh6pxx5z3\\u002ftb7HzHG\\u002fv\\u002fT3C0vmvrOfxunP1SNOebQp660Kz+1k23Xa1vtx44zAEB9\\u002frmvTsYhgIPn\\u002fNd2q9VqtT4Wxk0n9RPff+A4Ak9NTb3u1z++8PvtxdeP2w5edz7e\\u002fPrVcfyDqvq33z1jnJ0iv6P1qBsmrFNOX3B7uQNv6dmvUtg4BHDglRecC8xfPc7PefbP8m41AHjCe17f2cSPmb7p5GcA\\u002fMg\\u002f7GhiX\\u002fLoCyeeCgBH3\\u002fXkzrdv3WkFpi8Djn5pnP5AWphF68cf+S\\u002f\\u002ftlO3O6Zy3ocWgDvf85FbfuO3tuFt2p+OEwB40C9fntF93Qc\\u002f\\u002ffrvjVnefNnJ82d99Kubpz929g7H8Jn7aXv74f9rYuNMf6P3p8db\\u002f7LdCODg9YRn3zwGt+nl4cGX43sXjGOc+5L9OLgf\\u002f+McOnbq4P7RKx77EPza\\u002fY+58Ruj9nbHvPfnAeC8+q0\\u002f9tBtdJsufjG+9\\u002fOLY7D5lqc3gDuflnxjZmbMhC9chqWPkuGCi3bgK7+2ozn\\u002f\\u002fBt3ePTI6gQAfH39x4sbt\\u002fNNXbH\\u002fs6+8fxxu6rHnXvRkguHsr58\\u002fbvrx5wLDGy9+Fexjp4yYp79zhr40+1bQzAtGYJtjzruMcOtfvfX4N1s\\u002fseMBbunC353Ae4+M0yc\\u002fD8BdTzl69rgBwPU3oVwE0LhtN246OV\\u002fGAtv7cOeO9tobHv\\u002fNd+FbT+2f88s7+Ib++uGHrzm9X+Y\\u002ffCaaNbr9PABcHbf+6lX42MpvLx\\u002f65MzyJ8dM7lHXVb\\u002f8jr9P\\u002f\\u002fBS3L6BTjrm0KeadssLL3rLHy1\\u002fWy97xDe3+Ek9awFf+uNxiKcBh\\u002f\\u002fhjUfxoHEDADk6Ol46CRwtNulDd22ejdTEF3aCm77YPfTc6\\u002fq44xU7OQDgiefbJwfjEABw8XX7AOD8lZmFD+zFHePmauXet5zAA14z2792OGa64n34\\u002fPM7eMalOPrxDbTlmINXTawc\\u002f3jvs58FgMrLf3GTn9TML+j6u8Yh8PIXfP6uJQBz44aTesbzK8DbtpqPq2yzAXNn4tgOAHSwjuf9uY5RAMDEhUDrGICX7sV\\u002f32l65T5g+MZv\\u002fAtWX7oXh39ppxH41OMe\\u002fOuvav7m41ffff2Y5Q2vtg\\u002f9Rgd4LXD18gbbdEzy1ss6v3R7tvnR\\u002fZsnJ3XGDcDv\\u002ft04BY5fOzo+eic+qWe++qwAfOtkonsg\\u002fnmbGW\\u002fb9f3u9jYA4NpHXnTx58chAMgjWb8MvMxefAZe8eDtU+qS84Ejv\\u002fRVANgD3LyyzQQA+NbXHnzxJdfux9t\\u002fb8zwulcXn3tjjvTSffTOrZi+6ZjzLsMVX96Ep9VPPQx\\u002f+4FxuKGXVMnOxW23jfMzrvhJ4EID2m+6Jd\\u002fGT4abxk9dfinesb7NNlL\\u002f5V+67u9u\\u002f9CptcFFj9Ejqzh04RPQO\\u002fbAj75gW8h7eRW3XftVAJM\\u002f\\u002fVjcdstJw4aKNhZuIPujnaUCMPEi+9yVwAOufyQ++Z4tuumYt9GtJ\\u002f3Cemr0fdKv4+9f3B6nAFB5yOsuAyuOv3R87J974+bI+\\u002fuPbOeYAvAwvnhP8kzOvz70\\u002f7jDONLdL\\u002fnAlVfWPn5iDNcP4PiNdx686okrn7+ucfNmWgcAfHim\\u002fcJFAHjhG\\u002fDPzx1PngCOAMBnf3sj7m0pmcFr557zM+fWzf6kv0U3HPP4h9tnthjUTlmHnHEDcPfSOAXgH3HDwuD4bT9VhXvK+8frQiIArMDjH7ftCeb2ntcAD6PYv+Ojt9+6+N3KePkDALjprt+8+E373zWWfy58Oz78jrm3Xtb5i2vOfm\\u002fni9tz5Kc\\u002fPTr+zOsR\\u002f+A0fuHHEPBXl49jFMuz3zbg\\u002fs7Cyl+epBuOyZKlP99EyTX44ps2G5v6FQX+5zgEEH76Y7j27746ddO5mH3zkZu2Mg8A4DtPuPxzOYDnvmQHftWRRwO47+Y7vg4Az5+9e4d1S9953s984IVnP3UnfBjwDnzsfFzx5Qs+i98Zi74j\\u002fbHhtR8ZhwA+8hTD6er29Sv\\u002fbOquz9yw9pGFT2yjW1lpuDlok6uvOnpdbxNv6NAlwM3jFSgA\\u002f2tX4a9\\u002fb332Ew8t3nPuE3\\u002f\\u002fC+9pYftgO\\u002fJuAMC1Ox2z08MXY+NJn6L1G9\\u002fnH3vRrTvYBN2MQwfomi8fvJ6uef8O04bexIrTRMuF5zzV\\u002fvHbzzld7vzGWQDwmIv0nm1wyzGbM+nQVc+4+TmbcEufmsQ3xu4OAPgNr+i9+RPrP\\u002fKuR9z5yi81Hv3MJ3wK9x0a\\u002fxBw6TjYqfFouKGHPu1HPO74yhg1A9Qe+p3snstOG\\u002fHCw9Wu3lkwAgAu\\u002fu94ywef9JxTqpstVdS2Jg22HEP0pNcBAF722ok\\u002fefE2+4amFR8cH0UAXvCK\\u002flWfP\\u002f85j8vefsNRdP7mb37umfjVLaO\\u002f9IujTPQLb99iP7ge+OInzwNyfCygf+aqJ17wsDqeRStvP231W7n8EvzZn45nAeCid+LyL8y\\u002fDveOG7b0uZ3NDceYzb\\u002fzo6vnX3Fo75HPjZc\\u002fAN7PwCm5GMDr4a665gHAb\\u002f7W6Kd8YtssvfA1lzzsKICpx72tisHpa1UAAJ29c+kEALue+aIDAP7h3dtSAgCg6FdvMQCdvzg1HwOoX\\u002fc0vP6Dp\\u002foFl0zc+lf+8RN0SnWzpbFhvTWV3Iue2jkb+NoXT1aoWzp0iRYfPE2cx4nZ9BA++5WbDp\\u002fmp7z7XLyyC+AnzzN86fp\\u002fZZPAxjfLMPeQdz8IwNff+5lTvvcfX\\u002fiyHwM+\\u002fk\\u002ffPE0YAbD3abjrd8chAJiZf9I71\\u002f7wNE99Q2ftbG445mv\\u002f+1GY34XVT4wm1JgmduHYaRPA45\\u002f0iKWPtsaT9JZ+cXRY+surxxcnO3TBx3Y0p9576CwAt133N9trwk2N1iz\\u002fFz3oZfj+08chAGAWy59+DH55Wz4e11d4x1PYcMyxZ7\\u002fwauD9f3CaqPWvqXvjafcFAAAvffGzAOCuwVc+8p1x2w7tLCZ\\u002f9KpH7QEw+MC7TxZbP7CufgZ+75TlPwDgu3garX5obLG6Q9\\u002f5\\u002fllnbS6UcHIqnbh2Y8lzOn3vtgvH0b+tb\\u002f3KN944edPnbz7dFNyuv\\u002f7ZHc0nPxn47l\\u002fKb5+6Svi3dU4DH\\u002f7iOBzp48nVt3\\u002fmd8bpDv3W+974mu9uteg\\u002f0gu3t7z83p87TbH1A6rxhz\\u002f56ZduDdNTAt+\\u002fZ30O1\\u002fy\\u002f+wWd513\\u002flJO7Cv+hRswPU0yA+iB5CYIniAkcm3kiDUbGICIzUbAxExGBCCYIQmYAC2CiRiowIjZleK9QEEiJiIiZzLEjgjGCF4KSkRGRiLpRKUvARj8D2EaXYSgTE8MYIQjMAFaYRVHSaErkzBiejchgpAoyGBOMoATAGGQMEJupgowZICJmmMBt9rNRP5zs57yP5pWTtIA4LSJqkXPvY1S10gBTpujEs8DUPAgmXHhnkQCYwcxgDuZEgwkZixUOIJgSzJyyOhfNqcJY1IjM2GBkZHAcjRhKICgKh9F3AsrGSr5UbwJjsYKIAJgqwcCkRBpMDSRWAAYQqRGxeTFlttGDYTFHqkyR1LOQqTkimFLpnZWAgc1gjs2r2sl+kaqM6AGlykDIKOl7QQZyJYEVEJCJN4apMogSGX2pGkAGUhCRd+YRIVSyuRJGBiM2YQ\\u002fyAU5VQTkbRTIDnBnBiKDK6oVVmYgjlM1ABGUHcgHOohkNnXKEAWAzMiOwIziKFElJfWnGYFMHVWYyM2NjVcABZACJORNnDDUlIgoKpdI5NSIow5SZFAra6gejLFWT1BnnBYEzNccRrvQFsYx+iS+9kYoao5Z5yePoebPCYOQp+JAmQD4oo2AE2RQgOO+SNEnUlcMyL9XUWEGg0TgxNTaH0VUAAxGrgkHe+ZAkiXExiHk0UyN1pGRm5BCcSxJCnkcVEjKDEUZmKIkTAAECMBlBDQTz0SksmjIqWZBYmgGmRExKZqRQFjIEEwKxAd4LK1giU40n5usNl7XXOuvdthMHmHNKCETG3lU1ZEml1+0WoSQwTJkohLTRbFac07X15SLXEKFwUDA5SrNGY6aeeO63FtvrpUINRGoKo+iViMkrmYOKK0m9A+DIuSRrNKbr3qGzvtjtisXR3QkB3qXVejVzTtY7LTFLSlIikCmDlIwdpWbsE7ECBiIzz8oI5hVMFfVpVsv73SKUbEZkRgZldUypGbtErABA5MuMWToBtVCbm3\\u002fggdmsPH7i7ruPIleUFXLG4pgImiaN6mQjG6xI4UsyE1Iil2TVqfmZ2UqG7okTbonKkuAgpOY5CY2pXQu7m81QLq\\u002fU7o3dnI1EGaQgeOeTtBl99APuS1QlOIEa+5DWp+Z3LdQbnC8up8d0kI+mhhJckqYTs5MT1YDe8lJY9TEyQBFsJKQgl2TBUZqwWlfKXIWIWZ0wiJwlvppNTFTj+pKEIZsZaNQPnFQSppBA0ZM4UGHP0bNzxn5q\\u002f5nzD9lbqQ\\u002f23l+JeenWORgjOiuJlZPK1MzurCGdHjNcVCZjsPO16Zn9s1NpkMxQlm1YFAWBjJhqk9P7ds\\u002fVKy6SHw6GsTSCQYkBj2parU5UPcT1eu1+WVoJsBGIuDY1s29+rpKiYpznpZQKU2cMcr42Ob13qpkE6QcP7Q8J0QACjAgJqtXJepb4Shz0skFPB0bGEEIEiU9qE5PzyTT1Zd2Zj8rAKDsmqFan6pl3WZn3KnlPcoMnskLJTUwt7N13VoOGvYDpg0M3XAxmCiiIIN6HytT+fc1KS7TSVyUigA1JpVadSMIA69bLxScAFGRQNU0T7yuOu9ZyPe25igeVTkHE5CwkkxO7puYo5NU8X1peys1HR2aA+sS7jLkta9wt+5wySFgBYqO0PjE526gTD2LBoZL2CQYCw4wMLtRndu1Jq5gEtVsnWk5LBUxUCKY+rU7O7ts1OZEvrzYGhRARA8pKPq3N7dqTVHTC0F4\\u002fsc5SCnlykVySNapzu+d9d229DLMT9f1Lk2tdIV8mEWbmLJnctXvPnmosNHNJSWBWJXLkHTvqYbWFmArMqQBmrAYoTEwHg9W2izUzTjyxCTiSI6415xZmZ2tFoUl1UObrOQwY3b9CRaWHlbYrK4XBk5EpIOScC1lWSQpqt2EJE7kYDWah8CBNuTmzcOYskTbIZdwbrpuY+TIIGZS5umtubmGh6ZJW1acRBnJFAFHmm7PzZ80YlQ1wxffLtgnUgzmIghfOODBRtO\\u002frtMLuA3snz1k80ZGYUWHsRCT1KVw11f5au9NXUVeaMhgaRftrbtguuQYh1aEBXtSrQ8GpxHxN1wskkVScqplTIyvSJGvumt9dK9qrMjlVbaxAzMhIvDLKYVoOu6V0SspEiohSoV4ikwEEGrZpsF74BsGrFETwyqwWggu1+bP3pGut4XBP1a9zNGUDU2nMkaxSqQWfskin0+pFFV+oc2rB+6Q+f3B3srI6zPfUkq6LqhzJa2EJUbZv\\u002f+7p4fLi0fuirBl2J5WUiBjmHAjsUyfDqMN+q9Xpx6EomRGrQNVIi1ZHK1UEOIRczchAah4cEm+dbunCMC2E06gwKOAxSoedtXvX2E84lkEBNiWA1YLBe4qdjqRpdAJKOjAhMMFIxSwO19qxVqOEnPqoJqQGb0ZwFY\\u002f24Y6kUQftlZVeEU2dWWAj9T710ssLc+319fZwINFs1M\\u002fMVbyt37Mek2jD9spKvxRVD2\\u002fGlb3nnHlA1u9dPLy+xktU37N79z8LaWnOsRETOOcwVW8dvefoyiComhopDCYxiklqrjIdSu+1jMYb9bDC+yThCRKbNLEgpZbsYCANnkKg\\u002fvCuE+3J0lVWexrFoEwKNYOjkFjTm5uyEk5KFccGdSDE4bD0hYW0Ua+VwVkZDWRCpF6lWmuknaOH85pLtHPfWqcnQlaaI1ZjdiGXerXaWz98z7GuFzUoRv2SWj207727X+MK+kdb7V4UNk9EypMLe\\u002fb51buO3N\\u002fvAr4wV3AW\\u002fEAIpKzkuHB+YncldFfXcoGacijU4IR92sxqRQzZpO9UEoQCZsZqQvC1icka503zzTKuFy4ELlSdqndiGofayYtkutnQcjgoWImMxRTGWWOy6suU0mYcDDwHz6pKYp6N2FeDD0VSm663U69sRqphVBKHJOZF39f2zrvBieXVNR0KkgiDkHCgwifN+aYeW1nslaJRKBEzmHIIkud9V9274IdLKytrWggSn6qmPL37QNI5cvtyS4fpIOV8SC6qpqyqlJNAoMnZs1hZXO6WxCyMaA6syqhWmqGUJGtS1l\\u002fNesmQlYkQSgRfqaXmEk6TFBRDyDoMZ8wwNpWyLGkm7D84uzjoR4iZerC50ryr1eq+EJ9VJSv7qc\\u002f6DFbPDCHNkoYbSlKbCWk7yXq+JHUEMrALAd2h1mfPmHN3H1lZJzUnYFHioZmZxeTA7uSexaNrQ\\u002fMEZ0Igg3NJ0E4utekzF7I7jqysc4SP8KXzwrUp+Pu+eaQ1CIokrTezlpRcBGHHRmokki3sn1sdLHVzhkUYlAQGQvC+Ion3SUi0Xq9UCydwBoCzrFqF9osAiVWp59XM+dySOKrFMWhktCCTZ+xl7fZLhQmpVwOFUMmcG2pwpInUGpVKzxfwKuIJ5uGr6n2oVlPJKmmt44RYABiIyyEn1cr8wsR9y0dXesJQRCNHBjPEcnLhzIVeXOz0iASkEBr1o2LIyWyya\\u002f\\u002fsieX7lnviIIjecq5U9yzsOXznkeVWvUAIaTVYp1PCF4GU4MQrV6b3zdDRe9cHrAxSVoDIEIEkE1\\u002fEYb9oJtVaIHajJQiA4DJbKwbOOJmqJ8GZCEiMiCRIb2KYouZnF2aGZV\\u002fJiQEexErqKHN95E6RNCqVSoAZmQDOpDANFSTCcZAkWbUWiAmjPWzLOA46niam5qc7x+463kNCMGVAiXwRhKoTe2fC0t1LbY7emWz8c8EyKvptp9MTu+eKY3ce61IKwNiLpFrJ5spha6nXKMn7yr79e\\u002frdlU6pTp0z9qKJy6amMVxbGeRiSe5ICSwCJpeY6WDAuTbcRCWrNXujyAv1aaUZyHp9L1JJZ5NeSByxwAHsLBatKoKZqHR6ra5EUWVjqLJP6wzr9XwpKTddJas4JiOnygC4FJEhlwzyIVSLXMyZEuCcll1P8zDEwXKr22fLTMzIkbJXCRymJ1GsLXfzofIgwEiJAMdadDzmTCH9lVanT5apmnnnpN6YTh05LTGRZdXdDz4QFu9cGsJ3KgqiyOzqjWraL47nAyUozDg6YzL1MZbDlOLK0GyaQtVHF02NmYiz1HsBqG0akjRkZMwgIWdaCJO7v+Zpplr2W4tt1cjsbbRBlZGxMGwlyhR7VJw5gkVmQ\\u002fRFkXcTGqwXmWt4n7nSiQkJm9cyGYA5+CnJ148tr7OPxCS+FBBF8q7WzJLh0vFBL4LVDBw5snktwwAExoQO20dOtCiJDFLnzZsxN9KsXp9jPzk9deABM+XR4yf6Rh4AiB1qlWrNd4frvQEiq2MtOXpxlnpCOcyH3aFSUg9cIGEmwABkWW0iFSb1HKZnJiQqEDQaGRvrEJSYo2Q4GKwtt3uqok7ZjJCllaqDFkP4tDlVLyIcOWfG4ixQlH4vlV6PhxTUCk0w2rdiYwarqZb9IdZauYiDRYYSwcgF1CuVimuXnc6ASqfMUpJs9IOoSDEo+qvrgwhHKmTmSWMp5bC2\\u002f+DwXpqemprb31g5\\u002fN0jbWNRNgMkS+dm56vdidW13CwFnDEZk6M0OK\\u002fmOI3d0Jyv+0IlqkpkViRZpRGqaVHpt0N9fk+yMiiEjcicgowh5XLCjWkna0dWh6ZwJCCAkkqScTLBSXXN13bvStplKTCYMcg75mJYDhnCE5NBCpNSVaJzQswgroZgXC1Xjqz0A3l2CkcwI5I02z23u9Kuri73RTIa3QOcgtmIM8fRVeX+w4u9QGHUz0Or\\u002fW63tVD9LzMtmgqNmq3fd++9K+tmVAVYwaE+UatXs87SSsfI2BnUAHGOXZKkmfMWptN6jTqrq708KjPEeUWg+mQd\\u002fZ4hbYb28ROrnVxBTtUZRaelQ9qsVLXT7YKIwDAx50Cpr000k2plkrNJ11laWu8XCjYhdo6D96pAtdYM2m63hlGNHAysLIkPtdrUDJdrKwP15qEUiQms4KTRrDerle7y8roA5M1stEeqLInz1er0jItrq30J6mAkYJ+I+fz709k5+xcGearaOXzXXYcX+27oID4Kq3e1eqNZKdeOrxiIIWwgIiXT6I1KGaaVWpKUayeWVju9aKLsoBzzYT\\u002fWkslBaUW\\u002fdWzp6FpXVAxw5kCAM9RqM+j31stitMFOZFCKQ4llllSqkWPeO758f6srKkrmTEHmYtGu+WqtVq4fX+32+2KqDERWslBvzMxPYvHo0sCM1akRE0chSXxjcqJRlZVjS9FsdA8MNhNWp75en16YdkvHFgdQNidGxF4MWi7eUesdTDmVteUjdxw+2u0IvIDU2CyqURJc0V7pFRSESBgQUlalIu\\u002f4TAoONoj56urx9VwUhOhUY+d4hblJUQetVuvE6mpnYGpGyrBIKhlqlSZJd7ndMyI2cWbizGJ\\u002ftRrSJgvKXqe7tLrU7quqkZqaQ+y5NrnEx04nX11Z7ZcqxFAiUlh0abOSdlfXlksiZlNjg4JHrxVC4Ly91B0gGJESoDBiUkuiSyaq2aC1tjQEOTIzNvUaolvtLd134MBsIu3VY8dPdPLSkagkRlDliit6RbfXP3qirQ4+EhuB1EVyYizFsNLInA3yvN3r9KOyMgjm8pj3jx9v1C3vLbXbvUEsTEmYfHTqAIfgA7Q7XOkaM1nB4sBKPJRYtNZqdYrD1W63O8iHqqxMLhJMY26SN+vDXhwO2512PwpHgosszByokoXB0onFYYRzRuaMJQgiJ166k91O557FdSUmMVYCaYiIzJRQtZIOVxZP5ALPRsZGSlnFDcwybVqz9LnmbfFOq6pCKuzUXEiS6Umf90+sR8mSCDEiiFNhZuNAFed9otFKyXMFVKFMbKTOh2riIP1yGClqgIti8EIOpsFXGhOzNW4Pltp9FS29waAMNg6u7jwoL2NpZWRiEZgv2TEoWOpDViGhoujnBakJKTPUcVKdm52ryOKx43m06FUtiJI5NZdm2exU0u8eWy0kDUJqcCpeGUYUqnOzu2pYuv\\u002f+fKjRmVoSlagBC8KWkzpHWsBJ8InYMHFWwsBgVCsch7FXkDbVCwtMiYzM4JxZZFLn4SCqwkSixqRsDEH0NCr1wQynpGoOHBG9c2ma1gKVeXc4VAEbRtvZYBJET2Js3gxkDlA1Jig4mAkxfAJnsZTIbKrmjJSVJ2qTFaHlfq9UZWVliDoDCB71GssgdoemNQ3ixEjAMFJSbtamqkYr\\u002fW4ZlWyjH9WJjMsgYKPISIpElXyuqOZsYMC8ZjoskJPLfBgyzKDGrFAi8qWqaSBzqs5AXoRHL9QAjgooqYeagyMSMrhIBoCZOVRBZVGIkhnIWJ1CGXClmRobs5ozZhYD3Mb1oijgnTkVViOnwsZixOa5njKkVUY2VgbUCUBGBHJaQV5oTpy6UG7eA4kRq+d65qCtsmAjZdro14yAJa4M5LrkvQpBDNDU9ypDOKAkIo7Ohs47UuIyicZCPgqbN9ONN5vioU5BCiQo1ZmHGJyACNHByAhkmooqk8LZqDKLICUy4hLkqVQ2DzVzChBkox\\u002fMUovC5gxqREZk6kbXE1AShdiVFMirRiE4ig7mLcJchAMVxMSRtXTO8egelHRUA5QUyJtIZGOSrX7\\u002fB0RITnctg35lAAAAAElFTkSuQmCC\",\"type\":\"image\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"AE reconstructions\\u003cbr\\u003esingle input shape = torch.Size([1, 28, 28])\"},\"height\":300,\"width\":750},                        {\"displaylogo\": false, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ca0e423b-a559-4314-9a6e-7864e9702265');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch=09, loss=0.6177, step=600000: 100%|##########| 118/118 [00:14<00:00,  7.94it/s]\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class AutoencoderArgs:\n",
        "    # architecture\n",
        "    latent_dim_size: int = 5\n",
        "    hidden_dim_size: int = 128\n",
        "\n",
        "    # data / training\n",
        "    dataset: Literal[\"MNIST\", \"CELEB\"] = \"MNIST\"\n",
        "    batch_size: int = 512\n",
        "    epochs: int = 10\n",
        "    lr: float = 1e-3\n",
        "    betas: tuple[float, float] = (0.5, 0.999)\n",
        "\n",
        "    # logging\n",
        "    use_wandb: bool = False\n",
        "    wandb_project: str | None = \"day5-autoencoder\"\n",
        "    wandb_name: str | None = None\n",
        "    log_every_n_steps: int = 250\n",
        "\n",
        "\n",
        "class AutoencoderTrainer:\n",
        "    def __init__(self, args: AutoencoderArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True)\n",
        "        self.model = Autoencoder(\n",
        "            latent_dim_size=args.latent_dim_size,\n",
        "            hidden_dim_size=args.hidden_dim_size,\n",
        "        ).to(device)\n",
        "        self.optimizer = t.optim.Adam(self.model.parameters(), lr=args.lr, betas=args.betas)\n",
        "        self.step = 0\n",
        "        self.loss = nn.MSELoss()\n",
        "\n",
        "    def training_step(self, img: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Performs a training step on the batch of images in `img`. Returns the loss. Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        # pass imgs to model\n",
        "\n",
        "        pred = self.model.forward(img)\n",
        "        loss = self.loss(pred, img)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        self.step += img.shape[0]\n",
        "\n",
        "        if args.use_wandb:\n",
        "          wandb.log(dict(loss=loss), step=self.step)\n",
        "\n",
        "        return loss\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluates model on holdout data, either logging to weights & biases or displaying output.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        output = self.model(HOLDOUT_DATA)\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output.cpu().numpy()]}, step=self.step)\n",
        "        else:\n",
        "            display_data(t.concat([HOLDOUT_DATA, output]), nrows=2, title=\"AE reconstructions\")\n",
        "\n",
        "    def train(self) -> Autoencoder:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        # YOUR CODE HERE - iterate over epochs, and train your model\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "\n",
        "            progress_bar = tqdm(self.trainloader, total=int(len(self.trainloader)), ascii=True)\n",
        "\n",
        "            for imgs, _ in progress_bar:\n",
        "                imgs = imgs.to(device)\n",
        "                loss = self.training_step(imgs)\n",
        "                progress_bar.set_description(f\"{epoch=:02d}, {loss=:.4f}, step={self.step:05d}\")\n",
        "                #pbar.set_postfix(loss=f\"{loss:.3f}\", ex_seen=f\"{self.step=:06}\")\n",
        "                # log every 250 steps\n",
        "                if self.step % self.args.log_every_n_steps == 0:\n",
        "\n",
        "                  self.log_samples()\n",
        "\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model\n",
        "\n",
        "\n",
        "args = AutoencoderArgs(use_wandb=False)\n",
        "trainer = AutoencoderTrainer(args)\n",
        "autoencoder = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICTgcCII6eju"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class AutoencoderTrainer:\n",
        "    def __init__(self, args: AutoencoderArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True)\n",
        "        self.model = Autoencoder(\n",
        "            latent_dim_size=args.latent_dim_size,\n",
        "            hidden_dim_size=args.hidden_dim_size,\n",
        "        ).to(device)\n",
        "        self.optimizer = t.optim.Adam(self.model.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step(self, img: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Performs a training step on the batch of images in `img`. Returns the loss. Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        # Compute loss, backprop on it, and perform an optimizer step\n",
        "        img_reconstructed = self.model(img)\n",
        "        loss = nn.MSELoss()(img, img_reconstructed)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Increment step counter and log to wandb if enabled\n",
        "        self.step += img.shape[0]\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log(dict(loss=loss), step=self.step)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluates model on holdout data, either logging to weights & biases or displaying output.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        output = self.model(HOLDOUT_DATA)\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output.cpu().numpy()]}, step=self.step)\n",
        "        else:\n",
        "            display_data(t.concat([HOLDOUT_DATA, output]), nrows=2, title=\"AE reconstructions\")\n",
        "\n",
        "    def train(self) -> Autoencoder:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            # Iterate over training data, performing a training step for each batch\n",
        "            progress_bar = tqdm(self.trainloader, total=int(len(self.trainloader)), ascii=True)\n",
        "            for img, label in progress_bar:  # remember that label is not used\n",
        "                img = img.to(device)\n",
        "                loss = self.training_step(img)\n",
        "                progress_bar.set_description(f\"{epoch=:02d}, {loss=:.4f}, step={self.step:05d}\")\n",
        "                if self.step % self.args.log_every_n_steps == 0:\n",
        "                    self.log_samples()\n",
        "\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPGRJRHP6eju"
      },
      "source": [
        "After the first epoch, you should be able to get output of the following quality:\n",
        "\n",
        "<br>\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ae-epoch-1.png\" width=\"750\">\n",
        "\n",
        "And by the 10th epoch, you should be getting something like this:\n",
        "\n",
        "<br>\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ae-epoch-10.png\" width=\"750\">\n",
        "\n",
        "Note how the reconstructions it's mixing up features for some of the numbers - for instance, the 5 seems to have been partly reconstructed as a 3. But overall, it seems pretty accurate!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-scT4rm6eju"
      },
      "source": [
        "## Latent space of an autoencoder\n",
        "\n",
        "We'll now return to the issue we mentioned briefly earlier - how to generate output? We might want to generate output by just producing random noise and passing it through our decoder, but this raises a question - how should we interpret the latent space between our encoder and decoder?\n",
        "\n",
        "We can try and plot the outputs produced by the decoder over a range. The code below does this (you might have to adjust it slightly depending on how you've implemented your autoencoder):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SDbZRgf6ejv"
      },
      "outputs": [],
      "source": [
        "def create_grid_of_latents(\n",
        "    model, interpolation_range=(-1, 1), n_points=11, dims=(0, 1)\n",
        ") -> Float[Tensor, \"rows_x_cols latent_dims\"]:\n",
        "    \"\"\"Create a tensor of zeros which varies along the 2 specified dimensions of the latent space.\"\"\"\n",
        "    grid_latent = t.zeros(n_points, n_points, model.latent_dim_size, device=device)\n",
        "    x = t.linspace(*interpolation_range, n_points)\n",
        "    grid_latent[..., dims[0]] = x.unsqueeze(-1)  # rows vary over dim=0\n",
        "    grid_latent[..., dims[1]] = x  # cols vary over dim=1\n",
        "    return grid_latent.flatten(0, 1)  # flatten over (rows, cols) into a single batch dimension\n",
        "\n",
        "\n",
        "grid_latent = create_grid_of_latents(autoencoder, interpolation_range=(-3, 3))\n",
        "\n",
        "# Map grid latent through the decoder (note we need to flatten (rows, cols) into a single batch dim)\n",
        "output = autoencoder.decoder(grid_latent)\n",
        "\n",
        "# Visualize the output\n",
        "utils.visualise_output(output, grid_latent, title=\"Autoencoder latent space visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW7oub_W6ejv"
      },
      "source": [
        "This code generates images from a vector in the latent space which is zero in all directions, except for the first two dimensions. (Note, we normalize with `(0.3081, 0.1307)` in the code above because this is the mean and standard deviation of the MNIST dataset - see discussion [here](https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457).)\n",
        "\n",
        "This is ... pretty underwhelming. Some of these shapes seem legible in some regions (e.g. in the demo example on Streamlit we have some patchy but still recognisable 9s, 3s, 0s and 4s in the corners of the latent space), but a lot of the space doesn't look like any recognisable number. For example, much of the middle region is just an unrecognisable blob. Using the default interpolation range of `(-1, 1)` makes things look even worse. And this is a problem, since our goal is to be able to randomly sample points inside this latent space and use them to generate output which resembles the MNIST dataset - this is our true goal, not accurate reconstruction.\n",
        "\n",
        "Why does this happen? Well unfortunately, the model has no reason to treat the latent space in any meaningful way. It might be the case that almost all the images are embedded into a particular subspace of the latent space, and so the encoder only gets trained on inputs in this subspace. To further illustrate this, the code below feeds MNIST data into your encoder, and plots the resulting latent vectors (projected along the first two latent dimensions). Note that there are some very high-density spots, and other much lower-density spots. So it stands to reason that we shouldn't expect the decoder to be able to produce good output for all points in the latent space (especially when we're using a 5-dimensional latent space rather than just 2-dimensional as visualised below - we can imagine that 5D latent space would have significantly more \"dead space\").\n",
        "\n",
        "To emphasise, we're not looking for a crisp separation of digits here. We're only plotting 2 of 5 dimensions, it would be a coincidence if they were cleanly separated. We're looking for efficient use of the space, because this is likely to lead to an effective generator when taken out of the context of the discriminator. We don't really see that here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F1LLu-86ejv"
      },
      "outputs": [],
      "source": [
        "# Get a small dataset with 5000 points\n",
        "small_dataset = Subset(get_dataset(\"MNIST\"), indices=range(0, 5000))\n",
        "imgs = t.stack([img for img, label in small_dataset]).to(device)\n",
        "labels = t.tensor([label for img, label in small_dataset]).to(device).int()\n",
        "\n",
        "# Get the latent vectors for this data along first 2 dims, plus for the holdout data\n",
        "latent_vectors = autoencoder.encoder(imgs)[:, :2]\n",
        "holdout_latent_vectors = autoencoder.encoder(HOLDOUT_DATA)[:, :2]\n",
        "\n",
        "# Plot the results\n",
        "utils.visualise_input(latent_vectors, labels, holdout_latent_vectors, HOLDOUT_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rYYy75D6ejv"
      },
      "source": [
        "## Variational Autoencoders\n",
        "\n",
        "Variational autoencoders try and solve the problem posed by autoencoders: how to actually make the latent space meaningful, such that you can generate output by feeding a $N(0, 1)$ random vector into your model's decoder?\n",
        "\n",
        "The key perspective shift is this: **rather than mapping the input into a fixed vector, we map it into a distribution**. The way we learn a distribution is very similar to the way we learn our fixed inputs for the autoencoder, i.e. we have a bunch of linear or convolutional layers, our input is the original image, and our output is the tuple of parameters $(\\mu(\\boldsymbol{x}), \\Sigma(\\boldsymbol{x}))$ (as a trivial example, our VAE learning a distribution $\\mu(\\boldsymbol{x})=z(\\boldsymbol{x})$, $\\Sigma(\\boldsymbol{x})=0$ is equivalent to our autoencoder learning the function $z(\\boldsymbol{x})$ as its encoder).\n",
        "\n",
        "From this [TowardsDataScience](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73) article:\n",
        "\n",
        "> Due to overfitting, the latent space of an autoencoder can be extremely irregular (close points in latent space can give very *different* decoded data, some point of the latent space can give *meaningless* content once decoded) and, so, we can’t really define a *generative* process that simply consists to sample a point from the *latent space* and make it go through the decoder to get new data. *Variational autoencoders* (VAEs) are autoencoders that tackle the problem of the latent space irregularity by making the encoder return a *distribution over the latent space* instead of a single point and by adding in the loss function a *regularisation* term over that returned distribution in order to ensure a better *organisation* of the latent space.\n",
        "\n",
        "Or, in fewer words:\n",
        "\n",
        "> **A variational autoencoder can be defined as being an autoencoder whose training is regularised to avoid overfitting and ensure that the latent space has good properties that enable generative process.**\n",
        "\n",
        "At first, this idea of mapping to a distribution sounds like a crazy hack - why on earth does it work? This diagram should help convey some of the intuitions:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/vae-scatter-one.png\" width=\"800\">\n",
        "\n",
        "With our encoder, there was nothing incentivising us to make full and meaningful use of the latent space. It's hypothetically possible that our network was mapping all the inputs to some very small subspace and reconstructing them with perfect fidelity. This wouldn't have required numbers with different features to be far apart from each other in the latent space, because even if they are close together no information is lost. See the first image above.\n",
        "\n",
        "But with our variational autoencoder, each MNIST image produces a **sample** from the latent space, with a certain mean and variance. This means that, when two numbers look very different, their latent vectors are forced apart - if the means were close together then the decoder wouldn't be able to reconstruct them.\n",
        "\n",
        "Another nice property of using random latent vectors is that the entire latent space will be meaningful. For instance, with autoencoders there is no reason why we should expect the linear interpolation between two points in the latent space to have meaningful decodings. The decoder output *will* change continuously as we continuously vary the latent vector, but that's about all we can say about it. However, if we use a variational autoencoder, we don't have this problem. The output of a linear interpolation between the cluster of $2$s and cluster of $7$s will be ***\"a symbol which pattern-matches to the family of MNIST digits, but has equal probability to be interpreted as a $2$ or a $7$\"***, and this is indeed what we find.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/vae-scatter-two.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugBPiDgH6ejv"
      },
      "source": [
        "### Reparameterisation trick\n",
        "\n",
        "One question that might have occurred to you - how can we perform backward passes through our network? We know how to differentiate with respect to the inputs to a function, but how can we differentiate wrt the parameters of a probability distribution from which we sample our vector? The solution is to convert our random sampling into a function, by introducing an extra parameter $\\epsilon$. We sample $\\epsilon$ from the standard normal distribution, and then express $\\boldsymbol{z}$ as a deterministic function of $\\mu$, $\\sigma$ and $\\epsilon$:\n",
        "\n",
        "$$\n",
        "z = \\mu + \\sigma \\odot \\epsilon\n",
        "$$\n",
        "\n",
        "where $\\odot$ is a notation meaning pointwise product, i.e. $z_i = \\mu_i + \\sigma_i \\epsilon_i$. Intuitively, we can think of this as follows: when there is randomness in the process that generates the output, there is also randomness in the derivative of the output wrt the input, so **we can get a value for the derivative by sampling from this random distribution**. If we average over enough samples, this will give us a valid gradient for training.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/vae-reparam-l.png\" width=\"800\">\n",
        "\n",
        "Note that if we have $\\sigma_\\theta(\\boldsymbol{x})=0$ for all $\\boldsymbol{x}$, the VAE reduces to an autoencoder (since the latent vector $z = \\mu_\\theta(\\boldsymbol{x})$ is once again a deterministic function of $\\boldsymbol{x}$). This is why it's important to add a KL-divergence term to the loss function, to make sure this doesn't happen. It's also why, if you print out the average value of $\\sigma(\\boldsymbol{x})$ while training, you'll probably see it stay below 1 (it's being pulled towards 1 by the KL-divergence loss, **and** pulled towards 0 by the reconstruction loss).\n",
        "\n",
        "---\n",
        "\n",
        "Before you move on to implementation details, there are a few questions below designed to test your understanding. They are based on material from this section, as well as the [KL divergence LessWrong post](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence). You might also find [this post](https://lilianweng.github.io/posts/2018-08-12-vae/#vae-variational-autoencoder) on VAEs from the readings helpful.\n",
        "\n",
        "<details>\n",
        "<summary>State in your own words why we need the reparameterization trick in order to train our network.</summary>\n",
        "\n",
        "The following would work:\n",
        "\n",
        "We can't backpropagate through random processes like $z_i \\sim N(\\mu_i(\\boldsymbol{x}), \\sigma_i(\\boldsymbol{x})^2)$, but if we instead write $\\boldsymbol{z}$ as a deterministic function of $\\mu_i(\\boldsymbol{x})$ and $\\sigma_i(\\boldsymbol{x})$ with the randomness coming from some some auxiliary random variable $\\epsilon$, then we can differentiate our loss function wrt the inputs, and train our network.\n",
        "\n",
        "<!-- Our encoder works by generating parameters and then using those parameters to sample latent vectors $\\boldsymbol{z}$ (i.e. a **stochastic process**). Our decoder is deterministic; it just maps our latent vectors $\\boldsymbol{z}$ to fixed outputs $x'$. The stochastic part is the problem; we can't backpropagate gradients through random functions. However, instead of just writing $\\boldsymbol{z} \\sim N(\\mu_\\theta(\\boldsymbol{x}), \\sigma_\\theta(\\boldsymbol{x})^2I)$, we can write $\\boldsymbol{z}$ as a deterministic function of its inputs: $z = g(\\theta, x, \\epsilon)$, where $\\theta$ are the parameters of the distribution, $\\boldsymbol{x}$ is the input, and $\\epsilon$ is a randomly sampled value. We can then backpropagate through the network. -->\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Summarize in one sentence what concept we're capturing when we measure the KL divergence D(P||Q) between two distributions.</summary>\n",
        "\n",
        "Any of the following would work - $D(P||Q)$ is...\n",
        "\n",
        "* How much information is lost if the distribution $Q$ is used to represent $P$.\n",
        "* The quality of $Q$ as a probabilistic model for $P$ (where lower means $Q$ is a better model).\n",
        "* How close $P$ and $Q$ are, with $P$ as the actual ground truth.\n",
        "* How much evidence you should expect to get for hypothesis $P$ over $Q$, when $P$ is the actual ground truth.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIL_WZ1_6ejv"
      },
      "source": [
        "## Building a VAE\n",
        "\n",
        "For your final exercise of this section, you'll build a VAE and run it to produce the same kind of output you did in the previous section. Luckily, this won't require much tweaking from your encoder architecture. The decoder can stay unchanged; there are just two big changes you'll need to make:\n",
        "\n",
        "### Probabilistic encoder\n",
        "\n",
        "Rather than your encode outputting a latent vector $\\boldsymbol{z}$, it should output a mean $\\mu$ and standard deviation $\\sigma$; both vectors of dimension `latent_dim_size`. We then sample our latent vector $\\boldsymbol{z}$ using $z_i = \\mu_i + \\sigma_i \\cdot \\epsilon_i$. Note that this is equivalent to $z = \\mu + \\Sigma \\epsilon$ as shown in the diagram above, but where we assume $\\Sigma$ is a diagonal matrix (i.e. the auxiliary random variables $\\epsilon$ which we're sampling are independent). This is the most common approach taken in situations like these.\n",
        "\n",
        "Note - we actually calculate `mu` and `logsigma` rather than `mu` and `sigma` - we get `sigma = logsigma.exp()` from this. This is a more numerically stable method.\n",
        "\n",
        "How exactly should this work in your model's architecture? You can replace the final linear layer (which previously just gave you the latent vector) with two linear layers returning `mu` and `logsigma`, then you calculate `z` from these (and from a randomly sampled `epsilon`). If you want, you can combine the two linear layers into one linear layer with `out_channels=2*latent_dim_size`, then rearrange to split this up into `mu` and `logsigma` (this is what we do in the solution, and in the diagram below).\n",
        "\n",
        "You should also return the parameters `mu` and `logsigma` in your VAE's forward function, as well as the final output - the reasons for this will become clear below.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ae-before-after-fixed.png\" width=\"750\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi8C5uEM6ejw"
      },
      "source": [
        "### Exercise - build your VAE\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Build your VAE. It should be identical to the autoencoder you built above, except for the changes made at the end of the encoder (outputting mean and std rather than a single latent vector; this latent vector needs to get generated via the reparameterisation trick).\n",
        "\n",
        "For consistency with code that will come later, we recommend having your `model.encoder` output be of shape `(2, batch_size, latent_dim_size)`, where `output[0]` are the mean vectors $\\mu$ and `output[1]` are the log standard deviation vectors $\\log \\sigma$. The tests below will check this.\n",
        "\n",
        "We've also given you a `sample_latent_vector` method - this should return the output of your encoder, but in the form of sampled latent vectors $\\mu$ and $\\sigma$ rather than the deterministic output `model.encoder(x)` of shape `(2, batch_size, latent_dim_size)`. This will be a useful method for later (and you can use it in your implementation of `forward`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSMa_PSF6ejw"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    encoder: nn.Module\n",
        "    decoder: nn.Module\n",
        "\n",
        "    def __init__(self, latent_dim_size: int, hidden_dim_size: int):\n",
        "        super().__init__()\n",
        "        self.encoder = ...\n",
        "        self.decoder = ...\n",
        "\n",
        "    def sample_latent_vector(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Passes `x` through the encoder, and returns a tuple of (sampled latent vector, mean, log std dev).\n",
        "        This function can be used in `forward`, but also used on its own to generate samples for\n",
        "        evaluation.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Passes `x` through the encoder and decoder. Returns the reconstructed input, as well as mu and logsigma.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_vae(VAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPwQ37eo6ejw"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class VAE(nn.Module):\n",
        "    encoder: nn.Module\n",
        "    decoder: nn.Module\n",
        "\n",
        "    def __init__(self, latent_dim_size: int, hidden_dim_size: int):\n",
        "        super().__init__()\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.hidden_dim_size = hidden_dim_size\n",
        "        self.encoder = Sequential(\n",
        "            Conv2d(1, 16, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            Conv2d(16, 32, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            Rearrange(\"b c h w -> b (c h w)\"),\n",
        "            Linear(7 * 7 * 32, hidden_dim_size),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim_size, latent_dim_size * 2),\n",
        "            Rearrange(\"b (n latent_dim) -> n b latent_dim\", n=2),  # makes it easier to separate mu and sigma\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            Linear(latent_dim_size, hidden_dim_size),\n",
        "            ReLU(),\n",
        "            Linear(hidden_dim_size, 7 * 7 * 32),\n",
        "            ReLU(),\n",
        "            Rearrange(\"b (c h w) -> b c h w\", c=32, h=7, w=7),\n",
        "            ConvTranspose2d(32, 16, 4, stride=2, padding=1),\n",
        "            ReLU(),\n",
        "            ConvTranspose2d(16, 1, 4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "    def sample_latent_vector(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Passes `x` through the encoder, and returns a tuple of (sampled latent vector, mean, log std dev).\n",
        "        This function can be used in `forward`, but also used on its own to generate samples for\n",
        "        evaluation.\n",
        "        \"\"\"\n",
        "        mu, logsigma = self.encoder(x)\n",
        "        sigma = t.exp(logsigma)\n",
        "        z = mu + sigma * t.randn_like(sigma)\n",
        "        return z, mu, logsigma\n",
        "\n",
        "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Passes `x` through the encoder and decoder. Returns the reconstructed input, as well as mu and logsigma.\n",
        "        \"\"\"\n",
        "        z, mu, logsigma = self.sample_latent_vector(x)\n",
        "        x_prime = self.decoder(z)\n",
        "        return x_prime, mu, logsigma\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmbswBTs6ejw"
      },
      "source": [
        "You can also do the previous thing (compare your architecture to the solution), but this might be less informative if your model doesn't implement the 2-variables approach in the same way as the solution does."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLmvyohM6ejw"
      },
      "source": [
        "## New loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_7W80SS6ejw"
      },
      "source": [
        "We're no longer calculating loss simply as the reconstruction error between the original input $\\boldsymbol{x}$ and our decoder's output $\\boldsymbol{x}'$. Instead, we have a new loss function. For a fixed input $\\boldsymbol{x}$, our loss is:\n",
        "\n",
        "$$\n",
        "L_{\\mathrm{VAE}}(\\boldsymbol{x}, \\boldsymbol{x}') = \\|\\boldsymbol{x} - \\boldsymbol{x}'\\|^2 + D_{\\mathrm{KL}}(N(\\mu, \\sigma^2) || N(0, 1))\n",
        "$$\n",
        "\n",
        "The first term is just the regular reconstruction loss we used for our autoencoder. The second term is the KL divergence between the generator's output distribution and the standard normal distribution, and it's designed to penalize the generator for producing latent vectors which are far from the standard normal distribution.\n",
        "\n",
        "There is a much deeper way to understand this loss function, which also connects to intuitions around diffusion models and other more complicated generative models. For more on this, see the section at the end. For now, we'll move on to the practicalities of implementing this loss function.\n",
        "\n",
        "The KL divergence of these two distributions has a closed form expression, which is given by:\n",
        "\n",
        "$$\n",
        "D_{KL}(N(\\mu, \\sigma^2) || N(0, 1)) = \\frac{\\sigma^2 + \\mu^2 - 1}{2} - \\log{\\sigma}\n",
        "$$\n",
        "\n",
        "This is why it was important to output `mu` and `logsigma` in our forward functions, so we could compute this expression! (It's easier to use `logsigma` than `sigma` when evaluating the expression above, for stability reasons).\n",
        "\n",
        "We won't ask you to derive this formula, because it requires understanding of **differential entropy** which is a topic we don't need to get into here. However, it is worth doing some sanity checks, e.g. plot some graphs and convince yourself that this expression is larger as $\\mu$ is further away from 0, or $\\sigma$ is further away from 1.\n",
        "\n",
        "<details>\n",
        "<summary>Derivation of KL divergence result</summary>\n",
        "\n",
        "If you'd like a derivation, you can find one [here](https://statproofbook.github.io/P/norm-kl), where a slightly more general form of the KL divergence between two normal distributions is derived. Our result is a special case of this, for $\\mu_2 = 0$, $\\sigma_2^2 = 1$.\n",
        "In this derivation, they use $\\langle \\cdot \\rangle_{p(x)}$ to denote the expectation of a function under the distribution $p$, i.e. $\\langle f(x) \\rangle_{p(x)} = \\mathbb{E}_{p} [ f(x) ] = \\int_{\\mathcal{X}} p(x) f(x) \\; dx$.\n",
        "A more general result for multi-variate normal distributions with different means and covariances\n",
        "can be found [here](https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/).\n",
        "</details>\n",
        "\n",
        "One can interpret this as the penalty term to make the latent space meaningful. If all the latent vectors $\\boldsymbol{z}$ you generate have each component $z_i$ normally distributed with mean 0, variance 1 (and we know they're independent because our $\\epsilon_i$ we used to generate them are independent), then there will be no gaps in your latent space where you produce weird-looking output (like we saw in our autoencoder plots from the previous section). You can try training your VAE without this term, and it might do okay at reproducing $\\boldsymbol{x}$, but it will perform much worse when it comes time to use it for generation. Again, you can quantify this by encoding some input data and projecting it onto the first two dimensions. When you include this term you should expect to see a nice regular cloud surrounding the origin, but without this term you might see some irregular patterns or blind spots:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/vae_latent_space.png\" width=\"700\">\n",
        "\n",
        "Once you've computed both of these loss functions, you should add them together and perform gradient descent on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advaK-KL6ejw"
      },
      "source": [
        "### Beta-VAEs\n",
        "\n",
        "The Beta-VAE is a very simple extension of the VAE, with a different loss function: we multiply the KL Divergence term by a constant $\\beta$. This helps us balance the two different loss terms. Here, we've given you the default value of $\\beta = 0.1$ rather than using $\\beta = 1$ (which is implicit when we use regular VAEs rather than beta-VAEs).\n",
        "\n",
        "As a general comment on tuning hyperparameters like $\\beta$, it's important to sweep over ranges of different values and know how to tell when one of them is dominating the model's behaviour. In this particular case, $\\beta$ being too large means your model will too heavily prioritize having its latent vectors' distribution equal to the standard normal distribution, to the point where it might essentially lose all structure in the data and ignore accurate reconstruction. On the other hand, $\\beta$ being too small means we just reduce to the autoencoder case where the model has no incentive to make meaningful use of the latent space. Weights and biases hyperparameter searches are a good tool for sweeping over ranges and testing the results, but they'll only work if you log the relevant data / output and know how to interpret it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVWp7wlp6ejw"
      },
      "source": [
        "### Exercise - write your VAE training loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-30 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should write and run your training loop below. This will involve a lot of recycled code from the corresponding `Autoencoder` exercise - in fact, depending on how you implemented the `train` method before, you might literally be able to copy and paste that method here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8KWzYFJ6ejw"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class VAEArgs(AutoencoderArgs):\n",
        "    wandb_project: str | None = \"day5-vae-mnist\"\n",
        "    beta_kl: float = 0.1\n",
        "\n",
        "\n",
        "class VAETrainer:\n",
        "    def __init__(self, args: VAEArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True, num_workers=8)\n",
        "        self.model = VAE(\n",
        "            latent_dim_size=args.latent_dim_size,\n",
        "            hidden_dim_size=args.hidden_dim_size,\n",
        "        ).to(device)\n",
        "        self.optimizer = t.optim.Adam(self.model.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step(self, img: Tensor):\n",
        "        \"\"\"\n",
        "        Performs a training step on the batch of images in `img`. Returns the loss. Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluates model on holdout data, either logging to weights & biases or displaying output inline.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        output = self.model(HOLDOUT_DATA)[0]\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output.cpu().numpy()]}, step=self.step)\n",
        "        else:\n",
        "            display_data(t.concat([HOLDOUT_DATA, output]), nrows=2, title=\"VAE reconstructions\")\n",
        "\n",
        "    def train(self) -> VAE:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        # YOUR CODE HERE - iterate over epochs, and train your model\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A43iyNd6ejw"
      },
      "outputs": [],
      "source": [
        "args = VAEArgs(latent_dim_size=5, hidden_dim_size=100, use_wandb=False)\n",
        "trainer = VAETrainer(args)\n",
        "vae = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQY3S5gO6ejw"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class VAEArgs(AutoencoderArgs):\n",
        "    wandb_project: str | None = \"day5-vae-mnist\"\n",
        "    beta_kl: float = 0.1\n",
        "\n",
        "\n",
        "class VAETrainer:\n",
        "    def __init__(self, args: VAEArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True, num_workers=8)\n",
        "        self.model = VAE(\n",
        "            latent_dim_size=args.latent_dim_size,\n",
        "            hidden_dim_size=args.hidden_dim_size,\n",
        "        ).to(device)\n",
        "        self.optimizer = t.optim.Adam(self.model.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step(self, img: Tensor):\n",
        "        \"\"\"\n",
        "        Performs a training step on the batch of images in `img`. Returns the loss. Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        # Get the different loss components, as well as the total loss\n",
        "        img = img.to(device)\n",
        "        img_reconstructed, mu, logsigma = self.model(img)\n",
        "        reconstruction_loss = nn.MSELoss()(img, img_reconstructed)\n",
        "        kl_div_loss = (0.5 * (mu**2 + t.exp(2 * logsigma) - 1) - logsigma).mean() * self.args.beta_kl\n",
        "        loss = reconstruction_loss + kl_div_loss\n",
        "\n",
        "        # Backprop on the loss, and step with optimizers\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Log various values, and also increment `self.step`\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log(\n",
        "                dict(\n",
        "                    reconstruction_loss=reconstruction_loss.item(),\n",
        "                    kl_div_loss=kl_div_loss.item(),\n",
        "                    mean=mu.mean(),\n",
        "                    std=t.exp(logsigma).mean(),\n",
        "                    total_loss=loss.item(),\n",
        "                ),\n",
        "                step=self.step,\n",
        "            )\n",
        "        return loss\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluates model on holdout data, either logging to weights & biases or displaying output inline.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        output = self.model(HOLDOUT_DATA)[0]\n",
        "        if self.args.use_wandb:\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output.cpu().numpy()]}, step=self.step)\n",
        "        else:\n",
        "            display_data(t.concat([HOLDOUT_DATA, output]), nrows=2, title=\"VAE reconstructions\")\n",
        "\n",
        "    def train(self) -> VAE:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            # Iterate over training data, performing a training step for each batch\n",
        "            progress_bar = tqdm(self.trainloader, total=int(len(self.trainloader)), ascii=True)\n",
        "            for img, label in progress_bar:  # remember that label is not used\n",
        "                img = img.to(device)\n",
        "                loss = self.training_step(img)\n",
        "                self.step += 1\n",
        "                progress_bar.set_description(f\"{epoch=:02d}, {loss=:.4f}, batches={self.step:05d}\")\n",
        "                if self.step % self.args.log_every_n_steps == 0:\n",
        "                    self.log_samples()\n",
        "\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model\n",
        "\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU-U2XzW6ejw"
      },
      "source": [
        "You might be disappointed when comparing your VAE's reconstruction to the autoencoder, since it's likely to be worse. However, remember that the focus of VAEs is in better generation, not reconstruction. To test it's generation, let's produce some plots of latent space like we did for the autoencoder.\n",
        "\n",
        "First, we'll visualize the latent space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nePJ0g3M6ejw"
      },
      "outputs": [],
      "source": [
        "grid_latent = create_grid_of_latents(vae, interpolation_range=(-1, 1))\n",
        "output = vae.decoder(grid_latent)\n",
        "utils.visualise_output(output, grid_latent, title=\"VAE latent space visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bLAP3HQ6ejx"
      },
      "source": [
        "which should look a lot better! The vast majority of images in this region should be recognisable digits. In this case, starting from the top-left and going clockwise, we can see 0s, 6s, 5s, 1s, 9s and 8s. Even the less recognisable regions seem like they're just interpolations between digits which are recognisable (which is something we should expect to happen given our VAE's output is continuous).\n",
        "\n",
        "Now for the scatter plot to visualize our input space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFFr_4QA6ejx"
      },
      "outputs": [],
      "source": [
        "small_dataset = Subset(get_dataset(\"MNIST\"), indices=range(0, 5000))\n",
        "imgs = t.stack([img for img, label in small_dataset]).to(device)\n",
        "labels = t.tensor([label for img, label in small_dataset]).to(device).int()\n",
        "\n",
        "# We're getting the mean vector, which is the [0]-indexed output of the encoder\n",
        "latent_vectors = vae.encoder(imgs)[0, :, :2]\n",
        "holdout_latent_vectors = vae.encoder(HOLDOUT_DATA)[0, :, :2]\n",
        "\n",
        "utils.visualise_input(latent_vectors, labels, holdout_latent_vectors, HOLDOUT_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50bOhpds6ejx"
      },
      "source": [
        "The range of the distribution looks much more like a standard normal distribution (most points are in `[-2, 2]` whereas in the previous plot the range was closer to `[-10, 10]`). There are also no longer any large gaps in the latent space that you wouldn't find in the corresponding standard normal distribution.\n",
        "\n",
        "To emphasize - don't be disheartened if your *reconstructions of the original MNIST images* don't look as faithful for your VAE than they did for your encoder. Remember the goal of these architectures isn't to reconstruct images faithfully, it's to generate images from samples in the latent dimension. This is the basis on which you should compare your models to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho8MzlO86ejx"
      },
      "source": [
        "## A deeper dive into the maths of VAEs\n",
        "\n",
        "If you're happy with the loss function as described in the section above, then you can move on from here. If you'd like to take a deeper dive into the mathematical justifications of this loss function, you can read the following content. I'd consider it pretty essential in laying the groundwork for understanding diffusion models, and most kinds of generative image models (which we might dip into later in this course).\n",
        "\n",
        "> *Note - this section is meant to paint more of an intuitive picture than deal with formal and rigorous mathematics, which is why we'll play fairly fast and loose with things like limit theorems and whether we can swap around integrals and expected values. This can be formalized further, but we'll leave that for other textbooks.*\n",
        "\n",
        "Firstly, let's ignore the encoder, and suppose we're just starting from a latent vector $\\boldsymbol{z} \\sim p(z) = N(0, I)$. We can parameterize a **probabilistic decoder** as $p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})$, i.e. a way of mapping from latent vectors $z$ to a distribution over images $\\boldsymbol{x}$. To use it as a decoder, we just sample a latent vector then sample from the resulting probability distribution our decoder gives us. Imagine this as a factory line: the latent vector $\\boldsymbol{z}$ is some kind of compressed blueprint for our image, and our decoder is a way of reconstructing images from this information.\n",
        "\n",
        "On this factory line, the probability of producing any given image $\\boldsymbol{x}$ can be found from integrating over the possible latent vectors $\\boldsymbol{z}$ which could have produced it:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p(\\boldsymbol{x})&=\\int_z p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z}) p(\\boldsymbol{z}) \\; d \\boldsymbol{z} \\\\\n",
        "&= \\mathbb{E}_{\\boldsymbol{z} \\sim p(\\boldsymbol{z})}\\big[p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})\\big]\n",
        "\\end{aligned}\n",
        "$$\n",
        "What if we estimate this value over random samples $x_i \\sim \\hat{p}(\\boldsymbol{x})$ from our dataset? We could perform gradient ascent on $\\theta$ using this estimate to find a decoder $p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})$ that makes this estimate high, in other words a factory line that is *likely to produce images like the ones in our dataset*. Then we're done - right?\n",
        "\n",
        "Unfortunately, it's not that easy. Evaluating this integral would be computationally intractible, because we would have to sample over all possible values for the latent vectors $\\boldsymbol{z}$:\n",
        "$$\n",
        "\\theta^*=\\underset{\\theta}{\\operatorname{argmax}}\\; \\mathbb{E}_{x \\sim \\hat{p}(\\boldsymbol{x}),\\, \\boldsymbol{z} \\sim p(\\boldsymbol{z})}\\big[p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})\\big]\n",
        "$$\n",
        "In our ideal factory line, for any given image $\\boldsymbol{x}$ there's probably only a small cluster of latent vectors $\\boldsymbol{z}$ that could have produced it, and it's that small cluster that we should be concentrating our probability mass over. Without this, it'll take an exponentially long time to get full sampling coverage of the latent space of $\\boldsymbol{z}$.\n",
        "\n",
        "This is where our encoder function $q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})$ comes in! It helps concentrate our guess for $\\boldsymbol{z}$ for any given $\\boldsymbol{x}$, essentially telling us **which latent vectors were likely to have produced the image $\\boldsymbol{x}$**. We can now replace our original integral with the following:\n",
        "\n",
        "<!-- <img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/vae-graphical.png\" width=\"500\"> -->\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p(\\boldsymbol{x}) &=\\int q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x}) \\frac{p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z}) p(\\boldsymbol{z})}{q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})} \\;d \\boldsymbol{z}\\\\\n",
        "\\theta^*&=\\underset{\\theta}{\\operatorname{argmax}}\\; \\mathbb{E}_{\\boldsymbol{x} \\sim \\hat{p}(\\boldsymbol{x}), \\boldsymbol{z} \\sim q_\\phi(\\boldsymbol{z}\\mid \\boldsymbol{x})}\\left[\\frac{p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})p(\\boldsymbol{z})}{q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right] \\\\\n",
        "&=\\underset{\\theta}{\\operatorname{argmax}}\\; \\mathbb{E}_{\\boldsymbol{x} \\sim \\hat{p}(\\boldsymbol{x})}\\left[\\mathbb{E}_{\\boldsymbol{z} \\sim q_\\phi(\\boldsymbol{z}\\mid \\boldsymbol{x})}\\left[\\frac{p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})p(\\boldsymbol{z})}{q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right]\\right]\n",
        "\\end{aligned}\n",
        "$$\n",
        "Why is this easier? Well, now that we've rearranged it by introducing this $q_\\phi$ term, our distribution of $\\boldsymbol{z}$ is conditioned on $\\boldsymbol{x}$. So for any given sample $x_i$, we don't need to sample a huge number of latent vectors $\\boldsymbol{z}$ to estimate the inner expected value in the expression above - we can just sample from $q_\\phi(\\boldsymbol{z}\\mid \\boldsymbol{x_i})$, which already concentrates a lot of our probability mass for where $\\boldsymbol{z}$ should be.\n",
        "\n",
        "We now introduce an important quantity, called the **ELBO**, or **evidence lower-bound**. It is defined as the value inside the expectation in the expression above, but using log instead.\n",
        "$$\n",
        "\\operatorname{ELBO}(\\boldsymbol{x})=\\mathbb{E}_{\\boldsymbol{z} \\sim q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\left[\\log \\frac{p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})p(\\boldsymbol{z})}{q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right]\n",
        "$$\n",
        "Why do we call this the ELBO? Answer - because it's a lower bound for the quantity $\\log p(\\boldsymbol{x})$, which we call the **evidence**. The proof for this being a lower bound comes from **Jensen's inequality**, which states that $\\mathbb{E}[f(X)] \\geq f(\\mathbb{E}[X])$ for any convex function $f$ (and $f(\\boldsymbol{x})=-\\log(\\boldsymbol{x})$ is convex).\n",
        "\n",
        "<!-- In fact,  [we can prove](https://lilianweng.github.io/posts/2018-08-12-vae/#loss-function-elbo) that the difference between $\\log p(\\boldsymbol{x})$ and the ELBO is equal to the KL divergence between the distribution $q_\\phi$ and the **posterior distribution** $p_\\theta(\\boldsymbol{z} \\mid \\boldsymbol{x})$ (the order of $\\boldsymbol{z}$ and $\\boldsymbol{x}$ have been swapped). KL divergence is always non-negative, hence the lower bound. -->\n",
        "\n",
        "<!-- $$\n",
        "\\log{p(\\boldsymbol{x})}=\\mathbb{E}_{\\mathbb{z} \\sim q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\left[\\log \\frac{p(\\boldsymbol{z}) p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right]+D_{\\mathrm{KL}}\\left(q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x}) \\,\\|\\, p_\\theta(\\boldsymbol{z} \\mid \\boldsymbol{x})\\right)\n",
        "$$ -->\n",
        "\n",
        "It turns out that by looking at log probs rather than probabilities, we can now rewrite the ELBO as something which looks a lot like our VAE loss function! $p_\\theta(\\boldsymbol{x} \\mid \\boldsymbol{z})$ is our decoder, $q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})$ is our encoder, and we train them jointly using gradient ascent on our estimate of the ELBO. For any given sample $x_i$, the value $\\operatorname{ELBO}(x_i)$ is estimated by sampling a latent vector $z_i \\sim q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x_i})$, and then performing gradient ascent on the ELBO, which can be rewritten as:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\operatorname{ELBO}(\\boldsymbol{x}) & =\\mathbb{E}_{\\mathbb{z} \\sim q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x} \\mid \\boldsymbol{z}) + \\log \\frac{p(\\boldsymbol{z})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\right] \\\\\n",
        "& =\\underbrace{\\mathbb{E}_{\\boldsymbol{z} \\sim q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x} \\mid \\boldsymbol{z})\\right]}_{\\text {reconstruction loss}}-\\underbrace{D_{\\mathrm{KL}}\\left(q_{\\boldsymbol{\\phi}}(\\boldsymbol{z} \\mid \\boldsymbol{x}) \\,\\|\\, p(\\boldsymbol{z})\\right)}_{\\text {regularisation term}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "which if you tilt your head a bit, is just like our VAE loss function! To see this:\n",
        "\n",
        "* **The first term** is playing the role of reconstruction loss, since it's equivalent to the log probability that our image $x$ is perfectly reconstructed via the series of maps $\\boldsymbol{x} \\xrightarrow{\\text{encoder}} \\boldsymbol{z} \\xrightarrow{\\text{decoder}} \\boldsymbol{x}$. If we had perfect reconstruction then this value would be zero (which is its maximum value).\n",
        "* **The second term** is the KL divergence between $q_\\phi(\\boldsymbol{z} \\mid \\boldsymbol{x})$ and $p_{\\theta}(\\boldsymbol{z})$. The former is your own encoder's distribution of latent vectors which you may recall is $N(\\mu(\\boldsymbol{x}), \\sigma(\\boldsymbol{x})^2)$, and the latter was assumed to be the uniform distribution $N(0, I)$. This just reduces to our KL penalty term from earlier.\n",
        "\n",
        "The decoder used in our VAE isn't actually probabilistic $p_\\theta(\\cdot \\mid \\boldsymbol{z})$, it's deterministic (i.e. it's a map from latent vector $\\boldsymbol{z}$ to reconstructed input $\\boldsymbol{x}'$). But we can pretend that the decoder output is actually the mean of a probability distribution, and we're choosing this mean as the value of our reconstruction $\\boldsymbol{x}'$. The reconstruction loss term in the formula above will be smallest when this mean is close to the original value $\\boldsymbol{x}$ (because then $p_\\theta(\\cdot \\mid \\boldsymbol{z})$ will be a probability distribution centered around $\\boldsymbol{x}$). And it turns out that we can just replace this reconstruction loss with something that fulfils basically the same purpose (the $L_2$ penalty) - although we sometimes need to adjust these two terms (see $\\beta$-VAEs above).\n",
        "\n",
        "And that's the math of VAEs in a nutshell!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyhSS0xs6ejx"
      },
      "source": [
        "## Bonus exercises\n",
        "\n",
        "### PCA\n",
        "\n",
        "In the code earlier, we visualised our autoencoder / VAE output along the first two dimensions of the latent space. If each dimension is perfectly IID then we should expect this to get similar results to varying along any two arbitrarily chosen orthogonal directions. However, in practice you might find it an improvement to choose directions in a more principled way. One way to do this is to use **principal component analysis** (PCA). Can you write code to extract the PCA components from your model's latent space, and plot the data along these components?\n",
        "\n",
        "<details>\n",
        "<summary>Template (code for extracting PCA from the Autoencoder)</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "@t.inference_mode()\n",
        "def get_pca_components(\n",
        "    model: Autoencoder,\n",
        "    dataset: Dataset,\n",
        ") -> tuple[t.Tensor, t.Tensor]:\n",
        "    '''\n",
        "    Gets the first 2 principal components in latent space, from the data.\n",
        "\n",
        "    Returns:\n",
        "        pca_vectors: shape (2, latent_dim_size)\n",
        "            the first 2 principal component vectors in latent space\n",
        "        principal_components: shape (batch_size, 2)\n",
        "            components of data along the first 2 principal components\n",
        "    '''\n",
        "    # Unpack the (small) dataset into a single batch\n",
        "    imgs = t.stack([batch[0] for batch in dataset]).to(device)\n",
        "    labels = t.tensor([batch[1] for batch in dataset])\n",
        "\n",
        "    # Get the latent vectors\n",
        "    latent_vectors = model.encoder(imgs.to(device)).cpu().numpy()\n",
        "    if latent_vectors.ndim == 3: latent_vectors = latent_vectors[0] # useful for VAEs; see later\n",
        "\n",
        "    # Perform PCA, to get the principle component directions (& projections of data in these directions)\n",
        "    pca = PCA(n_components=2)\n",
        "    principal_components = pca.fit_transform(latent_vectors)\n",
        "    pca_vectors = pca.components_\n",
        "    return (\n",
        "        t.from_numpy(pca_vectors).float(),\n",
        "        t.from_numpy(principal_components).float(),\n",
        "    )\n",
        "```\n",
        "\n",
        "And then you can use this function in your `visualise_output` by replacing the code at the start with this:\n",
        "\n",
        "```python\n",
        "pca_vectors, principal_components = get_pca_components(model, dataset)\n",
        "\n",
        "# Constructing latent dim data by making two of the dimensions vary independently in the interpolation range\n",
        "x = t.linspace(*interpolation_range, n_points)\n",
        "grid_latent = t.stack([\n",
        "    einops.repeat(x, \"dim1 -> dim1 dim2\", dim2=n_points),\n",
        "    einops.repeat(x, \"dim2 -> dim1 dim2\", dim1=n_points),\n",
        "], dim=-1)\n",
        "# Map grid to the basis of the PCA components\n",
        "grid_latent = grid_latent @ pca_vectors\n",
        "```\n",
        "\n",
        "Note that this will require adding `dataset` to the arguments of this function.\n",
        "\n",
        "\n",
        "You can do something similar for the `visualise_input` function:\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def visualise_input(\n",
        "    model: Autoencoder,\n",
        "    dataset: Dataset,\n",
        ") -> None:\n",
        "    '''\n",
        "    Visualises (in the form of a scatter plot) the input data in the latent space, along the first two latent dims.\n",
        "    '''\n",
        "    # First get the model images' latent vectors, along first 2 dims\n",
        "    imgs = t.stack([batch for batch, label in dataset]).to(device)\n",
        "    latent_vectors = model.encoder(imgs)\n",
        "    if latent_vectors.ndim == 3: latent_vectors = latent_vectors[0] # useful for VAEs later\n",
        "    latent_vectors = latent_vectors[:, :2].cpu().numpy()\n",
        "    labels = [str(label) for img, label in dataset]\n",
        "\n",
        "    # Make a dataframe for scatter (px.scatter is more convenient to use when supplied with a dataframe)\n",
        "    df = pd.DataFrame({\"dim1\": latent_vectors[:, 0], \"dim2\": latent_vectors[:, 1], \"label\": labels})\n",
        "    df = df.sort_values(by=\"label\")\n",
        "    fig = px.scatter(df, x=\"dim1\", y=\"dim2\", color=\"label\")\n",
        "    fig.update_layout(height=700, width=700, title=\"Scatter plot of latent space dims\", legend_title=\"Digit\")\n",
        "    data_range = df[\"dim1\"].max() - df[\"dim1\"].min()\n",
        "\n",
        "    # Add images to the scatter plot (optional)\n",
        "    output_on_data_to_plot = model.encoder(HOLDOUT_DATA.to(device))\n",
        "    if output_on_data_to_plot.ndim == 3: output_on_data_to_plot = output_on_data_to_plot[0] # useful for VAEs later\n",
        "    output_on_data_to_plot = output_on_data_to_plot[:, :2].cpu()\n",
        "    data_translated = (HOLDOUT_DATA.cpu().numpy() * 0.3081) + 0.1307\n",
        "    data_translated = (255 * data_translated).astype(np.uint8).squeeze()\n",
        "    for i in range(10):\n",
        "        x, y = output_on_data_to_plot[i]\n",
        "        fig.add_layout_image(\n",
        "            source=Image.fromarray(data_translated[i]).convert(\"L\"),\n",
        "            xref=\"x\", yref=\"y\",\n",
        "            x=x, y=y,\n",
        "            xanchor=\"right\", yanchor=\"top\",\n",
        "            sizex=data_range/15, sizey=data_range/15,\n",
        "        )\n",
        "    fig.show()\n",
        "```\n",
        "    \n",
        "</details>\n",
        "\n",
        "### Beta-VAEs\n",
        "\n",
        "Read the section on [Beta-VAEs](https://lilianweng.github.io/posts/2018-08-12-vae/#beta-vae), if you haven't already. Can you choose a better value for $\\beta$?\n",
        "\n",
        "To decide on an appropriate $\\beta$, you can look at the distribution of your latent vector. For instance, if your latent vector looks very different to the standard normal distribution when it's projected onto one of its components (e.g. maybe that component is very sharply spiked around some particular value), this is a sign that you need to use a larger parameter $\\beta$. You can also just use hyperparameter searches to find an optimal $\\beta$. See [the paper](https://openreview.net/pdf?id=Sy2fzU9gl) which introduced Beta-VAEs for more ideas.\n",
        "\n",
        "### CelebA dataset\n",
        "\n",
        "Try to build an autoencoder for the CelebA dataset. You shouldn't need to change the architecture much from your MNIST VAE. You should find the training much easier than with your GAN (as discussed yesterday, GANs are notoriously unstable when it comes to training). Can you get better results than you did for your GAN?\n",
        "\n",
        "### Hierarchical VAEs\n",
        "\n",
        "Hierarchical VAEs are ones which stack multiple layers of parameter-learning and latent-vector-sampling, rather than just doing this once. Read the section of [this paper](https://arxiv.org/pdf/2208.11970.pdf) for a more thorough description.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/vae-and-hvae-final.png\" width=\"1100\">\n",
        "\n",
        "(Note - the KL divergence loss used in HVAEs can sometimes be more complicated than the one presented in this diagram, if you want to implement conditional dependencies between the different layers. However, this isn't necessary for the basic HVAE architecture.)\n",
        "\n",
        "Try to implement your own hierarchical VAE.\n",
        "\n",
        "Note - when you get to the material on **diffusion models** later in the course, you might want to return here, because understanding HVAEs can be a useful step to understanding diffusion models. In fact diffusion models can almost be thought of as a special type of HVAE.\n",
        "\n",
        "### Denoising and sparse autoencoders\n",
        "\n",
        "The reading material on VAEs talks about [denoising](https://lilianweng.github.io/posts/2018-08-12-vae/#denoising-autoencoder) and [sparse](https://lilianweng.github.io/posts/2018-08-12-vae/#sparse-autoencoder) autoencoders. Try changing the architecture of your autoencoder (not your VAE) to test out one of these two techniques. Do does your decoder output change? How about your encoder scatter plot?\n",
        "\n",
        "***Note - sparse autoencoders will play an important role in some later sections of this course (when we study superposition in mechanistic interpretability).***\n",
        "\n",
        "If you're mathematically confident and feeling like a challenge, you can also try to implement [contractive autoencoders](https://lilianweng.github.io/posts/2018-08-12-vae/#contractive-autoencoder)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgLlf91F6ejx"
      },
      "source": [
        "# 2️⃣ GANs\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand the loss function used in GANs, and why it can be expected to result in the generator producing realistic outputs.\n",
        "> - Implement the DCGAN architecture from the paper, with relatively minimal guidance.\n",
        "> - Learn how to identify and fix bugs in your GAN architecture, to improve convergence properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv26lnXB6ejx"
      },
      "source": [
        "## Reading\n",
        "\n",
        "* Google Machine Learning Education, [Generative Adversarial Networks](https://developers.google.com/machine-learning/gan) (strongly recommended, ~15 mins)\n",
        "    * This is a very accessible introduction to the core ideas behind GANs\n",
        "    * You should read at least the sections in **Overview**, and the sections in **GAN Anatomy** up to and including **Loss Functions**\n",
        "* [Unsupervised representation learning with deep convolutional generative adversarial networks](https://paperswithcode.com/method/dcgan) (optional, we'll be going through parts of this paper later on in the exercises)\n",
        "    * This paper introduced the DCGAN, and describes an architecture very close to the one we'll be building today.\n",
        "    * It's one of the most cited ML papers of all time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBrV23WT6ejx"
      },
      "source": [
        "## How GANs work\n",
        "\n",
        "The basic idea behind GANs is as follows:\n",
        "\n",
        "* You have two networks, the **generator** and the **discriminator**.\n",
        "* The generator's job is to produce output realistic enough to fool the discriminator, and the discriminator's job is to try and tell the difference between real and fake output.\n",
        "\n",
        "The idea is for both networks to be trained simultaneously, in a positive feedback loop: as the generator produces better output, the discriminator's job becomes harder, and it has to learn to spot more subtle features distinguishing real and fake images, meaning the generator has to work harder to produce images with those features.\n",
        "\n",
        "### Discriminator\n",
        "\n",
        "The discriminator works by taking an image (either real, or created by the generator), and outputting a single value between 0 and 1, which is the probability that the discriminator puts on the image being real. The discriminator sees the images, but not the labels (i.e. whether the images are real or fake), and it is trained to distinguish between real and fake images with maximum accuracy. The discriminator's loss function is the cross entropy between its probability estimates ($D(x)$ for real images, $D(G(z))$ for fake images) and the true labels ($1$ for real images, $0$ for fake images).\n",
        "\n",
        "### Generator\n",
        "\n",
        "The architecture of generators in a GAN setup is generally a mirror image of the discriminator, with convolutions swapped out for **transposed convolutions**. This is the case for the DCGAN paper we'll be reading (which is why they only give a diagram of the generator, not both). The generator works by taking in a vector $z$, whose elements are all normally distributed with mean 0 and variance 1. We call the space from which $z$ is sampled **latent dimension** or **latent space**, and we call $z$ a **latent vector**. The formal definition of a latent space is *an abstract multi-dimensional space that encodes a meaningful internal representation of externally observed events.* We'll dive a little deeper into what this means and the overall significance of latent spaces later on, but for now it's fine to understand this vector $z$ as a kind of random seed, which causes the generator to produce different outputs. After all, if the generator only ever produced the same image as output then the discriminator's job would be pretty easy (just subtract the image $g$ always produces from the input image, and see if the result is close to zero!). The generator's objective function is an increasing function of $D(G(z))$, in other words it tries to produce images $G(z)$ which have a high chance of fooling the discriminator (i.e. $D(G(z)) \\approx 1$).\n",
        "\n",
        "### Convergence\n",
        "\n",
        "The ideal outcome when training a GAN is for the generator to produce perfect output indistinguishable from real images, and the discriminator just guesses randomly. However, the precise nature of the situations when GANs converge is an ongoing area of study (in general, adversarial networks have very unstable training patterns). For example, you can imagine a situation where the discriminator becomes almost perfect at spotting fake outputs, because of some feature that the discriminator spots and that the generator fails to capture in its outputs. It will be very difficult for the generator to get a training signal, because it has to figure out what feature is missing from its outputs, and how it can add that feature to fool the discriminator. And to make matters worse, maybe marginal steps in that direction will only increase the probability of fooling the discriminator from almost-zero to slightly-more-than-almost-zero, which isn't much of a training signal! Later on we will see techniques people have developed to overcome problems like this and others, but in general they can't be solved completely.\n",
        "\n",
        "<details>\n",
        "<summary>Optional exercise - what conditions must hold for the discriminator's best strategy to be random guessing with probability 0.5?</summary>\n",
        "\n",
        "It is necessary for the generator to be producing perfect outputs, because otherwise the discriminator could do better than random guessing.\n",
        "\n",
        "If the generator is producing perfect outputs, then the discriminator never has any ability to distinguish real from fake images, so it has no information. Its job is to minimise the cross entropy between its output distribution $(D(x), 1-D(x))$, and the distribution of real/fake images. Call this $(p, 1-p)$, i.e. $p$ stands for the proportion of images in training which are real. Note how we just used $p$ rather than $p(x)$, because there's no information in the image $x$ which indicates whether it is real or fake. Trying to minimize the cross entropy between $(p, 1-p)$ and $(D(x), 1-D(x))$ gives us the solution $D(x) = p$ for all $x$. In other words, our discriminator guesses real/fake randomly with probability equal to the true underlying frequency of real/fake images in the data. This is 0.5 if and only if the data contains an equal number of real and fake images.\n",
        "\n",
        "To summarize, the necessary and sufficient conditions for $(\\forall x) \\; D(x) = 0.5$ being the optimal strategy are:\n",
        "\n",
        "* The generator $G$ produces perfect output\n",
        "* The underlying frequency of real/fake images in the data is 50/50\n",
        "\n",
        "</details>\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/dcgan-9-solid.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrLzceE26ejx"
      },
      "source": [
        "### Exercise - some more modules\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You'll also need to implement a few more modules, which have docstrings provided below (they should be fairly quick, and will just serve as a refresher for the structure of modules). They are:\n",
        "\n",
        "* [`Tanh`](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html) which is an activation function used by the DCGAN you'll be implementing.\n",
        "* [`LeakyReLU`](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html) which is an activation function used by the DCGAN you'll be implementing. This function is popular in tasks where we we may suffer from sparse gradients (GANs are a primary example of this).\n",
        "* [`Sigmoid`](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html), for converting the single logit output from the discriminator into a probability.\n",
        "\n",
        "They should all be relatively short. You can go back to day 2's exercises to remind yourself of the basic syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr4uSQZR6ejx"
      },
      "outputs": [],
      "source": [
        "class Tanh(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class LeakyReLU(nn.Module):\n",
        "    def __init__(self, negative_slope: float = 0.01):\n",
        "        super().__init__()\n",
        "        self.negative_slope = negative_slope\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"negative_slope={self.negative_slope}\"\n",
        "\n",
        "\n",
        "class Sigmoid(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_Tanh(Tanh)\n",
        "tests.test_LeakyReLU(LeakyReLU)\n",
        "tests.test_Sigmoid(Sigmoid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_O1Hqn76ejx"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Tanh(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return (t.exp(x) - t.exp(-x)) / (t.exp(x) + t.exp(-x))\n",
        "\n",
        "\n",
        "class LeakyReLU(nn.Module):\n",
        "    def __init__(self, negative_slope: float = 0.01):\n",
        "        super().__init__()\n",
        "        self.negative_slope = negative_slope\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return t.where(x > 0, x, self.negative_slope * x)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"negative_slope={self.negative_slope}\"\n",
        "\n",
        "\n",
        "class Sigmoid(nn.Module):\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return 1 / (1 + t.exp(-x))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0I3Nb1b6ejx"
      },
      "source": [
        "## GANs\n",
        "\n",
        "Now, you're ready to implement and train your own DCGAN! You'll be basing your implementation on the [DCGAN paper](https://arxiv.org/abs/1511.06434v2). Implementing architectures based on descriptions in papers is an incredibly valuable skill for any would-be research engineer, however in these exercises we've given enough guidance on this page that you shouldn't need to refer to the paper much if at all. However, we do encourage you to skim the paper, and think about how you might go about this replication task without guidance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnlqBf9b6ejx"
      },
      "source": [
        "### Discriminator & Generator architectures\n",
        "\n",
        "We refer back to the diagram at the start of this section for the basic discriminator and generator architectures. Rather than hardcoding a single set of values, we're going to make our architecture more flexible - giving us the ability to change the number of layers, or the sizes of each layer, by using different input arguments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RZP_2ug6ejx"
      },
      "source": [
        "#### Discriminator\n",
        "\n",
        "The discriminator starts with a series of blocks of the form `(Conv -> BatchNorm -> ActivationFunction)`. Following the paper's conventions:\n",
        "\n",
        "* Each convolution should have kernel size 4, stride 2, padding 1. This will halve the width and height of the image at each step. The output channels of each convolution are given by the `hidden_channels` argument. For instance, if `img_channels=3` (because the image is RGB) and `hidden_channels=[128, 256, 512]`, then there will be three convolutions: the first mapping from 3 -> 128 channels, the second from 128 -> 256, and the third from 256 -> 512.\n",
        "* All blocks have a batchnorm layer, **except for the very first one**.\n",
        "* All blocks' activation functions are `LeakyRelu`.\n",
        "\n",
        "Lastly, we flatten the output of the final convolutional block, and use a fully connected layer to map it to a single value (i.e. a vector of length `batch_size`) which we then pass through a sigmoid to get a probability that the image is real. Again, we recommend the `Rearrange` module from the `einops` library for this.\n",
        "\n",
        "None of the convolutions or linear layers should have biases (this is also true for the generator).\n",
        "\n",
        "The diagram below shows what we'd get with the following arguments:\n",
        "\n",
        "```python\n",
        "img_size = 64\n",
        "img_channels = 3\n",
        "hidden_channels = [128, 256, 512]\n",
        "```\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/dcgan-d-help-9-solid.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNTmN27K6ejx"
      },
      "source": [
        "#### Generator\n",
        "\n",
        "The generator is essentially the mirror image of the discriminator. While the discriminator had convolutions which halved the image size on each layer, the generator has transposed convolutions which double the size on each layer (so apart from the very start of the generator / end of the discriminator, all the activations have the same shape, just in reverse).\n",
        "\n",
        "We start with the latent vector of shape `(batch_size, latent_dim_size)`, and apply a fully connected layer & reshaping to get our first tensor which has shape `(batch_size, channels, height, width)`. The parameters `channels` and `height` (which is equal to `width`) can be calculated from the `img_size` and `hidden_channels` arguments (remember that image size doubles at each transposed convolution, and after applying all the transposed convolutions we'll eventually get back to `img_size`). Then, we apply batchnorm and relu.\n",
        "\n",
        "After this, we apply a series of blocks of the form `(ConvTranspose -> BatchNorm -> ActivationFunction)`. Following the paper's conventions:\n",
        "\n",
        "* Each transposed convolution has kernel size 4, stride 2, padding 1. Like for the discriminator, the input & output channels of the convolutions are determined by the `hidden_channels` argument (although this time they're in reverse order).\n",
        "* All blocks have a batchnorm layer, except for the very last one.\n",
        "* All blocks' activation functions are `ReLU`, except for the last one which is `Tanh`.\n",
        "\n",
        "The diagram below shows what we'd get with the following arguments:\n",
        "\n",
        "```python\n",
        "img_size = 64\n",
        "img_channels = 3\n",
        "hidden_channels = [128, 256, 512]\n",
        "latent_dim_size = 100\n",
        "```\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/gan_images/dcgan-g-help-10-light.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7H2aQC06ejx"
      },
      "source": [
        "### Exercise - building your GAN\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴🔴\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 30-50 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should implement your code below. We've provided one possible design choice and the corresponding forward functions:\n",
        "\n",
        "- The generator is made of an initial `project_and_reshape` block that performs the first linear map, and then `hidden_layers` which are a stack of blocks each consisting of a (transponsed convolution, optional batchnorm, activation fn).\n",
        "- The discriminator is made of `hidden_layers` which are a stack of (convolution, optional batchnorm, activation fn) blocks, and a final `classifier` block which flattens and maps to a single output (which represents the probability pre-sigmoid).\n",
        "\n",
        "We've also given you the `DCGAN` class - note that we've not included a `forward` method here, because you'll usually be calling your discriminator and generators' forward methods directly. You can think of the DCGAN class as essentially a wrapper for both.\n",
        "\n",
        "If you're stuck, you can import the generator and discriminator from the solutions, and compare it with yours. We've given you this option in place of test functions.\n",
        "\n",
        "```python\n",
        "print_param_count(Generator(), solutions.DCGAN().netG)\n",
        "print_param_count(Discriminator(), solutions.DCGAN().netD)\n",
        "```\n",
        "\n",
        "Lastly, remember that `torchinfo` is a useful library for inspecting the architecture of your model. Since it works by running input through your model, it provides another useful way to check your model's architecture is correct (since errors like the wrong convolution size will often cause forward passes to fail).\n",
        "\n",
        "```python\n",
        "model = DCGAN().to(device)\n",
        "x = t.randn(3, 100).to(device)\n",
        "print(torchinfo.summary(model.netG, input_data=x), end=\"\\n\\n\")\n",
        "print(torchinfo.summary(model.netD, input_data=model.netG(x)))\n",
        "```\n",
        "\n",
        "You can also check that the output of your model is the correct shape. **Note - we're using a 3-layer model rather than the 4-layer model shown in the diagram and described the paper.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPHW4Xy36ejx"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim_size: int = 100,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the generator architecture from the DCGAN paper (the diagram at the top\n",
        "        of page 4). We assume the size of the activations doubles at each layer (so image\n",
        "        size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            latent_dim_size:\n",
        "                the size of the latent dimension, i.e. the input to the generator\n",
        "            img_size:\n",
        "                the size of the image, i.e. the output of the generator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the generator (starting closest\n",
        "                to the middle of the DCGAN and going outward, i.e. in chronological order for\n",
        "                the generator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # self.project_and_reshape = ...\n",
        "        # self.hidden_layers = ...\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.project_and_reshape(x)\n",
        "        x = self.hidden_layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the discriminator architecture from the DCGAN paper (the mirror image of\n",
        "        the diagram at the top of page 4). We assume the size of the activations doubles at\n",
        "        each layer (so image size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            img_size:\n",
        "                the size of the image, i.e. the input of the discriminator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the discriminator (starting\n",
        "                closest to the middle of the DCGAN and going outward, i.e. in reverse-\n",
        "                chronological order for the discriminator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_layers = ...\n",
        "        self.classifier = ...\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.hidden_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.squeeze()  # remove dummy `out_channels` dimension\n",
        "\n",
        "\n",
        "class DCGAN(nn.Module):\n",
        "    netD: Discriminator\n",
        "    netG: Generator\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim_size: int = 100,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.netD = Discriminator(img_size, img_channels, hidden_channels)\n",
        "        self.netG = Generator(latent_dim_size, img_size, img_channels, hidden_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-_g4GH_6ejx"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Generator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim_size: int = 100,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the generator architecture from the DCGAN paper (the diagram at the top\n",
        "        of page 4). We assume the size of the activations doubles at each layer (so image\n",
        "        size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            latent_dim_size:\n",
        "                the size of the latent dimension, i.e. the input to the generator\n",
        "            img_size:\n",
        "                the size of the image, i.e. the output of the generator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the generator (starting closest\n",
        "                to the middle of the DCGAN and going outward, i.e. in chronological order for\n",
        "                the generator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Reverse hidden channels, so they're in chronological order\n",
        "        hidden_channels = hidden_channels[::-1]\n",
        "\n",
        "        self.latent_dim_size = latent_dim_size\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        # Reverse them, so they're in chronological order for generator\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        # Define the first layer, i.e. latent dim -> (512, 4, 4) and reshape\n",
        "        first_height = img_size // (2**n_layers)\n",
        "        first_size = hidden_channels[0] * (first_height**2)\n",
        "        self.project_and_reshape = Sequential(\n",
        "            Linear(latent_dim_size, first_size, bias=False),\n",
        "            Rearrange(\"b (ic h w) -> b ic h w\", h=first_height, w=first_height),\n",
        "            BatchNorm2d(hidden_channels[0]),\n",
        "            ReLU(),\n",
        "        )\n",
        "\n",
        "        # Equivalent, but using conv rather than linear:\n",
        "        # self.project_and_reshape = Sequential(\n",
        "        #     Rearrange(\"b ic -> b ic 1 1\"),\n",
        "        #     solutions.ConvTranspose2d(latent_dim_size, hidden_channels[0], first_height, 1, 0),\n",
        "        #     BatchNorm2d(hidden_channels[0]),\n",
        "        #     ReLU(),\n",
        "        # )\n",
        "\n",
        "        # Get list of input & output channels for the convolutional blocks\n",
        "        in_channels = hidden_channels\n",
        "        out_channels = hidden_channels[1:] + [img_channels]\n",
        "\n",
        "        # Define all the convolutional blocks (conv_transposed -> batchnorm -> activation)\n",
        "        conv_layer_list = []\n",
        "        for i, (c_in, c_out) in enumerate(zip(in_channels, out_channels)):\n",
        "            conv_layer = [ConvTranspose2d(c_in, c_out, 4, 2, 1), ReLU() if i < n_layers - 1 else Tanh()]\n",
        "            if i < n_layers - 1:\n",
        "                conv_layer.insert(1, BatchNorm2d(c_out))\n",
        "            conv_layer_list.append(Sequential(*conv_layer))\n",
        "\n",
        "        self.hidden_layers = Sequential(*conv_layer_list)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.project_and_reshape(x)\n",
        "        x = self.hidden_layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: int = 64,\n",
        "        img_channels: int = 3,\n",
        "        hidden_channels: list[int] = [128, 256, 512],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Implements the discriminator architecture from the DCGAN paper (the mirror image of\n",
        "        the diagram at the top of page 4). We assume the size of the activations doubles at\n",
        "        each layer (so image size has to be divisible by 2 ** len(hidden_channels)).\n",
        "\n",
        "        Args:\n",
        "            img_size:\n",
        "                the size of the image, i.e. the input of the discriminator\n",
        "            img_channels:\n",
        "                the number of channels in the image (3 for RGB, 1 for grayscale)\n",
        "            hidden_channels:\n",
        "                the number of channels in the hidden layers of the discriminator (starting\n",
        "                closest to the middle of the DCGAN and going outward, i.e. in reverse-\n",
        "                chronological order for the discriminator)\n",
        "        \"\"\"\n",
        "        n_layers = len(hidden_channels)\n",
        "        assert img_size % (2**n_layers) == 0, \"activation size must double at each layer\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        # Get list of input & output channels for the convolutional blocks\n",
        "        in_channels = [img_channels] + hidden_channels[:-1]\n",
        "        out_channels = hidden_channels\n",
        "\n",
        "        # Define all the convolutional blocks (conv_transposed -> batchnorm -> activation)\n",
        "        conv_layer_list = []\n",
        "        for i, (c_in, c_out) in enumerate(zip(in_channels, out_channels)):\n",
        "            conv_layer = [\n",
        "                Conv2d(c_in, c_out, 4, 2, 1),\n",
        "                LeakyReLU(0.2),\n",
        "            ]\n",
        "            if i > 0:\n",
        "                conv_layer.insert(1, BatchNorm2d(c_out))\n",
        "            conv_layer_list.append(Sequential(*conv_layer))\n",
        "\n",
        "        self.hidden_layers = Sequential(*conv_layer_list)\n",
        "\n",
        "        # Define the last layer, i.e. reshape and (512, 4, 4) -> real/fake classification\n",
        "        final_height = img_size // (2**n_layers)\n",
        "        final_size = hidden_channels[-1] * (final_height**2)\n",
        "        self.classifier = Sequential(\n",
        "            Rearrange(\"b c h w -> b (c h w)\"),\n",
        "            Linear(final_size, 1, bias=False),\n",
        "            Sigmoid(),\n",
        "        )\n",
        "        # Equivalent, but using conv rather than linear:\n",
        "        # self.classifier = Sequential(\n",
        "        #     Conv2d(out_channels[-1], 1, final_height, 1, 0),\n",
        "        #     Rearrange(\"b c h w -> b (c h w)\"),\n",
        "        #     Sigmoid(),\n",
        "        # )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.hidden_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.squeeze()  # remove dummy `out_channels` dimension\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBXAvRhE6ejy"
      },
      "source": [
        "### Exercise - Weight initialisation\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The paper mentions at the end of page 3 that all weights were initialized from a $N(0, 0.02)$ distribution. This applies to the convolutional and convolutional transpose layers' weights (plus the weights in the linear classifier), but the BatchNorm layers' weights should be initialised from $N(1, 0.02)$ (since 1 is their default value). The BatchNorm biases should all be set to zero.\n",
        "\n",
        "You can fill in the following function to initialise your weights, and call it within the `__init__` method of your DCGAN. (Hint: you can use the functions `nn.init.normal_` and `nn.init.constant_` here.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jqHQU-U6ejy"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(model: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Initializes weights according to the DCGAN paper (details at the end of page 3 of the DCGAN paper), by modifying the\n",
        "    weights of the model in place.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_initialize_weights(initialize_weights, ConvTranspose2d, Conv2d, Linear, BatchNorm2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9x7YOQk6ejy"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def initialize_weights(model: nn.Module) -> None:\n",
        "    \"\"\"\n",
        "    Initializes weights according to the DCGAN paper (details at the end of page 3 of the DCGAN paper), by modifying the\n",
        "    weights of the model in place.\n",
        "    \"\"\"\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, (ConvTranspose2d, Conv2d, Linear)):\n",
        "            nn.init.normal_(module.weight.data, 0.0, 0.02)\n",
        "        elif isinstance(module, BatchNorm2d):\n",
        "            nn.init.normal_(module.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(module.bias.data, 0.0)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8wxGm5r6ejy"
      },
      "source": [
        "Note - the tests for this aren't maximally strict, but don't worry if you don't get things exactly right, since your model will still probably train successfully. If you think you've got the architecture right but your model still isn't training, you might want to return here and check your initialisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OS76Y3z6ejy"
      },
      "outputs": [],
      "source": [
        "model = DCGAN().to(device)\n",
        "x = t.randn(3, 100).to(device)\n",
        "print(torchinfo.summary(model.netG, input_data=x), end=\"\\n\\n\")\n",
        "print(torchinfo.summary(model.netD, input_data=model.netG(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--NhWG3i6ejy"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Recall, the goal of training the discriminator is to maximize the probability of correctly classifying a given input as real or fake. The goal of the generator is to produce images to fool the discriminator. This is framed as a **minimax game**, where the discriminator and generator try to solve the following:\n",
        "$$\n",
        "\\min_G \\max_D V(D, G)=\\mathbb{E}_x[\\log (D(x))]+\\mathbb{E}_z[\\log (1-D(G(z)))]\n",
        "$$\n",
        "where $D$ is the discriminator function mapping an image to a probability estimate for whether it is real, and $G$ is the generator function which produces an image from latent vector $z$.\n",
        "\n",
        "The literature on minimax games is extensive, so we won't go into it here. It's better to understand this formula on an intuitive level:\n",
        "\n",
        "* Given a fixed $G$ (generator), the goal of the discriminator is to produce high values for $D$ when fed real images $x$, and low values when fed fake images $G(z)$.\n",
        "* The generator $G$ is searching for a strategy where, even if the discriminator $D$ was optimal, it would still find it hard to distinguish between real and fake images with high confidence.\n",
        "\n",
        "Since we can't know the true distribution of $x$, we instead estimate the expression above by calculating it over a batch of real images $x$ (and some random noise $z$). This gives us a loss function to train against (since $D$ wants to maximise this value, and $G$ wants to minimise this value). For each batch, we perform gradient descent on the discriminator and then on the generator.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98mXjxVI6ejy"
      },
      "source": [
        "### Training the discriminator\n",
        "\n",
        "We take the following steps:\n",
        "\n",
        "* Zero the gradients of $D$.\n",
        "    * This is important because if the last thing we did was evaluate $D(G(z))$ (in order to update the parameters of $G$), then $D$ will have stored gradients from that backward pass.\n",
        "* Generate random noise $z$, and compute $D(G(z))$. Take the average of $\\log(1 - D(G(z)))$, and we have the first part of our loss function.\n",
        "    * Note - you can use the same random noise (and even the same fake image) as in the generator step. But make sure you're using the detached version, because we don't want gradients to propagate back through the generator!\n",
        "* Take the real images  $x$ in the current batch, and use that to compute $\\log(D(x))$. This gives us the second part of our loss function.\n",
        "* We now add the two terms together, and perform gradient ascent (since we're trying to maximise this expression).\n",
        "    * You can perform gradient ascent by either flipping the sign of the thing you're doing a backward pass on, or passing the keyword argument `maximize=True` when defining your optimiser (all optimisers have this option).\n",
        "\n",
        "Tip - when calculating $D(G(z))$, for the purpose of training the discriminator, it's best to first calculate $G(z)$ then call `detach` on this tensor before passing it to $D$. This is because you then don't need to worry about gradients accumulating for $G$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZs_8ZXi6ejy"
      },
      "source": [
        "### Training the generator\n",
        "\n",
        "We take the following steps:\n",
        "\n",
        "* Zero the gradients of $G$.\n",
        "* Generate random noise $z$, and compute $D(G(z))$.\n",
        "* We **don't** use $\\log(1 - D(G(z)))$ to calculate our loss function, instead we use $\\log(D(G(z)))$ (and gradient ascent).\n",
        "\n",
        "**Question - can you explain why we use $\\log(D(G(z))$? (The Google reading material mentions this but doesn't really explain it.)**\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "Early in learning, when the generator is really bad at producing realistic images, it will be easy for the discriminator to distinguish between them. So $\\log(1 - D(G(z)))$ will be very close to $\\log(1) = 0$. The gradient of $\\log$ at this point is quite flat, so there won't be a strong gradient with which to train $G$. To put it another way, a marginal improvement in $G$ will have very little effect on the loss function. On the other hand, $\\log(D(G(z)))$ tends to negative infinity as $D(G(z))$ gets very small. So the gradients here are very steep, and a small improvement in $G$ goes a long way.\n",
        "\n",
        "It's worth emphasising that these two functions are both monotonic in opposite directions, so maximising one is equivalent to minimising the other. We haven't changed anything fundamental about how the GAN works; this is just a trick to help with gradient descent.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH7TYu1A6ejy"
      },
      "source": [
        "Note - PyTorch's [`BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html) clamps its log function outputs to be greater than or equal to -100. This is because in principle our loss function could be negative infinity (if we take log of zero). You might find you need to employ a similar trick if you're manually computing the log of probabilities. Aside from the clamping, the following two code snippets are equivalent:\n",
        "\n",
        "```python\n",
        "# Calculating loss manually, without clamping:\n",
        "loss = - t.log(D_G_z)\n",
        "\n",
        "# Calculating loss with clamping behaviour:\n",
        "labels_real = t.ones_like(D_G_z)\n",
        "loss = nn.BCELoss()(D_G_z, labels_real)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjaTGPvz6ejy"
      },
      "source": [
        "### Optimizers\n",
        "\n",
        "The generator and discriminator will have separate optimizers (this makes sense, since we'll have separate training steps for these two, and both are \"trying\" to optimize different things). The [paper](https://arxiv.org/abs/1511.06434v2) describes using an Adam optimizer with learning rate 0.0002, and momentum parameters $\\beta_1 = 0.5, \\beta_2 = 0.999$. This is set up for you already, in the `__init__` block below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z9Nf-Fy6ejy"
      },
      "source": [
        "### Gradient Clipping\n",
        "\n",
        "Gradient clipping is a useful technique for improving the stability of certain training loops, especially those like DCGANs which have potentially unstable loss functions. The idea is that you clip the gradients of your weights to some fixed threshold during backprop, and use these clipped gradients to update the weights. This can be done using [`nn.utils.clip_grad_norm`](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html), which is called between the `loss.backward()` and `optimizer.step()` methods (since it directly modifies the `.grad` attributes of your weights). You shouldn't find this absolutely necessary to train your models, however it might help to clip the gradients to a value like `1.0` for your generator & discriminator. We've given you this as an optional parameter to use in your `DCGANArgs` dataclass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvscr9hZ6ejy"
      },
      "source": [
        "### Exercise - implement GAN training loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 30-45 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should now implement your training loop below. We've filled in the `__init__` method for you, as well as `log_samples` method which determines the core structure of the training loop. Your task is to:\n",
        "\n",
        "* Fill in the two functions `training_step_discriminator` and `training_step_generator`, which perform a single gradient step on the discriminator and generator respectively.\n",
        "    * Note that the discriminator training function takes two arguments: the real and fake image (in the notation above, $x$ and $z$), because it trains to distinguish real and fake. The generator training function only takes the fake image $z$, because it trains to fool the discriminator.\n",
        "    * Also note, you should increment `self.step` only once per (discriminator & generator) step, not for both.\n",
        "* Fill in the `train` method, which should perform the training loop over the number of epochs specified in `args.epochs`. This will be similar to previous training loops, but with a few key differences we'll highlight here:\n",
        "    * You'll need to compute both losses from `training_step_generator` and `training_step_discriminator`. For the former you should pass in just the fake image (you're only training the generator to produce better fake images), for the latter you should pass in the real image and the **detached fake image** i.e. `img.detach()` (because you're training the discriminator to tell real from fake, and you don't want gradients propagating back to the generator).\n",
        "        * The fake image should be created from random noise `t.randn(batch_size, latent_dim_size)` and passing it into your generator.\n",
        "    * Once again the trainloader gives us an iterable of `(img, label)` but we don't need to use the labels (because all these images are real, and that's all we care about).\n",
        "\n",
        "Again, we recommend not using `wandb` until you've got your non-wandb based code working without errors. Once the generator loss is going down (or at least not exploding!) then you can enable it. However, an important note - **generator loss going down is does not imply the model is working, and vice-versa!** For training systems as unstable as GANs, the best you can do is often just inspecting the output. Although it varies depending on details of the hardware and dataset & model you're training with, at least for these exercises if your generator's output doesn't resemble anything like a face after the first epoch, then something's probably going wrong in your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVo-CGE96ejy"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DCGANArgs:\n",
        "    \"\"\"\n",
        "    Class for the arguments to the DCGAN (training and architecture).\n",
        "    Note, we use field(defaultfactory(...)) when our default value is a mutable object.\n",
        "    \"\"\"\n",
        "\n",
        "    # architecture\n",
        "    latent_dim_size: int = 100\n",
        "    hidden_channels: list[int] = field(default_factory=lambda: [128, 256, 512])\n",
        "\n",
        "    # data & training\n",
        "    dataset: Literal[\"MNIST\", \"CELEB\"] = \"CELEB\"\n",
        "    batch_size: int = 64\n",
        "    epochs: int = 3\n",
        "    lr: float = 0.0002\n",
        "    betas: tuple[float, float] = (0.5, 0.999)\n",
        "    clip_grad_norm: float | None = 1.0\n",
        "\n",
        "    # logging\n",
        "    use_wandb: bool = False\n",
        "    wandb_project: str | None = \"day5-gan\"\n",
        "    wandb_name: str | None = None\n",
        "    log_every_n_steps: int = 250\n",
        "\n",
        "\n",
        "class DCGANTrainer:\n",
        "    def __init__(self, args: DCGANArgs):\n",
        "        self.args = args\n",
        "        self.trainset = get_dataset(self.args.dataset)\n",
        "        self.trainloader = DataLoader(self.trainset, batch_size=args.batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "        batch, img_channels, img_height, img_width = next(iter(self.trainloader))[0].shape\n",
        "        assert img_height == img_width\n",
        "\n",
        "        self.model = DCGAN(args.latent_dim_size, img_height, img_channels, args.hidden_channels).to(device).train()\n",
        "        self.optG = t.optim.Adam(self.model.netG.parameters(), lr=args.lr, betas=args.betas)\n",
        "        self.optD = t.optim.Adam(self.model.netD.parameters(), lr=args.lr, betas=args.betas)\n",
        "\n",
        "    def training_step_discriminator(\n",
        "        self,\n",
        "        img_real: Float[Tensor, \"batch channels height width\"],\n",
        "        img_fake: Float[Tensor, \"batch channels height width\"],\n",
        "    ) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Generates a real and fake image, and performs a gradient step on the discriminator to maximize\n",
        "        log(D(x)) + log(1-D(G(z))). Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def training_step_generator(self, img_fake: Float[Tensor, \"batch channels height width\"]) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Performs a gradient step on the generator to maximize log(D(G(z))). Logs to wandb if enabled.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def log_samples(self) -> None:\n",
        "        \"\"\"\n",
        "        Performs evaluation by generating 8 instances of random noise and passing them through the generator, then\n",
        "        optionally logging the results to Weights & Biases.\n",
        "        \"\"\"\n",
        "        assert self.step > 0, \"First call should come after a training step. Remember to increment `self.step`.\"\n",
        "        self.model.netG.eval()\n",
        "\n",
        "        # Generate random noise\n",
        "        t.manual_seed(42)\n",
        "        noise = t.randn(10, self.model.latent_dim_size).to(device)\n",
        "        # Get generator output\n",
        "        output = self.model.netG(noise)\n",
        "        # Clip values to make the visualization clearer\n",
        "        output = output.clamp(output.quantile(0.01), output.quantile(0.99))\n",
        "        # Log to weights and biases\n",
        "        if self.args.use_wandb:\n",
        "            output = einops.rearrange(output, \"b c h w -> b h w c\").cpu().numpy()\n",
        "            wandb.log({\"images\": [wandb.Image(arr) for arr in output]}, step=self.step)\n",
        "        else:\n",
        "            display_data(output, nrows=1, title=\"Generator-produced images\")\n",
        "\n",
        "        self.model.netG.train()\n",
        "\n",
        "    def train(self) -> DCGAN:\n",
        "        \"\"\"Performs a full training run.\"\"\"\n",
        "        self.step = 0\n",
        "        if self.args.use_wandb:\n",
        "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            progress_bar = tqdm(self.trainloader, total=len(self.trainloader), ascii=True)\n",
        "\n",
        "            for img_real, label in progress_bar:\n",
        "                # YOUR CODE HERE - fill in the training step for generator & discriminator\n",
        "\n",
        "        if self.args.use_wandb:\n",
        "            wandb.finish()\n",
        "\n",
        "        return self.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_-7s9ZV6ejy"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def training_step_discriminator(\n",
        "    self,\n",
        "    img_real: Float[Tensor, \"batch channels height width\"],\n",
        "    img_fake: Float[Tensor, \"batch channels height width\"],\n",
        ") -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Generates a real and fake image, and performs a gradient step on the discriminator to maximize\n",
        "    log(D(x)) + log(1-D(G(z))). Logs to wandb if enabled.\n",
        "    \"\"\"\n",
        "    # Zero gradients\n",
        "    self.optD.zero_grad()\n",
        "\n",
        "    # Calculate D(x) and D(G(z)), for use in the objective function\n",
        "    D_x = self.model.netD(img_real)\n",
        "    D_G_z = self.model.netD(img_fake)\n",
        "\n",
        "    # Calculate loss\n",
        "    lossD = -(t.log(D_x).mean() + t.log(1 - D_G_z).mean())\n",
        "\n",
        "    # Gradient descent step (with optional clipping)\n",
        "    lossD.backward()\n",
        "    if self.args.clip_grad_norm is not None:\n",
        "        nn.utils.clip_grad_norm_(self.model.netD.parameters(), self.args.clip_grad_norm)\n",
        "    self.optD.step()\n",
        "\n",
        "    if self.args.use_wandb:\n",
        "        wandb.log(dict(lossD=lossD), step=self.step)\n",
        "    return lossD\n",
        "\n",
        "\n",
        "def training_step_generator(self, img_fake: Float[Tensor, \"batch channels height width\"]) -> Float[Tensor, \"\"]:\n",
        "    \"\"\"\n",
        "    Performs a gradient step on the generator to maximize log(D(G(z))). Logs to wandb if enabled.\n",
        "    \"\"\"\n",
        "    # Zero gradients\n",
        "    self.optG.zero_grad()\n",
        "\n",
        "    # Calculate D(G(z)), for use in the objective function\n",
        "    D_G_z = self.model.netD(img_fake)\n",
        "\n",
        "    # Calculate loss\n",
        "    lossG = -(t.log(D_G_z).mean())\n",
        "\n",
        "    # Gradient descent step (with optional clipping)\n",
        "    lossG.backward()\n",
        "    if self.args.clip_grad_norm is not None:\n",
        "        nn.utils.clip_grad_norm_(self.model.netG.parameters(), self.args.clip_grad_norm)\n",
        "    self.optG.step()\n",
        "\n",
        "    if self.args.use_wandb:\n",
        "        wandb.log(dict(lossG=lossG), step=self.step)\n",
        "    return lossG\n",
        "\n",
        "\n",
        "def train(self) -> DCGAN:\n",
        "    \"\"\"Performs a full training run.\"\"\"\n",
        "    self.step = 0\n",
        "    if self.args.use_wandb:\n",
        "        wandb.init(project=self.args.wandb_project, name=self.args.wandb_name)\n",
        "\n",
        "    for epoch in range(self.args.epochs):\n",
        "        progress_bar = tqdm(self.trainloader, total=len(self.trainloader), ascii=True)\n",
        "\n",
        "        for img_real, label in progress_bar:\n",
        "            # Generate random noise & fake image\n",
        "            noise = t.randn(self.args.batch_size, self.args.latent_dim_size).to(device)\n",
        "            img_real = img_real.to(device)\n",
        "            img_fake = self.model.netG(noise)\n",
        "\n",
        "            # Training steps\n",
        "            lossD = self.training_step_discriminator(img_real, img_fake.detach())\n",
        "            lossG = self.training_step_generator(img_fake)\n",
        "\n",
        "            # Update progress bar\n",
        "            self.step += 1\n",
        "            progress_bar.set_description(f\"{epoch=}, {lossD=:.4f}, {lossG=:.4f}, batches={self.step}\")\n",
        "\n",
        "            # Log batch of data\n",
        "            if self.step % self.args.log_every_n_steps == 0:\n",
        "                self.log_samples()\n",
        "\n",
        "    if self.args.use_wandb:\n",
        "        wandb.finish()\n",
        "\n",
        "    return self.model\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oESbBN36ejy"
      },
      "source": [
        "Once you've written your code, here are some default arguments for MNIST and CelebA you can try out.\n",
        "\n",
        "Note that the MNIST model is very small in comparison to CelebA - if you make it any larger, you fall into a very common GAN failure mode where the discriminator becomes perfect (loss goes to zero) and the generator is unable to get a gradient signal to produce better images - see next section for a discussion of this. Larger architectures are generally more likely to fall into this failure mode, and empirically it seems to happen more for MNIST than for CelebA which is why we generally recommend using the CelebA dataset & architecture for this exercise - although this failure mode can happen in both cases!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XJVXvnk6ejy"
      },
      "outputs": [],
      "source": [
        "# Arguments for CelebA\n",
        "args = DCGANArgs(\n",
        "    dataset=\"CELEB\",\n",
        "    hidden_channels=[128, 256, 512],\n",
        "    batch_size=32,  # if you get OOM errors, reduce this!\n",
        "    epochs=5,\n",
        "    use_wandb=False,\n",
        ")\n",
        "trainer = DCGANTrainer(args)\n",
        "dcgan = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbOHf_Bn6ejy"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see an example of the output you should be producing by the end of this CelebA training run.</summary>\n",
        "\n",
        "Here was my output after 250 batches (8000 images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/celeb-gans-1.png\" width=\"700\">\n",
        "\n",
        "After 2000 batches (64000 images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/celeb-gans-2.png\" width=\"700\">\n",
        "\n",
        "And after the end of training (5 epochs, approx 625k images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/celeb-gans-3.png\" width=\"700\">\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-M55VLc6ejy"
      },
      "outputs": [],
      "source": [
        "# Arguments for MNIST\n",
        "args = DCGANArgs(\n",
        "    dataset=\"MNIST\",\n",
        "    hidden_channels=[12, 24],\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    use_wandb=False,\n",
        ")\n",
        "trainer = DCGANTrainer(args)\n",
        "dcgan = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fki-AbOG6ejy"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see an example of the output you should be producing by the end of this MNIST training run.</summary>\n",
        "\n",
        "Here was my output after 250 batches (32k images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mnist-gans-1.png\" width=\"700\">\n",
        "\n",
        "After 2000 batches (256k images):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mnist-gans-2.png\" width=\"700\">\n",
        "\n",
        "About 90% of the way through training, it was achieving the best results:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mnist-gans-3.png\" width=\"700\">\n",
        "\n",
        "However after this point it broke, and produced NaNs from both the discriminator and the generator:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/mnist-gans-nan.png\" width=\"900\">\n",
        "\n",
        "This is a common problem for training GANs - they're just a pretty cursed architecture! Read on for more on this.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scY9IVU-6ejy"
      },
      "source": [
        "### Fixing bugs\n",
        "\n",
        "GANs are notoriously hard to get exactly right. I ran into quite a few bugs myself building this architecture, and I've tried to mention them somewhere on this page to help participants avoid them. If you run into a bug and are able to fix it, please send it to me and I can add it here, for the benefit of everyone else!\n",
        "\n",
        "* Make sure you apply the layer normalisation (mean 0, std dev 0.02) to your linear layers as well as your convolutional layers.\n",
        "* More generally, in your function to initialise the weights of your network, make sure no layers are being missed out. The easiest way to do this is to inspect your model afterwards (i.e. loop through all the params, printing out their mean and std dev).\n",
        "\n",
        "Also, you might find [this page](https://github.com/soumith/ganhacks) useful. It provides several tips and tricks for how to make your GAN work (many of which we've already mentioned on this page)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdvSiHZx6ejy"
      },
      "source": [
        "## Why so unstable during training?\n",
        "\n",
        "If you try training your GAN on MNIST, you might find that it eventually blows up (with close to zero discriminator loss, and spiking generator loss - possibly even gradients large enough to overflow and lead to `nan` values). This might also happen if you train on CelebA but your architecture is too big, or even if you train with a reasonably-sized architecture but for too long!\n",
        "\n",
        "This is a common problem with GANs, which are notoriously unstable to train. Essentially, the discriminator gets so good at its job that the generator can't latch onto a good gradient for improving its performance. Although the theoretical formulation of GANs as a minimax game is elegant, there are quite a few assumptions that have to go into it in order for there to be one theoretical optimum involving the generator producing perfect images - and in practice this is rarely achieved, even in the limit.\n",
        "\n",
        "Different architectures like diffusion models and VAEs are generally more stable, although many of the most advanced image generation architectures do still take important conceptual ideas from the GAN framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MuGo9ka6ejy"
      },
      "source": [
        "## Bonus - Smooth interpolation\n",
        "\n",
        "Suppose you take two vectors in the latent space. If you use your generator to create output at points along the linear interpolation between these vectors, your image will change continuously (because it is a continuous function of the latent vector), but it might look very different at the start and the end. Can you create any cool animations from this?\n",
        "\n",
        "Instead of linearly interpolating between two vectors, you could try applying a [rotation matrix](https://en.wikipedia.org/wiki/Rotation_matrix) to a vector (this has the advantage of keeping the interpolated vector \"in distribution\", since the rotation between two standard normally distributed vectors is also standard normal, whereas the linear interpolation isn't). Are the results better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_k3ZOhJ6ejy"
      },
      "source": [
        "# 3️⃣ Bonus - Transposed Convolutions\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about & implement the transposed convolution operation.\n",
        "> - Implement GANs and/or VAEs entirely from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1qZAr_G6ejz"
      },
      "source": [
        "## Transposed convolutions\n",
        "\n",
        "In this section, we'll build all the modules required to implement our DCGAN.\n",
        "\n",
        "> Note - this section is similar in flavour to the bonus exercises from the \"CNNs & ResNets\" chapter, i.e. you'll be implementing transposed convolutions using low-level stride and tensor manipulation operations. That section should be considered a prerequisite for this one.\n",
        "\n",
        "Let's start by importing some useful functions from the bonus section of \"CNNs & ResNets\", where we implemented convolutions from scratch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTYCXIAl6ejz"
      },
      "outputs": [],
      "source": [
        "from part2_cnns.solutions import IntOrPair, Pair, conv1d_minimal, conv2d_minimal, force_pair, pad1d, pad2d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gygDKzVZ6ejz"
      },
      "source": [
        "Now, **what are transposed convolutions, and why should we care about them?** One high-level intuition goes something like this: most of the generator's architecture is basically the discriminator architecture in reverse. We need something that performs the reverse of a convolution - not literally the inverse operation, but something reverse in spirit, which uses a kernel of weights to project up to some array of larger size.\n",
        "\n",
        "**Importantly, a transposed convolution isn't literally the inverse of a convolution**. A lot of confusion can come from misunderstanding this!\n",
        "\n",
        "You can describe the difference between convolutions and transposed convolutions as follows:\n",
        "\n",
        "* In convolutions, you slide the kernel around inside the input. At each position of the kernel, you take a sumproduct between the kernel and that section of the input to calculate a single element in the output.\n",
        "* In transposed convolutions, you slide the kernel around what will eventually be your output, and at each position you add some multiple of the kernel to your output.\n",
        "\n",
        "Below is an illustration of both for comparison, in the 1D case (where $*$ stands for the 1D convolution operator, and $*^T$ stands for the transposed convolution operator). Note the difference in size between the output in both cases. With standard convolutions, our output is smaller than our input, because we're having to fit the kernel inside the input in order to produce the output. But in our transposed convolutions, the output is actually larger than the input, because we're fitting the kernel inside the output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-1.png\" width=\"700\">\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Question - what do you think the formula is relating <code>input_size</code>, <code>kernel_size</code> and <code>output_size</code> in the case of 1D convolutions (with no padding or stride)?</summary>\n",
        "\n",
        "The formula is `output_size = input_size + kernel_size - 1`.\n",
        "        \n",
        "Note how this exactly mirrors the equation in the convolutional case; it's identical if we swap around `output_size` and `input_size`.\n",
        "</details>\n",
        "\n",
        "<br>\n",
        "\n",
        "Now, consider the elements in the output of the transposed convolution: `z+4y+3x, 4x+3y-2x`, etc. Note that these look a bit like convolutions, since they're inner products of slices of the input with versions of the kernel. This observation leads nicely into why transposed convolutions are called transposed convolutions - because they can actually be written as convolutions, just with a slightly modified input and kernel.\n",
        "\n",
        "<details>\n",
        "<summary>Question - how can this operation be cast as a convolution? In other words, exactly what arrays <code>input</code> and <code>kernel</code> would produce the same output as the transposed convolution above, if we performed a standard convolution on them?</summary>\n",
        "\n",
        "From looking at the diagram, note that the final output (the blue row at the bottom) looks a bit like sliding the _reversed_ kernel over the input. In other words, we get elements like `z+4y+3x` which are an inner product between the input slice `input[:3] = [1, 4, 3]` and the reversed kernel `[z, y, x]`. This suggests we should be using the reversed kernel in our convolution.\n",
        "\n",
        "Can we just use a reversed kernel on our original input and call it a day? No, because the output size wouldn't be correct. Using a reversed kernel on our original input would give us just the two elements `[z+4y+3x, 4z+3y-2x]`, not the full 6-element output we actually get. The answer is that we need to pad out our input with zeros on the left and right, with the padding amount equal to `kernel_size - 1`.\n",
        "\n",
        "To conclude - with `input_modified = pad(input, kernel_size-1)` and `kernel_modified = kernel[::-1]`, we get:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-2A.png\" width=\"850\">\n",
        "\n",
        "Note - it's also valid to say we use the original kernel and pad & flip the input, but for the exercises below we'll stick to the former interpretation.\n",
        "\n",
        "</details>\n",
        "\n",
        ">\n",
        "\n",
        "<!-- <details>\n",
        "<summary>Hint</summary>\n",
        "\n",
        "Let `input_mod` and `kernel_mod` be the modified versions of the input and kernel, to be used in the convolution.\n",
        "\n",
        "You should be able to guess what `kernel_mod` is by looking at the diagram.\n",
        "\n",
        "Also, from the formula for transposed convolutions, we must have:\n",
        "\n",
        "```\n",
        "output_size = input_mod_size + kernel_mod_size - 1\n",
        "```\n",
        "\n",
        "But we currently have:\n",
        "\n",
        "```\n",
        "output_size = input_size - kernel_size + 1\n",
        "```\n",
        "\n",
        "which should help you figure out what size `input_mod` needs to be, relative to `input`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Hint 2</summary>\n",
        "\n",
        "`kernel_mod` should be the same size as kernel (but altered in a particular way). `input_mod` should be formed by padding `input`, so that its size increases by `2 * (kernel_size - 1)`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "If you create `input_mod` by padding `input` with exactly `kernel_size - 1` zeros on either side, and reverse your kernel to create `kernel_mod`, then the convolution of these modified arrays equals your original transposed convolution output.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-2A.png\" width=\"850\">\n",
        "\n",
        "</details> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_x9Ustb6ejz"
      },
      "source": [
        "### Exercise - minimal 1D transposed convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-25 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Now, you should implement the function `conv_transpose1d_minimal`. You're allowed to call functions like `conv1d_minimal` and `pad1d` which you wrote previously (if you didn't do these exercises, then you can import the solution versions of them - although we do recommend doing the conv from scratch exercises before these ones).\n",
        "\n",
        "One important note - in our convolutions we assumed the kernel had shape `(out_channels, in_channels, kernel_width)`. Here, the order is different: `in_channels` comes before `out_channels`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCQkoWE16ejz"
      },
      "outputs": [],
      "source": [
        "def conv_transpose1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"in_channels out_channels kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"Like torch's conv_transpose1d using bias=False and all other keyword arguments left at their default values.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv_transpose1d_minimal(conv_transpose1d_minimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YgLcFRG6ejz"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv_transpose1d_minimal(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"in_channels out_channels kernel_width\"],\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"Like torch's conv_transpose1d using bias=False and all other keyword arguments left at their default values.\"\"\"\n",
        "    batch, in_channels, width = x.shape\n",
        "    in_channels_2, out_channels, kernel_width = weights.shape\n",
        "    assert in_channels == in_channels_2, \"in_channels for x and weights don't match up\"\n",
        "\n",
        "    x_mod = pad1d(x, left=kernel_width - 1, right=kernel_width - 1, pad_value=0)\n",
        "    weights_mod = einops.rearrange(weights.flip(-1), \"i o w -> o i w\")\n",
        "\n",
        "    return conv1d_minimal(x_mod, weights_mod)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shCi6bLl6ejz"
      },
      "source": [
        "### Exercise - 1D transposed convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴🔴\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 25-40 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Now we add in the extra parameters `padding` and `stride`, just like we did for our convolutions back in week 0.\n",
        "\n",
        "The basic idea is that both parameters mean the inverse of what they did in for convolutions.\n",
        "\n",
        "In convolutions, `padding` tells you how much to pad the input by. But in transposed convolutions, we pad the input by `kernel_size - 1 - padding` (recall that we're already padding by `kernel_size - 1` by default). So padding decreases our output size rather than increasing it.\n",
        "\n",
        "In convolutions, `stride` tells you how much to step the kernel by, as it's being moved around inside the input. In transposed convolutions, stride does something different: you space out all your input elements by an amount equal to `stride` before performing your transposed convolution. This might sound strange, but **it's actually equivalent to performing strides as you're moving the kernel around inside the output.** This diagram should help show why:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/convtranspose-3.png\" width=\"750\">\n",
        "\n",
        "For this reason, transposed convolutions are also referred to as **fractionally strided convolutions**, since a stride of 2 over the output is equivalent to a 1/2 stride over the input (i.e. every time the kernel takes two steps inside the spaced-out version of the input, it moves one stride with reference to the original input).\n",
        "\n",
        "**Question - what is the formula relating output size, input size, kernel size, stride and padding? (note, you shouldn't need to refer to this explicitly in your functions)**\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "Without any padding, we had:\n",
        "\n",
        "```\n",
        "output_size = input_size + kernel_size - 1\n",
        "```\n",
        "\n",
        "Twice the `padding` parameter gets subtracted from the RHS (since we pad by the same amount on each side), so this gives us:\n",
        "\n",
        "```\n",
        "output_size = input_size + kernel_size - 1 - 2 * padding\n",
        "```\n",
        "\n",
        "Finally, consider `stride`. As mentioned above, we can consider stride here to have the same effect as \"spacing out\" elements in the input. Each non-zero element will be `stride - 1` positions apart (for instance, `stride = 2` turns `[1, 2, 3]` into `[1, 0, 2, 0, 3]`). You can check that the number of zeros added between elements equals `(input_size - 1) * (stride - 1)`. When you add this to the right hand side, and simplify, you are left with:\n",
        "\n",
        "```\n",
        "output_size = (input_size - 1) * stride + kernel_size - 2 * padding\n",
        "```\n",
        "</details>\n",
        "\n",
        "Padding should be pretty easy for you to implement on top of what you've already done. For strides, you will need to construct a strided version of the input which is \"spaced out\" in the way described above, before performing the transposed convolution. It might help to write a `fractional_stride` function; we've provided the code for you to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1RGpGml6ejz"
      },
      "outputs": [],
      "source": [
        "def fractional_stride_1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], stride: int = 1\n",
        ") -> Float[Tensor, \"batch in_channels output_width\"]:\n",
        "    \"\"\"Returns a version of x suitable for transposed convolutions, i.e. \"spaced out\" with zeros between its values.\n",
        "    This spacing only happens along the last dimension.\n",
        "    x: shape (batch, in_channels, width)\n",
        "    Example:\n",
        "        x = [[[1, 2, 3], [4, 5, 6]]]\n",
        "        stride = 2\n",
        "        output = [[[1, 0, 2, 0, 3], [4, 0, 5, 0, 6]]]\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_fractional_stride_1d(fractional_stride_1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u-oWkVZ6ejz"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to implement <code>fractional_stride</code>.</summary>\n",
        "\n",
        "The easiest way is to initialise an array of zeros with the appropriate size, then slicing to set its elements from `x`.\n",
        "\n",
        "Warning - if you do it this way, **make sure the output has the same device as `x`**.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def fractional_stride_1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"], stride: int = 1\n",
        ") -> Float[Tensor, \"batch in_channels output_width\"]:\n",
        "    \"\"\"Returns a version of x suitable for transposed convolutions, i.e. \"spaced out\" with zeros between its values.\n",
        "    This spacing only happens along the last dimension.\n",
        "    x: shape (batch, in_channels, width)\n",
        "    Example:\n",
        "        x = [[[1, 2, 3], [4, 5, 6]]]\n",
        "        stride = 2\n",
        "        output = [[[1, 0, 2, 0, 3], [4, 0, 5, 0, 6]]]\n",
        "    \"\"\"\n",
        "    batch, in_channels, width = x.shape\n",
        "    width_new = width + (stride - 1) * (\n",
        "        width - 1\n",
        "    )  # the RHS of this sum is the number of zeros we need to add between elements\n",
        "    x_new_shape = (batch, in_channels, width_new)\n",
        "\n",
        "    # Create an empty array to store the spaced version of x in.\n",
        "    x_new = t.zeros(size=x_new_shape, dtype=x.dtype, device=x.device)\n",
        "\n",
        "    x_new[..., ::stride] = x\n",
        "\n",
        "    return x_new\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bChC55DZ6ejz"
      },
      "outputs": [],
      "source": [
        "def conv_transpose1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"in_channels out_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"Like torch's conv_transpose1d using bias=False and all other keyword arguments left at their default values.\"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_conv_transpose1d(conv_transpose1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuSyxBEh6ejz"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to implement <code>conv_transpose1d</code>.</summary>\n",
        "\n",
        "There are three things you need to do:\n",
        "\n",
        "* Modify `x` by \"spacing it out\" with `fractional_stride_1d` and padding it the appropriate amount\n",
        "* Modify `weights` (just like you did for `conv_transpose1d_minimal`)\n",
        "* Use `conv1d_minimal` on your modified `x` and `weights` (just like you did for `conv_transpose1d_minimal`)\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def conv_transpose1d(\n",
        "    x: Float[Tensor, \"batch in_channels width\"],\n",
        "    weights: Float[Tensor, \"in_channels out_channels kernel_width\"],\n",
        "    stride: int = 1,\n",
        "    padding: int = 0,\n",
        ") -> Float[Tensor, \"batch out_channels output_width\"]:\n",
        "    \"\"\"Like torch's conv_transpose1d using bias=False and all other keyword arguments left at their default values.\"\"\"\n",
        "    batch, ic, width = x.shape\n",
        "    ic_2, oc, kernel_width = weights.shape\n",
        "    assert ic == ic_2, f\"in_channels for x and weights don't match up. Shapes are {x.shape}, {weights.shape}.\"\n",
        "\n",
        "    # Apply spacing\n",
        "    x_spaced_out = fractional_stride_1d(x, stride)\n",
        "\n",
        "    # Apply modification (which is controlled by the padding parameter)\n",
        "    padding_amount = kernel_width - 1 - padding\n",
        "    assert padding_amount >= 0, \"total amount padded should be positive\"\n",
        "    x_mod = pad1d(x_spaced_out, left=padding_amount, right=padding_amount, pad_value=0)\n",
        "\n",
        "    # Modify weights, then return the convolution\n",
        "    weights_mod = einops.rearrange(weights.flip(-1), \"i o w -> o i w\")\n",
        "\n",
        "    return conv1d_minimal(x_mod, weights_mod)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpE_-pW76ejz"
      },
      "source": [
        "Another fun fact about transposed convolutions - they are also called **backwards strided convolutions**, because they are equivalent to taking the gradient of Conv2d with respect to its output. As an optional bonus, can you formally prove this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EaH7uif6ejz"
      },
      "source": [
        "### Exercise - 2D transposed convolutions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Finally, we get to 2D transposed convolutions! Since there's no big conceptual difference between this and the 1D case, we'll jump straight to implementing the full version of these convolutions, with padding and strides. A few notes:\n",
        "\n",
        "* You'll need to make `fractional_stride_2d`, which performs spacing along the last two dimensions rather than just the last dimension.\n",
        "* Defining the modified version of your kernel will involve reversing on more than one dimension. You'll still need to perform the same rearrangement flipping the output and input channel dimensions though.\n",
        "* You can use the `force_pair` function from earlier this week (it's been imported for you, as have the `Pair` and `IntOrPair` types)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYoLsk5c6ejz"
      },
      "outputs": [],
      "source": [
        "def fractional_stride_2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"], stride_h: int, stride_w: int\n",
        ") -> Float[Tensor, \"batch in_channels output_height output_width\"]:\n",
        "    \"\"\"\n",
        "    Same as fractional_stride_1d, except we apply it along the last 2 dims of x (height and width).\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def conv_transpose2d(x, weights, stride: IntOrPair = 1, padding: IntOrPair = 0) -> Tensor:\n",
        "    \"\"\"Like torch's conv_transpose2d using bias=False\n",
        "    x: shape (batch, in_channels, height, width)\n",
        "    weights: shape (out_channels, in_channels, kernel_height, kernel_width)\n",
        "    Returns: shape (batch, out_channels, output_height, output_width)\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_fractional_stride_2d(fractional_stride_2d)\n",
        "tests.test_conv_transpose2d(conv_transpose2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1ONhY0A6ejz"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def fractional_stride_2d(\n",
        "    x: Float[Tensor, \"batch in_channels height width\"], stride_h: int, stride_w: int\n",
        ") -> Float[Tensor, \"batch in_channels output_height output_width\"]:\n",
        "    \"\"\"\n",
        "    Same as fractional_stride_1d, except we apply it along the last 2 dims of x (height and width).\n",
        "    \"\"\"\n",
        "    batch, in_channels, height, width = x.shape\n",
        "    width_new = width + (stride_w - 1) * (width - 1)\n",
        "    height_new = height + (stride_h - 1) * (height - 1)\n",
        "    x_new_shape = (batch, in_channels, height_new, width_new)\n",
        "\n",
        "    # Create an empty array to store the spaced version of x in.\n",
        "    x_new = t.zeros(size=x_new_shape, dtype=x.dtype, device=x.device)\n",
        "\n",
        "    x_new[..., ::stride_h, ::stride_w] = x\n",
        "\n",
        "    return x_new\n",
        "\n",
        "\n",
        "def conv_transpose2d(x, weights, stride: IntOrPair = 1, padding: IntOrPair = 0) -> Tensor:\n",
        "    \"\"\"Like torch's conv_transpose2d using bias=False\n",
        "    x: shape (batch, in_channels, height, width)\n",
        "    weights: shape (out_channels, in_channels, kernel_height, kernel_width)\n",
        "    Returns: shape (batch, out_channels, output_height, output_width)\n",
        "    \"\"\"\n",
        "    stride_h, stride_w = force_pair(stride)\n",
        "    padding_h, padding_w = force_pair(padding)\n",
        "\n",
        "    batch, ic, height, width = x.shape\n",
        "    ic_2, oc, kernel_height, kernel_width = weights.shape\n",
        "    assert ic == ic_2, f\"in_channels for x and weights don't match up. Shapes are {x.shape}, {weights.shape}.\"\n",
        "\n",
        "    # Apply spacing\n",
        "    x_spaced_out = fractional_stride_2d(x, stride_h, stride_w)\n",
        "\n",
        "    # Apply modification (which is controlled by the padding parameter)\n",
        "    pad_h_actual = kernel_height - 1 - padding_h\n",
        "    pad_w_actual = kernel_width - 1 - padding_w\n",
        "    assert min(pad_h_actual, pad_w_actual) >= 0, \"total amount padded should be positive\"\n",
        "    x_mod = pad2d(\n",
        "        x_spaced_out, left=pad_w_actual, right=pad_w_actual, top=pad_h_actual, bottom=pad_h_actual, pad_value=0\n",
        "    )\n",
        "\n",
        "    # Modify weights\n",
        "    weights_mod = einops.rearrange(weights.flip(-1, -2), \"i o h w -> o i h w\")\n",
        "\n",
        "    # Return the convolution\n",
        "    return conv2d_minimal(x_mod, weights_mod)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BenR8gvF6ejz"
      },
      "source": [
        "### Exercise - transposed conv module\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Now that you've written a function to calculate the convolutional transpose, you should implement it as a module just like you've done for `Conv2d` previously. Your weights should be initialised with the uniform distribution `Unif[-sqrt(k), sqrt(k)]` where `k = 1 / (out_channels * kernel_width * kernel_height)` (this is PyTorch's standard behaviour for convolutional transpose layers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cth-Ojp6ejz"
      },
      "outputs": [],
      "source": [
        "class ConvTranspose2d(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, kernel_size: IntOrPair, stride: IntOrPair = 1, padding: IntOrPair = 0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.ConvTranspose2d with bias=False.\n",
        "        Name your weight field `self.weight` for compatibility with the tests.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = force_pair(kernel_size)\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(\n",
        "        self, x: Float[Tensor, \"batch in_channels height width\"]\n",
        "    ) -> Float[Tensor, \"batch out_channels output_height output_width\"]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "\n",
        "\n",
        "tests.test_ConvTranspose2d(ConvTranspose2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaMTOiOg6ejz"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class ConvTranspose2d(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, kernel_size: IntOrPair, stride: IntOrPair = 1, padding: IntOrPair = 0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Same as torch.nn.ConvTranspose2d with bias=False.\n",
        "        Name your weight field `self.weight` for compatibility with the tests.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = force_pair(kernel_size)\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        sf = 1 / (self.out_channels * self.kernel_size[0] * self.kernel_size[1]) ** 0.5\n",
        "        self.weight = nn.Parameter(sf * (2 * t.rand(in_channels, out_channels, *self.kernel_size) - 1))\n",
        "\n",
        "    def forward(\n",
        "        self, x: Float[Tensor, \"batch in_channels height width\"]\n",
        "    ) -> Float[Tensor, \"batch out_channels output_height output_width\"]:\n",
        "        return conv_transpose2d(x, self.weight, self.stride, self.padding)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        keys = [\"in_channels\", \"out_channels\", \"kernel_size\", \"stride\", \"padding\"]\n",
        "        return \", \".join([f\"{key}={getattr(self, key)}\" for key in keys])\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGaQwdA56ejz"
      },
      "source": [
        "Now, you're all done! You can go back and implement GANs or VAEs using the transposed convolution module you've just written."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}